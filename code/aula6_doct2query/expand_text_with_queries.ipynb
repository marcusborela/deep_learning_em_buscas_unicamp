{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula6 - Doc2Query\n",
    "\n",
    "[Unicamp - IA368DD: Deep Learning aplicado a sistemas de busca.](https://www.cpg.feec.unicamp.br/cpg/lista/caderno_horario_show.php?id=1779)\n",
    "\n",
    "Autor: Marcus Vinícius Borela de Castro\n",
    "\n",
    "[Repositório no github](https://github.com/marcusborela/deep_learning_em_buscas_unicamp)\n",
    "\n",
    "Stage: expanding texts with queries generated by finetuned t5-base doc2query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmRLgbyi_Dvg"
   },
   "source": [
    "# Organizando o ambiente"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRETORIO_TRABALHO = '/home/borela/fontes/deep_learning_em_buscas_unicamp/local/doc2query'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(DIRETORIO_TRABALHO), f\"Path para {DIRETORIO_TRABALHO} não existe!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DKAZ8CWCAM3-"
   },
   "outputs": [],
   "source": [
    "from psutil import virtual_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9XgIWvkkH-kn"
   },
   "outputs": [],
   "source": [
    "def mostra_memoria(lista_mem=['cpu']):\n",
    "  \"\"\"\n",
    "  Esta função exibe informações de memória da CPU e/ou GPU, conforme parâmetros fornecidos.\n",
    "\n",
    "  Parâmetros:\n",
    "  -----------\n",
    "  lista_mem : list, opcional\n",
    "      Lista com strings 'cpu' e/ou 'gpu'. \n",
    "      'cpu' - exibe informações de memória da CPU.\n",
    "      'gpu' - exibe informações de memória da GPU (se disponível).\n",
    "      O valor padrão é ['cpu'].\n",
    "\n",
    "  Saída:\n",
    "  -------\n",
    "  A função não retorna nada, apenas exibe as informações na tela.\n",
    "\n",
    "  Exemplo de uso:\n",
    "  ---------------\n",
    "  Para exibir informações de memória da CPU:\n",
    "      mostra_memoria(['cpu'])\n",
    "\n",
    "  Para exibir informações de memória da CPU e GPU:\n",
    "      mostra_memoria(['cpu', 'gpu'])\n",
    "  \n",
    "  Autor: Marcus Vinícius Borela de Castro\n",
    "\n",
    "  \"\"\"  \n",
    "  if 'cpu' in lista_mem:\n",
    "    vm = virtual_memory()\n",
    "    ram={}\n",
    "    ram['total']=round(vm.total / 1e9,2)\n",
    "    ram['available']=round(virtual_memory().available / 1e9,2)\n",
    "    # ram['percent']=round(virtual_memory().percent / 1e9,2)\n",
    "    ram['used']=round(virtual_memory().used / 1e9,2)\n",
    "    ram['free']=round(virtual_memory().free / 1e9,2)\n",
    "    ram['active']=round(virtual_memory().active / 1e9,2)\n",
    "    ram['inactive']=round(virtual_memory().inactive / 1e9,2)\n",
    "    ram['buffers']=round(virtual_memory().buffers / 1e9,2)\n",
    "    ram['cached']=round(virtual_memory().cached/1e9 ,2)\n",
    "    print(f\"Your runtime RAM in gb: \\n total {ram['total']}\\n available {ram['available']}\\n used {ram['used']}\\n free {ram['free']}\\n cached {ram['cached']}\\n buffers {ram['buffers']}\")\n",
    "    print('/nGPU')\n",
    "    gpu_info = !nvidia-smi\n",
    "  if 'gpu' in lista_mem:\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "    if gpu_info.find('failed') >= 0:\n",
    "      print('Not connected to a GPU')\n",
    "    else:\n",
    "      print(gpu_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dri9iiMAvCT",
    "outputId": "53aebd5a-e29f-4c8e-d233-5221aae9f9b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime RAM in gb: \n",
      " total 67.35\n",
      " available 54.03\n",
      " used 12.15\n",
      " free 8.57\n",
      " cached 44.61\n",
      " buffers 2.02\n",
      "/nGPU\n",
      "Mon Apr 10 22:37:11 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 87%   74C    P2   219W / 370W |  15033MiB / 24576MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1241      G   /usr/lib/xorg/Xorg                 45MiB |\n",
      "|    0   N/A  N/A      1381      G   /usr/bin/gnome-shell               14MiB |\n",
      "|    0   N/A  N/A    171944      C   ...treinapython39/bin/python    14969MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "mostra_memoria(['cpu','gpu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "achvQ78sa3p3"
   },
   "source": [
    "## Fixando as seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AG9RjMb8Qlot"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bkETIyWGkbOf"
   },
   "outputs": [],
   "source": [
    "def inicializa_seed(num_semente:int=123):\n",
    "  \"\"\"\n",
    "  Inicializa as sementes para garantir a reprodutibilidade dos resultados do modelo.\n",
    "  Essa é uma prática recomendada, já que a geração de números aleatórios pode influenciar os resultados do modelo.\n",
    "  Além disso, a função também configura as sementes da GPU para garantir a reprodutibilidade quando se utiliza aceleração por GPU. \n",
    "  \n",
    "  Args:\n",
    "      num_semente (int): número da semente a ser utilizada para inicializar as sementes das bibliotecas.\n",
    "  \n",
    "  References:\n",
    "      http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "      https://github.com/CyberZHG/torch-multi-head-attention/blob/master/torch_multi_head_attention/multi_head_attention.py#L15\n",
    "  \"\"\"\n",
    "  # Define as sementes das bibliotecas random, numpy e pytorch\n",
    "  random.seed(num_semente)\n",
    "  np.random.seed(num_semente)\n",
    "  torch.manual_seed(num_semente)\n",
    "  \n",
    "  # Define as sementes da GPU\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "\n",
    "  #torch.cuda.manual_seed(num_semente)\n",
    "  #Cuda algorithms\n",
    "  #torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ViMcw_kVkbOf"
   },
   "outputs": [],
   "source": [
    "num_semente=123\n",
    "inicializa_seed(num_semente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8v2gtkEPhA0t"
   },
   "source": [
    "## Preparando para debug e display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BJ6S4P5Hw4iG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kebsl1uQDFUf",
    "outputId": "4b1ed269-722b-4a2a-f1a0-908d1683cc62"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rnR2kDS_2FgZ"
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LjrlXHq1hC8n",
    "outputId": "18d94254-4bf8-4632-ef84-012727944746"
   },
   "outputs": [],
   "source": [
    "# https://zohaib.me/debugging-in-google-collab-notebook/\n",
    "# !pip install -Uqq ipdb\n",
    "import ipdb\n",
    "# %pdb off # desativa debug em exceção\n",
    "# %pdb on  # ativa debug em exceção\n",
    "# ipdb.set_trace(context=8)  para execução nesse ponto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wQ5pmlOHxHhk"
   },
   "outputs": [],
   "source": [
    "def config_display():\n",
    "  \"\"\"\n",
    "  Esta função configura as opções de display do Pandas.\n",
    "  \"\"\"\n",
    "\n",
    "  # Configurando formato saída Pandas\n",
    "  # define o número máximo de colunas que serão exibidas\n",
    "  pd.options.display.max_columns = None\n",
    "\n",
    "  # define a largura máxima de uma linha\n",
    "  pd.options.display.width = 1000\n",
    "\n",
    "  # define o número máximo de linhas que serão exibidas\n",
    "  pd.options.display.max_rows = 100\n",
    "\n",
    "  # define o número máximo de caracteres por coluna\n",
    "  pd.options.display.max_colwidth = 50\n",
    "\n",
    "  # se deve exibir o número de linhas e colunas de um DataFrame.\n",
    "  pd.options.display.show_dimensions = True\n",
    "\n",
    "  # número de dígitos após a vírgula decimal a serem exibidos para floats.\n",
    "  pd.options.display.precision = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "b2tDy72ATNHs"
   },
   "outputs": [],
   "source": [
    "def config_debug():\n",
    "  \"\"\"\n",
    "  Esta função configura as opções de debug do PyTorch e dos pacotes\n",
    "  transformers e datasets.\n",
    "  \"\"\"\n",
    "\n",
    "  # Define opções de impressão de tensores para o modo científico\n",
    "  torch.set_printoptions(sci_mode=True) \n",
    "  \"\"\"\n",
    "    Significa que valores muito grandes ou muito pequenos são mostrados em notação científica.\n",
    "    Por exemplo, em vez de imprimir o número 0.0000012345 como 0.0000012345, \n",
    "    ele seria impresso como 1.2345e-06. Isso é útil em situações em que os valores dos tensores \n",
    "    envolvidos nas operações são muito grandes ou pequenos, e a notação científica permite \n",
    "    uma melhor compreensão dos números envolvidos.  \n",
    "  \"\"\"\n",
    "\n",
    "  # Habilita detecção de anomalias no autograd do PyTorch\n",
    "  torch.autograd.set_detect_anomaly(True)\n",
    "  \"\"\"\n",
    "    Permite identificar operações que podem causar problemas de estabilidade numérica, \n",
    "    como gradientes explodindo ou desaparecendo. Quando essa opção é ativada, \n",
    "    o PyTorch verifica se há operações que geram valores NaN ou infinitos nos tensores \n",
    "    envolvidos no cálculo do gradiente. Se for detectado um valor anômalo, o PyTorch \n",
    "    interrompe a execução e gera uma exceção, permitindo que o erro seja corrigido \n",
    "    antes que se torne um problema maior.\n",
    "\n",
    "    É importante notar que a detecção de anomalias pode ter um impacto significativo \n",
    "    no desempenho, especialmente em modelos grandes e complexos. Por esse motivo,\n",
    "    ela deve ser usada com cautela e apenas para depuração.\n",
    "  \"\"\"\n",
    "\n",
    "  # Configura variável de ambiente para habilitar a execução síncrona (bloqueante) das chamadas da API do CUDA.\n",
    "  os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "  \"\"\"\n",
    "    o Python aguarda o término da execução de uma chamada da API do CUDA antes de executar a próxima chamada. \n",
    "    Isso é útil para depurar erros no código que envolve operações na GPU, pois permite que o erro seja capturado \n",
    "    no momento em que ocorre, e não depois de uma sequência de operações que pode tornar a origem do erro mais difícil de determinar.\n",
    "    No entanto, é importante lembrar que esse modo de execução é significativamente mais lento do que a execução assíncrona, \n",
    "    que é o comportamento padrão do CUDA. Por isso, é recomendado utilizar esse comando apenas em situações de depuração \n",
    "    e removê-lo após a solução do problema.\n",
    "  \"\"\"\n",
    "\n",
    "  # Define o nível de verbosity do pacote transformers para info\n",
    "  # transformers.utils.logging.set_verbosity_info() \n",
    "  \n",
    "  \n",
    "  \"\"\"\n",
    "    Define o nível de detalhamento das mensagens de log geradas pela biblioteca Hugging Face Transformers \n",
    "    para o nível info. Isso significa que a biblioteca irá imprimir mensagens de log informativas sobre\n",
    "    o andamento da execução, tais como tempo de execução, tamanho de batches, etc.\n",
    "\n",
    "    Essas informações podem ser úteis para entender o que está acontecendo durante a execução da tarefa \n",
    "    e auxiliar no processo de debug. É importante notar que, em alguns casos, a quantidade de informações\n",
    "    geradas pode ser muito grande, o que pode afetar o desempenho do sistema e dificultar a visualização\n",
    "    das informações relevantes. Por isso, é importante ajustar o nível de detalhamento de acordo com a \n",
    "    necessidade de cada tarefa.\n",
    "  \n",
    "    Caso queira reduzir a quantidade de mensagens, comentar a linha acima e \n",
    "      descomentar as duas linhas abaixo, para definir o nível de verbosity como error ou warning\n",
    "  \n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_warning()\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  # Define o modo verbose do xmode, que é utilizado no debug\n",
    "  # %xmode Verbose \n",
    "\n",
    "  \"\"\"\n",
    "    Comando usado no Jupyter Notebook para controlar o modo de exibição das informações de exceções.\n",
    "    O modo verbose é um modo detalhado que exibe informações adicionais ao imprimir as exceções.\n",
    "    Ele inclui as informações de pilha de chamadas completa e valores de variáveis locais e globais \n",
    "    no momento da exceção. Isso pode ser útil para depurar e encontrar a causa de exceções em seu código.\n",
    "    Ao usar %xmode Verbose, as informações de exceção serão impressas com mais detalhes e informações adicionais serão incluídas.\n",
    "\n",
    "    Caso queira desabilitar o modo verbose e utilizar o modo plain, \n",
    "    comentar a linha acima e descomentar a linha abaixo:\n",
    "    %xmode Plain\n",
    "  \"\"\"\n",
    "\n",
    "  \"\"\"\n",
    "    Dica:\n",
    "    1.  pdb (Python Debugger)\n",
    "      Quando ocorre uma exceção em uma parte do código, o programa para a execução e exibe uma mensagem de erro \n",
    "      com informações sobre a exceção, como a linha do código em que ocorreu o erro e o tipo da exceção.\n",
    "\n",
    "      Se você estiver depurando o código e quiser examinar o estado das variáveis ​​e executar outras operações \n",
    "      no momento em que a exceção ocorreu, pode usar o pdb (Python Debugger). Para isso, é preciso colocar o comando %debug \n",
    "      logo após ocorrer a exceção. Isso fará com que o programa pare na linha em que ocorreu a exceção e abra o pdb,\n",
    "      permitindo que você explore o estado das variáveis, examine a pilha de chamadas e execute outras operações para depurar o código.\n",
    "\n",
    "\n",
    "    2. ipdb\n",
    "      O ipdb é um depurador interativo para o Python que oferece recursos mais avançados do que o pdb,\n",
    "      incluindo a capacidade de navegar pelo código fonte enquanto depura.\n",
    "      \n",
    "      Você pode começar a depurar seu código inserindo o comando ipdb.set_trace() em qualquer lugar do \n",
    "      seu código onde deseja pausar a execução e começar a depurar. Quando a execução chegar nessa linha, \n",
    "      o depurador entrará em ação, permitindo que você examine o estado atual do seu programa e execute \n",
    "      comandos para investigar o comportamento.\n",
    "\n",
    "      Durante a depuração, você pode usar comandos:\n",
    "        next (para executar a próxima linha de código), \n",
    "        step (para entrar em uma função chamada na próxima linha de código) \n",
    "        continue (para continuar a execução normalmente até o próximo ponto de interrupção).\n",
    "\n",
    "      Ao contrário do pdb, o ipdb é um depurador interativo que permite navegar pelo código fonte em que\n",
    "      está trabalhando enquanto depura, permitindo que você inspecione variáveis, defina pontos de interrupção\n",
    "      adicionais e até mesmo execute expressões Python no contexto do seu programa.\n",
    "  \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Tb4aqtcExR84"
   },
   "outputs": [],
   "source": [
    "config_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5Bq4043fkfh",
    "outputId": "fa8e5db1-1feb-4393-fb66-d394d1ad693c"
   },
   "outputs": [],
   "source": [
    "config_debug()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentações"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando geração de perguntas com o modelo treinado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicas em https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb#scrollTo=AZ6xs-KLi9jT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borela/miniconda3/envs/treinamento/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(f'{DIRETORIO_TRABALHO}/base-checkpoint-2340 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Python is an interpreted, high-level and general-purpose programming language.Python's design philosophy emphasizes code readability with its notable use of significant whitespace.Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Python is an interpreted, high-level and general-purpose programming language.\"\n",
    "text += \"Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\"\n",
    "text += \"Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.\"\n",
    "\n",
    "\n",
    "input_ids = tokenizer.encode(text, max_length=320, truncation=True, return_tensors='pt')\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=64,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=5)\n",
    "\n",
    "print(f\"Text: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Queries:\n",
      "1: what is python design philosophy\n",
      "2: what is python design philosophy\n",
      "3: what is python design philosophy\n",
      "4: what is python design philosophy\n",
      "5: what is python design philosophy\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerated Queries:\")\n",
    "for i in range(len(outputs)):\n",
    "    query = tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
    "    print(f'{i + 1}: {query}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentando pipeline text2text-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646574012f154c8c9611b812ddf22994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borela/miniconda3/envs/treinamento/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5_fast.py:165: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text2text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Python is a programming language that is interpreted, high-level and general-purpose'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Queries:\n",
      "1: Python is a programming language that is interpreted, high-level and general-purpose\n",
      "2: Python is a programming language that is interpreted, high-level and general-purpose\n",
      "3: Python is a programming language that is interpreted, high-level and general-purpose\n",
      "4: Python is a programming language that is interpreted, high-level and general-purpose\n",
      "5: Python is a programming language that is interpreted, high-level and general-purpose\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerated Queries:\")\n",
    "for i in range(5):\n",
    "    saida  = pipe(text, return_tensors=False, temperature=0, top_p=0.5, top_k=50)[0]['generated_text']\n",
    "    print(f'{i + 1}: {saida }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### num_beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: Python is a high-level and general-purpose programming language.\n",
      "Sentença 2: Python is a high-level and general-purpose programming language. written in Python\n",
      "Sentença 3: Python is a high-level, high-level and general-purpose programming language.\n",
      "Sentença 4: Python is a high-level and general-purpose programming language.\n",
      "Sentença 5: Python is a high-level, high-level and general-purpose programming language.\n"
     ]
    }
   ],
   "source": [
    "# Gere 5 sentenças\n",
    "num_sentences = 5\n",
    "for i in range(num_sentences):\n",
    "    sentence = pipe(text, do_sample=True, num_beams=5, early_stopping=False)[0]['generated_text']\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: Python is an interpreted, high-level and general-purpose programming language\n",
      "Sentença 2: Python is a high-level and general-purpose programming language. written in Python\n",
      "Sentença 3: Python is a high-level and general-purpose programming language.\n",
      "Sentença 4: Python is a high-level and general-purpose programming language.\n",
      "Sentença 5: Python is a programming language that aims to help programmers write clear, logical\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 5\n",
    "for i in range(num_sentences):\n",
    "    sentence = pipe(text, do_sample=True, num_beams=5, early_stopping=False, no_repeat_ngram_size=2)[0]['generated_text']\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = pipe(text, do_sample=True, num_beams=6, early_stopping=False, num_return_sequences=5, no_repeat_ngram_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Python is an interpreted, high-level and general-purpose programming language'},\n",
       " {'generated_text': 'Python is an interpretive, high-level and general-purpose programming language'},\n",
       " {'generated_text': 'Python is an interpreted, high-level and general-purpose programming language. '},\n",
       " {'generated_text': 'Python is an interpretable, high-level and general-purpose programming language'},\n",
       " {'generated_text': 'Python is a high-level and general-purpose programming language. written in Python'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: Python is an interpreted, high-level and general-purpose programming language\n",
      "Sentença 2: Python is an interpretive, high-level and general-purpose programming language\n",
      "Sentença 3: Python is an interpreted, high-level and general-purpose programming language. \n",
      "Sentença 4: Python is an interpretable, high-level and general-purpose programming language\n",
      "Sentença 5: Python is a high-level and general-purpose programming language. written in Python\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: , a purported language for general purpose language programming.. used for basic\n",
      "Sentença 2: .Information-oriented programming is crucial to this new concept. a language with\n",
      "Sentença 3: Python is a development language aimed at designing people's worklife and computing strategies\n",
      "Sentença 4: written in high-level programming languages. it is interpreted, high level programming language\n",
      "Sentença 5: and widely used programming language, primarily for advanced advanced projects. A logical studio\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = pipe(text, do_sample=True, top_k=0, num_return_sequences=5, no_repeat_ngram_size=2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: Python is a programming language for large-scale projects. syntax has\n",
      "Sentença 2: it is primarily a low-level and general-purpose programming language. written\n",
      "Sentença 3: a global language that is widely used used for low level tasks. a powerful\n",
      "Sentença 4: Python was developed in the 1990s, and is still used today. language.\n",
      "Sentença 5: The Python language is a highly interpreted, high-level and general-purpose programming\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, do_sample=True, top_k=0, temperature=0.7, num_return_sequences=5, no_repeat_ngram_size=2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: The language is well-designed, high-level and general-purpose..\n",
      "Sentença 2: is a programming language that is interpreted, high-level and general-purpose.\n",
      "Sentença 3: Python is an interpretable, high-level and general-purpose programming language. designed\n",
      "Sentença 4: Its intended to be interpreted, high-level and general-purpose programming language.\n",
      "Sentença 5: the accepted language for high-level and general-purpose programming. has been around since\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, do_sample=True, top_k=0, temperature=0.7, num_return_sequences=5)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-K Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: ., high-level and general-purpose programming language.a simple programming language\n",
      "Sentença 2: is a high-level and general purpose programming language the programming language used to create\n",
      "Sentença 3: A. A. a strong design philosophy and general-purpose programming language.\n",
      "Sentença 4: Python (pronounced 'py') is a programming language \n",
      "Sentença 5: Python is an interpreted programming language and general-purpose language. a programming language\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=50, do_sample=True,  num_return_sequences=5)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: . language aimed at programming. is a programming language intended for small\n",
      "Sentença 2: Python is a written, high-level, and general-purpose programming\n",
      "Sentença 3: py is a programming language that works for various applications. is an interpreted\n",
      "Sentença 4: This program is designed especially for user and business developers. application programming language is \n",
      "Sentença 5: The Python language is interpreted, high-level and general-purpose programming language language\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=50, do_sample=True,  num_return_sequences=5)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: a distributed language for general-purpose applications. is an interpreted, high-level\n",
      "Sentença 2: is a broader programming language, primarily used for higher-level and larger projects\n",
      "Sentença 3: , written and distributed with minimal documentation. a high-level and general purpose programming\n",
      "Sentença 4: it is not just a functional language.. in general use.,\n",
      "Sentença 5: is a general-purpose programming language. an interpretive programming language that is extremely\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "sentences = pipe(text, top_k=50, do_sample=True,  num_return_sequences=5)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: a programming language developed by Apple Inc., an American, based in London,\n",
      "Sentença 2: Python (plugins), a high level programable language, is \n",
      "Sentença 3: Python is a high-level, general-purpose programming language. a high\n",
      "Sentença 4: Python is a highly-interpreted, high-level programming language. a common\n",
      "Sentença 5: , high-level and general-purpose programming language. an interpretive, high-\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=50, do_sample=True,  num_return_sequences=5)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: written and used using Python to write complex and logical programs.. intended to\n",
      "Sentença 2: Python is an interpretable, high-level and general-purpose programming language. widely\n",
      "Sentença 3: In which it is intended to build and interpret programs, Python is the preferred programming language for\n",
      "Sentença 4: It's design philosophy emphasizes code readability with its notable use of significant whitespace\n",
      "Sentença 5: . a specialized programming language and object-oriented programming style.,\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=50, do_sample=True,  num_return_sequences=5, no_repeat_ngram_size=2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-p (nucleus) sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: Python is designed to run Python code and is an editor that works with Python.\n",
      "Sentença 2: By default, Python is an interpreted, high-level and general-purpose programming\n",
      "Sentença 3: Written by C++++, employed by professional developers in many fields and fields.\n",
      "Sentença 4: Python. A programming language for general-purpose and non-interpretable tasks\n",
      "Sentença 5: PLY is an interpretive, high-level and general-purpose programming language.\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=0, top_p=0.92, do_sample=True,  num_return_sequences=5, no_repeat_ngram_size=2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: it's design philosophy emphasizes code readability with its notable use of significant whitespace\n",
      "Sentença 2: Its design philosophy emphasizes code readability with its notable use of significant whitespace.\n",
      "Sentença 3: is a high-level programming language. general-purpose, high level and\n",
      "Sentença 4: Python is a high-level programming language . is generally used in high level\n",
      "Sentença 5: a high-level and general-purpose programming language. a general purpose Python language\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=50, top_p=0.92, do_sample=True,  num_return_sequences=5, no_repeat_ngram_size=2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: is a high-level programming language.'s design philosophy emphasizes code read\n",
      "Sentença 2: .Python is a programming language for computer systems, machines and general-\n",
      "Sentença 3: programming software developed primarily for non-technical uses. language that includes many\n",
      "Sentença 4: Python is a programming language intended to help programmers write clear, \n",
      "Sentença 5: , the most widely used programming language in the world. for all kinds of programming applications\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=50, top_p=0.92, do_sample=True, min_length=20, num_return_sequences=5, repetition_penalty=1.2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: Python is a programming language that has been compiled to fast, robust\n",
      "Sentença 2: The Python language is named after Gary Perry and his wife, Ashley. a widely\n",
      "Sentença 3: it is an interpretable language intended for high-level programminggeneral-purpose programming\n",
      "Sentença 4: includes several modules. written in high-level, high encoding\n",
      "Sentença 5: Python is an interpreted programming language. usually aimed at beginners. a\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=0, top_p=0.95, do_sample=True,  num_return_sequences=5, no_repeat_ngram_size=2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: is a programming language that aims to help programmers write clear and logical code\n",
      "Sentença 2: py and a general-purpose programming language.4.python\n",
      "Sentença 3: it is considered an languages library. a programming language. and intended for general\n",
      "Sentença 4: .Python is a programming language for the general user and intermediate level development\n",
      "Sentença 5: available for unix,  primarily used for high-level programmers general\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=0, top_p=0.95, do_sample=True,  num_return_sequences=5, repetition_penalty=1.2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: By default code is a text buffer., high-level and general purpose\n",
      "Sentença 2: The Python language aims to improve your project code. interpreted, high-level\n",
      "Sentença 3: Python was a programming language from the 1960s-80s, a style for\n",
      "Sentença 4: It is a programming language that emphasizes code readability with significant whitespace.\n",
      "Sentença 5: it is a low-level programming language. a high-level, general\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=50, top_p=0.95, do_sample=True,  num_return_sequences=5, repetition_penalty=1.2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentença 1: Python is a programming language for general-purpose projects. designed to help programmers\n",
      "Sentença 2: . a well-known and widely used programming language that is interpreted,\n",
      "Sentença 3: Python is a high-level and general-purpose programming language.\n",
      "Sentença 4: a programming language designed to improve code readability and code reuse., high-\n",
      "Sentença 5: The Python programming language is interpreted, high-level and general-purpose programming language.\n"
     ]
    }
   ],
   "source": [
    "sentences = pipe(text, top_k=50, top_p=0.95, temperature=0.8, do_sample=True,  num_return_sequences=5, repetition_penalty=1.2)\n",
    "for i, sentence in enumerate([x['generated_text'] for x in sentences]):\n",
    "    print(\"Sentença \" + str(i + 1) + \": \" + sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão: Achei que as frases geradas com top-p=0.95, top_k=50 e do_sample, com  repetition_penalty foram melhores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentando chamar o pipeline com batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de strings\n",
    "lista_texto = [\n",
    "    \"Example 1: This is an example of a text with more than 20 words for testing.\",\n",
    "    \"Example 2: Here is another example of a text with more than 20 words for validation.\",\n",
    "    \"Example 3: This is a third example of a text with more than 20 words for verification.\",\n",
    "    \"Example 4: Another example of a text with more than 20 words for analysis.\",\n",
    "    \"Example 5: Sample text with more than 20 words for evaluation.\",\n",
    "    \"Example 6: Example of a text with more than 20 words for use.\",\n",
    "    \"Example 7: Test text with more than 20 words for demonstration.\",\n",
    "    \"Example 8: Example of a long text with more than 20 words for experimentation.\",\n",
    "    \"Example 9: Sample text with more than 20 words for comparison.\",\n",
    "    \"Example 10: Example of a text with more than 20 words for reference.\",\n",
    "    \"Example 11: Test text with more than 20 words for illustrative purposes.\",\n",
    "    \"Example 12: Example of a text with more than 20 words for proof.\",\n",
    "    \"Example 13: Sample text with more than 20 words for performance analysis.\",\n",
    "    \"Example 14: Example of a text with more than 20 words for feature demonstration.\",\n",
    "    \"Example 15: Test text with more than 20 words for validation.\",\n",
    "    \"Example 16: Example of a text with more than 20 words for educational purposes.\",\n",
    "    \"Example 17: Sample text with more than 20 words for usability testing.\",\n",
    "    \"Example 18: Example of a text with more than 20 words for research purposes.\",\n",
    "    \"Example 19: Test text with more than 20 words for quality evaluation.\",\n",
    "    \"Example 20: Example of a text with more than 20 words for example purposes.\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para chamar o pipe em batch\n",
    "def generate_text_batch(batch):\n",
    "    return pipe(batch, num_return_sequences=5, top_k=50, top_p=0.95, do_sample=True, repetition_penalty=1.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "batch: ['Example 1: This is an example of a text with more than 20 words for testing.', 'Example 2: Here is another example of a text with more than 20 words for validation.', 'Example 3: This is a third example of a text with more than 20 words for verification.', 'Example 4: Another example of a text with more than 20 words for analysis.', 'Example 5: Sample text with more than 20 words for evaluation.']\n",
      "dentro do batch j 0\n",
      "Frase de entrada 1: Example 1: This is an example of a text with more than 20 words for testing.\n",
      "Frase gerada[0]: 2: This is an example of a text with more than 20 words for testing.\n",
      "\n",
      "Frase gerada[-1]: 1: Below is an example. Example 2: This is 2: This is an\n",
      "\n",
      "dentro do batch j 1\n",
      "Frase de entrada 2: Example 2: Here is another example of a text with more than 20 words for validation.\n",
      "Frase gerada[0]: Example 1: Here is another example of a text with more than 20 words for validation.\n",
      "\n",
      "Frase gerada[-1]: Example 1: This is an example of a text with more than 20 words for validation.\n",
      "\n",
      "dentro do batch j 2\n",
      "Frase de entrada 3: Example 3: This is a third example of a text with more than 20 words for verification.\n",
      "Frase gerada[0]: 2: 3: This is a third example of a text with more than\n",
      "\n",
      "Frase gerada[-1]: Example 2: This is a third example of a text with more than 20 words for\n",
      "\n",
      "dentro do batch j 3\n",
      "Frase de entrada 4: Example 4: Another example of a text with more than 20 words for analysis.\n",
      "Frase gerada[0]: Example 5: Another example of a text with more than 20 words for analysis.\n",
      "\n",
      "Frase gerada[-1]: Example 4: Another example of a text with more than 20 words for analysis.\n",
      "\n",
      "dentro do batch j 4\n",
      "Frase de entrada 5: Example 5: Sample text with more than 20 words for evaluation.\n",
      "Frase gerada[0]: Example 6: Example 4: Sample text with more than 20 words for evaluation.\n",
      "\n",
      "Frase gerada[-1]: Example 6: Example of a sample text with more than 20 words for evaluation.\n",
      "\n",
      "i 5\n",
      "batch: ['Example 6: Example of a text with more than 20 words for use.', 'Example 7: Test text with more than 20 words for demonstration.', 'Example 8: Example of a long text with more than 20 words for experimentation.', 'Example 9: Sample text with more than 20 words for comparison.', 'Example 10: Example of a text with more than 20 words for reference.']\n",
      "dentro do batch j 0\n",
      "Frase de entrada 6: Example 6: Example of a text with more than 20 words for use.\n",
      "Frase gerada[0]: 3: Example of a text with more than 20 words for use. Example 6:\n",
      "\n",
      "Frase gerada[-1]: 5: Example of a text with more than 20 words for use. Example 5:\n",
      "\n",
      "dentro do batch j 1\n",
      "Frase de entrada 7: Example 7: Test text with more than 20 words for demonstration.\n",
      "Frase gerada[0]: Voici un exemple 6: Text test text with more than 20 words for demonstration.\n",
      "\n",
      "Frase gerada[-1]: Exemple 6: Text with more than 20 words for demonstration.\n",
      "\n",
      "dentro do batch j 2\n",
      "Frase de entrada 8: Example 8: Example of a long text with more than 20 words for experimentation.\n",
      "Frase gerada[0]: 0x10: Text with more than 30 words or less as an experiment. Example 7\n",
      "\n",
      "Frase gerada[-1]: 1: Example 6: Example of a long text with more than 20 words for experiment\n",
      "\n",
      "dentro do batch j 3\n",
      "Frase de entrada 9: Example 9: Sample text with more than 20 words for comparison.\n",
      "Frase gerada[0]: Examples 8 to 10: Sample text with more than 20 words for comparison.\n",
      "\n",
      "Frase gerada[-1]: Example 8: Sample text with more than 20 words for comparison.\n",
      "\n",
      "dentro do batch j 4\n",
      "Frase de entrada 10: Example 10: Example of a text with more than 20 words for reference.\n",
      "Frase gerada[0]: Example 10: Example of a text with more than 20 words for reference.\n",
      "\n",
      "Frase gerada[-1]: - Example 10: Example of a text with more than 20 words for reference.\n",
      "\n",
      "i 10\n",
      "batch: ['Example 11: Test text with more than 20 words for illustrative purposes.', 'Example 12: Example of a text with more than 20 words for proof.', 'Example 13: Sample text with more than 20 words for performance analysis.', 'Example 14: Example of a text with more than 20 words for feature demonstration.', 'Example 15: Test text with more than 20 words for validation.']\n",
      "dentro do batch j 0\n",
      "Frase de entrada 11: Example 11: Test text with more than 20 words for illustrative purposes.\n",
      "Frase gerada[0]: 10: Exemple 10: Example 10: Test text with more than 20 words for\n",
      "\n",
      "Frase gerada[-1]: 10: Test text with more than 20 words for illustrative purposes. Example\n",
      "\n",
      "dentro do batch j 1\n",
      "Frase de entrada 12: Example 12: Example of a text with more than 20 words for proof.\n",
      "Frase gerada[0]: ., example 13: Example of a text with more than 20 words for proof.\n",
      "\n",
      "Frase gerada[-1]:  12.7  12: Example 11: Free proofs for a text that\n",
      "\n",
      "dentro do batch j 2\n",
      "Frase de entrada 13: Example 13: Sample text with more than 20 words for performance analysis.\n",
      "Frase gerada[0]: Example 13: Sample text with more than 20 words for performance analysis.\n",
      "\n",
      "Frase gerada[-1]: . Example 1: Example text with more than 20 words for performance analysis.\n",
      "\n",
      "dentro do batch j 3\n",
      "Frase de entrada 14: Example 14: Example of a text with more than 20 words for feature demonstration.\n",
      "Frase gerada[0]:  Example 13: Example of a text with more than 20 words for feature demonstration.\n",
      "\n",
      "Frase gerada[-1]: Examples 13: Example of a text with more than 20 words for feature demonstration.\n",
      "\n",
      "dentro do batch j 4\n",
      "Frase de entrada 15: Example 15: Test text with more than 20 words for validation.\n",
      "Frase gerada[0]: Exemple 15: Test text with more than 20 words for validation.\n",
      "\n",
      "Frase gerada[-1]: 20. Test text with more than 20 words for validation.\n",
      "\n",
      "i 15\n",
      "batch: ['Example 16: Example of a text with more than 20 words for educational purposes.', 'Example 17: Sample text with more than 20 words for usability testing.', 'Example 18: Example of a text with more than 20 words for research purposes.', 'Example 19: Test text with more than 20 words for quality evaluation.', 'Example 20: Example of a text with more than 20 words for example purposes.']\n",
      "dentro do batch j 0\n",
      "Frase de entrada 16: Example 16: Example of a text with more than 20 words for educational purposes.\n",
      "Frase gerada[0]: Example 19: Example of a text with more than 20 words for educational purposes.\n",
      "\n",
      "Frase gerada[-1]: Beispiel 16: Example of a text with more than 20 words for educational purposes.\n",
      "\n",
      "dentro do batch j 1\n",
      "Frase de entrada 17: Example 17: Sample text with more than 20 words for usability testing.\n",
      "Frase gerada[0]: Exemple 16: Example 13: Sample text with more than 20 words for usability testing\n",
      "\n",
      "Frase gerada[-1]:  Example 18: Sample text with more than 20 words for usability testing.\n",
      "\n",
      "dentro do batch j 2\n",
      "Frase de entrada 18: Example 18: Example of a text with more than 20 words for research purposes.\n",
      "Frase gerada[0]: 20: Example 17: Example of a text with more than 20 words for research purposes\n",
      "\n",
      "Frase gerada[-1]:  Exemplary 19: Example of a text with more than 20 words\n",
      "\n",
      "dentro do batch j 3\n",
      "Frase de entrada 19: Example 19: Test text with more than 20 words for quality evaluation.\n",
      "Frase gerada[0]: Example 24: Test text with more than 20 words for quality evaluation.\n",
      "\n",
      "Frase gerada[-1]: ; Test text with more than 20 words for quality evaluation.\n",
      "\n",
      "dentro do batch j 4\n",
      "Frase de entrada 20: Example 20: Example of a text with more than 20 words for example purposes.\n",
      "Frase gerada[0]:  Exe 20: Example of a text with more than 20 words for example purposes\n",
      "\n",
      "Frase gerada[-1]: Exemple 20: Example of a text with more than 20 words for example purposes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Gerar sequências de texto em batch\n",
    "batch_size = 5\n",
    "for i in range(0, len(lista_texto), batch_size):\n",
    "    print(f'i {i}')\n",
    "    batch = lista_texto[i:i+batch_size]\n",
    "    print(f\"batch: {batch}\")\n",
    "    generated_text = generate_text_batch(batch)\n",
    "    # print(f\"generated_text {generated_text}\")\n",
    "    for j, text in enumerate(batch):\n",
    "        print(f'dentro do batch j {j}')\n",
    "        print(f\"Frase de entrada {i+j+1}: {text}\")\n",
    "        print(f\"Frase gerada[0]: {generated_text[j][0]['generated_text']}\\n\")\n",
    "        print(f\"Frase gerada[-1]: {generated_text[j][-1]['generated_text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar o dataset\n",
    "dataset = Dataset.from_dict({\"text\": lista_texto})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "batch: ['Example 1: This is an example of a text with more than 20 words for testing.', 'Example 2: Here is another example of a text with more than 20 words for validation.', 'Example 3: This is a third example of a text with more than 20 words for verification.', 'Example 4: Another example of a text with more than 20 words for analysis.', 'Example 5: Sample text with more than 20 words for evaluation.']\n",
      "dentro do batch j 0\n",
      "Frase de entrada 1: Example 1: This is an example of a text with more than 20 words for testing.\n",
      "Frase gerada[0]: 2: This is an example of a text with more than 20 words for testing.\n",
      "\n",
      "Frase gerada[-1]: 1: This is an example of a text with more than 20 words for testing.\n",
      "\n",
      "dentro do batch j 1\n",
      "Frase de entrada 2: Example 2: Here is another example of a text with more than 20 words for validation.\n",
      "Frase gerada[0]: Example 3: Here is a second example of text with more than 20 words for validation.\n",
      "\n",
      "Frase gerada[-1]: Example 3: This is another example of a text with more than 20 words for validation.\n",
      "\n",
      "dentro do batch j 2\n",
      "Frase de entrada 3: Example 3: This is a third example of a text with more than 20 words for verification.\n",
      "Frase gerada[0]: 3: This is a third example of a text with more than 20 words for\n",
      "\n",
      "Frase gerada[-1]: n n Example 2: This is a third example of a text\n",
      "\n",
      "dentro do batch j 3\n",
      "Frase de entrada 4: Example 4: Another example of a text with more than 20 words for analysis.\n",
      "Frase gerada[0]: Example 4: Another example of a text with more than 20 words for analysis.\n",
      "\n",
      "Frase gerada[-1]: Example 5: Another example of a text with more than 20 words for analysis.\n",
      "\n",
      "dentro do batch j 4\n",
      "Frase de entrada 5: Example 5: Sample text with more than 20 words for evaluation.\n",
      "Frase gerada[0]: Exemple 4: Text sample with more than 20 words for evaluation.\n",
      "\n",
      "Frase gerada[-1]: eBag.com - Example 5: Example 3: Sample text with more\n",
      "\n",
      "i 5\n",
      "batch: ['Example 6: Example of a text with more than 20 words for use.', 'Example 7: Test text with more than 20 words for demonstration.', 'Example 8: Example of a long text with more than 20 words for experimentation.', 'Example 9: Sample text with more than 20 words for comparison.', 'Example 10: Example of a text with more than 20 words for reference.']\n",
      "dentro do batch j 0\n",
      "Frase de entrada 6: Example 6: Example of a text with more than 20 words for use.\n",
      "Frase gerada[0]: 8: Example of a text with more than 20 words for use. Example 4:\n",
      "\n",
      "Frase gerada[-1]: 7: Example of a text with more than 20 words for use. Example 4:\n",
      "\n",
      "dentro do batch j 1\n",
      "Frase de entrada 7: Example 7: Test text with more than 20 words for demonstration.\n",
      "Frase gerada[0]: - Test text with more than 20 words for demonstration.\n",
      "\n",
      "Frase gerada[-1]: Beispiel 8: Test text with more than 20 words for demonstration.\n",
      "\n",
      "dentro do batch j 2\n",
      "Frase de entrada 8: Example 8: Example of a long text with more than 20 words for experimentation.\n",
      "Frase gerada[0]: Exemple 8: Example of a long text with more than 20 words for experimentation\n",
      "\n",
      "Frase gerada[-1]: Example 9: Example of a long text with more than 20 words for experimentation.\n",
      "\n",
      "dentro do batch j 3\n",
      "Frase de entrada 9: Example 9: Sample text with more than 20 words for comparison.\n",
      "Frase gerada[0]: Exemple 10: Example 9: Text sample with more than 20 words for comparison.\n",
      "\n",
      "Frase gerada[-1]: . Example 9: Sample text with more than 20 words for comparison.\n",
      "\n",
      "dentro do batch j 4\n",
      "Frase de entrada 10: Example 10: Example of a text with more than 20 words for reference.\n",
      "Frase gerada[0]: 10: Examples of a text with more than 20 words for reference. Example 13:\n",
      "\n",
      "Frase gerada[-1]: 10: Text with more than 20 words for reference. Example 9: Example of a\n",
      "\n",
      "i 10\n",
      "batch: ['Example 11: Test text with more than 20 words for illustrative purposes.', 'Example 12: Example of a text with more than 20 words for proof.', 'Example 13: Sample text with more than 20 words for performance analysis.', 'Example 14: Example of a text with more than 20 words for feature demonstration.', 'Example 15: Test text with more than 20 words for validation.']\n",
      "dentro do batch j 0\n",
      "Frase de entrada 11: Example 11: Test text with more than 20 words for illustrative purposes.\n",
      "Frase gerada[0]: 10: Test text with more than 20 words for illustrative purposes.\n",
      "\n",
      "Frase gerada[-1]: 9: Test text with more than 20 words for illustrative purposes. Example\n",
      "\n",
      "dentro do batch j 1\n",
      "Frase de entrada 12: Example 12: Example of a text with more than 20 words for proof.\n",
      "Frase gerada[0]: Example 18: Example of an image or a clipart with more than 150 words as proof\n",
      "\n",
      "Frase gerada[-1]: Example 18: Example of a text with more than 20 words for proof.\n",
      "\n",
      "dentro do batch j 2\n",
      "Frase de entrada 13: Example 13: Sample text with more than 20 words for performance analysis.\n",
      "Frase gerada[0]: Exemple 11: Example 14: Example of a sample text with more than 20 words\n",
      "\n",
      "Frase gerada[-1]: Exemple 13: Text sample of more than 20 words used for performance analysis.\n",
      "\n",
      "dentro do batch j 3\n",
      "Frase de entrada 14: Example 14: Example of a text with more than 20 words for feature demonstration.\n",
      "Frase gerada[0]: Exemple 16: Example of a text with more than 20 words for feature demonstration.\n",
      "\n",
      "Frase gerada[-1]: 20-word feature demonstration. Example 15: Example of a text with more than 20 words\n",
      "\n",
      "dentro do batch j 4\n",
      "Frase de entrada 15: Example 15: Test text with more than 20 words for validation.\n",
      "Frase gerada[0]: 0x6dpi: Text test with more than 20 words for validation.\n",
      "\n",
      "Frase gerada[-1]: 20: Validate text with more than 20 words for validation.\n",
      "\n",
      "i 15\n",
      "batch: ['Example 16: Example of a text with more than 20 words for educational purposes.', 'Example 17: Sample text with more than 20 words for usability testing.', 'Example 18: Example of a text with more than 20 words for research purposes.', 'Example 19: Test text with more than 20 words for quality evaluation.', 'Example 20: Example of a text with more than 20 words for example purposes.']\n",
      "dentro do batch j 0\n",
      "Frase de entrada 16: Example 16: Example of a text with more than 20 words for educational purposes.\n",
      "Frase gerada[0]: 16: Describer of a text with more than 20 words for educational purposes.\n",
      "\n",
      "Frase gerada[-1]: 15: Example of a text with more than 20 words for educational purposes.\n",
      "\n",
      "dentro do batch j 1\n",
      "Frase de entrada 17: Example 17: Sample text with more than 20 words for usability testing.\n",
      "Frase gerada[0]: 16: Example 6: Sample text with more than 20 words for usability testing.\n",
      "\n",
      "Frase gerada[-1]: . Examples 17: Sample text with more than 20 words for usability testing.\n",
      "\n",
      "dentro do batch j 2\n",
      "Frase de entrada 18: Example 18: Example of a text with more than 20 words for research purposes.\n",
      "Frase gerada[0]: 18: Example of a text with more than 20 words for research purposes. Example 18\n",
      "\n",
      "Frase gerada[-1]: Fig. 18: Example of a text with more than 20 words for research purposes.\n",
      "\n",
      "dentro do batch j 3\n",
      "Frase de entrada 19: Example 19: Test text with more than 20 words for quality evaluation.\n",
      "Frase gerada[0]: Exemple 20: Text with more than 20 words for quality evaluation.\n",
      "\n",
      "Frase gerada[-1]: Exemple 19: Test text with more than 20 words for quality evaluation.\n",
      "\n",
      "dentro do batch j 4\n",
      "Frase de entrada 20: Example 20: Example of a text with more than 20 words for example purposes.\n",
      "Frase gerada[0]: Example 21: Example of a text with more than 20 words for example purposes.\n",
      "\n",
      "Frase gerada[-1]: Example 21: Example of a text with more than 20 words for example purposes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gerar sequências de texto em batch\n",
    "batch_size = 5\n",
    "for i in range(0, len(lista_texto), batch_size):\n",
    "    print(f'i {i}')\n",
    "    batch = dataset[i:i+batch_size]['text']\n",
    "    print(f\"batch: {batch}\")\n",
    "    generated_text = generate_text_batch(batch)\n",
    "    # print(f\"generated_text {gnerated_text}\")\n",
    "    for j, text in enumerate(batch):\n",
    "        print(f'dentro do batch j {j}')\n",
    "        print(f\"Frase de entrada {i+j+1}: {text}\")\n",
    "        print(f\"Frase gerada[0]: {generated_text[j][0]['generated_text']}\\n\")\n",
    "        print(f\"Frase gerada[-1]: {generated_text[j][-1]['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto de entrada 1: Example 1: This is an example of a text with more than 20 words for testing.\n",
      "Texto gerado: {'generated_text': '2: This is an example of a text with more than 20 words for testing.'}\n",
      "\n",
      "Texto de entrada 2: Example 2: Here is another example of a text with more than 20 words for validation.\n",
      "Texto gerado: {'generated_text': 'Example 1: Here is another example of a text with more than 20 words for validation.'}\n",
      "\n",
      "Texto de entrada 3: Example 3: This is a third example of a text with more than 20 words for verification.\n",
      "Texto gerado: {'generated_text': '2: This is a third example of a text with more than 20 words for'}\n",
      "\n",
      "Texto de entrada 4: Example 4: Another example of a text with more than 20 words for analysis.\n",
      "Texto gerado: {'generated_text': 'Example 5: Another example of a text with more than 20 words for analysis.'}\n",
      "\n",
      "Texto de entrada 5: Example 5: Sample text with more than 20 words for evaluation.\n",
      "Texto gerado: {'generated_text': 'Example 4: Sample text with more than 20 words for evaluation.'}\n",
      "\n",
      "Texto de entrada 6: Example 6: Example of a text with more than 20 words for use.\n",
      "Texto gerado: {'generated_text': '6: Example of a text with more than 20 words for use. Example 5:'}\n",
      "\n",
      "Texto de entrada 7: Example 7: Test text with more than 20 words for demonstration.\n",
      "Texto gerado: {'generated_text': 'Exemple 6: Test text with more than 20 words for demonstration.'}\n",
      "\n",
      "Texto de entrada 8: Example 8: Example of a long text with more than 20 words for experimentation.\n",
      "Texto gerado: {'generated_text': '9: Example of a long text with more than 20 words for experimentation. Example'}\n",
      "\n",
      "Texto de entrada 9: Example 9: Sample text with more than 20 words for comparison.\n",
      "Texto gerado: {'generated_text': 'Example 9: Sample text with more than 20 words for comparison.'}\n",
      "\n",
      "Texto de entrada 10: Example 10: Example of a text with more than 20 words for reference.\n",
      "Texto gerado: {'generated_text': '10: Example of a text with more than 20 words for reference.'}\n",
      "\n",
      "Texto de entrada 11: Example 11: Test text with more than 20 words for illustrative purposes.\n",
      "Texto gerado: {'generated_text': '10: Test text with more than 20 words for illustrative purposes. Example'}\n",
      "\n",
      "Texto de entrada 12: Example 12: Example of a text with more than 20 words for proof.\n",
      "Texto gerado: {'generated_text': 'Example 13: Example of a text with more than 20 words for proof.'}\n",
      "\n",
      "Texto de entrada 13: Example 13: Sample text with more than 20 words for performance analysis.\n",
      "Texto gerado: {'generated_text': '- Example 13: Example of a sample text with more than 20 words for performance analysis'}\n",
      "\n",
      "Texto de entrada 14: Example 14: Example of a text with more than 20 words for feature demonstration.\n",
      "Texto gerado: {'generated_text': 'Example 15: Example of a text with more than 20 words for feature demonstration.'}\n",
      "\n",
      "Texto de entrada 15: Example 15: Test text with more than 20 words for validation.\n",
      "Texto gerado: {'generated_text': '- Test text with more than 20 words for validation.'}\n",
      "\n",
      "Texto de entrada 16: Example 16: Example of a text with more than 20 words for educational purposes.\n",
      "Texto gerado: {'generated_text': '16: Example of a text with more than 20 words for educational purposes. Example 17'}\n",
      "\n",
      "Texto de entrada 17: Example 17: Sample text with more than 20 words for usability testing.\n",
      "Texto gerado: {'generated_text': '17: Sample text with more than 20 words for usability testing.'}\n",
      "\n",
      "Texto de entrada 18: Example 18: Example of a text with more than 20 words for research purposes.\n",
      "Texto gerado: {'generated_text': '18: Example of a text with more than 20 words for research purposes. Example 18'}\n",
      "\n",
      "Texto de entrada 19: Example 19: Test text with more than 20 words for quality evaluation.\n",
      "Texto gerado: {'generated_text': 'Exemple 19: Test text with more than 20 words for quality evaluation.'}\n",
      "\n",
      "Texto de entrada 20: Example 20: Example of a text with more than 20 words for example purposes.\n",
      "Texto gerado: {'generated_text': '20: Example of a text with more than 20 words for example purposes.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configurar os parâmetros para o pipe\n",
    "batch_size = 5\n",
    "num_workers = 8\n",
    "\n",
    "# Chamar o pipe com os parâmetros de batch_size, num_workers e device (gpu)\n",
    "generated_text = pipe(lista_texto, num_workers=num_workers, batch_size=batch_size, return_tensors=False, temperature=0.8)\n",
    "\n",
    "# Iterar sobre os textos gerados\n",
    "for i, text in enumerate(generated_text):\n",
    "    print(f'Texto de entrada {i + 1}: {lista_texto[i]}')\n",
    "    print(f'Texto gerado: {text}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentando pipe com o modelo treinado\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipe e funções movidas para mais avante no código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de strings\n",
    "lista_texto = [\n",
    "    \"Example 1: This is an example of a text with more than 20 words for testing.\",\n",
    "    \"Example 2: Here is another example of a text with more than 20 words for validation.\",\n",
    "    \"Example 3: This is a third example of a text with more than 20 words for verification.\",\n",
    "    \"Example 4: Another example of a text with more than 20 words for analysis.\",\n",
    "    \"Example 5: Sample text with more than 20 words for evaluation.\",\n",
    "    \"Example 6: Example of a text with more than 20 words for use.\",\n",
    "    \"Example 7: Test text with more than 20 words for demonstration.\",\n",
    "    \"Example 8: Example of a long text with more than 20 words for experimentation.\",\n",
    "    \"Example 9: Sample text with more than 20 words for comparison.\",\n",
    "    \"Example 10: Example of a text with more than 20 words for reference.\",\n",
    "    \"Example 11: Test text with more than 20 words for illustrative purposes.\",\n",
    "    \"Example 12: Example of a text with more than 20 words for proof.\",\n",
    "    \"Example 13: Sample text with more than 20 words for performance analysis.\",\n",
    "    \"Example 14: Example of a text with more than 20 words for feature demonstration.\",\n",
    "    \"Example 15: Test text with more than 20 words for validation.\",\n",
    "    \"Example 16: Example of a text with more than 20 words for educational purposes.\",\n",
    "    \"Example 17: Sample text with more than 20 words for usability testing.\",\n",
    "    \"Example 18: Example of a text with more than 20 words for research purposes.\",\n",
    "    \"Example 19: Test text with more than 20 words for quality evaluation.\",\n",
    "    \"Example 20: Example of a text with more than 20 words for example purposes.\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto de entrada 1: Example 1: This is an example of a text with more than 20 words for testing.\n",
      "Texto gerado: ['how many words are in an example of a math', 'how many words in an example of graph', 'how many words are in an example of a test', 'how many words in an example of rich text', 'how many words in an example of a text']\n",
      "\n",
      "Texto de entrada 2: Example 2: Here is another example of a text with more than 20 words for validation.\n",
      "Texto gerado: ['how many words on an example of data', 'how many words in an example of dynamic text', 'how many words in an example of texting', 'how many words in an example of validation', 'how many words in an example of validation?']\n",
      "\n",
      "Texto de entrada 3: Example 3: This is a third example of a text with more than 20 words for verification.\n",
      "Texto gerado: ['how many words in an example of a math', 'how many words in an example of cod', 'how many words in an example of rich text', 'how many words in an example of such text', 'how many words in an example of examples']\n",
      "\n",
      "Texto de entrada 4: Example 4: Another example of a text with more than 20 words for analysis.\n",
      "Texto gerado: ['how many words in an example of visual information', 'how many words in an example of graph', 'how many words in an example of a graph', 'how many words in an example of texting', 'how many words in an example of flowchart']\n",
      "\n",
      "Texto de entrada 5: Example 5: Sample text with more than 20 words for evaluation.\n",
      "Texto gerado: ['how many words in an example of test text', 'how many words in an example of sample text', 'how many words in an example of how many words are in each test?', 'how many words in an example of color']\n",
      "\n",
      "Texto de entrada 6: Example 6: Example of a text with more than 20 words for use.\n",
      "Texto gerado: ['how many words in an example of text', 'how many words in an example of descript', 'how many words in an example of one', 'how many words in an example of a text', 'how many words in an example of deficient text']\n",
      "\n",
      "Texto de entrada 7: Example 7: Test text with more than 20 words for demonstration.\n",
      "Texto gerado: ['how many words in an example of test text', 'how many words test text']\n",
      "\n",
      "Texto de entrada 8: Example 8: Example of a long text with more than 20 words for experimentation.\n",
      "Texto gerado: ['how many words in an example of experimentation', 'how many words are in an example of linear', 'how many words in an example of examples', 'how many words are in an example of rich text', 'how many words are in an example of experimental']\n",
      "\n",
      "Texto de entrada 9: Example 9: Sample text with more than 20 words for comparison.\n",
      "Texto gerado: ['how many words in an example of compare', 'how many words in an example of similar text', 'how many words in an example', 'how many words in an example of sample text', 'how many words in an example of comparison']\n",
      "\n",
      "Texto de entrada 10: Example 10: Example of a text with more than 20 words for reference.\n",
      "Texto gerado: ['how many words in an example of using a text', 'how many words in an example of rich text', 'how many words in an example of a text', 'how many words in an example of color', 'how many words in an example of learning']\n",
      "\n",
      "Texto de entrada 11: Example 11: Test text with more than 20 words for illustrative purposes.\n",
      "Texto gerado: ['how many words in an example of graph', 'how many words in an example of use text', 'how many words in an example', 'how many words in an example of test text', 'how many words in an example of the test text']\n",
      "\n",
      "Texto de entrada 12: Example 12: Example of a text with more than 20 words for proof.\n",
      "Texto gerado: ['how many words in an example of proof in relation to wikipedia', 'how many words in an example of used in an essay', 'how many words in an example of proof', 'how many words in an example of proof in a sentence', 'how many words in an example of a text']\n",
      "\n",
      "Texto de entrada 13: Example 13: Sample text with more than 20 words for performance analysis.\n",
      "Texto gerado: ['how many words in an example of performance analysis?', 'how many words in an example of performance analysis']\n",
      "\n",
      "Texto de entrada 14: Example 14: Example of a text with more than 20 words for feature demonstration.\n",
      "Texto gerado: ['how many words are in an example of a contentious text', 'how many words in an example of rich text', 'how many words in an example of text', 'how many words in an example of linear text', 'how many words in an example of examples']\n",
      "\n",
      "Texto de entrada 15: Example 15: Test text with more than 20 words for validation.\n",
      "Texto gerado: ['how many words in an example of test text', 'how many words test text', 'how many words for an example of test text']\n",
      "\n",
      "Texto de entrada 16: Example 16: Example of a text with more than 20 words for educational purposes.\n",
      "Texto gerado: ['how many words in an example of one or more words?', 'how many words in an example of rich text', 'how many words in an example of text', 'how many words in an example of background text', 'how many words in an example of a text']\n",
      "\n",
      "Texto de entrada 17: Example 17: Sample text with more than 20 words for usability testing.\n",
      "Texto gerado: ['how many words in an example of usability testing', 'how many words in an example of texting', 'how many words in an example of the sample text', 'how many words in an example of sample text', 'how many words in an example of usability testing.']\n",
      "\n",
      "Texto de entrada 18: Example 18: Example of a text with more than 20 words for research purposes.\n",
      "Texto gerado: ['how many words in an example of rich text', 'how many words in an example of narrative', 'how many words in an example of descript', 'how many words in an example of narrative essay', 'how many words in an example of a text']\n",
      "\n",
      "Texto de entrada 19: Example 19: Test text with more than 20 words for quality evaluation.\n",
      "Texto gerado: ['how many words in an example of quality test', 'how many words in an example of quality evaluation']\n",
      "\n",
      "Texto de entrada 20: Example 20: Example of a text with more than 20 words for example purposes.\n",
      "Texto gerado: ['how many words in an example of flowchart', 'how many words in an example of an example of graph', 'how many words in an example of text', 'how many words in an example of sirc', 'how many words in an example of a text']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configurar os parâmetros para o pipe\n",
    "batch_size = 5\n",
    "num_workers = 8\n",
    "\n",
    "# Chamar o pipe com os parbâmetros de batch_size, num_workers e device (gpu)\n",
    "#generated_text = pipe(lista_texto, num_workers=num_workers, batch_size=batch_size, top_k=50, do_sample=True, temperature=0.2, num_return_sequences=5)\n",
    "\n",
    "lista_texto_gerado = gerar_texto(lista_texto, 5)\n",
    "# Iterar sobre os textos gerados\n",
    "for i, text in enumerate(lista_texto_gerado):\n",
    "    print(f'Texto de entrada {i + 1}: {lista_texto[i]}')\n",
    "    print(f'Texto gerado: {text}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baixando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{DIRETORIO_TRABALHO}/corpus.jsonl.gz\"):\n",
    "    !wget https://huggingface.co/datasets/BeIR/trec-covid/resolve/main/corpus.jsonl.gz\n",
    "    !mv corpus.jsonl.gz {DIRETORIO_TRABALHO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descompacte o arquivo para a memória\n",
    "with gzip.open(f'{DIRETORIO_TRABALHO}/corpus.jsonl.gz', 'rt') as f:\n",
    "    # Leia o conteúdo do arquivo descompactado\n",
    "    corpus_original = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> len(corpus_original): 171332 corpus_original[0] {'_id': 'ug7v899j', 'title': 'Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia', 'text': 'OBJECTIVE: This retrospective chart review describes the epidemiology and clinical features of 40 patients with culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia. METHODS: Patients with positive M. pneumoniae cultures from respiratory specimens from January 1997 through December 1998 were identified through the Microbiology records. Charts of patients were reviewed. RESULTS: 40 patients were identified, 33 (82.5%) of whom required admission. Most infections (92.5%) were community-acquired. The infection affected all age groups but was most common in infants (32.5%) and pre-school children (22.5%). It occurred year-round but was most common in the fall (35%) and spring (30%). More than three-quarters of patients (77.5%) had comorbidities. Twenty-four isolates (60%) were associated with pneumonia, 14 (35%) with upper respiratory tract infections, and 2 (5%) with bronchiolitis. Cough (82.5%), fever (75%), and malaise (58.8%) were the most common symptoms, and crepitations (60%), and wheezes (40%) were the most common signs. Most patients with pneumonia had crepitations (79.2%) but only 25% had bronchial breathing. Immunocompromised patients were more likely than non-immunocompromised patients to present with pneumonia (8/9 versus 16/31, P = 0.05). Of the 24 patients with pneumonia, 14 (58.3%) had uneventful recovery, 4 (16.7%) recovered following some complications, 3 (12.5%) died because of M pneumoniae infection, and 3 (12.5%) died due to underlying comorbidities. The 3 patients who died of M pneumoniae pneumonia had other comorbidities. CONCLUSION: our results were similar to published data except for the finding that infections were more common in infants and preschool children and that the mortality rate of pneumonia in patients with comorbidities was high.', 'metadata': {'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC35282/', 'pubmed_id': '11472636'}}\n"
     ]
    }
   ],
   "source": [
    "# Exiba os dados carregados\n",
    "print(f\"{type(corpus_original)} len(corpus_original): {len(corpus_original)} corpus_original[0] {corpus_original[0]}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime RAM in gb: \n",
      " total 67.35\n",
      " available 53.54\n",
      " used 12.65\n",
      " free 8.07\n",
      " cached 44.61\n",
      " buffers 2.02\n",
      "/nGPU\n",
      "Mon Apr 10 22:37:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 87%   76C    P2   249W / 370W |  15033MiB / 24576MiB |     55%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1241      G   /usr/lib/xorg/Xorg                 45MiB |\n",
      "|    0   N/A  N/A      1381      G   /usr/bin/gnome-shell               14MiB |\n",
      "|    0   N/A  N/A    171944      C   ...treinapython39/bin/python    14969MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "mostra_memoria(['cpu','gpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_com_texto = [doc for doc in corpus_original if len(doc['text']) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sem_texto = [doc for doc in corpus_original if len(doc['text']) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129192, 42140)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_com_texto), len(corpus_sem_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "dict_corpus = {}\n",
    "docto_pendente_geracao = []\n",
    "for doc in corpus_original:\n",
    "    dict_corpus[doc['_id']] = {'title': doc['title'],'text': doc['text'], 'expanded_query':\"\", 'qtd_expanded_query':0}\n",
    "    if len(doc['text']) > 0: \n",
    "        docto_pendente_geracao.append(doc['_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(corpus_original), len(dict_corpus), len(docto_pendente_geracao)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expansão dos documentos (com texto apenas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicatas(generated_text, max_sequences):\n",
    "    frases_filtradas = []\n",
    "    for i, text in enumerate(generated_text):\n",
    "        frases_geradas = set()  # Conjunto para armazenar frases geradas e garantir que sejam distintas\n",
    "        for retorno in text:\n",
    "            frase = retorno[\"generated_text\"]\n",
    "            if frase not in frases_geradas:  # Verificar se a frase já foi gerada antes\n",
    "                frases_geradas.add(frase)  # Adicionar à lista de frases geradas\n",
    "                if len(frases_geradas) == max_sequences:  # Parar de adicionar frases quando atingir o limite máximo\n",
    "                    break\n",
    "        frases_filtradas.append(list(frases_geradas))  # Adicionar lista de frases geradas (set) a frases_filtradas\n",
    "    return frases_filtradas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_texto(lista_texto, parm_num_return_sequences:int=5, parm_batch_size:int=8):\n",
    "    generated_text = pipe(lista_texto, num_workers=8, batch_size=parm_batch_size, top_k=50, do_sample=True, num_return_sequences=parm_num_return_sequences*2)\n",
    "    return remove_duplicatas(generated_text, max_sequences = parm_num_return_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borela/miniconda3/envs/treinamento/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor modelo (bleu 19.9, época 82) (finetuning em andamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(f'{DIRETORIO_TRABALHO}/base-checkpoint-4264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0, max_length=512, repetition_penalty=1.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progresso ([2023-Apr-10 22:39:12]):   0%|          | 160/129192 [00:35<7:59:28,  4.49it/s]/home/borela/miniconda3/envs/treinamento/lib/python3.7/site-packages/transformers/pipelines/base.py:1046: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      "Progresso ([2023-Apr-11 04:14:37]): : 129200it [5:36:02,  8.64it/s]                            "
     ]
    }
   ],
   "source": [
    "# Defina o tamanho do subconjunto de documentos a serem processados de uma vez\n",
    "num_docs_processamento = 16\n",
    "\n",
    "# Inicializar o tqdm com o número total de iterações\n",
    "progress_bar = tqdm(total= len(corpus_com_texto), desc='Progresso')\n",
    "\n",
    "# Criar uma nova coluna \"texto_gerado\" nos documentos\n",
    "for i in range(0, len(corpus_com_texto), num_docs_processamento):\n",
    "    progress_bar.set_description(f'Progresso ({time.strftime(\"[%Y-%b-%d %H:%M:%S]\")})')   \n",
    "    # Selecionar o subconjunto de documentos a serem processados   \n",
    "    subconjunto = corpus_com_texto[i:i + num_docs_processamento]\n",
    "\n",
    "    # Extrair o texto dos documentos selecionados; \n",
    "    # limitando em 500 caracteres (menos tokens) para evitar erro \n",
    "    # sequence length is longer than the specified maximum sequence length for this model (655 > 512)\n",
    "    lista_texto = [doc['text'][:500] for doc in subconjunto]\n",
    "\n",
    "    # Gerar o texto para o subconjunto de documentos\n",
    "    generated_text = gerar_texto(lista_texto, parm_num_return_sequences=5, parm_batch_size=8)\n",
    "\n",
    "    # Adicionar a lista de texto gerado como uma nova coluna \"texto_gerado\" nos documentos\n",
    "    for j in range(len(subconjunto)):\n",
    "        subconjunto[j]['texto_gerado'] = '; '.join(generated_text[j])\n",
    "        subconjunto[j]['qtd_texto_gerado'] = len(generated_text[j])\n",
    "\n",
    "    # Atualizar os documentos originais com a nova coluna \"texto_gerado\"\n",
    "    # (subconjunto já está referenciando os documentos originais)\n",
    "    corpus_com_texto[i:i + num_docs_processamento] = subconjunto\n",
    "    progress_bar.update(num_docs_processamento)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DIRETORIO_TRABALHO}/trec-covid-corpus-com-queries.pickle\", \"wb\") as f:\n",
    "  pickle.dump(corpus_com_texto, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DIRETORIO_TRABALHO}/trec-covid-corpus-sem-texto.pickle\", \"wb\") as f:\n",
    "  pickle.dump(corpus_sem_texto, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processando documentos só com título \n",
    "\n",
    "Atualizando modelo para última versão (bleu 20.1, época 94, finetuning concluído)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(f'{DIRETORIO_TRABALHO}/checkpoint-5200')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo num_workers na criação do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text2text-generation\", model=model, num_workers=8, tokenizer=tokenizer, device=0, max_length=512, repetition_penalty=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_texto(lista_texto, parm_num_return_sequences:int=10, parm_batch_size:int=8):\n",
    "    generated_text = pipe(lista_texto, batch_size=parm_batch_size, top_k=50, do_sample=True, num_return_sequences=parm_num_return_sequences*2)\n",
    "    return remove_duplicatas(generated_text, max_sequences = parm_num_return_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '6iu1dtyl',\n",
       " 'title': 'The site of origin of the 1918 influenza pandemic and its public health implications',\n",
       " 'text': '',\n",
       " 'metadata': {'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC340389/',\n",
       "  'pubmed_id': '14733617'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_sem_texto[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando até 10 perguntas para um pequeno título."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progresso ([2023-Apr-11 07:20:10]):   2%|▏         | 720/42140 [04:13<4:02:39,  2.84it/s]\n",
      "Progresso ([2023-Apr-11 07:21:59]):   0%|          | 0/42140 [00:00<?, ?it/s]/home/borela/miniconda3/envs/treinamento/lib/python3.7/site-packages/transformers/pipelines/base.py:1046: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      "Progresso ([2023-Apr-11 07:27:03]):   4%|▍         | 1728/42140 [05:03<1:55:20,  5.84it/s]"
     ]
    }
   ],
   "source": [
    "# Defina o tamanho do subconjunto de documentos a serem processados de uma vez\n",
    "num_docs_processamento = 32\n",
    "\n",
    "# Inicializar o tqdm com o número total de iterações\n",
    "progress_bar = tqdm(total= len(corpus_sem_texto), desc='Progresso')\n",
    "\n",
    "# Criar uma nova coluna \"texto_gerado\" nos documentos\n",
    "for i in range(0, len(corpus_sem_texto), num_docs_processamento):\n",
    "    progress_bar.set_description(f'Progresso ({time.strftime(\"[%Y-%b-%d %H:%M:%S]\")})')   \n",
    "    # Selecionar o subconjunto de documentos a serem processados   \n",
    "    subconjunto = corpus_sem_texto[i:i + num_docs_processamento]\n",
    "\n",
    "    # Extrair o texto dos documentos selecionados; \n",
    "    # limitando em 500 caracteres (menos tokens) para evitar erro \n",
    "    # sequence length is longer than the specified maximum sequence length for this model (655 > 512)\n",
    "    lista_texto = [doc['title'][:500] for doc in subconjunto]\n",
    "\n",
    "    # Gerar o texto para o subconjunto de documentos\n",
    "    generated_text = gerar_texto(lista_texto, parm_num_return_sequences=10, parm_batch_size=8)\n",
    "\n",
    "    # Adicionar a lista de texto gerado como uma nova coluna \"texto_gerado\" nos documentos\n",
    "    for j in range(len(subconjunto)):\n",
    "        subconjunto[j]['texto_gerado'] = '; '.join(generated_text[j])\n",
    "        subconjunto[j]['qtd_texto_gerado'] = len(generated_text[j])\n",
    "\n",
    "    # Atualizar os documentos originais com a nova coluna \"texto_gerado\"\n",
    "    # (subconjunto já está referenciando os documentos originais)\n",
    "    corpus_sem_texto[i:i + num_docs_processamento] = subconjunto\n",
    "    progress_bar.update(num_docs_processamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DIRETORIO_TRABALHO}/trec-covid-corpus-sem-texto.pickle\", \"wb\") as f:\n",
    "  pickle.dump(corpus_sem_texto, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testa da saída da geração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '0wx6yoo8', 'title': 'Conflict and Emerging Infectious Diseases', 'text': '', 'metadata': {'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2600301/', 'pubmed_id': '18507934'}, 'texto_gerado': 'diseases of conflict; definition of conflict; current diseases burden of conflict; what is the incidence of conflict; current diseases of conflict; current disease burden of disease', 'qtd_texto_gerado': 6}\n"
     ]
    }
   ],
   "source": [
    "print(corpus_sem_texto[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '8zchiykl', 'title': 'The 21st International Symposium on Intensive Care and Emergency Medicine, Brussels, Belgium, 20-23 March 2001', 'text': \"The 21st International Symposium on Intensive Care and Emergency Medicine was dominated by the results of recent clinical trials in sepsis and acute respiratory distress syndrome (ARDS). The promise of extracorporeal liver replacement therapy and noninvasive ventilation were other areas of interest. Ethical issues also received attention. Overall, the 'state of the art' lectures, pro/con debates, seminars and tutorials were of a high standard. The meeting was marked by a sense of renewed enthusiasm that positive progress is occurring in intensive care medicine.\", 'metadata': {'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC137274/', 'pubmed_id': '11353930'}, 'texto_gerado': 'what is the overall purpose of intensive care & emergency room management; what is the importance of intensive care medicine; what is the overall purpose of intensive care; what is the overall purpose of intensive care medicine; what is the overall purpose of intensive care med', 'qtd_texto_gerado': 5}\n"
     ]
    }
   ],
   "source": [
    "print(subconjunto[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '8qnrcgnk', 'title': 'Heme oxygenase-1 and carbon monoxide in pulmonary medicine', 'text': 'Heme oxygenase-1 (HO-1), an inducible stress protein, confers cytoprotection against oxidative stress in vitro and in vivo. In addition to its physiological role in heme degradation, HO-1 may influence a number of cellular processes, including growth, inflammation, and apoptosis. By virtue of anti-inflammatory effects, HO-1 limits tissue damage in response to proinflammatory stimuli and prevents allograft rejection after transplantation. The transcriptional upregulation of HO-1 responds to many agents, such as hypoxia, bacterial lipopolysaccharide, and reactive oxygen/nitrogen species. HO-1 and its constitutively expressed isozyme, heme oxygenase-2, catalyze the rate-limiting step in the conversion of heme to its metabolites, bilirubin IXα, ferrous iron, and carbon monoxide (CO). The mechanisms by which HO-1 provides protection most likely involve its enzymatic reaction products. Remarkably, administration of CO at low concentrations can substitute for HO-1 with respect to anti-inflammatory and anti-apoptotic effects, suggesting a role for CO as a key mediator of HO-1 function. Chronic, low-level, exogenous exposure to CO from cigarette smoking contributes to the importance of CO in pulmonary medicine. The implications of the HO-1/CO system in pulmonary diseases will be discussed in this review, with an emphasis on inflammatory states.', 'metadata': {'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC193681/', 'pubmed_id': '12964953'}, 'texto_gerado': 'what is HO1 in chemistry; what is HO1 in the chemistry; what effects do holo on the lungs; what effects do HO-1 have on the lungs; what effects do HO1 have on the hcl', 'qtd_texto_gerado': 5}\n"
     ]
    }
   ],
   "source": [
    "print(corpus_com_texto[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['common complication pneumonia',\n",
       " 'relative importance for pneumonia',\n",
       " 'common symptom of pneumonia',\n",
       " 'what are the symptoms of pneumonia',\n",
       " 'pneumonia symptoms in children']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treinamento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ab495da778b1490ad558dda332ee040d5168b43173ece1a71630fac661e6874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
