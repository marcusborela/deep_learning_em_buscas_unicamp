{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CcN_5-RDWeqV"
      },
      "source": [
        "# Aula 9 - InPars\n",
        "\n",
        "[Unicamp - IA368DD: Deep Learning aplicado a sistemas de busca.](https://www.cpg.feec.unicamp.br/cpg/lista/caderno_horario_show.php?id=1779)\n",
        "\n",
        "Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "[Repositório no github](https://github.com/marcusborela/deep_learning_em_buscas_unicamp)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VQxzYKGgMqce"
      },
      "source": [
        "# Enunciado exercício\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Objetivo: gerar dataset para treino de modelos de buscas usando a técnica do InPars e avaliar um modelo reranqueador treinado neste dataset no TREC-COVID:\n",
        "\n",
        "Entrada: 3-5 exemplos few-shot + documento amostrado da coleção do TREC-COVID\n",
        "\n",
        "Saída: query que seja relevante para o documento amostrado\n",
        "\n",
        "É opcional fazer a etapa de filtragem usando as queries de maior prob descrita no Artigo.\n",
        "\n",
        "Como modelo gerador, use um dos seguintes modelos:\n",
        "ChatGPT-3.5-turbo: ~1 USD para cada 1k exemplos\n",
        "FLAN-T5 (base, large ou XL), LLAMA-(7,13B), Alpaca-(7/13B), que são possiveis de rodar no Colab Pro.\n",
        "\n",
        "Também tem a inference-api da HF: https://huggingface.co/inference-api.\n",
        "\n",
        "Com exceção do LLAMA, é possivel usar zero-shot ao inves de few-shot.\n",
        "Dado 1k-10k pares <query sintética; documento>, treinar um modelo reranqueador miniLM igual ao da aula 2/3.\n",
        "\n",
        "Exemplos negativos (i.e., <query sintética; doc não relevant) vem do BM25: dado a query sintetica, retornar top 1000 com o BM25, e amostrar aleatoriamente alguns documentos como negativo\n",
        "\n",
        "Começar treino do miniLM já treinado no MS MARCO\n",
        "\n",
        "Avaliar no TREC-COVID e comparar com o reranqueador apenas treinado no MSMARCO\n",
        "\n",
        "Nota: Também usar o dataset dos colegas para obter diversidade de exemplos: Assim que tiver gerado o dataset sintético, favor colocar na planilha, assim outras pessoas podem usa-lo.\n",
        "- Para aumentar a aleatoriedade, seed usada deve o seu numero na planilha.\n",
        "\n",
        "Colocar dataset no formato jsonlines:\n",
        "{\"query\": query, \"positive_doc_id\": doc_id, \"negative_doc_ids\": [opcional]}\\n \n",
        "\n",
        "\n",
        "\n",
        "Dicas: (do exercício da aula 2)\n",
        "\n",
        "- Siga sempre um padrão ao criar os exemplos few-shot. Aqui tem uma pagina com dicas para prompt engineering: https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api\n",
        "\n",
        "\n",
        "- Usar a API do LLAMA fornecida por nós (licença exclusiva para pesquisa). [Colab demo da API do LLAMA](https://colab.research.google.com/drive/1zZ-ch29LTicNPA62t2MaOwMROywnqUxf?usp=sharing) (obrigado, Thales Rogério)\n",
        "- Opcionalmente, usar a API do code-davinci-002, que é de graça e trás resultados muito bons.\n",
        "CUIDADO: NÃO USAR O TEXT-DAVINCI-002/003, que é pago\n",
        "\n",
        "- Opcionalmente, usar a API do ChatGPT (gpt-3.5-turbo) que é barata: ~1 centavo de real por 1000 tokens (uma página)\n",
        "  \n",
        "- Opcionalmente, usar o Alpaca: https://alpaca-ai.ngrok.io/\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este caderno contempla os passos 3 (filtrar por relevância) e 4 (encontrar exemplos negativos) do [fluxo de processamento](https://github.com/marcusborela/deep_learning_em_buscas_unicamp/blob/main/presentations/articles/Aula%208%20-%20InPars%20Process.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmRLgbyi_Dvg"
      },
      "source": [
        "# Organizando o ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjCY6qqxCXrd"
      },
      "source": [
        "## Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {
        "id": "gHPHUE5PCZdu"
      },
      "outputs": [],
      "source": [
        "import requests  # para Llama\n",
        "import time # para Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "id": "AEUf1Hk5dQba"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "id": "6pLmlN-NipyL"
      },
      "outputs": [],
      "source": [
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {
        "id": "4fhQJQgkEAfY"
      },
      "outputs": [],
      "source": [
        "import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 368,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 369,
      "metadata": {
        "id": "ry_ieNro1kUa"
      },
      "outputs": [],
      "source": [
        "from transformers import BatchEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {
        "id": "AG9RjMb8Qlot"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {
        "id": "DKAZ8CWCAM3-"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {
        "id": "BJ6S4P5Hw4iG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {
        "id": "AG9RjMb8Qlot"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {
        "id": "rnR2kDS_2FgZ"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {},
      "outputs": [],
      "source": [
        "# para limpar texto\n",
        "import ftfy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v19yOgi9OMjD"
      },
      "source": [
        "## Definindo paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {},
      "outputs": [],
      "source": [
        "DIRETORIO_LOCAL = '/home/borela/fontes/deep_learning_em_buscas_unicamp/local'\n",
        "DIRETORIO_TRABALHO = F'{DIRETORIO_LOCAL}/inpars'\n",
        "DIRETORIO_TREC_COVID = F'{DIRETORIO_LOCAL}/trec_covid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {},
      "outputs": [],
      "source": [
        "DIRETORIO_TREC_COVID_CARDIN = F'{DIRETORIO_TRABALHO}/cardin'\n",
        "CAMINHO_CARDIN_TREC_COVID = f\"{DIRETORIO_TREC_COVID_CARDIN}/trec-covid-inpars.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {},
      "outputs": [],
      "source": [
        "DIRETORIO_INDICE = f\"{DIRETORIO_TRABALHO}/indexes/trec-covid-index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pasta já existia!\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(DIRETORIO_LOCAL):\n",
        "    print('pasta já existia!')\n",
        "else:\n",
        "    os.makedirs(DIRETORIO_LOCAL)\n",
        "    print('pasta criada!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pasta já existia!\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(DIRETORIO_TREC_COVID_CARDIN):\n",
        "    print('pasta já existia!')\n",
        "else:\n",
        "    os.makedirs(DIRETORIO_TREC_COVID_CARDIN)\n",
        "    print('pasta criada!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pasta já existia!\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(DIRETORIO_TRABALHO):\n",
        "    print('pasta já existia!')\n",
        "else:\n",
        "    os.makedirs(DIRETORIO_TRABALHO)\n",
        "    print('pasta criada!')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Função de verificação de memória"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns_pq59lAHke",
        "outputId": "8c340509-fb4b-4264-d29c-98fa9313e8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Tue May  2 22:14:07 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.116.03   Driver Version: 525.116.03   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
            "| 66%   50C    P8    27W / 370W |   1140MiB / 24576MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1229      G   /usr/lib/xorg/Xorg                 46MiB |\n",
            "|    0   N/A  N/A      1371      G   /usr/bin/gnome-shell                9MiB |\n",
            "|    0   N/A  N/A    169810      C   ...treinapython39/bin/python     1080MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {
        "id": "9XgIWvkkH-kn"
      },
      "outputs": [],
      "source": [
        "def mostra_memoria(lista_mem=['cpu']):\n",
        "  \"\"\"\n",
        "  Esta função exibe informações de memória da CPU e/ou GPU, conforme parâmetros fornecidos.\n",
        "\n",
        "  Parâmetros:\n",
        "  -----------\n",
        "  lista_mem : list, opcional\n",
        "      Lista com strings 'cpu' e/ou 'gpu'. \n",
        "      'cpu' - exibe informações de memória da CPU.\n",
        "      'gpu' - exibe informações de memória da GPU (se disponível).\n",
        "      O valor padrão é ['cpu'].\n",
        "\n",
        "  Saída:\n",
        "  -------\n",
        "  A função não retorna nada, apenas exibe as informações na tela.\n",
        "\n",
        "  Exemplo de uso:\n",
        "  ---------------\n",
        "  Para exibir informações de memória da CPU:\n",
        "      mostra_memoria(['cpu'])\n",
        "\n",
        "  Para exibir informações de memória da CPU e GPU:\n",
        "      mostra_memoria(['cpu', 'gpu'])\n",
        "  \n",
        "  Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "  \"\"\"  \n",
        "  if 'cpu' in lista_mem:\n",
        "    vm = virtual_memory()\n",
        "    ram={}\n",
        "    ram['total']=round(vm.total / 1e9,2)\n",
        "    ram['available']=round(virtual_memory().available / 1e9,2)\n",
        "    # ram['percent']=round(virtual_memory().percent / 1e9,2)\n",
        "    ram['used']=round(virtual_memory().used / 1e9,2)\n",
        "    ram['free']=round(virtual_memory().free / 1e9,2)\n",
        "    ram['active']=round(virtual_memory().active / 1e9,2)\n",
        "    ram['inactive']=round(virtual_memory().inactive / 1e9,2)\n",
        "    ram['buffers']=round(virtual_memory().buffers / 1e9,2)\n",
        "    ram['cached']=round(virtual_memory().cached/1e9 ,2)\n",
        "    print(f\"Your runtime RAM in gb: \\n total {ram['total']}\\n available {ram['available']}\\n used {ram['used']}\\n free {ram['free']}\\n cached {ram['cached']}\\n buffers {ram['buffers']}\")\n",
        "    print('/nGPU')\n",
        "    gpu_info = !nvidia-smi\n",
        "  if 'gpu' in lista_mem:\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 386,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dri9iiMAvCT",
        "outputId": "347c9e3b-238b-46f4-f530-a00030c343c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 67.35\n",
            " available 49.13\n",
            " used 17.03\n",
            " free 28.91\n",
            " cached 20.95\n",
            " buffers 0.46\n",
            "/nGPU\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Tue May  2 22:14:09 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.116.03   Driver Version: 525.116.03   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
            "| 66%   51C    P8    38W / 370W |   1140MiB / 24576MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1229      G   /usr/lib/xorg/Xorg                 46MiB |\n",
            "|    0   N/A  N/A      1371      G   /usr/bin/gnome-shell                9MiB |\n",
            "|    0   N/A  N/A    169810      C   ...treinapython39/bin/python     1080MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "mostra_memoria(['cpu','gpu'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9xRdgUGMPgh"
      },
      "source": [
        "### Vinculando pasta do google drive para salvar dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achvQ78sa3p3"
      },
      "source": [
        "## Fixando as seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "id": "bkETIyWGkbOf"
      },
      "outputs": [],
      "source": [
        "def inicializa_seed(num_semente:int=123):\n",
        "  \"\"\"\n",
        "  Inicializa as sementes para garantir a reprodutibilidade dos resultados do modelo.\n",
        "  Essa é uma prática recomendada, já que a geração de números aleatórios pode influenciar os resultados do modelo.\n",
        "  Além disso, a função também configura as sementes da GPU para garantir a reprodutibilidade quando se utiliza aceleração por GPU. \n",
        "  \n",
        "  Args:\n",
        "      num_semente (int): número da semente a ser utilizada para inicializar as sementes das bibliotecas.\n",
        "  \n",
        "  References:\n",
        "      http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "      https://github.com/CyberZHG/torch-multi-head-attention/blob/master/torch_multi_head_attention/multi_head_attention.py#L15\n",
        "  \"\"\"\n",
        "  # Define as sementes das bibliotecas random, numpy e pytorch\n",
        "  random.seed(num_semente)\n",
        "  np.random.seed(num_semente)\n",
        "  torch.manual_seed(num_semente)\n",
        "  \n",
        "  # Define as sementes da GPU\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "  #torch.cuda.manual_seed(num_semente)\n",
        "  #Cuda algorithms\n",
        "  #torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A semente dever ser meu número na planilha da tarefa no [classoom](https://docs.google.com/spreadsheets/u/0/d/1mvA8ZrN2FjPxIDwJkYJGsVdZNH49Z1w1L0_3pIAZhQo/htmlview#gid=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_semente = 13 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "id": "UJGxQIrdaVp4"
      },
      "outputs": [],
      "source": [
        "inicializa_seed(num_semente)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v2gtkEPhA0t"
      },
      "source": [
        "## Preparando para debug e display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "id": "wQ5pmlOHxHhk"
      },
      "outputs": [],
      "source": [
        "def config_display():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de display do Pandas.\n",
        "  \"\"\"\n",
        "\n",
        "  # Configurando formato saída Pandas\n",
        "  # define o número máximo de colunas que serão exibidas\n",
        "  pd.options.display.max_columns = None\n",
        "\n",
        "  # define a largura máxima de uma linha\n",
        "  pd.options.display.width = 1000\n",
        "\n",
        "  # define o número máximo de linhas que serão exibidas\n",
        "  pd.options.display.max_rows = 100\n",
        "\n",
        "  # define o número máximo de caracteres por coluna\n",
        "  pd.options.display.max_colwidth = 50\n",
        "\n",
        "  # se deve exibir o número de linhas e colunas de um DataFrame.\n",
        "  pd.options.display.show_dimensions = True\n",
        "\n",
        "  # número de dígitos após a vírgula decimal a serem exibidos para floats.\n",
        "  pd.options.display.precision = 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {
        "id": "b2tDy72ATNHs"
      },
      "outputs": [],
      "source": [
        "def config_debug():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de debug do PyTorch e dos pacotes\n",
        "  transformers e datasets.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define opções de impressão de tensores para o modo científico\n",
        "  torch.set_printoptions(sci_mode=True) \n",
        "  \"\"\"\n",
        "    Significa que valores muito grandes ou muito pequenos são mostrados em notação científica.\n",
        "    Por exemplo, em vez de imprimir o número 0.0000012345 como 0.0000012345, \n",
        "    ele seria impresso como 1.2345e-06. Isso é útil em situações em que os valores dos tensores \n",
        "    envolvidos nas operações são muito grandes ou pequenos, e a notação científica permite \n",
        "    uma melhor compreensão dos números envolvidos.  \n",
        "  \"\"\"\n",
        "\n",
        "  # Habilita detecção de anomalias no autograd do PyTorch\n",
        "  torch.autograd.set_detect_anomaly(True)\n",
        "  \"\"\"\n",
        "    Permite identificar operações que podem causar problemas de estabilidade numérica, \n",
        "    como gradientes explodindo ou desaparecendo. Quando essa opção é ativada, \n",
        "    o PyTorch verifica se há operações que geram valores NaN ou infinitos nos tensores \n",
        "    envolvidos no cálculo do gradiente. Se for detectado um valor anômalo, o PyTorch \n",
        "    interrompe a execução e gera uma exceção, permitindo que o erro seja corrigido \n",
        "    antes que se torne um problema maior.\n",
        "\n",
        "    É importante notar que a detecção de anomalias pode ter um impacto significativo \n",
        "    no desempenho, especialmente em modelos grandes e complexos. Por esse motivo,\n",
        "    ela deve ser usada com cautela e apenas para depuração.\n",
        "  \"\"\"\n",
        "\n",
        "  # Configura variável de ambiente para habilitar a execução síncrona (bloqueante) das chamadas da API do CUDA.\n",
        "  os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "  \"\"\"\n",
        "    o Python aguarda o término da execução de uma chamada da API do CUDA antes de executar a próxima chamada. \n",
        "    Isso é útil para depurar erros no código que envolve operações na GPU, pois permite que o erro seja capturado \n",
        "    no momento em que ocorre, e não depois de uma sequência de operações que pode tornar a origem do erro mais difícil de determinar.\n",
        "    No entanto, é importante lembrar que esse modo de execução é significativamente mais lento do que a execução assíncrona, \n",
        "    que é o comportamento padrão do CUDA. Por isso, é recomendado utilizar esse comando apenas em situações de depuração \n",
        "    e removê-lo após a solução do problema.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define o nível de verbosity do pacote transformers para info\n",
        "  # transformers.utils.logging.set_verbosity_info() \n",
        "  \n",
        "  \n",
        "  \"\"\"\n",
        "    Define o nível de detalhamento das mensagens de log geradas pela biblioteca Hugging Face Transformers \n",
        "    para o nível info. Isso significa que a biblioteca irá imprimir mensagens de log informativas sobre\n",
        "    o andamento da execução, tais como tempo de execução, tamanho de batches, etc.\n",
        "\n",
        "    Essas informações podem ser úteis para entender o que está acontecendo durante a execução da tarefa \n",
        "    e auxiliar no processo de debug. É importante notar que, em alguns casos, a quantidade de informações\n",
        "    geradas pode ser muito grande, o que pode afetar o desempenho do sistema e dificultar a visualização\n",
        "    das informações relevantes. Por isso, é importante ajustar o nível de detalhamento de acordo com a \n",
        "    necessidade de cada tarefa.\n",
        "  \n",
        "    Caso queira reduzir a quantidade de mensagens, comentar a linha acima e \n",
        "      descomentar as duas linhas abaixo, para definir o nível de verbosity como error ou warning\n",
        "  \n",
        "    transformers.utils.logging.set_verbosity_error()\n",
        "    transformers.utils.logging.set_verbosity_warning()\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Define o modo verbose do xmode, que é utilizado no debug\n",
        "  # %xmode Verbose \n",
        "\n",
        "  \"\"\"\n",
        "    Comando usado no Jupyter Notebook para controlar o modo de exibição das informações de exceções.\n",
        "    O modo verbose é um modo detalhado que exibe informações adicionais ao imprimir as exceções.\n",
        "    Ele inclui as informações de pilha de chamadas completa e valores de variáveis locais e globais \n",
        "    no momento da exceção. Isso pode ser útil para depurar e encontrar a causa de exceções em seu código.\n",
        "    Ao usar %xmode Verbose, as informações de exceção serão impressas com mais detalhes e informações adicionais serão incluídas.\n",
        "\n",
        "    Caso queira desabilitar o modo verbose e utilizar o modo plain, \n",
        "    comentar a linha acima e descomentar a linha abaixo:\n",
        "    %xmode Plain\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "    Dica:\n",
        "    1.  pdb (Python Debugger)\n",
        "      Quando ocorre uma exceção em uma parte do código, o programa para a execução e exibe uma mensagem de erro \n",
        "      com informações sobre a exceção, como a linha do código em que ocorreu o erro e o tipo da exceção.\n",
        "\n",
        "      Se você estiver depurando o código e quiser examinar o estado das variáveis ​​e executar outras operações \n",
        "      no momento em que a exceção ocorreu, pode usar o pdb (Python Debugger). Para isso, é preciso colocar o comando %debug \n",
        "      logo após ocorrer a exceção. Isso fará com que o programa pare na linha em que ocorreu a exceção e abra o pdb,\n",
        "      permitindo que você explore o estado das variáveis, examine a pilha de chamadas e execute outras operações para depurar o código.\n",
        "\n",
        "\n",
        "    2. ipdb\n",
        "      O ipdb é um depurador interativo para o Python que oferece recursos mais avançados do que o pdb,\n",
        "      incluindo a capacidade de navegar pelo código fonte enquanto depura.\n",
        "      \n",
        "      Você pode começar a depurar seu código inserindo o comando ipdb.set_trace() em qualquer lugar do \n",
        "      seu código onde deseja pausar a execução e começar a depurar. Quando a execução chegar nessa linha, \n",
        "      o depurador entrará em ação, permitindo que você examine o estado atual do seu programa e execute \n",
        "      comandos para investigar o comportamento.\n",
        "\n",
        "      Durante a depuração, você pode usar comandos:\n",
        "        next (para executar a próxima linha de código), \n",
        "        step (para entrar em uma função chamada na próxima linha de código) \n",
        "        continue (para continuar a execução normalmente até o próximo ponto de interrupção).\n",
        "\n",
        "      Ao contrário do pdb, o ipdb é um depurador interativo que permite navegar pelo código fonte em que\n",
        "      está trabalhando enquanto depura, permitindo que você inspecione variáveis, defina pontos de interrupção\n",
        "      adicionais e até mesmo execute expressões Python no contexto do seu programa.\n",
        "  \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {
        "id": "Tb4aqtcExR84"
      },
      "outputs": [],
      "source": [
        "config_display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 393,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5Bq4043fkfh",
        "outputId": "fa8e5db1-1feb-4393-fb66-d394d1ad693c"
      },
      "outputs": [],
      "source": [
        "config_debug()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4WJ9VOUMHFz1"
      },
      "source": [
        "# Carregando queries geradas e textos dos documentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carregando as queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 394,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f\"{DIRETORIO_TRABALHO}/queries_geradas_102878.pickle\", 'rb') as outputFile:\n",
        "    dict_queries_geradas = pickle.load(outputFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "102878"
            ]
          },
          "execution_count": 395,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dict_queries_geradas)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baixando o dataset trec-covid para buscar o texto e depois gerar índice para busca dos exemplos negativos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 396,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Já existia a pasta\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(f\"{DIRETORIO_TREC_COVID}/corpus.jsonl.gz\"):\n",
        "    !wget https://huggingface.co/datasets/BeIR/trec-covid/resolve/main/corpus.jsonl.gz\n",
        "    !mv corpus.jsonl.gz {DIRETORIO_TREC_COVID}\n",
        "    print('Baixado')\n",
        "else:\n",
        "    print('Já existia a pasta')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descompacte o arquivo para a memória\n",
        "with gzip.open(f'{DIRETORIO_TREC_COVID}/corpus.jsonl.gz', 'rt') as f:\n",
        "    # Leia o conteúdo do arquivo descompactado\n",
        "    corpus = [json.loads(line) for line in f]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'> len(corpus): 171332 corpus[0] {'_id': 'ug7v899j', 'title': 'Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia', 'text': 'OBJECTIVE: This retrospective chart review describes the epidemiology and clinical features of 40 patients with culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia. METHODS: Patients with positive M. pneumoniae cultures from respiratory specimens from January 1997 through December 1998 were identified through the Microbiology records. Charts of patients were reviewed. RESULTS: 40 patients were identified, 33 (82.5%) of whom required admission. Most infections (92.5%) were community-acquired. The infection affected all age groups but was most common in infants (32.5%) and pre-school children (22.5%). It occurred year-round but was most common in the fall (35%) and spring (30%). More than three-quarters of patients (77.5%) had comorbidities. Twenty-four isolates (60%) were associated with pneumonia, 14 (35%) with upper respiratory tract infections, and 2 (5%) with bronchiolitis. Cough (82.5%), fever (75%), and malaise (58.8%) were the most common symptoms, and crepitations (60%), and wheezes (40%) were the most common signs. Most patients with pneumonia had crepitations (79.2%) but only 25% had bronchial breathing. Immunocompromised patients were more likely than non-immunocompromised patients to present with pneumonia (8/9 versus 16/31, P = 0.05). Of the 24 patients with pneumonia, 14 (58.3%) had uneventful recovery, 4 (16.7%) recovered following some complications, 3 (12.5%) died because of M pneumoniae infection, and 3 (12.5%) died due to underlying comorbidities. The 3 patients who died of M pneumoniae pneumonia had other comorbidities. CONCLUSION: our results were similar to published data except for the finding that infections were more common in infants and preschool children and that the mortality rate of pneumonia in patients with comorbidities was high.', 'metadata': {'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC35282/', 'pubmed_id': '11472636'}}\n"
          ]
        }
      ],
      "source": [
        "# Exiba os dados carregados\n",
        "print(f\"{type(corpus)} len(corpus): {len(corpus)} corpus[0] {corpus[0]}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus_dict = {}\n",
        "\n",
        "for docto in corpus:\n",
        "    if ('title' in docto) and len(docto['title']) >= 5:\n",
        "        texto_usado_na_geracao_de_query = docto['title'] + '. ' + docto['text']\n",
        "    else:\n",
        "        texto_usado_na_geracao_de_query = docto['text']\n",
        "    corpus_dict[docto['_id']] = {'text_query_generation': texto_usado_na_geracao_de_query, \n",
        "                                 'title': docto['title'],\n",
        "                                 'text': docto['text']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "171332\n"
          ]
        }
      ],
      "source": [
        "print(len(corpus_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(dict_keys(['text_query_generation', 'title', 'text']),\n",
              " 'Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia. OBJECTIVE: This retrospective chart review describes the epidemiology and clinical features of 40 patients with culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia. METHODS: Patients with positive M. pneumoniae cultures from respiratory specimens from January 1997 through December 1998 were identified through the Microbiology records. Charts of patients were reviewed. RESULTS: 40 patients were identified, 33 (82.5%) of whom required admission. Most infections (92.5%) were community-acquired. The infection affected all age groups but was most common in infants (32.5%) and pre-school children (22.5%). It occurred year-round but was most common in the fall (35%) and spring (30%). More than three-quarters of patients (77.5%) had comorbidities. Twenty-four isolates (60%) were associated with pneumonia, 14 (35%) with upper respiratory tract infections, and 2 (5%) with bronchiolitis. Cough (82.5%), fever (75%), and malaise (58.8%) were the most common symptoms, and crepitations (60%), and wheezes (40%) were the most common signs. Most patients with pneumonia had crepitations (79.2%) but only 25% had bronchial breathing. Immunocompromised patients were more likely than non-immunocompromised patients to present with pneumonia (8/9 versus 16/31, P = 0.05). Of the 24 patients with pneumonia, 14 (58.3%) had uneventful recovery, 4 (16.7%) recovered following some complications, 3 (12.5%) died because of M pneumoniae infection, and 3 (12.5%) died due to underlying comorbidities. The 3 patients who died of M pneumoniae pneumonia had other comorbidities. CONCLUSION: our results were similar to published data except for the finding that infections were more common in infants and preschool children and that the mortality rate of pneumonia in patients with comorbidities was high.')"
            ]
          },
          "execution_count": 401,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_dict['ug7v899j'].keys(),corpus_dict['ug7v899j']['text_query_generation']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Filtro de queries mais relevantes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lógica:\n",
        "\n",
        "         Para cada par docto com query gerada (<= usa: dict_queries_geradas):\n",
        "            Calcular índice de relevância conforme rankeador \n",
        "         Ordenar pelos primeiros <qtd_documento_filtrado> documentos \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calcular relevância entre queries geradas e documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b9687f745b78489c8d20b1b8e83a8a0c",
            "23d37e6a19cc44eb8fbbca2d532a6a7c",
            "e5b62351b5804bee903a9b40cff992df",
            "a7b0817200914363bc4804d37cedbe99",
            "a370f9920d65417c9cc3f1d7881d0923",
            "779528a697524011aa043155533eab2f",
            "0f7e722200c741348120db558964eb4b",
            "4f32d436738544418231bb9242ac66d1",
            "798f407e2f084992900952e90d0ae018",
            "8a8684e559484460b5eabaad70245441",
            "79c8028e18a744918e503d3218cf5b2c",
            "29b2a64024564bf0ad5238e5fa38e934",
            "00c0da6b84ad4100ac6bc560ba7dc4ab",
            "93dd402fe48e4936927162a39dde8147",
            "2c3deeabab2a450fb8596605fdf55d89",
            "94f25490266245b284286c8d8236c6ad",
            "0c8b23aa2672423c88624b84301e2496",
            "720cc4034b4e46c8b5abcf43fac2a7a2",
            "32ec1752eae842e58531e6e3d227767e",
            "10afa4deb9b94fecbb66211deea6137c",
            "15387ba3c44c4264be66682d9e4d8b28",
            "09ced38d656f46e1913988c55746307b",
            "be1898724fbb42e68d136cb607f84093",
            "1d0710e62acb43d7bc155a87b8c0afca",
            "d0ef69a90a4d45b6a45e2b69c7ffeed0",
            "4cc17cacd6ed43149d09f6bd50b5fc54",
            "ffb117d9a292489b90ca1f8a0bf9dfc9",
            "476dba5f604f448dabdfcf0670ff8f61",
            "e8a45538c72640529911ec6546ccfd6e",
            "9f4bad7c399343f69b38fecb4304f7a6",
            "270cf7305e364d6d9006abf50dc0b04d",
            "84605f9a0199417b881b8ca4022730ee",
            "4cdaa94bec484a82b19e2adf6f485f31",
            "7e97fba0f9fe4be899f42dbd42b5ac5a",
            "09cf49b152cb44aba8dacaf13f895901",
            "aeff355d3ed14827b1c5312a4931a9d3",
            "d444223480d44420b73ee4f1f4c40002",
            "3b1832012af647a3bddfbe28bde6c838",
            "ea8f9b6dcf054543ba8300f3b18d93ed",
            "f4cc04c7cc8a4a41aa467a6276428bc6",
            "1ee626011f7240c3ad716f82bfe2617a",
            "02b8904772b849509c011215456172a9",
            "5b85c7d845e4483d9522ad7810b56d24",
            "b2b2a003ae9743a894dbaa2d5045c465"
          ]
        },
        "id": "rsngiRh3NjDE",
        "outputId": "47e889a5-940a-48e9-cdc6-4de8162449cc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 405,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_workers_dataloader = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 406,
      "metadata": {},
      "outputs": [],
      "source": [
        "#const_nome_modelo = 'microsoft/MiniLM-L12-H384-uncased'\n",
        "const_nome_modelo = 'cross-encoder/ms-marco-TinyBERT-L-2'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(const_nome_modelo).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(const_nome_modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 407,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "execution_count": 407,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config.max_position_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "509"
            ]
          },
          "execution_count": 408,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.max_len_sentences_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "execution_count": 409,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.model_max_length"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_hs0ZWBmeOAi"
      },
      "source": [
        "### Criando código para o Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {
        "id": "XeakUpqJeQpz"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"\n",
        "      Classe para representar um dataset de texto e classes.\n",
        "    \"\"\"  \n",
        "    def __init__(self, texts: np.ndarray, classes:list[int], tokenizer):\n",
        "      \"\"\"\n",
        "      Inicializa um novo objeto MyDataset.\n",
        "\n",
        "      Args:\n",
        "          texts (np.ndarray): um array com as strings de texto. Cada linha deve ter 2 strings.\n",
        "          classes (np.ndarray): um array com as classes de cada texto.\n",
        "          tokenizer: um objeto tokenizer do Hugging Face Transformers.\n",
        "          max_seq_length (int): o tamanho máximo da sequência a ser considerado.\n",
        "      Raises:\n",
        "          AssertionError: se os parâmetros não estiverem no formato esperado.\n",
        "      \"\"\"\n",
        "      # Verifica se os parâmetros são do tipo esperado\n",
        "      assert isinstance(texts, np.ndarray), f\"Parâmetro texts deve ser do tipo np.ndarray e não {type(texts)}\"\n",
        "      assert texts.shape[1] == 2, \"Array must have 2 columns\"\n",
        "      for row in texts:\n",
        "          assert isinstance(row, np.ndarray) and row.shape == (2,), f\"Each row in texts must have 2 elements\"\n",
        "          assert isinstance(row[0], str) and isinstance(row[1], str), f\"Each element in texts.row must be a string e não {type(row[0])}\"\n",
        "      assert isinstance(classes,np.ndarray), f'classes deve ser do tipo np.ndarray e não {type(classes)}'\n",
        "      assert isinstance(classes[0],np.int64), f'classes[0] deve ser do tipo numpy.int64 e não {type(classes[0])} '\n",
        "\n",
        "      self.texts = texts\n",
        "      self.classes = classes\n",
        "      self.tokenizer = tokenizer\n",
        "      self.max_seq_length = tokenizer.model_max_length\n",
        "\n",
        "      # Salvar os dados dos tensores\n",
        "      x_data_input_ids = []\n",
        "      x_data_token_type_ids = []\n",
        "      x_data_attention_masks = []\n",
        "      for text_pair in tqdm(texts, desc='encoding text pair'):\n",
        "          encoding = tokenizer.encode_plus(\n",
        "              text_pair[0],\n",
        "              text_pair[1],\n",
        "              add_special_tokens=True,\n",
        "              max_length=self.max_seq_length,\n",
        "              padding='max_length',\n",
        "              return_tensors = 'pt',\n",
        "              truncation=True,\n",
        "              return_attention_mask=True,\n",
        "              return_token_type_ids=True\n",
        "          )\n",
        "          x_data_input_ids.append(encoding['input_ids'].long())\n",
        "          x_data_token_type_ids.append(encoding['token_type_ids'].long())\n",
        "          x_data_attention_masks.append(encoding['attention_mask'].long())\n",
        "      print(F'\\tVou converter lista para tensor;  Momento: {time.strftime(\"[%Y-%b-%d %H:%M:%S]\")}')\n",
        "      # squeeze: vai transformar um tensor de shape [2, 1, 322] em um tensor de shape [2, 322].\n",
        "\n",
        "      self.x_tensor_input_ids = torch.stack(x_data_input_ids).squeeze(1)\n",
        "      self.x_tensor_attention_masks = torch.stack(x_data_attention_masks).squeeze(1)\n",
        "      self.x_tensor_token_type_ids = torch.stack(x_data_token_type_ids).squeeze(1)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "          Retorna o tamanho do dataset (= tamanho do array texts)\n",
        "        \"\"\"\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "          Retorna um dicionário com os dados do texto e sua classe correspondente, em um formato que pode \n",
        "          ser usado pelo dataloader do PyTorch para alimentar um modelo de aprendizado de máquina.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'input_ids': self.x_tensor_input_ids[idx],\n",
        "            'attention_mask': self.x_tensor_attention_masks[idx],\n",
        "            'token_type_ids': self.x_tensor_token_type_ids[idx],\n",
        "            # 'labels': int(self.classes[idx])\n",
        "            'labels': torch.tensor(self.classes[idx], dtype=torch.long)            \n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17AcNhe2C4tb"
      },
      "source": [
        "#### Testando o MyDataset e o Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "id": "_tNkc8kmC8ie"
      },
      "outputs": [],
      "source": [
        "# Cria dados fictícios\n",
        "texts = np.array([['This is the first query', 'text associated with query 1'],\n",
        "                  ['This is the second query', 'text associated with query 2'],\n",
        "                  ['This is the third query', 'text associated with query 3'],\n",
        "                  ['This is the fourth query', 'text associated with query 4'],\n",
        "                  ['This is the fifty query', 'text associated with query 5'],\n",
        "                  ['This is the sixty query', 'text associated with query 6'],])\n",
        "classes = np.ones(len(texts), dtype=int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbaCMoKRDy20",
        "outputId": "1853f452-f5a4-4803-d33b-b0dd58c8ba65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "encoding text pair: 100%|██████████| 6/6 [00:00<00:00, 2786.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tVou converter lista para tensor;  Momento: [2023-mai-02 22:15:34]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Cria um objeto da classe MyDataset\n",
        "dummy_dataset = MyDataset(texts=texts, classes=classes, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 413,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFNuWyMYDz7v",
        "outputId": "f74ff3bd-84d6-42a8-a7de-88501b882de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([]) tensor(1) torch.Size([512])\n",
            "tensor([  101,  2023,  2003,  1996,  2034, 23032,   102,  3793,  3378,  2007,\n",
            "        23032,  1015,   102,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ],
      "source": [
        "# Testa o método __len__()\n",
        "assert len(dummy_dataset) == 6\n",
        "\n",
        "# Testa o método __getitem__()\n",
        "sample = dummy_dataset[0]\n",
        "assert set(sample.keys()) == {'input_ids', 'attention_mask', 'token_type_ids', 'labels'} # \n",
        "assert isinstance(sample['input_ids'], torch.Tensor)\n",
        "assert sample['input_ids'].shape[0] == tokenizer.model_max_length\n",
        "assert isinstance(sample['attention_mask'], torch.Tensor)\n",
        "assert sample['attention_mask'].shape[0] == tokenizer.model_max_length\n",
        "# assert isinstance(sample['labels'], int)\n",
        "assert isinstance(sample['labels'], torch.Tensor)\n",
        "print(sample['labels'].shape, sample['labels'], sample['input_ids'].shape)\n",
        "print(sample['input_ids'][:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "id": "5INVpV1RGuau"
      },
      "outputs": [],
      "source": [
        "dummy_loader = DataLoader(dummy_dataset, batch_size=2, shuffle=False, num_workers= num_workers_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 415,
      "metadata": {
        "id": "TeyvxkA3G93w"
      },
      "outputs": [],
      "source": [
        "first_batch = next(iter(dummy_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 416,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LozP3eU01QLu",
        "outputId": "8c01b043-8887-4ff1-c54e-e9113a5f00c1"
      },
      "outputs": [],
      "source": [
        "first_batch = BatchEncoding(first_batch).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRdGtm3_G9lv",
        "outputId": "37c4bce2-965f-4445-c3f3-708edbeec626"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 2023, 2003,  ...,    0,    0,    0],\n",
              "        [ 101, 2023, 2003,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0')}"
            ]
          },
          "execution_count": 417,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm53nP5pKW44"
      },
      "source": [
        "Confirmando efeito do parâmetro shuffle em DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCy-mUJDIiGj",
        "outputId": "af1f88e2-ac04-4875-838d-a77b4c7bf920"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 1it [00:00, 868.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 1])\n",
            "tensor([1, 1])\n",
            "tensor([1, 1])\n",
            "Fim época 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_loader = DataLoader(dummy_dataset, batch_size=2, shuffle=False, num_workers=num_workers_dataloader)\n",
        "for ndx, epoch in tqdm(enumerate(range(1)), desc='Epochs'):\n",
        "  for batch in dummy_loader:\n",
        "    print(batch['labels'])\n",
        "  print(f\"Fim época {ndx}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "id": "SPNgfp4WoiXg"
      },
      "outputs": [],
      "source": [
        "del dummy_loader, dummy_dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculando relevância para os pares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar um DataFrame a partir do dicionário\n",
        "df = pd.DataFrame.from_dict(dict_queries_geradas, orient='index', columns=['generated_query'])\n",
        "df['id_docto'] = df.index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 421,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_query</th>\n",
              "      <th>id_docto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of the finding that i...</td>\n",
              "      <td>ug7v899j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the significance of the presumed contr...</td>\n",
              "      <td>02tnwd4m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the significance of SP-D in the innate...</td>\n",
              "      <td>ejv2xln0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the significance of ET-1 in lung disease?</td>\n",
              "      <td>2b73a28n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the significance of the mucosal respon...</td>\n",
              "      <td>9785vg6d</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     generated_query  id_docto\n",
              "0  What is the significance of the finding that i...  ug7v899j\n",
              "1  What is the significance of the presumed contr...  02tnwd4m\n",
              "2  What is the significance of SP-D in the innate...  ejv2xln0\n",
              "3  What is the significance of ET-1 in lung disease?  2b73a28n\n",
              "4  What is the significance of the mucosal respon...  9785vg6d\n",
              "\n",
              "[5 rows x 2 columns]"
            ]
          },
          "execution_count": 422,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(102878, 2)"
            ]
          },
          "execution_count": 423,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['text_docto_query_generation'] = df['id_docto'].apply(lambda x: corpus_dict[x]['text_query_generation'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_query</th>\n",
              "      <th>id_docto</th>\n",
              "      <th>text_docto_query_generation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of the finding that i...</td>\n",
              "      <td>ug7v899j</td>\n",
              "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the significance of the presumed contr...</td>\n",
              "      <td>02tnwd4m</td>\n",
              "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the significance of SP-D in the innate...</td>\n",
              "      <td>ejv2xln0</td>\n",
              "      <td>Surfactant protein-D and pulmonary host defens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the significance of ET-1 in lung disease?</td>\n",
              "      <td>2b73a28n</td>\n",
              "      <td>Role of endothelin-1 in lung disease. Endothel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the significance of the mucosal respon...</td>\n",
              "      <td>9785vg6d</td>\n",
              "      <td>Gene expression in epithelial cells in respons...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     generated_query  id_docto                        text_docto_query_generation\n",
              "0  What is the significance of the finding that i...  ug7v899j  Clinical features of culture-proven Mycoplasma...\n",
              "1  What is the significance of the presumed contr...  02tnwd4m  Nitric oxide: a pro-inflammatory mediator in l...\n",
              "2  What is the significance of SP-D in the innate...  ejv2xln0  Surfactant protein-D and pulmonary host defens...\n",
              "3  What is the significance of ET-1 in lung disease?  2b73a28n  Role of endothelin-1 in lung disease. Endothel...\n",
              "4  What is the significance of the mucosal respon...  9785vg6d  Gene expression in epithelial cells in respons...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "execution_count": 425,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "id": "RvfCt_vJ28Au"
      },
      "outputs": [],
      "source": [
        "def calcula_relevancia(parm_model, parm_dataloader_reranking):\n",
        "  # para 'cross-encoder/ms-marco-TinyBERT-L-2'\n",
        "  prob_relevancia = []\n",
        "  parm_model.eval()\n",
        "  with torch.no_grad():\n",
        "      for ndx, batch in tqdm(enumerate(parm_dataloader_reranking), total=len(parm_dataloader_reranking), mininterval=0.5, desc='dataset_reranking', disable=False):\n",
        "          logits_model = parm_model(**BatchEncoding(batch).to(device)).logits                          \n",
        "          relevantes_float = [float(t) for t in logits_model]\n",
        "          prob_relevancia.extend(relevantes_float)          \n",
        "          # prob_relevancia.append(pa.array(scores.numpy()))\n",
        "  return prob_relevancia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MT5MpOcBfCl",
        "outputId": "a153d84f-92fb-47ed-e185-612b1ece94a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "carregando dataset\n",
            "(102878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "encoding text pair: 100%|██████████| 102878/102878 [01:45<00:00, 979.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tVou converter lista para tensor;  Momento: [2023-mai-02 22:17:43]\n",
            "CPU times: user 1min 45s, sys: 688 ms, total: 1min 46s\n",
            "Wall time: 1min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"carregando dataset\")  \n",
        "classes_dummy = np.zeros(len(dict_queries_geradas), dtype=np.int64)\n",
        "print(classes_dummy.shape)\n",
        "dataset_reranking = MyDataset(texts=df[['generated_query','text_docto_query_generation']].values, classes=classes_dummy, tokenizer=tokenizer)    \n",
        "# torch.save(dataset_reranking, path_treino+'dataset_reranking_input_layout_qp_len_'+str(hparam['num_sentenca_valid'])+'.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Limpa o cache da memória da GPU\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 429,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "id": "Ni6ZszRbBfCm"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "id": "K_vZwfZSBfCm"
      },
      "outputs": [],
      "source": [
        "dataloader_reranking = DataLoader(dataset_reranking,\n",
        "                                  batch_size= batch_size, \n",
        "                                  shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MUHIjATfDpT",
        "outputId": "2c85289e-4b32-474c-abeb-dc58885e6d91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "dataset_reranking: 100%|██████████| 3215/3215 [00:23<00:00, 136.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 23.5 s, sys: 21.7 ms, total: 23.5 s\n",
            "Wall time: 23.6 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prob_relevancia_query = calcula_relevancia(model,dataloader_reranking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "id": "FWG_u7lgCiSs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-2.144087314605713,\n",
              " 3.8457999229431152,\n",
              " 1.7638808488845825,\n",
              " 2.4114737510681152,\n",
              " 3.2398197650909424,\n",
              " 3.3087615966796875,\n",
              " 4.076657295227051,\n",
              " 3.372711181640625]"
            ]
          },
          "execution_count": 434,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prob_relevancia_query[:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['score_relevance'] = prob_relevancia_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_query</th>\n",
              "      <th>id_docto</th>\n",
              "      <th>text_docto_query_generation</th>\n",
              "      <th>score_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of the finding that i...</td>\n",
              "      <td>ug7v899j</td>\n",
              "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
              "      <td>-2.1440873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the significance of the presumed contr...</td>\n",
              "      <td>02tnwd4m</td>\n",
              "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
              "      <td>3.8457999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the significance of SP-D in the innate...</td>\n",
              "      <td>ejv2xln0</td>\n",
              "      <td>Surfactant protein-D and pulmonary host defens...</td>\n",
              "      <td>1.7638808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the significance of ET-1 in lung disease?</td>\n",
              "      <td>2b73a28n</td>\n",
              "      <td>Role of endothelin-1 in lung disease. Endothel...</td>\n",
              "      <td>2.4114738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the significance of the mucosal respon...</td>\n",
              "      <td>9785vg6d</td>\n",
              "      <td>Gene expression in epithelial cells in respons...</td>\n",
              "      <td>3.2398198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     generated_query  id_docto                        text_docto_query_generation  score_relevance\n",
              "0  What is the significance of the finding that i...  ug7v899j  Clinical features of culture-proven Mycoplasma...       -2.1440873\n",
              "1  What is the significance of the presumed contr...  02tnwd4m  Nitric oxide: a pro-inflammatory mediator in l...        3.8457999\n",
              "2  What is the significance of SP-D in the innate...  ejv2xln0  Surfactant protein-D and pulmonary host defens...        1.7638808\n",
              "3  What is the significance of ET-1 in lung disease?  2b73a28n  Role of endothelin-1 in lung disease. Endothel...        2.4114738\n",
              "4  What is the significance of the mucosal respon...  9785vg6d  Gene expression in epithelial cells in respons...        3.2398198\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "execution_count": 436,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Encontrar exemplos negativos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gerar índice com texto sem pré-processamento\n",
        "   \n",
        "      .. entrada: 171mil textos \n",
        "      .. saída: índice lucene (só de textos que tiveram queries geradas: exclui textos vazios)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Construindo o cardin com os textos usados na geração das queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/home/borela/fontes/deep_learning_em_buscas_unicamp/local/inpars/cardin',\n",
              " '/home/borela/fontes/deep_learning_em_buscas_unicamp/local/inpars/cardin/trec-covid-inpars.jsonl',\n",
              " '/home/borela/fontes/deep_learning_em_buscas_unicamp/local/inpars/indexes/trec-covid-index')"
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DIRETORIO_TREC_COVID_CARDIN, CAMINHO_CARDIN_TREC_COVID, DIRETORIO_INDICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 171332/171332 [00:00<00:00, 675781.39it/s]\n"
          ]
        }
      ],
      "source": [
        "jsonl_trecc_selecionada = []\n",
        "# Para cada índice único, armazena a lista de tokens correspondente\n",
        "for docto in tqdm(corpus):\n",
        "    if len(docto['text']) > 20:\n",
        "        if ('title' in docto) and len(docto['title']) >= 5 :\n",
        "            texto = docto['title'] + '. ' + docto['text'] \n",
        "        else:\n",
        "            texto = docto['text'] \n",
        "        jsonl_trecc_selecionada.append(\n",
        "            {\"id\": docto['_id'],\n",
        "            \"contents\": texto})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128924"
            ]
          },
          "execution_count": 265,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(jsonl_trecc_selecionada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 746 ms, sys: 108 ms, total: 854 ms\n",
            "Wall time: 856 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "with open(CAMINHO_CARDIN_TREC_COVID, 'w') as arquivo:\n",
        "    for doc in jsonl_trecc_selecionada:\n",
        "        # Converte o dicionário em uma string JSON\n",
        "        linha_json = json.dumps(doc)\n",
        "        # Escreve a linha JSON no arquivo\n",
        "        arquivo.write(f'{linha_json}\\n')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Criando o índice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['JVM_PATH'] = '/usr/lib/jvm/java-11-openjdk-amd64/lib/server/libjvm.so'\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-11-openjdk-amd64'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyserini.search import SimpleSearcher\n",
        "from pyserini.search.lucene import LuceneSearcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
            "2023-05-01 13:30:59,395 INFO  [main] index.IndexCollection (IndexCollection.java:380) - Setting log level to INFO\n",
            "2023-05-01 13:30:59,396 INFO  [main] index.IndexCollection (IndexCollection.java:383) - Starting indexer...\n",
            "2023-05-01 13:30:59,396 INFO  [main] index.IndexCollection (IndexCollection.java:384) - ============ Loading Parameters ============\n",
            "2023-05-01 13:30:59,396 INFO  [main] index.IndexCollection (IndexCollection.java:385) - DocumentCollection path: /home/borela/fontes/deep_learning_em_buscas_unicamp/local/inpars/cardin\n",
            "2023-05-01 13:30:59,396 INFO  [main] index.IndexCollection (IndexCollection.java:386) - CollectionClass: JsonCollection\n",
            "2023-05-01 13:30:59,397 INFO  [main] index.IndexCollection (IndexCollection.java:387) - Generator: DefaultLuceneDocumentGenerator\n",
            "2023-05-01 13:30:59,397 INFO  [main] index.IndexCollection (IndexCollection.java:388) - Threads: 9\n",
            "2023-05-01 13:30:59,397 INFO  [main] index.IndexCollection (IndexCollection.java:389) - Language: en\n",
            "2023-05-01 13:30:59,397 INFO  [main] index.IndexCollection (IndexCollection.java:390) - Stemmer: porter\n",
            "2023-05-01 13:30:59,397 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Keep stopwords? false\n",
            "2023-05-01 13:30:59,397 INFO  [main] index.IndexCollection (IndexCollection.java:392) - Stopwords: null\n",
            "2023-05-01 13:30:59,398 INFO  [main] index.IndexCollection (IndexCollection.java:393) - Store positions? true\n",
            "2023-05-01 13:30:59,398 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Store docvectors? true\n",
            "2023-05-01 13:30:59,398 INFO  [main] index.IndexCollection (IndexCollection.java:395) - Store document \"contents\" field? false\n",
            "2023-05-01 13:30:59,398 INFO  [main] index.IndexCollection (IndexCollection.java:396) - Store document \"raw\" field? true\n",
            "2023-05-01 13:30:59,398 INFO  [main] index.IndexCollection (IndexCollection.java:397) - Additional fields to index: []\n",
            "2023-05-01 13:30:59,398 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Optimize (merge segments)? false\n",
            "2023-05-01 13:30:59,398 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Whitelist: null\n",
            "2023-05-01 13:30:59,398 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Pretokenized?: false\n",
            "2023-05-01 13:30:59,399 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Index path: /home/borela/fontes/deep_learning_em_buscas_unicamp/local/inpars/indexes/trec-covid-index\n",
            "2023-05-01 13:30:59,427 INFO  [main] index.IndexCollection (IndexCollection.java:481) - ============ Indexing Collection ============\n",
            "2023-05-01 13:30:59,460 INFO  [main] index.IndexCollection (IndexCollection.java:468) - Using DefaultEnglishAnalyzer\n",
            "2023-05-01 13:30:59,460 INFO  [main] index.IndexCollection (IndexCollection.java:469) - Stemmer: porter\n",
            "2023-05-01 13:30:59,461 INFO  [main] index.IndexCollection (IndexCollection.java:470) - Keep stopwords? false\n",
            "2023-05-01 13:30:59,461 INFO  [main] index.IndexCollection (IndexCollection.java:471) - Stopwords file: null\n",
            "2023-05-01 13:30:59,597 INFO  [main] index.IndexCollection (IndexCollection.java:510) - Thread pool with 9 threads initialized.\n",
            "2023-05-01 13:30:59,598 INFO  [main] index.IndexCollection (IndexCollection.java:512) - Initializing collection in /home/borela/fontes/deep_learning_em_buscas_unicamp/local/inpars/cardin\n",
            "2023-05-01 13:30:59,599 INFO  [main] index.IndexCollection (IndexCollection.java:521) - 1 file found\n",
            "2023-05-01 13:30:59,599 INFO  [main] index.IndexCollection (IndexCollection.java:522) - Starting to index...\n",
            "2023-05-01 13:31:17,099 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - cardin/trec-covid-inpars.jsonl: 128924 docs added.\n",
            "2023-05-01 13:31:19,898 INFO  [main] index.IndexCollection (IndexCollection.java:578) - Indexing Complete! 128.924 documents indexed\n",
            "2023-05-01 13:31:19,898 INFO  [main] index.IndexCollection (IndexCollection.java:579) - ============ Final Counter Values ============\n",
            "2023-05-01 13:31:19,898 INFO  [main] index.IndexCollection (IndexCollection.java:580) - indexed:          128.924\n",
            "2023-05-01 13:31:19,898 INFO  [main] index.IndexCollection (IndexCollection.java:581) - unindexable:            0\n",
            "2023-05-01 13:31:19,898 INFO  [main] index.IndexCollection (IndexCollection.java:582) - empty:                  0\n",
            "2023-05-01 13:31:19,899 INFO  [main] index.IndexCollection (IndexCollection.java:583) - skipped:                0\n",
            "2023-05-01 13:31:19,899 INFO  [main] index.IndexCollection (IndexCollection.java:584) - errors:                 0\n",
            "2023-05-01 13:31:19,920 INFO  [main] index.IndexCollection (IndexCollection.java:587) - Total 128.924 documents indexed in 00:00:20\n"
          ]
        }
      ],
      "source": [
        "!python -m pyserini.index.lucene \\\n",
        "  --collection JsonCollection \\\n",
        "  --input {DIRETORIO_TREC_COVID_CARDIN} \\\n",
        "  --index {DIRETORIO_INDICE} \\\n",
        "  --generator DefaultLuceneDocumentGenerator \\\n",
        "  --threads 9 \\\n",
        "  --storePositions --storeDocvectors --storeRaw\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Realizando a busca e atualizando em df_sorted_by_relevance a lista de exemplos negativos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {},
      "outputs": [],
      "source": [
        "# realizando busca e salvando dados do estágio 1\n",
        "searcher = LuceneSearcher(DIRETORIO_INDICE)\n",
        "searcher.set_bm25(k1=0.82, b=0.68)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_max_hits = 1000\n",
        "num_negative_example = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "102878it [58:46, 29.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 2s, sys: 3.09 s, total: 1h 5s\n",
            "Wall time: 58min 46s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "negative_ids = []\n",
        "for idx, registro in tqdm(df.iterrows()):\n",
        "    query_text = registro['generated_query']\n",
        "    hits = searcher.search(query_text, num_max_hits)\n",
        "    if len(hits)>0:\n",
        "        indices_selecao = np.random.randint(0, high=len(hits), size=num_negative_example)\n",
        "        negative_ids.append([hits[ndx].docid for ndx in indices_selecao])\n",
        "    else:\n",
        "        negative_ids.append([])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adicionar a lista como uma nova coluna no dataframe\n",
        "df['negative_ids'] = negative_ids"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Excluir queries que não lograram sucesso na busca (visto um caso que o texto era \"nneneneneeeeeee\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_query</th>\n",
              "      <th>id_docto</th>\n",
              "      <th>text_docto_query_generation</th>\n",
              "      <th>score_relevance</th>\n",
              "      <th>negative_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>𝑛𝑒𝑡𝑒𝑡𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒�</td>\n",
              "      <td>5dk231qs</td>\n",
              "      <td>Torsional restraint: a new twist on frameshift...</td>\n",
              "      <td>-6.5541410</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>𝑛𝑒𝑡𝑒𝑡𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒�</td>\n",
              "      <td>noscodew</td>\n",
              "      <td>Cell-penetrating peptides as transporters for ...</td>\n",
              "      <td>-5.5144677</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>𝑛𝑡𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟�</td>\n",
              "      <td>6lezilfv</td>\n",
              "      <td>Host Gene Expression Profiling of Dengue Virus...</td>\n",
              "      <td>-6.2530360</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛�</td>\n",
              "      <td>fpsyem7x</td>\n",
              "      <td>Endothelial Cells Support Persistent Gammaherp...</td>\n",
              "      <td>-5.8792858</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>𝑛𝑒𝑡𝑒𝑡𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒</td>\n",
              "      <td>928pkpv2</td>\n",
              "      <td>Rift Valley Fever Virus NSs Protein Promotes P...</td>\n",
              "      <td>-6.0086517</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102379</th>\n",
              "      <td>𝑛𝑒𝑛𝑒𝑛𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒�</td>\n",
              "      <td>fxtzitpk</td>\n",
              "      <td>Structures of MERS-CoV spike glycoprotein in c...</td>\n",
              "      <td>-6.2074203</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102404</th>\n",
              "      <td>?</td>\n",
              "      <td>9g3gvkgr</td>\n",
              "      <td>Numbers with little meaning. Estimates of covi...</td>\n",
              "      <td>-6.6821342</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102460</th>\n",
              "      <td>̶W̶h̶e̶r̶e̶ ̶i̶s̶ ̶t̶h̶e̶ ̶i̶n̶t̶e̶r̶f̶e̶n̶s̶i...</td>\n",
              "      <td>4elisewv</td>\n",
              "      <td>Antiviral Innate Immunity: Introduction☆. Abst...</td>\n",
              "      <td>-6.4218655</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102678</th>\n",
              "      <td>𝑛𝑡𝑟𝑜𝑙𝑒𝑟𝑜𝑛𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑛𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑛𝑒𝑟�</td>\n",
              "      <td>78dznsqw</td>\n",
              "      <td>The aqueous extract from Toona sinensis leaves...</td>\n",
              "      <td>-6.0982895</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102862</th>\n",
              "      <td>𝑛𝑒𝑛𝑒𝑛𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒</td>\n",
              "      <td>675lfem3</td>\n",
              "      <td>Engineering a novel endopeptidase based on SAR...</td>\n",
              "      <td>-6.2511234</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          generated_query  id_docto                        text_docto_query_generation  score_relevance negative_ids\n",
              "26                           𝑛𝑒𝑡𝑒𝑡𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒�  5dk231qs  Torsional restraint: a new twist on frameshift...       -6.5541410           []\n",
              "106                          𝑛𝑒𝑡𝑒𝑡𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒�  noscodew  Cell-penetrating peptides as transporters for ...       -5.5144677           []\n",
              "114                          𝑛𝑡𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑙𝑒𝑟�  6lezilfv  Host Gene Expression Profiling of Dengue Virus...       -6.2530360           []\n",
              "172                          𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛𝑒𝑛�  fpsyem7x  Endothelial Cells Support Persistent Gammaherp...       -5.8792858           []\n",
              "206                          𝑛𝑒𝑡𝑒𝑡𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒  928pkpv2  Rift Valley Fever Virus NSs Protein Promotes P...       -6.0086517           []\n",
              "...                                                   ...       ...                                                ...              ...          ...\n",
              "102379                       𝑛𝑒𝑛𝑒𝑛𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒�  fxtzitpk  Structures of MERS-CoV spike glycoprotein in c...       -6.2074203           []\n",
              "102404                                                  ?  9g3gvkgr  Numbers with little meaning. Estimates of covi...       -6.6821342           []\n",
              "102460  ̶W̶h̶e̶r̶e̶ ̶i̶s̶ ̶t̶h̶e̶ ̶i̶n̶t̶e̶r̶f̶e̶n̶s̶i...  4elisewv  Antiviral Innate Immunity: Introduction☆. Abst...       -6.4218655           []\n",
              "102678                       𝑛𝑡𝑟𝑜𝑙𝑒𝑟𝑜𝑛𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑛𝑒𝑟𝑜𝑙𝑒𝑟𝑜𝑛𝑒𝑟�  78dznsqw  The aqueous extract from Toona sinensis leaves...       -6.0982895           []\n",
              "102862                       𝑛𝑒𝑛𝑒𝑛𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒  675lfem3  Engineering a novel endopeptidase based on SAR...       -6.2511234           []\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "execution_count": 441,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['negative_ids'].apply(lambda x: len(x) == 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[df['negative_ids'].apply(lambda x: len(x) > 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_query</th>\n",
              "      <th>id_docto</th>\n",
              "      <th>text_docto_query_generation</th>\n",
              "      <th>score_relevance</th>\n",
              "      <th>negative_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of the finding that i...</td>\n",
              "      <td>ug7v899j</td>\n",
              "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
              "      <td>-2.1440873</td>\n",
              "      <td>[onqy3xyu, 0zas25r9, 7ambsarg, d2tfg3af, 9sxxa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the significance of the presumed contr...</td>\n",
              "      <td>02tnwd4m</td>\n",
              "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
              "      <td>3.8457999</td>\n",
              "      <td>[1a1ryj8b, ls2nud43, blbaqbo7, xn6oomgn, 4fcyo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the significance of SP-D in the innate...</td>\n",
              "      <td>ejv2xln0</td>\n",
              "      <td>Surfactant protein-D and pulmonary host defens...</td>\n",
              "      <td>1.7638808</td>\n",
              "      <td>[1ijxfc1v, vtkhwj57, jqqaffaw, 3w6hivv8, y8ry0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the significance of ET-1 in lung disease?</td>\n",
              "      <td>2b73a28n</td>\n",
              "      <td>Role of endothelin-1 in lung disease. Endothel...</td>\n",
              "      <td>2.4114738</td>\n",
              "      <td>[ciz3xai2, add4i1c9, ch8dfex0, u61mcemm, z8j6w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the significance of the mucosal respon...</td>\n",
              "      <td>9785vg6d</td>\n",
              "      <td>Gene expression in epithelial cells in respons...</td>\n",
              "      <td>3.2398198</td>\n",
              "      <td>[l5ok3bvx, bkr3wmku, xanewi59, 2j4pjjwk, sp212...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     generated_query  id_docto                        text_docto_query_generation  score_relevance                                       negative_ids\n",
              "0  What is the significance of the finding that i...  ug7v899j  Clinical features of culture-proven Mycoplasma...       -2.1440873  [onqy3xyu, 0zas25r9, 7ambsarg, d2tfg3af, 9sxxa...\n",
              "1  What is the significance of the presumed contr...  02tnwd4m  Nitric oxide: a pro-inflammatory mediator in l...        3.8457999  [1a1ryj8b, ls2nud43, blbaqbo7, xn6oomgn, 4fcyo...\n",
              "2  What is the significance of SP-D in the innate...  ejv2xln0  Surfactant protein-D and pulmonary host defens...        1.7638808  [1ijxfc1v, vtkhwj57, jqqaffaw, 3w6hivv8, y8ry0...\n",
              "3  What is the significance of ET-1 in lung disease?  2b73a28n  Role of endothelin-1 in lung disease. Endothel...        2.4114738  [ciz3xai2, add4i1c9, ch8dfex0, u61mcemm, z8j6w...\n",
              "4  What is the significance of the mucosal respon...  9785vg6d  Gene expression in epithelial cells in respons...        3.2398198  [l5ok3bvx, bkr3wmku, xanewi59, 2j4pjjwk, sp212...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "execution_count": 443,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 444,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(101878, 5)"
            ]
          },
          "execution_count": 444,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ordenar pelos primeiros <qtd_documento_filtrado> documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sorted_by_relevance = df.sort_values('score_relevance', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 446,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_query</th>\n",
              "      <th>id_docto</th>\n",
              "      <th>text_docto_query_generation</th>\n",
              "      <th>score_relevance</th>\n",
              "      <th>negative_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>83756</th>\n",
              "      <td>What is the importance of COVID-19 information...</td>\n",
              "      <td>vpowumff</td>\n",
              "      <td>Availability of COVID-19 information from nati...</td>\n",
              "      <td>5.0976543</td>\n",
              "      <td>[t4wofvv4, 4567mu8n, v9oqlouj, 6d25aq3i, rgeel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51386</th>\n",
              "      <td>What is the impact of COVID-19 lockdown on hou...</td>\n",
              "      <td>l813q689</td>\n",
              "      <td>COVID-19 Lockdown in a Kenyan Informal Settlem...</td>\n",
              "      <td>5.0703812</td>\n",
              "      <td>[3tjem9ny, 6x0nzxpz, ev8ap5fa, udhvfos0, ge70t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83755</th>\n",
              "      <td>What is the importance of COVID-19 information...</td>\n",
              "      <td>pq0jrvi6</td>\n",
              "      <td>Availability of COVID-19 Information From Nati...</td>\n",
              "      <td>5.0661101</td>\n",
              "      <td>[nfklfcw6, 4567mu8n, p3egbdrw, d0v3d730, 1i0hz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69750</th>\n",
              "      <td>What is the importance of risk perception asse...</td>\n",
              "      <td>nkz53jzy</td>\n",
              "      <td>Risk Perception of COVID-19 Among the Portugue...</td>\n",
              "      <td>5.0235000</td>\n",
              "      <td>[qcr1fl8s, unzbduqk, bnnl700a, 4dv6954b, j8h7e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53173</th>\n",
              "      <td>\"We've Cared for the Dead since We Started Car...</td>\n",
              "      <td>g2beiwe4</td>\n",
              "      <td>“We've Cared for the Dead since We Started Car...</td>\n",
              "      <td>5.0054770</td>\n",
              "      <td>[wlrcaypa, ceo6gfgc, 0prx2rfp, vhvngxzm, w1d2k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15926</th>\n",
              "      <td>何内容?</td>\n",
              "      <td>irqyqa9b</td>\n",
              "      <td>Overview of Data Visualization. This chapter w...</td>\n",
              "      <td>-7.0421448</td>\n",
              "      <td>[f1airzpg, 9svv192k, 9svv192k, h81q345m, lze5g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14383</th>\n",
              "      <td>何が良いのか?</td>\n",
              "      <td>yjcb1stx</td>\n",
              "      <td>Spectral Clustering by Subspace Randomization ...</td>\n",
              "      <td>-7.0431447</td>\n",
              "      <td>[trjtmyef, aezp1isw, k8o0cuby, 20suvitt, yk3fp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91591</th>\n",
              "      <td>What is the importance of early recognition an...</td>\n",
              "      <td>wkrl4hrz</td>\n",
              "      <td>A Trip through Southeast Asian Airports in Tim...</td>\n",
              "      <td>-7.0432777</td>\n",
              "      <td>[0m3svdmy, z0sfqbfr, clc0bggd, wat7s3cl, 4k4qk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10131</th>\n",
              "      <td>何者が言いたいのか?</td>\n",
              "      <td>od0fr8l0</td>\n",
              "      <td>Epidemic-Logistics Network Considering Time Wi...</td>\n",
              "      <td>-7.0434837</td>\n",
              "      <td>[04zs475e, kvbh5poh, fmnij1ta, 0kxail2v, e9nz2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99695</th>\n",
              "      <td>What is the impact of the COVID-19 pandemic on...</td>\n",
              "      <td>k53eufio</td>\n",
              "      <td>Linking resource supplies and price drivers: L...</td>\n",
              "      <td>-7.0478392</td>\n",
              "      <td>[f936bioj, s3lfn8th, 0jlvx2kf, xkbo4mlq, 16hlv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101878 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         generated_query  id_docto                        text_docto_query_generation  score_relevance                                       negative_ids\n",
              "83756  What is the importance of COVID-19 information...  vpowumff  Availability of COVID-19 information from nati...        5.0976543  [t4wofvv4, 4567mu8n, v9oqlouj, 6d25aq3i, rgeel...\n",
              "51386  What is the impact of COVID-19 lockdown on hou...  l813q689  COVID-19 Lockdown in a Kenyan Informal Settlem...        5.0703812  [3tjem9ny, 6x0nzxpz, ev8ap5fa, udhvfos0, ge70t...\n",
              "83755  What is the importance of COVID-19 information...  pq0jrvi6  Availability of COVID-19 Information From Nati...        5.0661101  [nfklfcw6, 4567mu8n, p3egbdrw, d0v3d730, 1i0hz...\n",
              "69750  What is the importance of risk perception asse...  nkz53jzy  Risk Perception of COVID-19 Among the Portugue...        5.0235000  [qcr1fl8s, unzbduqk, bnnl700a, 4dv6954b, j8h7e...\n",
              "53173  \"We've Cared for the Dead since We Started Car...  g2beiwe4  “We've Cared for the Dead since We Started Car...        5.0054770  [wlrcaypa, ceo6gfgc, 0prx2rfp, vhvngxzm, w1d2k...\n",
              "...                                                  ...       ...                                                ...              ...                                                ...\n",
              "15926                                               何内容?  irqyqa9b  Overview of Data Visualization. This chapter w...       -7.0421448  [f1airzpg, 9svv192k, 9svv192k, h81q345m, lze5g...\n",
              "14383                                            何が良いのか?  yjcb1stx  Spectral Clustering by Subspace Randomization ...       -7.0431447  [trjtmyef, aezp1isw, k8o0cuby, 20suvitt, yk3fp...\n",
              "91591  What is the importance of early recognition an...  wkrl4hrz  A Trip through Southeast Asian Airports in Tim...       -7.0432777  [0m3svdmy, z0sfqbfr, clc0bggd, wat7s3cl, 4k4qk...\n",
              "10131                                         何者が言いたいのか?  od0fr8l0  Epidemic-Logistics Network Considering Time Wi...       -7.0434837  [04zs475e, kvbh5poh, fmnij1ta, 0kxail2v, e9nz2...\n",
              "99695  What is the impact of the COVID-19 pandemic on...  k53eufio  Linking resource supplies and price drivers: L...       -7.0478392  [f936bioj, s3lfn8th, 0jlvx2kf, xkbo4mlq, 16hlv...\n",
              "\n",
              "[101878 rows x 5 columns]"
            ]
          },
          "execution_count": 446,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sorted_by_relevance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8tWDQiXCiSt",
        "outputId": "19961246-1a2e-48bd-c38c-b9ba5a2254b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(101878, 5)"
            ]
          },
          "execution_count": 447,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sorted_by_relevance.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Salvar arquivos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f\"{DIRETORIO_TRABALHO}/df_sorted_by_relevance_{len(df_sorted_by_relevance)}.pickle\", 'wb') as outputFile:\n",
        "    pickle.dump(df_sorted_by_relevance, outputFile, pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apenas com os <qtd_mais_relevantes>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 449,
      "metadata": {},
      "outputs": [],
      "source": [
        "qtd_documento_filtrado = 30000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "execution_count": 450,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qtd_mais_relevantes = min(qtd_documento_filtrado,len(df_sorted_by_relevance))\n",
        "qtd_mais_relevantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f\"{DIRETORIO_TRABALHO}/df_sorted_by_relevance_{qtd_mais_relevantes}_mais_relevantes.pickle\", 'wb') as outputFile:\n",
        "    pickle.dump(df_sorted_by_relevance[:qtd_mais_relevantes], outputFile, pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Salvar dados em formato para fazer upload do split em dataset huggingface"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do meu split (usando semente meu número na planilha da tarefa no [classoom](https://docs.google.com/spreadsheets/u/0/d/1mvA8ZrN2FjPxIDwJkYJGsVdZNH49Z1w1L0_3pIAZhQo/htmlview#gid=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_semente = 13 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "metadata": {
        "id": "UJGxQIrdaVp4"
      },
      "outputs": [],
      "source": [
        "inicializa_seed(num_semente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "metadata": {},
      "outputs": [],
      "source": [
        "indices_docto_my_split = np.random.randint(0, high=len(corpus)-1, size=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 455,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_doc_id_my_split = [corpus[ndx]['_id'] for ndx in indices_docto_my_split]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 456,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_my_split = df_sorted_by_relevance[df_sorted_by_relevance['id_docto'].isin(list_doc_id_my_split)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11322, 5)"
            ]
          },
          "execution_count": 457,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_my_split.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 458,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 458,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_registros = min(len(df_my_split), 1000)\n",
        "num_registros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 459,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_my_split = df_my_split[:num_registros]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f\"{DIRETORIO_TRABALHO}/df_sorted_by_relevance_split_borela_{num_registros}_v2.pickle\", 'wb') as outputFile:\n",
        "    pickle.dump(df_my_split, outputFile, pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets_username = 'unicamp-dl/trec-covid-experiment'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "hugging_face_token = getpass.getpass('Informe seu_token de API para acesso ao hugging face')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading builder script: 100%|██████████| 2.18k/2.18k [00:00<00:00, 3.11MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset trec-covid-experiment/default to /home/borela/.cache/huggingface/datasets/unicamp-dl___trec-covid-experiment/default/0.0.0/39177de766cb7ace6cb0b5a27f1db36700b181fd775fbd271589004af3109267...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading data: 100%|██████████| 309/309 [00:00<00:00, 348kB/s]\n",
            "Downloading data: 100%|██████████| 346/346 [00:00<00:00, 469kB/s]it/s]\n",
            "Downloading data: 100%|██████████| 185k/185k [00:00<00:00, 1.39MB/s]s]\n",
            "Downloading data: 100%|██████████| 255k/255k [00:00<00:00, 4.97MB/s]s]\n",
            "Downloading data: 100%|██████████| 152k/152k [00:00<00:00, 4.26MB/s]s]\n",
            "Downloading data: 100%|██████████| 311k/311k [00:00<00:00, 921kB/s]/s]\n",
            "Downloading data: 100%|██████████| 627k/627k [00:00<00:00, 2.60MB/s]s]\n",
            "Downloading data: 100%|██████████| 280k/280k [00:00<00:00, 834kB/s]/s]\n",
            "Downloading data: 100%|██████████| 307k/307k [00:00<00:00, 5.24MB/s]s]\n",
            "Downloading data: 100%|██████████| 238k/238k [00:00<00:00, 4.85MB/s]s]\n",
            "Downloading data: 100%|██████████| 237k/237k [00:00<00:00, 1.74MB/s]/s]\n",
            "Downloading data files: 100%|██████████| 11/11 [00:06<00:00,  1.83it/s]\n",
            "                                                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset trec-covid-experiment downloaded and prepared to /home/borela/.cache/huggingface/datasets/unicamp-dl___trec-covid-experiment/default/0.0.0/39177de766cb7ace6cb0b5a27f1db36700b181fd775fbd271589004af3109267. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1420.40it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ds = datasets.load_dataset(datasets_username, \n",
        "                            download_mode='force_redownload',\n",
        "                            use_auth_token=hugging_face_token)\n",
        "                            # Outros possíveis parâmetros\n",
        "                            # split='train', \n",
        "                            # ignore_verifications=False,\n",
        "                            # beam_pipeline_options=None,\n",
        "                            # cache_dir=None,\n",
        "                            # revision=None,\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    example: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 3\n",
              "    })\n",
              "    example2: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 3\n",
              "    })\n",
              "    eduseiti_100_queries_expansion_20230501_01: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 463\n",
              "    })\n",
              "    leandro_carisio_01: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 1001\n",
              "    })\n",
              "    thales_1k_generated_queries_20230429: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    manoel_1k_generated_queries_20230430: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    manoel_2k_generated_queries_20230501: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    thiago_laitz_1k_queries: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    mirelle_1k_generated_queries_20230501: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 999\n",
              "    })\n",
              "    hugo_padovani_query_generation: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 979\n",
              "    })\n",
              "    marcus_borela_1k_gptj6b_20230501: Dataset({\n",
              "        features: ['query', 'positive_doc_id', 'negative_doc_ids'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 358,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': ['What is the significance of the speculation about the catastrophe that awaits once COVID-19 establishes itself in the poorest communities of South Africa?'],\n",
              " 'positive_doc_id': ['jmn8ctlt'],\n",
              " 'negative_doc_ids': [['n26csuks',\n",
              "   '09jyekp5',\n",
              "   'g5bhkd55',\n",
              "   'x1xzcacy',\n",
              "   'qv794vbt']]}"
            ]
          },
          "execution_count": 360,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds['marcus_borela_1k_gptj6b_20230501'][:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>positive_doc_id</th>\n",
              "      <th>negative_doc_ids</th>\n",
              "      <th>origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is a example query 1</td>\n",
              "      <td>doc1</td>\n",
              "      <td>[xxx, yyy, zzz]</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is another example query</td>\n",
              "      <td>doc2</td>\n",
              "      <td>[aaa, bbb, ccc]</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Example of query with no negative doc_ids</td>\n",
              "      <td>doc2</td>\n",
              "      <td>[]</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is a example query 1 (file 2)</td>\n",
              "      <td>doc12222</td>\n",
              "      <td>[xxx, yyy, zzz]</td>\n",
              "      <td>example2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is another example query (file 2)</td>\n",
              "      <td>doc12345</td>\n",
              "      <td>[aaa, bbb, ccc]</td>\n",
              "      <td>example2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9443</th>\n",
              "      <td>What is the significance of the phylogeny of t...</td>\n",
              "      <td>28nv3b8a</td>\n",
              "      <td>[0sedbv51, m8lrc4c0, i6puqauk, bp8dqis1, exlsn...</td>\n",
              "      <td>marcus_borela_1k_gptj6b_20230501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9444</th>\n",
              "      <td>What is the significance of the accuracy of th...</td>\n",
              "      <td>sffuejo1</td>\n",
              "      <td>[go4d8jwn, n5gk1xhb, edunzo0f, xk2a7tsw, 6l888...</td>\n",
              "      <td>marcus_borela_1k_gptj6b_20230501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9445</th>\n",
              "      <td>What is the significance of the low fecundity ...</td>\n",
              "      <td>3dyatdlv</td>\n",
              "      <td>[azv9yw9n, r55fe25x, wc23tqv2, vqmqnipq, d0dni...</td>\n",
              "      <td>marcus_borela_1k_gptj6b_20230501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9446</th>\n",
              "      <td>What is the significance of regional and natio...</td>\n",
              "      <td>jps1j60a</td>\n",
              "      <td>[uu4k2j2a, mo4luyx6, mnt12ot2, fex8sd1t, fex8s...</td>\n",
              "      <td>marcus_borela_1k_gptj6b_20230501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9447</th>\n",
              "      <td>What is the significance of the use of small m...</td>\n",
              "      <td>oa3x63xd</td>\n",
              "      <td>[jk62vnz0, zwo7e7gy, twcwhgun, w5s8anjj, z22a5...</td>\n",
              "      <td>marcus_borela_1k_gptj6b_20230501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9448 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  query positive_doc_id                                   negative_doc_ids                            origin\n",
              "0                             This is a example query 1            doc1                                    [xxx, yyy, zzz]                           example\n",
              "1                         This is another example query            doc2                                    [aaa, bbb, ccc]                           example\n",
              "2             Example of query with no negative doc_ids            doc2                                                 []                           example\n",
              "3                    This is a example query 1 (file 2)        doc12222                                    [xxx, yyy, zzz]                          example2\n",
              "4                This is another example query (file 2)        doc12345                                    [aaa, bbb, ccc]                          example2\n",
              "...                                                 ...             ...                                                ...                               ...\n",
              "9443  What is the significance of the phylogeny of t...        28nv3b8a  [0sedbv51, m8lrc4c0, i6puqauk, bp8dqis1, exlsn...  marcus_borela_1k_gptj6b_20230501\n",
              "9444  What is the significance of the accuracy of th...        sffuejo1  [go4d8jwn, n5gk1xhb, edunzo0f, xk2a7tsw, 6l888...  marcus_borela_1k_gptj6b_20230501\n",
              "9445  What is the significance of the low fecundity ...        3dyatdlv  [azv9yw9n, r55fe25x, wc23tqv2, vqmqnipq, d0dni...  marcus_borela_1k_gptj6b_20230501\n",
              "9446  What is the significance of regional and natio...        jps1j60a  [uu4k2j2a, mo4luyx6, mnt12ot2, fex8sd1t, fex8s...  marcus_borela_1k_gptj6b_20230501\n",
              "9447  What is the significance of the use of small m...        oa3x63xd  [jk62vnz0, zwo7e7gy, twcwhgun, w5s8anjj, z22a5...  marcus_borela_1k_gptj6b_20230501\n",
              "\n",
              "[9448 rows x 4 columns]"
            ]
          },
          "execution_count": 362,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.concat((v.to_pandas().assign(origin=k) for k,v in ds.items()), ignore_index=True)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': ['Here are some relevant queries that the user can use to search for the given document extract:\\n\\n1. How many birds have been inoculated so far?\\n2. What is the number of birds that officials claim to have inoculated?\\n3. What is the total count of birds that have received inoculation according to officials?\\n4. What is the progress of bird inoculation as claimed by officials?\\n5. How successful has the bird inoculation drive been according to officials?'],\n",
              " 'positive_doc_id': ['xvdlbbds'],\n",
              " 'negative_doc_ids': [['sbr9qd0k',\n",
              "   '850teajs',\n",
              "   'm7w7aue8',\n",
              "   's64v656n',\n",
              "   'ea3gwnw7']]}"
            ]
          },
          "execution_count": 359,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds['leandro_carisio_01'][:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': ['What are the clinical outcomes in patients undergoing transcatheter aortic valve replacement with percutaneous coronary intervention of the left main coronary artery, as evaluated by the TAVR-LM registry?',\n",
              "  'What is the impact of the Coronavirus pandemic on crime rates in Italy and how has it been reflected in data from Ministries, Europol reports, newspapers, and news?'],\n",
              " 'positive_doc_id': ['ikrs1k76', '0jv5mnnl'],\n",
              " 'negative_doc_ids': [['f7s8s770',\n",
              "   'f8m1b8gd',\n",
              "   'mff7zlg9',\n",
              "   '1bx244k1',\n",
              "   'yb8r0ezg'],\n",
              "  ['ijlnizev', '3mu9rrql', 'i6khpntc', 'd37t9f4i', 'h2k4utqr']]}"
            ]
          },
          "execution_count": 312,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds['mirelle_1k_generated_queries_20230501'][:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_query</th>\n",
              "      <th>id_docto</th>\n",
              "      <th>text_docto_query_generation</th>\n",
              "      <th>score_relevance</th>\n",
              "      <th>negative_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22994</th>\n",
              "      <td>What is the significance of the speculation ab...</td>\n",
              "      <td>jmn8ctlt</td>\n",
              "      <td>COVID-19 and tuberculosis in South Africa: A d...</td>\n",
              "      <td>4.7682772</td>\n",
              "      <td>[n26csuks, 09jyekp5, g5bhkd55, x1xzcacy, qv794...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13399</th>\n",
              "      <td>What is the significance of the TRAP-18 in ass...</td>\n",
              "      <td>ysz3oocp</td>\n",
              "      <td>Assessing the threat of lone-actor terrorism: ...</td>\n",
              "      <td>4.7625756</td>\n",
              "      <td>[ayt31knx, hycd9zua, xug622im, rjzy3z8t, m54mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10873</th>\n",
              "      <td>€œIn augustus 2011 wijdde de Journal of the Am...</td>\n",
              "      <td>jnuncmd5</td>\n",
              "      <td>1 Inleiding. In augustus 2011 wijdde de Journa...</td>\n",
              "      <td>4.7553005</td>\n",
              "      <td>[tfvn7xp8, yxmqmetv, 420px62r, s3xnieig, aey40...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22425</th>\n",
              "      <td>What is the estimated reproduction number of C...</td>\n",
              "      <td>k1qq4qgg</td>\n",
              "      <td>Epidemic curve and reproduction number of COVI...</td>\n",
              "      <td>4.7455740</td>\n",
              "      <td>[axjrmk48, q4a1n1wm, m2bgbqzg, raav221g, oen0y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15497</th>\n",
              "      <td>What is the significance of automatic semantic...</td>\n",
              "      <td>c5zewz3m</td>\n",
              "      <td>Automatic Semantic Description Extraction from...</td>\n",
              "      <td>4.7357488</td>\n",
              "      <td>[70x44y0t, 5b78ow1j, vr1kmria, 5htvzkpt, borka...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         generated_query  id_docto                        text_docto_query_generation  score_relevance                                       negative_ids\n",
              "22994  What is the significance of the speculation ab...  jmn8ctlt  COVID-19 and tuberculosis in South Africa: A d...        4.7682772  [n26csuks, 09jyekp5, g5bhkd55, x1xzcacy, qv794...\n",
              "13399  What is the significance of the TRAP-18 in ass...  ysz3oocp  Assessing the threat of lone-actor terrorism: ...        4.7625756  [ayt31knx, hycd9zua, xug622im, rjzy3z8t, m54mo...\n",
              "10873  €œIn augustus 2011 wijdde de Journal of the Am...  jnuncmd5  1 Inleiding. In augustus 2011 wijdde de Journa...        4.7553005  [tfvn7xp8, yxmqmetv, 420px62r, s3xnieig, aey40...\n",
              "22425  What is the estimated reproduction number of C...  k1qq4qgg  Epidemic curve and reproduction number of COVI...        4.7455740  [axjrmk48, q4a1n1wm, m2bgbqzg, raav221g, oen0y...\n",
              "15497  What is the significance of automatic semantic...  c5zewz3m  Automatic Semantic Description Extraction from...        4.7357488  [70x44y0t, 5b78ow1j, vr1kmria, 5htvzkpt, borka...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "execution_count": 307,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_my_split.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mudar para o formato jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_nome = \"marcus_borela_1k_gptj6b_20230501\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 463,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1000it [00:00, 15136.59it/s]\n"
          ]
        }
      ],
      "source": [
        "with open(f\"{DIRETORIO_TRABALHO}/{split_nome}.jsonl\", 'w') as arquivo:\n",
        "    for ndx, registro in tqdm(df_my_split.iterrows()):\n",
        "        doc = {\"query\": registro['generated_query'],\n",
        "                \"positive_doc_id\":  registro['id_docto'],\n",
        "                \"negative_doc_ids\":  registro['negative_ids'],\n",
        "                }\n",
        "        json.dump(doc, arquivo)\n",
        "        # linha_json = json.dumps(doc)\n",
        "        # Escreve a linha JSON no arquivo\n",
        "        arquivo.write('\\n')        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 464,
      "metadata": {},
      "outputs": [],
      "source": [
        "lista_json = []\n",
        "with open(f\"{DIRETORIO_TRABALHO}/{split_nome}.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        doc = json.loads(line)\n",
        "        lista_json.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 471,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'query': 'What is the importance of COVID-19 information provided by national plastic surgery society websites?', 'positive_doc_id': 'vpowumff', 'negative_doc_ids': ['t4wofvv4', '4567mu8n', 'v9oqlouj', '6d25aq3i', 'rgeeld8q']}, {'query': 'What is the importance of risk perception assessment of COVID-19 among Portuguese healthcare professionals and general population?', 'positive_doc_id': 'nkz53jzy', 'negative_doc_ids': ['qcr1fl8s', 'unzbduqk', 'bnnl700a', '4dv6954b', 'j8h7endt']}]\n"
          ]
        }
      ],
      "source": [
        "print(lista_json[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "meu_dataset_dict = DatasetDict({\n",
        "    split_nome: Dataset.from_dict(lista_json),\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comandos a testar depois"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adicionar o novo conjunto de dados ao ds existente\n",
        "ds.update(meu_dataset_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# carregar o novo split a partir do arquivo jsonl\n",
        "new_split = datasets.load_dataset('json', data_files='marcus_borela_v1.jsonl') #['train']\n",
        "\n",
        "# adicionar o novo split ao dataset original\n",
        "ds = ds.add_dataset(new_split, name='marcus_borela_01')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "P9bepRrfCG3a",
        "v19yOgi9OMjD",
        "4WJ9VOUMHFz1",
        "Mebj-4wbn9k7",
        "jOGRYPn-3bmp",
        "YygV4s372xYS",
        "lcf4EzA9EhC8",
        "-LBQrhPb7gnh",
        "6tEsBGVO7NWF",
        "f3jLQOCm7Vnj",
        "F3sDzZyQoe4Z",
        "UmzDpf8FEIWz"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "treinapython39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e431eb1d856c426fade2a694f8536bd46c4e9c4bd47cb4afd3fb4d2c61122b03"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
