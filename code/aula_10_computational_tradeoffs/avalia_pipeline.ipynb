{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CcN_5-RDWeqV"
   },
   "source": [
    "# Aula 10 - Computational Tradeoffs\n",
    "\n",
    "[Unicamp - IA368DD: Deep Learning aplicado a sistemas de busca.](https://www.cpg.feec.unicamp.br/cpg/lista/caderno_horario_show.php?id=1779)\n",
    "\n",
    "Autor: Marcus Vinícius Borela de Castro\n",
    "\n",
    "[Repositório no github](https://github.com/marcusborela/deep_learning_em_buscas_unicamp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VQxzYKGgMqce"
   },
   "source": [
    "# Enunciado exercício\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Exercício desta semana: Trade-offs de eficiência e qualidade\n",
    "\n",
    "O objetivo do exercício desta semana é construir alguns pipelines de busca e analisá-los em termos das seguintes métricas:\n",
    "Qualidade dos resultados: nDCG@10;\n",
    "Latência (seg/query);\n",
    "USD por query assumindo utilização \"perfeita\": assim que terminou de processar uma query, já tem outra para ser processada;\n",
    "USD/mês para deixar o sistema rodando para poucos usuários (ex: 100 queries/dia);\n",
    "Custo de indexação em USD;\n",
    "\n",
    "Iremos avaliar os pipelines no TREC-COVID.\n",
    "A latência precisa ser menor que 2 segundos por query.\n",
    "Não assumir processamento de queries em batch.\n",
    "\n",
    "Considerar:\n",
    "1,50 USD/hora por A100 ou 0,21 USD/hora por T4 ou 0,50 USD/hora por V100\n",
    "0,03 USD/hora por CPU core\n",
    "0,005 USD/hora por GB de CPU RAM\n",
    "Dicas:\n",
    "Utilizar modelos de busca \"SOTA\" já treinados no MS MARCO como parte do pipeline, como o SPLADE distil (esparso), contriever (denso), Colbert-v2 (denso), miniLM (reranker), monoT5-3B (reranker), doc2query minus-minus (expansão de documentos + filtragem com reranqueador na etapa de indexação)\n",
    "Pode usar API's como Cohere, OpenAI Embeddings\n",
    "\n",
    "Variar parâmetros como número de documentos retornados em cada estágio. Por exemplo, BM25 retorna 1000 documentos, um modelo denso ou esparso pode franqueá-los, e passar os top 50 para o miniLM/monoT5 fazer um ranqueamento final.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizando o ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4AJiH6lQQHc5"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['JVM_PATH'] = '/usr/lib/jvm/java-11-openjdk-amd64/lib/server/libjvm.so'\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-11-openjdk-amd64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borela/miniconda3/envs/treinapython39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b9687f745b78489c8d20b1b8e83a8a0c",
      "23d37e6a19cc44eb8fbbca2d532a6a7c",
      "e5b62351b5804bee903a9b40cff992df",
      "a7b0817200914363bc4804d37cedbe99",
      "a370f9920d65417c9cc3f1d7881d0923",
      "779528a697524011aa043155533eab2f",
      "0f7e722200c741348120db558964eb4b",
      "4f32d436738544418231bb9242ac66d1",
      "798f407e2f084992900952e90d0ae018",
      "8a8684e559484460b5eabaad70245441",
      "79c8028e18a744918e503d3218cf5b2c",
      "29b2a64024564bf0ad5238e5fa38e934",
      "00c0da6b84ad4100ac6bc560ba7dc4ab",
      "93dd402fe48e4936927162a39dde8147",
      "2c3deeabab2a450fb8596605fdf55d89",
      "94f25490266245b284286c8d8236c6ad",
      "0c8b23aa2672423c88624b84301e2496",
      "720cc4034b4e46c8b5abcf43fac2a7a2",
      "32ec1752eae842e58531e6e3d227767e",
      "10afa4deb9b94fecbb66211deea6137c",
      "15387ba3c44c4264be66682d9e4d8b28",
      "09ced38d656f46e1913988c55746307b",
      "be1898724fbb42e68d136cb607f84093",
      "1d0710e62acb43d7bc155a87b8c0afca",
      "d0ef69a90a4d45b6a45e2b69c7ffeed0",
      "4cc17cacd6ed43149d09f6bd50b5fc54",
      "ffb117d9a292489b90ca1f8a0bf9dfc9",
      "476dba5f604f448dabdfcf0670ff8f61",
      "e8a45538c72640529911ec6546ccfd6e",
      "9f4bad7c399343f69b38fecb4304f7a6",
      "270cf7305e364d6d9006abf50dc0b04d",
      "84605f9a0199417b881b8ca4022730ee",
      "4cdaa94bec484a82b19e2adf6f485f31",
      "7e97fba0f9fe4be899f42dbd42b5ac5a",
      "09cf49b152cb44aba8dacaf13f895901",
      "aeff355d3ed14827b1c5312a4931a9d3",
      "d444223480d44420b73ee4f1f4c40002",
      "3b1832012af647a3bddfbe28bde6c838",
      "ea8f9b6dcf054543ba8300f3b18d93ed",
      "f4cc04c7cc8a4a41aa467a6276428bc6",
      "1ee626011f7240c3ad716f82bfe2617a",
      "02b8904772b849509c011215456172a9",
      "5b85c7d845e4483d9522ad7810b56d24",
      "b2b2a003ae9743a894dbaa2d5045c465"
     ]
    },
    "id": "rsngiRh3NjDE",
    "outputId": "47e889a5-940a-48e9-cdc6-4de8162449cc"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AG9RjMb8Qlot"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ry_ieNro1kUa"
   },
   "outputs": [],
   "source": [
    "from transformers import BatchEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v19yOgi9OMjD"
   },
   "source": [
    "## Definindo paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRETORIO_LOCAL = '/home/borela/fontes/deep_learning_em_buscas_unicamp/local'\n",
    "DIRETORIO_TREC_COVID = F'{DIRETORIO_LOCAL}/trec_covid'\n",
    "DIRETORIO_MSMARCO = F'{DIRETORIO_LOCAL}/msmarco'\n",
    "DIRETORIO_TRABALHO = F'{DIRETORIO_LOCAL}/tradeoff'\n",
    "DIRETORIO_RUN = f\"{DIRETORIO_TRABALHO}/runs\"\n",
    "PATH_RUN_AVALIACAO = f\"{DIRETORIO_RUN}/run-trec-covid.txt\"\n",
    "PATH_RESULTADO_PIPELINE = f\"{DIRETORIO_TRABALHO}/resultado_pipeline.pickle\"\n",
    "PATH_AVALIACAO_CONTEXTO_PIPELINE = f\"{DIRETORIO_TRABALHO}/avaliacao_contexto_pipeline.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pasta já existia!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(DIRETORIO_LOCAL):\n",
    "    print('pasta já existia!')\n",
    "else:\n",
    "    os.makedirs(DIRETORIO_LOCAL)\n",
    "    print('pasta criada!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pasta já existia!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(DIRETORIO_TRABALHO):\n",
    "    print('pasta já existia!')\n",
    "else:\n",
    "    os.makedirs(DIRETORIO_TRABALHO)\n",
    "    print('pasta criada!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pasta já existia!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(DIRETORIO_RUN):\n",
    "    print('pasta já existia!')\n",
    "else:\n",
    "    os.makedirs(DIRETORIO_RUN)\n",
    "    print('pasta criada!')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras inicializações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo o índice prebuilt trec-covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_inicio = time.time()\n",
    "LuceneSearcher.from_prebuilt_index('beir-v1.0.0-trec-covid.flat')\n",
    "tempo_construcao_indice_trecc_pyserine = round(time.time() - tempo_inicio, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo para construir índice TRECC com pyserini 0.109634 segundos\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tempo para construir índice TRECC com pyserini {tempo_construcao_indice_trecc_pyserine} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/borela/fontes/deep_learning_em_buscas_unicamp/code/aula_10_computational_tradeoffs'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lucene-index.beir-v1.0.0-trec-covid.flat.20221116.505594.57b812594b11d064a23123137ae7dade\n"
     ]
    }
   ],
   "source": [
    "!ls /home/borela/.cache/pyserini/indexes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOME_INDICE_TRECC = os.popen('ls /home/borela/.cache/pyserini/indexes/').read()[:-1]\n",
    "PATH_INDICE_TRECC = \"/home/borela/.cache/pyserini/indexes/\" + NOME_INDICE_TRECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4096\n",
      "drwxrwxr-x 2 borela borela 4096 nov 16 12:21 lucene-index.beir-v1.0.0-trec-covid.flat.20221116.505594.57b812594b11d064a23123137ae7dade\n"
     ]
    }
   ],
   "source": [
    "!ls  -l --block-size=1 /home/borela/.cache/pyserini/indexes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lucene-index.beir-v1.0.0-trec-covid.flat.20221116.505594.57b812594b11d064a23123137ae7dade\n"
     ]
    }
   ],
   "source": [
    "print(NOME_INDICE_TRECC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho do arquivo lucene-index.beir-v1.0.0-trec-covid.flat.20221116.505594.57b812594b11d064a23123137ae7dade é: 4096 bytes\n"
     ]
    }
   ],
   "source": [
    "tamanho_em_bytes_indice_trecc = os.path.getsize(PATH_INDICE_TRECC)\n",
    "print(\"O tamanho do arquivo\", NOME_INDICE_TRECC, \"é:\", tamanho_em_bytes_indice_trecc, \"bytes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tamanho não está correto. Mas continuaremos o código deixando esse ponto pendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.index import IndexReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de documentos no índice: {'total_terms': 20822821, 'documents': 171331, 'non_empty_documents': 171331, 'unique_terms': 202648}\n"
     ]
    }
   ],
   "source": [
    "index_reader = IndexReader(PATH_INDICE_TRECC)\n",
    "num_docs = index_reader.stats()\n",
    "print(f'Número de documentos no índice: {num_docs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(PATH_INDICE_TRECC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tamanho_em_bytes_indice_trecc = int(subprocess.check_output(['du', '-b', PATH_INDICE_TRECC]).split()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269772727"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tamanho_em_bytes_indice_trecc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baixando os dados e preparando para avaliação "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Já existia a pasta\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(f\"{DIRETORIO_TREC_COVID}/corpus.jsonl.gz\"):\n",
    "    !wget https://huggingface.co/datasets/BeIR/trec-covid/resolve/main/corpus.jsonl.gz\n",
    "    !mv corpus.jsonl.gz {DIRETORIO_TREC_COVID}\n",
    "    print('Baixado')\n",
    "else:\n",
    "    print('Já existia a pasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descompacte o arquivo para a memória\n",
    "with gzip.open(f'{DIRETORIO_TREC_COVID}/corpus.jsonl.gz', 'rt') as f:\n",
    "    # Leia o conteúdo do arquivo descompactado\n",
    "    corpus = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> len(corpus): 171332 \n"
     ]
    }
   ],
   "source": [
    "# Exiba os dados carregados\n",
    "print(f\"{type(corpus)} len(corpus): {len(corpus)} \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dict = {}\n",
    "\n",
    "for docto in corpus:\n",
    "    if ('title' in docto) and len(docto['title']) >= 5:\n",
    "        texto_usado_na_geracao_de_query = docto['title'] + '. ' + docto['text']\n",
    "    else:\n",
    "        texto_usado_na_geracao_de_query = docto['text']\n",
    "    corpus_dict[docto['_id']] = {'text_query_generation': texto_usado_na_geracao_de_query, \n",
    "                                 'title': docto['title'],\n",
    "                                 'text': docto['text']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171332\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_dict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search import get_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 queries total\n"
     ]
    }
   ],
   "source": [
    "topics = get_topics('covid-round5')\n",
    "print(f'{len(topics)} queries total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what is the origin of COVID-19',\n",
       " 'query': 'coronavirus origin',\n",
       " 'narrative': \"seeking range of information about the SARS-CoV-2 virus's origin, including its evolution, animal source, and first transmission into humans\"}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados de relevância (qrel de teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo já existia\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(f'{DIRETORIO_TREC_COVID}/test.tsv'):\n",
    "    !wget https://huggingface.co/datasets/BeIR/trec-covid-qrels/raw/main/test.tsv\n",
    "    !mv test.tsv {DIRETORIO_LOCAL}/\n",
    "else:\n",
    "    print('Arquivo já existia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel = pd.read_csv(f\"{DIRETORIO_TREC_COVID}/test.tsv\", sep=\"\\t\", header=None, \n",
    "                   skiprows=1, names=[\"query\", \"docid\", \"rel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>docid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>005b2j4b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00fmeepz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>g7dhmyyo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0194oljo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>021q9884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query     docid  rel\n",
       "0      1  005b2j4b    2\n",
       "1      1  00fmeepz    1\n",
       "2      1  g7dhmyyo    2\n",
       "3      1  0194oljo    1\n",
       "4      1  021q9884    1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>docid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>005b2j4b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00fmeepz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>g7dhmyyo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0194oljo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>021q9884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query     docid  rel\n",
       "0      1  005b2j4b    2\n",
       "1      1  00fmeepz    1\n",
       "2      1  g7dhmyyo    2\n",
       "3      1  0194oljo    1\n",
       "4      1  021q9884    1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel[\"q0\"] = \"q0\"\n",
    "qrel_dict = qrel.to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, '005b2j4b', 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_dict['query'][0], qrel_dict['docid'][0], qrel_dict['rel'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotinas para cálculos e lógica a ser usada"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Plano de ação:\n",
    "\n",
    "\n",
    "        Para cada pipeline, calcular  e salvar\n",
    "\n",
    "                indexação:\n",
    "                        tempo \n",
    "                        memória\n",
    "\n",
    "                retrieval: \n",
    "                        tempo_medio_por_query\n",
    "                        memória\n",
    "\n",
    "                resultado:\n",
    "                        ndcg@10\n",
    "        \n",
    "                Detalhes de implementação:  salvar no dict resultado_pipeline com key o nome pipeline e values outro dict:\n",
    "                        {\n",
    "                         'tempo_indexacao_segundo': lista de tuplas, conforme abaixo:\n",
    "                                        [{'tipo':'gpu'/'cpu', 'valor': float, segundos}], \n",
    "                         'memoria_indice_byte_ram'; float, em bytes\n",
    "                         'retrieval_tempo_medio_por_query': [{'tipo':'gpu'/'cpu', 'valor': float, segundos}], \n",
    "                         'se_retrieval_usa_gpu': boolean\n",
    "                         'ndcg_10': float formato 99,99}\n",
    "                \n",
    "                        sendo o tempo em segundos e memória em kbytes\n",
    "\n",
    "\n",
    "        Criar método explora_contexto que a partir dos parâmetros:\n",
    "                \n",
    "                tipo_gpu\n",
    "                        3090\n",
    "\n",
    "\n",
    "                resultado_pipeline (passo anterior)\n",
    "\n",
    "\n",
    "                calcula \n",
    "                        usd/query\n",
    "                        usd/mês\n",
    "\n",
    "                para os seguintes contextos: \n",
    "                        \"utilizacao_perfeita\" (assim que terminou de processar uma query, já tem outra para ser processada)\n",
    "                        \"utilizacao_precaria_100\" (sistema precisar rodar 24h/7h, mas apenas 100 queries/dia)\n",
    "\n",
    "\n",
    "                Detalhes de implementação: salva em um novo dict avaliacao_pipeline_contexto com key o nome do pipeline e value outro dict:\n",
    "                {<nome contexto>: \n",
    "                        {'usd_query':, \n",
    "                         'usd_mes';, }\n",
    "                }\n",
    "\n",
    "\n",
    "        Testar os seguintes pipelines:\n",
    "\n",
    "                bm25 \n",
    "                bm25@100_reranking_minilm\n",
    "                bm25@1000_reranking_minilm\n",
    "                splade\n",
    "\n",
    "                (se der tempo:)\n",
    "                bm25@100_reranking_monot5_3b\n",
    "                bm25@1000_reranking_monot5_3b\n",
    "                dpr\n",
    "\n",
    "\n",
    "                Detalhes de implementação: criar lista lista_pipeline com nomes acima\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(pode usar 3090, mas estimar o custo para A100, considerar quantas vezes mais lentas: a100 tem x flops e custa Z, daí derivar o 3090)\n",
    "\n",
    "\n",
    "        Velocidade do clock: 1,40 GHz (Boost Clock 1,70 GHz)\n",
    "        Memória de vídeo (VRAM): 24 GB\n",
    "\n",
    "https://versus.com/br/nvidia-geforce-rtx-3090-vs-nvidia-tesla-t4\n",
    "\n",
    "\n",
    "\n",
    "    Por que Nvidia GeForce RTX 3090 é melhor que Nvidia Tesla T4?\n",
    "        Clock do GPU 390MHz mais rápido?\n",
    "            1395MHz vs 1005MHz\n",
    "        Desempenho 27.82 TFLOPS maior de ponto flutuante?\n",
    "            35.58 TFLOPS vs 7.76 TFLOPS\n",
    "        Taxa de píxeis 92.84 GPixel/s maior?\n",
    "            189.8 GPixel/s vs 96.96 GPixel/s\n",
    "        Mais 8GB de VRAM?\n",
    "            24GB vs 16GB\n",
    "        Velocidade efetiva do clock da memória 9500MHz maior?\n",
    "            19500MHz vs 10000MHz\n",
    "        Taxa de textura 313.6 GTexels/s maior?\n",
    "            556 GTexels/s vs 242.4 GTexels/s\n",
    "        616GB/s mais largura de banda de memória?\n",
    "            936GB/s vs 320GB/s\n",
    "        Suporta ray tracing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memórica de cálculo de custo de GPU 3090\n",
    "\n",
    "Parâmetro de cálculo, site encontrado que tem tanto 3090 quanto uma das definidas no enunciado do exercício.\n",
    "\n",
    "\n",
    "Em [https://cloud.vast.ai](https://cloud.vast.ai/create?utm_medium=cpc&utm_target=&device=c&gad=1&gclid=Cj0KCQjwr82iBhCuARIsAO0EAZxdEU16ZYFVO9asqO5T3yMYqs1Y3WL3YbHbFIVh-8p_b4Svp9k0HLYaAgUVEALw_wcB&utm_content=633581964120&placement=&utm_group=143233570036&adposition=&utm_source=google&utm_campaign=18841339102_search) \n",
    "\n",
    "        3090  (44.1tflops/24gb) 0.20 a 0.33. \n",
    "        v100 (14.8tflops/16gb) 2.30 a 3.06 \n",
    "        a100 (19.5tflops/80gb) 1.55 a 1.8\n",
    "\n",
    "\n",
    "Considerando que no enunciado diz:\n",
    "        \n",
    "        1,50 USD/hora por A100 ou 0,21 USD/hora por T4 ou 0,50 USD/hora por V100\n",
    "\n",
    "\n",
    "Considerando a proporção de a100 para 3090 do site cloud.vast.ai: 6x\n",
    "\n",
    "Assumiremos custo de 0,25 USD/hora\n",
    "\n",
    "Mudando para segundo:\n",
    "\n",
    "Regra de 3:\n",
    "        3600 s       1s\n",
    "        0,25         x\n",
    "\n",
    "        x = 25e-2 / 3600 = 6,944...e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.944444444444444e-05\n"
     ]
    }
   ],
   "source": [
    "print( 25e-2 / 3600 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas suposições para cálculo\n",
    "\n",
    "Para fins de cálculo de memória ram, computaremos apenas o espaço ocupado pelo índice (o fator mais diferenciável entre os pipelines), descartando ocupações em memória por outros objetos e variáveis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outros valores definidos no enunciado - transformando\n",
    "\n",
    "        0,03 USD/hora por CPU core\n",
    "        0,005 USD/hora por GB de CPU RAM\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudando para bytes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.656612873077393e-12\n"
     ]
    }
   ],
   "source": [
    "print( 0.005 / 2**30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constantes de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "custo_gpu_segundo = {'3090': 6.944e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTO_RAM_CPU_HORA_BYTE = 4.656e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTO_CPU_ALOCADA_HORA = 0.03\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.333333333333334e-06\n"
     ]
    }
   ],
   "source": [
    "print(CUSTO_CPU_ALOCADA_HORA / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTO_CPU_ALOCADA_SEGUNDO = 8.333e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_pipeline = [  'bm25',\n",
    "                    'bm25@100_reranking_minilm',\n",
    "                    'bm25@1000_reranking_minilm',\n",
    "                    'bm25@100_reranking_monot5_3b',\n",
    "                    'bm25@1000_reranking_monot5_3b',\n",
    "                    'inpars',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_pipeline = {}\n",
    "avaliacao_pipeline_contexto = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_calculo_contexto (parm_resultado_pipeline: dict,\n",
    "                      parm_tipo_gpu:str='3090',\n",
    "                      ):\n",
    "    \"\"\"\n",
    "      Método para efetuar cálculos de gastos conforme\n",
    "        parm_tipo_gpu\n",
    "        parm_resultado_pipeline\n",
    "     \n",
    "    \"\"\" \n",
    "    global lista_pipeline \n",
    "    assert parm_tipo_gpu in ['3090'], f\"parm_tipo_gpu {parm_tipo_gpu} não está previsto para cálculos!\"\n",
    "\n",
    "    resultado = {}\n",
    "    for contexto in ['utilizacao_perfeita', 'utilizacao_precaria_100']:\n",
    "        avaliacao_contexto = calcula_gastos(parm_resultado_pipeline, parm_tipo_gpu, contexto)\n",
    "        resultado[contexto]= avaliacao_contexto\n",
    "    return resultado\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_gastos (parm_dados: dict,\n",
    "                      parm_tipo_gpu:str='3090',\n",
    "                      parm_contexto:str='utilizacao_perfeita'):\n",
    "    \"\"\"\n",
    "        parm_dados deve ter:\n",
    "                        {'tempo_indexacao_segundo':, lista de tuplas, conforme abaixo:\n",
    "                                        [{'tipo':'gpu'/'cpu', 'valor': float, segundos}], \n",
    "                         'memoria_indice_byte_ram';, \n",
    "                         'retrieval_tempo_medio_por_query':,\n",
    "                         'se_retrieval_usa_gpu':}\n",
    "\n",
    "    \"\"\"\n",
    "    global custo_gpu_segundo, CUSTO_RAM_CPU_HORA_BYTE, CUSTO_CPU_ALOCADA_HORA, CUSTO_CPU_ALOCADA_SEGUNDO\n",
    "    lista_chave_esperada = ['tempo_indexacao_segundo','memoria_indice_byte_ram','retrieval_tempo_medio_por_query','se_retrieval_usa_gpu']\n",
    "    assert parm_tipo_gpu in ['3090'], f\"parm_tipo_gpu {parm_tipo_gpu} não está previsto para cálculos!\"\n",
    "    assert parm_contexto in ['utilizacao_perfeita', 'utilizacao_precaria_100'], f\"parm_contexto {parm_contexto} não está previsto para cálculos!\"\n",
    "    \n",
    "    for chave in lista_chave_esperada:\n",
    "        assert chave in parm_dados, f\"chave {chave} não está em parm_dados {parm_dados} para os cálculos!\"\n",
    "\n",
    "    dict_retorno = {}\n",
    "\n",
    "\n",
    "    # custo indexacao\n",
    "    custo_indexacao_tempo = 0\n",
    "\n",
    "    ## acumular custo por tempo\n",
    "    for tempo_valor in parm_dados['tempo_indexacao_segundo']:\n",
    "        if tempo_valor['tipo'] == 'cpu':\n",
    "            custo_indexacao_tempo +=  tempo_valor['valor'] * CUSTO_CPU_ALOCADA_SEGUNDO \n",
    "        elif tempo_valor['tipo'] == 'gpu':\n",
    "            custo_indexacao_tempo +=  tempo_valor['valor'] * CUSTO_CPU_ALOCADA_SEGUNDO\n",
    "        else:\n",
    "            raise Exception(f\"Tipo de tempo deveria ser cpu ou gpu e não {tempo_valor['tipo']}\")\n",
    "\n",
    "\n",
    "    # tem que deixar cpu disponível 24h\n",
    "    custo_cpu_dia = 24 * CUSTO_CPU_ALOCADA_HORA\n",
    "\n",
    "    # índice tem que ficar em memória\n",
    "    custo_memoria_dia = 24 * parm_dados['memoria_indice_byte_ram'] * CUSTO_RAM_CPU_HORA_BYTE\n",
    "\n",
    "    custo_dia = custo_memoria_dia + custo_cpu_dia\n",
    "\n",
    "    custo_gpu_dia = 0\n",
    "\n",
    "    if parm_contexto == 'utilizacao_perfeita': #(assim que terminou de processar uma query, já tem outra para ser processada)\n",
    "\n",
    "        if parm_dados['se_retrieval_usa_gpu']:\n",
    "            custo_gpu_dia = 24 * 3600 * custo_gpu_segundo[parm_tipo_gpu]\n",
    "            custo_dia += custo_gpu_dia \n",
    "            print(f\"para {parm_contexto} custo gpu dia: {custo_gpu_dia}\")\n",
    "\n",
    "        num_queries_dia = (24 * 3600) / parm_dados['retrieval_tempo_medio_por_query']\n",
    "        custo_query = round(custo_dia / num_queries_dia, 10)\n",
    "\n",
    "    elif parm_contexto == 'utilizacao_precaria_100': #(assim que terminou de processar uma query, já tem outra para ser processada)\n",
    "\n",
    "        if parm_dados['se_retrieval_usa_gpu']:\n",
    "            custo_gpu_dia = 100 * parm_dados['retrieval_tempo_medio_por_query'] * custo_gpu_segundo[parm_tipo_gpu]\n",
    "            custo_dia += custo_gpu_dia \n",
    "            print(f\"para {parm_contexto} custo gpu dia: {custo_gpu_dia}\")\n",
    "\n",
    "        num_queries_dia = 100\n",
    "        custo_query = round(custo_dia / num_queries_dia, 10)\n",
    "\n",
    "    return {'usd_query': custo_query, \n",
    "            'usd_dia': custo_dia,\n",
    "            'usd_gpu_dia': custo_gpu_dia,\n",
    "            'usd_mes': (30 * custo_dia),\n",
    "            'usd_indexacao_tempo': custo_indexacao_tempo, \n",
    "             }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realiza buscas com os pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_eval = load(\"trec_eval\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline BM25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetos de apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_pipeline = 'bm25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "dUJuMaOKPmoZ"
   },
   "outputs": [],
   "source": [
    "# Run all queries in topics, retrive top 1k for each query\n",
    "def run_all_queries_bm25(file, topics, searcher, num_max_hits=100):\n",
    "  \"\"\"\n",
    "  A função run_all_queries é responsável por realizar todas as consultas armazenadas no dicionário topics utilizando o objeto searcher fornecido e salvar os resultados em um arquivo de texto.\n",
    "  Usada no notebook da aula 2\n",
    "\n",
    "  Parâmetros:\n",
    "\n",
    "  file: caminho do arquivo de saída onde serão salvos os resultados das consultas.\n",
    "  topics: dicionário contendo as consultas a serem executadas. Cada consulta é representada por uma chave única no dicionário. O valor correspondente a cada chave é um outro dicionário contendo as informações da consulta, como seu título e outras informações relevantes.\n",
    "  searcher: objeto do tipo Searcher que será utilizado para realizar as consultas.\n",
    "  num_max_hits: número máximo de documentos relevantes que serão retornados para cada consulta.\n",
    "  Retorno:\n",
    "\n",
    "  A função não retorna nenhum valor, mas salva os resultados das consultas no arquivo especificado em file.\n",
    "  Comentário:\n",
    "\n",
    "  A função usa a biblioteca tqdm para exibir uma barra de progresso enquanto executa as consultas.\n",
    "  O número de consultas concluídas é impresso a cada 100 consultas.\n",
    "  \"\"\"\n",
    "  tempos = []\n",
    "  print(f'Running {len(topics)} queries in total')\n",
    "  with open(file, 'w') as runfile:\n",
    "    cnt = 0\n",
    "    for id in tqdm(topics, desc='Running Queries'):\n",
    "        # print(f'id = {id}')\n",
    "        query = topics[id]['question']\n",
    "        # print(f'query = {query}')\n",
    "        tempo_inicio = time.time()\n",
    "        hits = searcher.search(query, num_max_hits)\n",
    "        tempos.append(time.time() - tempo_inicio)\n",
    "\n",
    "        for i in range(0, len(hits)):\n",
    "            _ = runfile.write(f'{id} Q0 {hits[i].docid} {i+1} {hits[i].score:.6f} Busca\\n')\n",
    "            # = runfile.write('{} Q0 {} {} {:.6f} Pyserini\\n'.format(id, hits[i].docid, i+1, hits[i].score))\n",
    "        cnt += 1\n",
    "        if cnt % 100 == 0:\n",
    "            print(f'{cnt} queries completed')\n",
    "  return tempos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = LuceneSearcher(PATH_INDICE_TRECC) # './indexes/lucene-index-msmarco-passage')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros k1=1.12, b=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max_hits = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['tempo_indexacao_segundo'] = [{'tipo':'cpu', 'valor': tempo_construcao_indice_trecc_pyserine}]\n",
    "resultado_execucao['memoria_indice_byte_ram'] = tamanho_em_bytes_indice_trecc\n",
    "resultado_execucao['se_retrieval_usa_gpu'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.set_bm25(k1=1.12, b=0.4)    # valor sugerido pelo Dr Carísio em seu grid na tarefa Doc2Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 queries in total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Queries: 100%|██████████| 50/50 [00:02<00:00, 21.65it/s]\n"
     ]
    }
   ],
   "source": [
    "tempo_gasto = run_all_queries_bm25(PATH_RUN_AVALIACAO, topics, searcher, num_max_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50.000000\n",
       "mean      0.044992\n",
       "std       0.018053\n",
       "min       0.033016\n",
       "25%       0.037938\n",
       "50%       0.039992\n",
       "75%       0.046751\n",
       "max       0.155465\n",
       "Name: tempo_gasto, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tempos = pd.DataFrame({'tempo_gasto': tempo_gasto})\n",
    "df_tempos['tempo_gasto'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044992"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df_tempos['tempo_gasto'].describe()['mean'],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['retrieval_tempo_medio_por_query'] = round(df_tempos['tempo_gasto'].describe()['mean'],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query  q0     docid  rank      score system\n",
      "0     44  Q0  xfjexm5b     1  11.889200  Busca\n",
      "1     44  Q0  28utunid     2  10.906200  Busca\n",
      "2     44  Q0  qi1henyy     3  10.906199  Busca\n",
      "3     44  Q0  ugkxxaeb     4  10.638000  Busca\n",
      "4     44  Q0  qp77vl6h     5  10.487900  Busca\n",
      "NDCG@10: 0.6187936694210939\n",
      "Resultados: {'runid': 'Busca', 'num_ret': 50000, 'num_rel': 24673, 'num_rel_ret': 9804, 'num_q': 50, 'map': 0.19397103009765435, 'gm_map': 0.13129328791759654, 'bpref': 0.334829488236771, 'Rprec': 0.28961812585830815, 'recip_rank': 0.8518571428571429, 'P@5': 0.7080000000000001, 'P@10': 0.67, 'P@15': 0.6453333333333333, 'P@20': 0.6199999999999999, 'P@30': 0.5946666666666667, 'P@100': 0.48460000000000003, 'P@200': 0.4014000000000001, 'P@500': 0.28308, 'P@1000': 0.19608, 'NDCG@5': 0.6494195661372965, 'NDCG@10': 0.6187936694210939, 'NDCG@15': 0.5930265595572919, 'NDCG@20': 0.5686991493574204, 'NDCG@30': 0.5424134242812346, 'NDCG@100': 0.45176650622218156, 'NDCG@200': 0.39092334821357283, 'NDCG@500': 0.3643405602785105, 'NDCG@1000': 0.4143286268113492}\n"
     ]
    }
   ],
   "source": [
    "### Calculando métricas\n",
    "run = pd.read_csv(f\"{PATH_RUN_AVALIACAO}\", sep=\"\\s+\", \n",
    "                names=[\"query\", \"q0\", \"docid\", \"rank\", \"score\", \"system\"])\n",
    "print(run.head())\n",
    "run = run.to_dict(orient=\"list\")\n",
    "results = trec_eval.compute(predictions=[run], references=[qrel_dict])\n",
    "# salvando métricas    \n",
    "print(f\"NDCG@10: {results['NDCG@10']}\")\n",
    "print(f\"Resultados: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['ndcg_10'] = round(100*results['NDCG@10'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado_pipeline[bm25] {'tempo_indexacao_segundo': [{'tipo': 'cpu', 'valor': 0.109634}], 'memoria_indice_byte_ram': 269772727, 'se_retrieval_usa_gpu': False, 'retrieval_tempo_medio_por_query': 0.044992, 'ndcg_10': 61.88}\n"
     ]
    }
   ],
   "source": [
    "resultado_pipeline[nome_pipeline] = resultado_execucao\n",
    "print(f\"resultado_pipeline[{nome_pipeline}] {resultado_pipeline[nome_pipeline]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utilizacao_perfeita': {'usd_query': 3.906e-07, 'usd_dia': 0.750145483605888, 'usd_gpu_dia': 0, 'usd_mes': 22.50436450817664, 'usd_indexacao_tempo': 9.135801219999999e-07}, 'utilizacao_precaria_100': {'usd_query': 0.0075014548, 'usd_dia': 0.750145483605888, 'usd_gpu_dia': 0, 'usd_mes': 22.50436450817664, 'usd_indexacao_tempo': 9.135801219999999e-07}}\n"
     ]
    }
   ],
   "source": [
    "avaliacao_pipeline_contexto[nome_pipeline] = retorna_calculo_contexto(resultado_execucao, parm_tipo_gpu='3090')\n",
    "print(avaliacao_pipeline_contexto[nome_pipeline] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliações de pipelines com estágio 1 bm25 e estágio 2 reranking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetos de apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "dUJuMaOKPmoZ"
   },
   "outputs": [],
   "source": [
    "# Run all queries in topics, retrive top 1k for each query\n",
    "def run_all_queries_bm25_reranking(file, topics, searcher, parm_model, parm_tokenizer, parm_model_name:str, num_max_hits=100):\n",
    "  \"\"\"\n",
    "  A função run_all_queries é responsável por realizar todas as consultas armazenadas no dicionário topics utilizando o objeto searcher fornecido e salvar os resultados em um arquivo de texto.\n",
    "  Usada no notebook da aula 2\n",
    "\n",
    "  Parâmetros:\n",
    "\n",
    "  file: caminho do arquivo de saída onde serão salvos os resultados das consultas.\n",
    "  topics: dicionário contendo as consultas a serem executadas. Cada consulta é representada por uma chave única no dicionário. O valor correspondente a cada chave é um outro dicionário contendo as informações da consulta, como seu título e outras informações relevantes.\n",
    "  searcher: objeto do tipo Searcher que será utilizado para realizar as consultas.\n",
    "  num_max_hits: número máximo de documentos relevantes que serão retornados para cada consulta.\n",
    "  Retorno:\n",
    "\n",
    "  A função não retorna nenhum valor, mas salva os resultados das consultas no arquivo especificado em file.\n",
    "  Comentário:\n",
    "\n",
    "  A função usa a biblioteca tqdm para exibir uma barra de progresso enquanto executa as consultas.\n",
    "  O número de consultas concluídas é impresso a cada 100 consultas.\n",
    "  \"\"\"\n",
    "  tempos = []\n",
    "  print(f'Running {len(topics)} queries in total')\n",
    "  with open(file, 'w') as runfile:\n",
    "    cnt = 0\n",
    "    for id in tqdm(topics, desc='Running Queries'):\n",
    "        query = topics[id]['question']\n",
    "        \n",
    "        tempo_inicio = time.time()\n",
    "        hits = searcher.search(query, num_max_hits)\n",
    "        # reranking\n",
    "        docids = [hit.docid for hit in hits]\n",
    "        pares_texto = [(query, corpus_dict[docid]['text_query_generation']) for docid in docids]\n",
    "\n",
    "        # print(\"carregando dataset\")  \n",
    "        classes_dummy = np.zeros(len(hits), dtype=np.int64)\n",
    "        dataset_reranking = MyDataset(texts=pares_texto, classes=classes_dummy, tokenizer=parm_tokenizer)    \n",
    "        dataloader_reranking = DataLoader(dataset_reranking,\n",
    "                                          batch_size= 16,\n",
    "                                          shuffle=False)\n",
    "        prob_relevancia = calcula_relevancia(parm_model,dataloader_reranking, parm_model_name = parm_model_name)\n",
    "        resultado_ordenado = sorted(zip(docids, prob_relevancia), key=lambda x: x[1], reverse=True)\n",
    "        tempos.append(time.time() - tempo_inicio)\n",
    "\n",
    "        for i in range(0, len(hits)):\n",
    "            _ = runfile.write(f'{id} Q0 {resultado_ordenado[i][0]} {i+1} {resultado_ordenado[i][1]:.6f} Busca\\n')\n",
    "        cnt += 1\n",
    "        if cnt % 100 == 0:\n",
    "            print(f'{cnt} queries completed')\n",
    "  return tempos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "XeakUpqJeQpz"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "      Classe para representar um dataset de texto e classes.\n",
    "    \"\"\"  \n",
    "    def __init__(self, texts: list, classes:list[int], tokenizer):\n",
    "      \"\"\"\n",
    "      Inicializa um novo objeto MyDataset.\n",
    "\n",
    "      Args:\n",
    "          texts (list): uma lista com as strings de texto. Cada elemento deve ter 2 strings.\n",
    "          classes (np.ndarray): um array com as classes de cada texto.\n",
    "          tokenizer: um objeto tokenizer do Hugging Face Transformers.\n",
    "          max_seq_length (int): o tamanho máximo da sequência a ser considerado.\n",
    "      Raises:\n",
    "          AssertionError: se os parâmetros não estiverem no formato esperado.\n",
    "      \"\"\"\n",
    "      # Verifica se os parâmetros são do tipo esperado\n",
    "      assert isinstance(texts, list), f\"Parâmetro texts deve ser do tipo list e não {type(texts)}\"\n",
    "      for row in texts:\n",
    "          assert isinstance(row, tuple) and len(row)== 2, f\"Each row in texts must have 2 elements\"\n",
    "          assert isinstance(row[0], str) and isinstance(row[1], str), f\"Each element in texts.row must be a string e não {type(row[0])}\"\n",
    "      assert isinstance(classes,np.ndarray), f'classes deve ser do tipo np.ndarray e não {type(classes)}'\n",
    "      assert isinstance(classes[0],np.int64), f'classes[0] deve ser do tipo numpy.int64 e não {type(classes[0])} '\n",
    "\n",
    "      self.texts = texts\n",
    "      self.classes = classes\n",
    "      self.tokenizer = tokenizer\n",
    "      self.max_seq_length = tokenizer.model_max_length # model.config.max_position_embeddings\n",
    "      if self.max_seq_length > 64000:\n",
    "        print(f\"Valor de self.max_seq_length  {self.max_seq_length} indica que deve ser usado outro campo do tokenizador. Assumido 512 \")\n",
    "        self.max_seq_length =  512\n",
    "      # Salvar os dados dos tensores\n",
    "      x_data_input_ids = []\n",
    "      x_data_token_type_ids = []\n",
    "      x_data_attention_masks = []\n",
    "      for text_pair in texts:\n",
    "          encoding = tokenizer.encode_plus(\n",
    "              text_pair[0],\n",
    "              text_pair[1],\n",
    "              add_special_tokens=True,\n",
    "              max_length=self.max_seq_length,\n",
    "              padding='max_length',\n",
    "              return_tensors = 'pt',\n",
    "              truncation=True,\n",
    "              return_attention_mask=True,\n",
    "              return_token_type_ids=True\n",
    "          )\n",
    "          x_data_input_ids.append(encoding['input_ids'].long())\n",
    "          x_data_token_type_ids.append(encoding['token_type_ids'].long())\n",
    "          x_data_attention_masks.append(encoding['attention_mask'].long())\n",
    "      # print(F'\\tVou converter lista para tensor;  Momento: {time.strftime(\"[%Y-%b-%d %H:%M:%S]\")}')\n",
    "      # squeeze: vai transformar um tensor de shape [2, 1, 322] em um tensor de shape [2, 322].\n",
    "\n",
    "      self.x_tensor_input_ids = torch.stack(x_data_input_ids).squeeze(1)\n",
    "      self.x_tensor_attention_masks = torch.stack(x_data_attention_masks).squeeze(1)\n",
    "      self.x_tensor_token_type_ids = torch.stack(x_data_token_type_ids).squeeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "          Retorna o tamanho do dataset (= tamanho do array texts)\n",
    "        \"\"\"\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "          Retorna um dicionário com os dados do texto e sua classe correspondente, em um formato que pode \n",
    "          ser usado pelo dataloader do PyTorch para alimentar um modelo de aprendizado de máquina.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'input_ids': self.x_tensor_input_ids[idx],\n",
    "            'attention_mask': self.x_tensor_attention_masks[idx],\n",
    "            'token_type_ids': self.x_tensor_token_type_ids[idx],\n",
    "            # 'labels': int(self.classes[idx])\n",
    "            'labels': torch.tensor(self.classes[idx], dtype=torch.long)            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "RvfCt_vJ28Au"
   },
   "outputs": [],
   "source": [
    "def calcula_relevancia(parm_model, parm_dataloader_reranking, parm_model_name:str):\n",
    "  # para 'cross-encoder/ms-marco-TinyBERT-L-2'\n",
    "  prob_relevancia = []\n",
    "  parm_model.eval()\n",
    "  with torch.no_grad():\n",
    "      for ndx, batch in enumerate(parm_dataloader_reranking):\n",
    "          if 'minilm' in parm_model_name:\n",
    "              logits_model = parm_model(**BatchEncoding(batch).to(device)).logits                          \n",
    "              relevantes_float = [float(t) for t in logits_model]\n",
    "          elif 'monobert' in parm_model_name:\n",
    "              logits_model = parm_model(**BatchEncoding(batch).to(device)).logits\n",
    "              probs = torch.nn.functional.softmax(logits_model, dim=1)\n",
    "              nao_relevante, relevante = zip(*probs)\n",
    "              relevantes_float = [float(t) for t in relevante]              \n",
    "          prob_relevancia.extend(relevantes_float)          \n",
    "          # prob_relevancia.append(pa.array(scores.numpy()))\n",
    "  return prob_relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_relevancia_softmax(parm_model, parm_dataloader_reranking):\n",
    "  prob_relevancia = []\n",
    "  parm_model.eval()\n",
    "  with torch.no_grad():\n",
    "      for ndx, batch in tqdm(enumerate(parm_dataloader_reranking), total=len(parm_dataloader_reranking), mininterval=0.5, desc='dataset_reranking', disable=False):\n",
    "          #print(\"\\nbatch['input_ids'][0]\", batch['input_ids'][0])\n",
    "          #print(\"batch['input_ids'][1]\", batch['input_ids'][1])\n",
    "          logits_model = parm_model(**BatchEncoding(batch).to(device)).logits\n",
    "          probs = torch.nn.functional.softmax(logits_model, dim=1)\n",
    "          nao_relevante, relevante = zip(*probs)\n",
    "          relevantes_float = [float(t) for t in relevante]\n",
    "          # print('logits_model', logits_model)\n",
    "          prob_relevancia.extend(relevantes_float)\n",
    "          # prob_relevancia.append(pa.array(scores.numpy()))\n",
    "          # print('probs',probs)\n",
    "          # print('relevantes_float',relevantes_float)\n",
    "          # break\n",
    "  return prob_relevancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvfCt_vJ28Au"
   },
   "source": [
    "def calcula_relevancia_monobert(parm_model, parm_dataloader_reranking):\n",
    "  # para 'cross-encoder/ms-marco-TinyBERT-L-2'\n",
    "  prob_relevancia = []\n",
    "  parm_model.eval()\n",
    "  with torch.no_grad():\n",
    "      for ndx, batch in enumerate(parm_dataloader_reranking):\n",
    "          outputs, = parm_model(**BatchEncoding(batch).to(device))                         \n",
    "          relevantes_float = [float(t) for t in outputs]\n",
    "          prob_relevancia.extend(relevantes_float)          \n",
    "          # prob_relevancia.append(pa.array(scores.numpy()))\n",
    "  return prob_relevancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                output, = self.model(input_ids, token_type_ids=tt_ids, return_dict=False)\n",
    "                if output.size(1) > 1:\n",
    "                    text.score = torch.nn.functional.log_softmax(\n",
    "                        output, 1)[0, -1].item()\n",
    "                else:\n",
    "                    text.score = output.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aT7_riDtAj_8"
   },
   "source": [
    "# Reranking com miniLM (treinado no ms-marco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nome_modelo = 'cross-encoder/ms-marco-TinyBERT-L-2'\n",
    "nome_modelo = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(nome_modelo).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(nome_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 509, 512)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.max_position_embeddings, tokenizer.max_len_sentences_pair, tokenizer.model_max_length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aT7_riDtAj_8"
   },
   "source": [
    "## bm25@100_reranking_minilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_pipeline = 'bm25@100_reranking_minilm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['tempo_indexacao_segundo'] = [{'tipo':'cpu', 'valor': tempo_construcao_indice_trecc_pyserine}]\n",
    "resultado_execucao['memoria_indice_byte_ram'] = tamanho_em_bytes_indice_trecc\n",
    "resultado_execucao['se_retrieval_usa_gpu'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 queries in total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Queries: 100%|██████████| 50/50 [00:14<00:00,  3.57it/s]\n"
     ]
    }
   ],
   "source": [
    "tempo_gasto = run_all_queries_bm25_reranking(PATH_RUN_AVALIACAO, topics, searcher, model, tokenizer, num_max_hits=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo médio por query 0.279581\n"
     ]
    }
   ],
   "source": [
    "df_tempos = pd.DataFrame({'tempo_gasto': tempo_gasto})\n",
    "resultado_execucao['retrieval_tempo_medio_por_query'] = round(df_tempos['tempo_gasto'].describe()['mean'],6)\n",
    "print(f\"Tempo médio por query {resultado_execucao['retrieval_tempo_medio_por_query']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query  q0     docid  rank     score system\n",
      "0     44  Q0  qi1henyy     1  6.995133  Busca\n",
      "1     44  Q0  28utunid     2  6.964627  Busca\n",
      "2     44  Q0  ej76fsxa     3  6.382739  Busca\n",
      "3     44  Q0  uc37poce     4  6.346030  Busca\n",
      "4     44  Q0  dt2pew66     5  6.306264  Busca\n"
     ]
    }
   ],
   "source": [
    "### Calculando métricas\n",
    "run = pd.read_csv(f\"{PATH_RUN_AVALIACAO}\", sep=\"\\s+\", \n",
    "                names=[\"query\", \"q0\", \"docid\", \"rank\", \"score\", \"system\"])\n",
    "print(run.head())\n",
    "run = run.to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10: 0.7484831661234049\n",
      "Resultados: {'runid': 'Busca', 'num_ret': 5000, 'num_rel': 24673, 'num_rel_ret': 2423, 'num_q': 50, 'map': 0.0877165751524934, 'gm_map': 0.06848099815752387, 'bpref': 0.10889678899977348, 'Rprec': 0.11195682644552621, 'recip_rank': 0.8745238095238095, 'P@5': 0.836, 'P@10': 0.8100000000000002, 'P@15': 0.7973333333333333, 'P@20': 0.7660000000000001, 'P@30': 0.7146666666666668, 'P@100': 0.48460000000000003, 'P@200': 0.24230000000000002, 'P@500': 0.09692, 'P@1000': 0.04846, 'NDCG@5': 0.7716916005180048, 'NDCG@10': 0.7484831661234049, 'NDCG@15': 0.7305901802777125, 'NDCG@20': 0.7090515248486612, 'NDCG@30': 0.6680300786452001, 'NDCG@100': 0.4800372821877119, 'NDCG@200': 0.29914468380869985, 'NDCG@500': 0.1991620051549731, 'NDCG@1000': 0.1875552589200808}\n"
     ]
    }
   ],
   "source": [
    "results = trec_eval.compute(predictions=[run], references=[qrel_dict])\n",
    "# salvando métricas    \n",
    "print(f\"NDCG@10: {results['NDCG@10']}\")\n",
    "print(f\"Resultados: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['ndcg_10'] = round(100*results['NDCG@10'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tempo_indexacao_segundo': [{'tipo': 'cpu', 'valor': 0.109634}], 'memoria_indice_byte_ram': 269772727, 'se_retrieval_usa_gpu': True, 'retrieval_tempo_medio_por_query': 0.279581, 'ndcg_10': 74.85}\n"
     ]
    }
   ],
   "source": [
    "resultado_pipeline[nome_pipeline] = resultado_execucao\n",
    "print(resultado_pipeline[nome_pipeline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para utilizacao_perfeita custo gpu dia: 5.999616\n",
      "para utilizacao_precaria_100 custo gpu dia: 0.001941410464\n",
      "{'utilizacao_perfeita': {'usd_query': 2.18415e-05, 'usd_dia': 6.749761483605887, 'usd_gpu_dia': 5.999616, 'usd_mes': 202.49284450817663, 'usd_indexacao_tempo': 9.135801219999999e-07}, 'utilizacao_precaria_100': {'usd_query': 0.0075208689, 'usd_dia': 0.7520868940698879, 'usd_gpu_dia': 0.001941410464, 'usd_mes': 22.562606822096637, 'usd_indexacao_tempo': 9.135801219999999e-07}}\n"
     ]
    }
   ],
   "source": [
    "avaliacao_pipeline_contexto[nome_pipeline] = retorna_calculo_contexto(resultado_execucao, parm_tipo_gpu='3090')\n",
    "print(avaliacao_pipeline_contexto[nome_pipeline] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aT7_riDtAj_8"
   },
   "source": [
    "## bm25@500_reranking_minilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_pipeline = 'bm25@500_reranking_minilm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['tempo_indexacao_segundo'] = [{'tipo':'cpu', 'valor': tempo_construcao_indice_trecc_pyserine}]\n",
    "resultado_execucao['memoria_indice_byte_ram'] = tamanho_em_bytes_indice_trecc\n",
    "resultado_execucao['se_retrieval_usa_gpu'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 queries in total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Queries: 100%|██████████| 50/50 [01:07<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "tempo_gasto = run_all_queries_bm25_reranking(PATH_RUN_AVALIACAO, topics, searcher, model, tokenizer, num_max_hits=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo médio por query 1.347039\n"
     ]
    }
   ],
   "source": [
    "df_tempos = pd.DataFrame({'tempo_gasto': tempo_gasto})\n",
    "resultado_execucao['retrieval_tempo_medio_por_query'] = round(df_tempos['tempo_gasto'].describe()['mean'],6)\n",
    "print(f\"Tempo médio por query {resultado_execucao['retrieval_tempo_medio_por_query']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query  q0     docid  rank     score system\n",
      "0     44  Q0  qi1henyy     1  6.995133  Busca\n",
      "1     44  Q0  28utunid     2  6.964627  Busca\n",
      "2     44  Q0  ej76fsxa     3  6.382739  Busca\n",
      "3     44  Q0  uc37poce     4  6.346030  Busca\n",
      "4     44  Q0  dt2pew66     5  6.306264  Busca\n",
      "NDCG@10: 0.7146676971972016\n",
      "Resultados: {'runid': 'Busca', 'num_ret': 25000, 'num_rel': 24673, 'num_rel_ret': 7077, 'num_q': 50, 'map': 0.18720813343505024, 'gm_map': 0.14347464567182966, 'bpref': 0.2724897873211263, 'Rprec': 0.2772609408960807, 'recip_rank': 0.87, 'P@5': 0.8039999999999999, 'P@10': 0.774, 'P@15': 0.772, 'P@20': 0.7450000000000001, 'P@30': 0.7213333333333334, 'P@100': 0.5663999999999999, 'P@200': 0.4569, 'P@500': 0.28308, 'P@1000': 0.14154, 'NDCG@5': 0.7370341620293666, 'NDCG@10': 0.7146676971972016, 'NDCG@15': 0.706085483631409, 'NDCG@20': 0.6825016095070311, 'NDCG@30': 0.6640399915178563, 'NDCG@100': 0.5384526958818792, 'NDCG@200': 0.4541754023619141, 'NDCG@500': 0.3820112923070092, 'NDCG@1000': 0.355961866516238}\n"
     ]
    }
   ],
   "source": [
    "### Calculando métricas\n",
    "run = pd.read_csv(f\"{PATH_RUN_AVALIACAO}\", sep=\"\\s+\", \n",
    "                names=[\"query\", \"q0\", \"docid\", \"rank\", \"score\", \"system\"])\n",
    "print(run.head())\n",
    "run = run.to_dict(orient=\"list\")\n",
    "\n",
    "results = trec_eval.compute(predictions=[run], references=[qrel_dict])\n",
    "# salvando métricas    \n",
    "print(f\"NDCG@10: {results['NDCG@10']}\")\n",
    "print(f\"Resultados: {results}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['ndcg_10'] = round(100*results['NDCG@10'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tempo_indexacao_segundo': [{'tipo': 'cpu', 'valor': 0.109634}], 'memoria_indice_byte_ram': 269772727, 'se_retrieval_usa_gpu': True, 'retrieval_tempo_medio_por_query': 1.347039, 'ndcg_10': 71.47}\n"
     ]
    }
   ],
   "source": [
    "resultado_pipeline[nome_pipeline] = resultado_execucao\n",
    "print(resultado_pipeline[nome_pipeline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para utilizacao_perfeita custo gpu dia: 5.999616\n",
      "para utilizacao_precaria_100 custo gpu dia: 0.009353838816\n",
      "{'utilizacao_perfeita': {'usd_query': 0.0001052337, 'usd_dia': 6.749761483605887, 'usd_gpu_dia': 5.999616, 'usd_mes': 202.49284450817663, 'usd_indexacao_tempo': 9.135801219999999e-07}, 'utilizacao_precaria_100': {'usd_query': 0.0075949932, 'usd_dia': 0.759499322421888, 'usd_gpu_dia': 0.009353838816, 'usd_mes': 22.78497967265664, 'usd_indexacao_tempo': 9.135801219999999e-07}}\n"
     ]
    }
   ],
   "source": [
    "avaliacao_pipeline_contexto[nome_pipeline] = retorna_calculo_contexto(resultado_execucao, parm_tipo_gpu='3090')\n",
    "print(avaliacao_pipeline_contexto[nome_pipeline] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aT7_riDtAj_8"
   },
   "source": [
    "# Reranking com monobert (treinado no ms-marco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSeq2SeqLM\n",
    "# nome_modelo = 'zeta-alpha-ai/monot5-3b-inpars-v2-hotpotqa'\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(nome_modelo).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 314/314 [00:00<00:00, 198kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.34G/1.34G [00:56<00:00, 23.6MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 58.0/58.0 [00:00<00:00, 13.1kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 935kB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|██████████| 2.00/2.00 [00:00<00:00, 1.05kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 24.6kB/s]\n"
     ]
    }
   ],
   "source": [
    "nome_modelo = 'castorini/monobert-large-msmarco'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(nome_modelo).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(nome_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 509, 512)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.max_position_embeddings, tokenizer.max_len_sentences_pair, tokenizer.model_max_length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com num_max_hits=100, deu 2.61s por query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aT7_riDtAj_8"
   },
   "source": [
    "## bm25@50_reranking_monobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_pipeline = 'bm25@50_reranking_monobert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['tempo_indexacao_segundo'] = [{'tipo':'cpu', 'valor': tempo_construcao_indice_trecc_pyserine}]\n",
    "resultado_execucao['memoria_indice_byte_ram'] = tamanho_em_bytes_indice_trecc\n",
    "resultado_execucao['se_retrieval_usa_gpu'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 queries in total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Queries: 100%|██████████| 50/50 [01:02<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "tempo_gasto = run_all_queries_bm25_reranking(PATH_RUN_AVALIACAO, topics, searcher, model, tokenizer, parm_model_name = nome_pipeline, num_max_hits=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo médio por query 1.255988\n"
     ]
    }
   ],
   "source": [
    "df_tempos = pd.DataFrame({'tempo_gasto': tempo_gasto})\n",
    "resultado_execucao['retrieval_tempo_medio_por_query'] = round(df_tempos['tempo_gasto'].describe()['mean'],6)\n",
    "print(f\"Tempo médio por query {resultado_execucao['retrieval_tempo_medio_por_query']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query  q0     docid  rank     score system\n",
      "0     44  Q0  1c3fpazy     1  0.999238  Busca\n",
      "1     44  Q0  tfrawa9z     2  0.999225  Busca\n",
      "2     44  Q0  qi8x5yaq     3  0.999223  Busca\n",
      "3     44  Q0  ej76fsxa     4  0.999214  Busca\n",
      "4     44  Q0  dt2pew66     5  0.999213  Busca\n"
     ]
    }
   ],
   "source": [
    "### Calculando métricas\n",
    "run = pd.read_csv(f\"{PATH_RUN_AVALIACAO}\", sep=\"\\s+\", \n",
    "                names=[\"query\", \"q0\", \"docid\", \"rank\", \"score\", \"system\"])\n",
    "print(run.head())\n",
    "run = run.to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10: 0.7096526870747231\n",
      "Resultados: {'runid': 'Busca', 'num_ret': 2500, 'num_rel': 24673, 'num_rel_ret': 1376, 'num_q': 50, 'map': 0.05166934942623486, 'gm_map': 0.04099062092032248, 'bpref': 0.0645296401936393, 'Rprec': 0.06572166044632141, 'recip_rank': 0.9216666666666667, 'P@5': 0.828, 'P@10': 0.7620000000000001, 'P@15': 0.7146666666666667, 'P@20': 0.695, 'P@30': 0.6519999999999999, 'P@100': 0.2752, 'P@200': 0.1376, 'P@500': 0.05504, 'P@1000': 0.02752, 'NDCG@5': 0.766001702045763, 'NDCG@10': 0.7096526870747231, 'NDCG@15': 0.670553196225495, 'NDCG@20': 0.6499719430381152, 'NDCG@30': 0.6095907287833424, 'NDCG@100': 0.3281946867628143, 'NDCG@200': 0.20559705151099014, 'NDCG@500': 0.13860890962768477, 'NDCG@1000': 0.13095453971365084}\n"
     ]
    }
   ],
   "source": [
    "results = trec_eval.compute(predictions=[run], references=[qrel_dict])\n",
    "# salvando métricas    \n",
    "print(f\"NDCG@10: {results['NDCG@10']}\")\n",
    "print(f\"Resultados: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['ndcg_10'] = round(100*results['NDCG@10'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tempo_indexacao_segundo': [{'tipo': 'cpu', 'valor': 0.109634}], 'memoria_indice_byte_ram': 269772727, 'se_retrieval_usa_gpu': True, 'retrieval_tempo_medio_por_query': 1.255988, 'ndcg_10': 70.97}\n"
     ]
    }
   ],
   "source": [
    "resultado_pipeline[nome_pipeline] = resultado_execucao\n",
    "print(resultado_pipeline[nome_pipeline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para utilizacao_perfeita custo gpu dia: 5.999616\n",
      "para utilizacao_precaria_100 custo gpu dia: 0.008721580672\n",
      "{'utilizacao_perfeita': {'usd_query': 9.81206e-05, 'usd_dia': 6.749761483605887, 'usd_gpu_dia': 5.999616, 'usd_mes': 202.49284450817663, 'usd_indexacao_tempo': 9.135801219999999e-07}, 'utilizacao_precaria_100': {'usd_query': 0.0075886706, 'usd_dia': 0.758867064277888, 'usd_gpu_dia': 0.008721580672, 'usd_mes': 22.76601192833664, 'usd_indexacao_tempo': 9.135801219999999e-07}}\n"
     ]
    }
   ],
   "source": [
    "avaliacao_pipeline_contexto[nome_pipeline] = retorna_calculo_contexto(resultado_execucao, parm_tipo_gpu='3090')\n",
    "print(avaliacao_pipeline_contexto[nome_pipeline] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aT7_riDtAj_8"
   },
   "source": [
    "## bm25@80_reranking_monobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_pipeline = 'bm25@70_reranking_monobert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['tempo_indexacao_segundo'] = [{'tipo':'cpu', 'valor': tempo_construcao_indice_trecc_pyserine}]\n",
    "resultado_execucao['memoria_indice_byte_ram'] = tamanho_em_bytes_indice_trecc\n",
    "resultado_execucao['se_retrieval_usa_gpu'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 queries in total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Queries: 100%|██████████| 50/50 [01:26<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "tempo_gasto = run_all_queries_bm25_reranking(PATH_RUN_AVALIACAO, topics, searcher, model, tokenizer, parm_model_name = nome_pipeline, num_max_hits=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo médio por query 1.722126\n"
     ]
    }
   ],
   "source": [
    "df_tempos = pd.DataFrame({'tempo_gasto': tempo_gasto})\n",
    "resultado_execucao['retrieval_tempo_medio_por_query'] = round(df_tempos['tempo_gasto'].describe()['mean'],6)\n",
    "print(f\"Tempo médio por query {resultado_execucao['retrieval_tempo_medio_por_query']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query  q0     docid  rank     score system\n",
      "0     44  Q0  sqr11fpv     1  0.999256  Busca\n",
      "1     44  Q0  1c3fpazy     2  0.999238  Busca\n",
      "2     44  Q0  tfrawa9z     3  0.999225  Busca\n",
      "3     44  Q0  qi8x5yaq     4  0.999223  Busca\n",
      "4     44  Q0  ej76fsxa     5  0.999214  Busca\n"
     ]
    }
   ],
   "source": [
    "### Calculando métricas\n",
    "run = pd.read_csv(f\"{PATH_RUN_AVALIACAO}\", sep=\"\\s+\", \n",
    "                names=[\"query\", \"q0\", \"docid\", \"rank\", \"score\", \"system\"])\n",
    "print(run.head())\n",
    "run = run.to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10: 0.7125345158714298\n",
      "Resultados: {'runid': 'Busca', 'num_ret': 3500, 'num_rel': 24673, 'num_rel_ret': 1809, 'num_q': 50, 'map': 0.06603235354497793, 'gm_map': 0.05126868034686285, 'bpref': 0.08373357630972357, 'Rprec': 0.0858115450641355, 'recip_rank': 0.9183333333333334, 'P@5': 0.8160000000000001, 'P@10': 0.7680000000000001, 'P@15': 0.7266666666666667, 'P@20': 0.7050000000000002, 'P@30': 0.664, 'P@100': 0.3618, 'P@200': 0.1809, 'P@500': 0.07236000000000001, 'P@1000': 0.036180000000000004, 'NDCG@5': 0.7558310986857175, 'NDCG@10': 0.7125345158714298, 'NDCG@15': 0.6781198651661505, 'NDCG@20': 0.657118300414957, 'NDCG@30': 0.6202108799800279, 'NDCG@100': 0.3904172391900226, 'NDCG@200': 0.24421554275576385, 'NDCG@500': 0.16421304918364274, 'NDCG@1000': 0.1550146349052302}\n"
     ]
    }
   ],
   "source": [
    "results = trec_eval.compute(predictions=[run], references=[qrel_dict])\n",
    "# salvando métricas    \n",
    "print(f\"NDCG@10: {results['NDCG@10']}\")\n",
    "print(f\"Resultados: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_execucao['ndcg_10'] = round(100*results['NDCG@10'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tempo_indexacao_segundo': [{'tipo': 'cpu', 'valor': 0.109634}], 'memoria_indice_byte_ram': 269772727, 'se_retrieval_usa_gpu': True, 'retrieval_tempo_medio_por_query': 1.722126, 'ndcg_10': 71.25}\n"
     ]
    }
   ],
   "source": [
    "resultado_pipeline[nome_pipeline] = resultado_execucao\n",
    "print(resultado_pipeline[nome_pipeline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para utilizacao_perfeita custo gpu dia: 5.999616\n",
      "para utilizacao_precaria_100 custo gpu dia: 0.011958442944000001\n",
      "{'utilizacao_perfeita': {'usd_query': 0.0001345363, 'usd_dia': 6.749761483605887, 'usd_gpu_dia': 5.999616, 'usd_mes': 202.49284450817663, 'usd_indexacao_tempo': 9.135801219999999e-07}, 'utilizacao_precaria_100': {'usd_query': 0.0076210393, 'usd_dia': 0.7621039265498879, 'usd_gpu_dia': 0.011958442944000001, 'usd_mes': 22.86311779649664, 'usd_indexacao_tempo': 9.135801219999999e-07}}\n"
     ]
    }
   ],
   "source": [
    "avaliacao_pipeline_contexto[nome_pipeline] = retorna_calculo_contexto(resultado_execucao, parm_tipo_gpu='3090')\n",
    "print(avaliacao_pipeline_contexto[nome_pipeline] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_AVALIACAO_CONTEXTO_PIPELINE, 'wb') as outputFile:\n",
    "    pickle.dump(avaliacao_pipeline_contexto, outputFile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_RESULTADO_PIPELINE, 'wb') as outputFile:\n",
    "    pickle.dump(resultado_pipeline, outputFile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga dos resultados para novas avaliações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_RESULTADO_PIPELINE, 'rb') as f:\n",
    "    resultado_pipeline = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_AVALIACAO_CONTEXTO_PIPELINE, 'rb') as f:\n",
    "    avaliacao_pipeline_contexto = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treinapython39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e431eb1d856c426fade2a694f8536bd46c4e9c4bd47cb4afd3fb4d2c61122b03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
