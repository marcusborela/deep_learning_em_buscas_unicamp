{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcN_5-RDWeqV"
      },
      "source": [
        "# Busca simples\n",
        "\n",
        "Desenvolvimento de um buscador Simples: Booleano, TF-IDF, BM25\n",
        "\n",
        "Tópicos abordados: Indexação, Bag-of-Words, TF-IDF, BM25\n",
        "\n",
        "Aula 1 - [Unicamp - IA368DD: Deep Learning aplicado a sistemas de busca.](https://www.cpg.feec.unicamp.br/cpg/lista/caderno_horario_show.php?id=1779)\n",
        "\n",
        "Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "[Repositório no github](https://github.com/marcusborela/deep_learning_em_buscas_unicamp)\n",
        "\n",
        "[Link para chat de apoio com WebChatGPT](https://github.com/marcusborela/deep_learning_em_buscas_unicamp/blob/main/chat/CG%20uso%20no%20buscador%20aula%201.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti1aFWTVgejM"
      },
      "source": [
        "[![Open In Colab latest github version](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcusborela/deep_learning_em_buscas_unicamp/blob/main/code/aula1_buscador_simples.ipynb) [Open In Colab latest github version]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQxzYKGgMqce"
      },
      "source": [
        "## Enunciado exercício\n",
        "\n",
        "Aula 2 - Notebook: Buscador Booleano/bag-of-words e buscador com TF-IDF\n",
        "\n",
        "1. Usar o BM25 implementado pelo pyserini para buscar queries no TREC-DL 2020\n",
        "Documentação referencia: https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md\n",
        "2. Implementar um buscador booleano/bag-of-words.\n",
        "3. Implementar um buscador com TF-IDF\n",
        "4. Avaliar implementações 1, 2, e 3 no TREC-DL 2020 e calcular o nDCG@10\n",
        "Nos itens 2 e 3:\n",
        "\n",
        "Fazer uma implementação que suporta buscar eficientemente milhões de documentos.\n",
        "\n",
        "Não se pode usar bibliotecas como sklearn, que já implementam o BoW e TF-IDF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organizando o ambiente"
      ],
      "metadata": {
        "id": "BmRLgbyi_Dvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns_pq59lAHke",
        "outputId": "cdf9cc72-06ae-47cf-e825-5164fd90d991"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar  4 15:05:40 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    52W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n"
      ],
      "metadata": {
        "id": "DKAZ8CWCAM3-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mostra_memoria():\n",
        "  vm = virtual_memory()\n",
        "  ram={}\n",
        "  ram['total']=round(vm.total / 1e9,2)\n",
        "  ram['available']=round(virtual_memory().available / 1e9,2)\n",
        "  # ram['percent']=round(virtual_memory().percent / 1e9,2)\n",
        "  ram['used']=round(virtual_memory().used / 1e9,2)\n",
        "  ram['free']=round(virtual_memory().free / 1e9,2)\n",
        "  ram['active']=round(virtual_memory().active / 1e9,2)\n",
        "  ram['inactive']=round(virtual_memory().inactive / 1e9,2)\n",
        "  ram['buffers']=round(virtual_memory().buffers / 1e9,2)\n",
        "  ram['cached']=round(virtual_memory().cached/1e9 ,2)\n",
        "  print(f\"Your runtime RAM in gb: \\n total {ram['total']}\\n available {ram['available']}\\n used {ram['used']}\\n free {ram['free']}\\n cached {ram['cached']}\\n buffers {ram['buffers']}\")\n"
      ],
      "metadata": {
        "id": "9XgIWvkkH-kn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_memoria()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dri9iiMAvCT",
        "outputId": "4db98aa6-46c0-4cb9-dac7-2833e6e584dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 89.64\n",
            " available 87.95\n",
            " used 0.9\n",
            " free 85.19\n",
            " cached 3.19\n",
            " buffers 0.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vinculando pasta do google drive para salvar dados"
      ],
      "metadata": {
        "id": "r9xRdgUGMPgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "IsJiN6H8K6pe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ae-Iy2oz_9os",
        "outputId": "4849a217-f67c-42e9-f66c-152a3f8c60d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive'"
      ],
      "metadata": {
        "id": "HlGfGbtnBP0K",
        "outputId": "f830f6f8-79bf-44cb-c93b-8952e5af72f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_dir = os.getcwd()\n",
        "print(\"Current directory:\", current_dir)"
      ],
      "metadata": {
        "id": "7GYGL4MV_yhQ",
        "outputId": "7b305452-fb5b-4d2b-fe59-7daf07e203bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalações de libraries"
      ],
      "metadata": {
        "id": "Y5MRuHo8md3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/castorini/pygaggle.git"
      ],
      "metadata": {
        "id": "N2af9dTbmPff",
        "outputId": "72bb72aa-f2fe-4380-f0ee-6ea021f5dd01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/castorini/pygaggle.git\n",
            "  Cloning https://github.com/castorini/pygaggle.git to /tmp/pip-req-build-zx5uu6_g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/castorini/pygaggle.git /tmp/pip-req-build-zx5uu6_g\n",
            "  Resolved https://github.com/castorini/pygaggle.git to commit c285f6084684367dd07b608ef19c2722b5b0637e\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coloredlogs==14.0\n",
            "  Downloading coloredlogs-14.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.8/dist-packages (from pygaggle==0.0.3.1) (1.22.4)\n",
            "Collecting pydantic==1.7.4\n",
            "  Downloading pydantic-1.7.4-cp38-cp38-manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyserini>=0.16.0\n",
            "  Downloading pyserini-0.20.0-py3-none-any.whl (137.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.8/dist-packages (from pygaggle==0.0.3.1) (3.4.4)\n",
            "Collecting tensorboard==2.7.0\n",
            "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp38-cp38-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.6/489.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.10.2\n",
            "  Downloading tokenizers-0.10.2-cp38-cp38-manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.56.0\n",
            "  Downloading tqdm-4.56.0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.6.1\n",
            "  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence_transformers==2.0.0\n",
            "  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 KB\u001b[0m \u001b[31m336.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from pygaggle==0.0.3.1) (1.13.1+cu116)\n",
            "Collecting humanfriendly>=7.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.24.2->pygaggle==0.0.3.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.24.2->pygaggle==0.0.3.1) (3.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence_transformers==2.0.0->pygaggle==0.0.3.1) (0.14.1+cu116)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence_transformers==2.0.0->pygaggle==0.0.3.1) (3.7)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (2.2.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (2.16.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (1.51.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (3.19.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (1.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (2.25.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 KB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (0.31.0)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (2.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (1.15.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (0.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (15.0.6.1)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (4.5.0)\n",
            "Collecting flatbuffers<3.0,>=1.12\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.6.1->pygaggle==0.0.3.1) (2022.6.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.6.1->pygaggle==0.0.3.1) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.6.1->pygaggle==0.0.3.1) (3.9.0)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.8/dist-packages (from pyserini>=0.16.0->pygaggle==0.0.3.1) (0.29.33)\n",
            "Collecting onnxruntime>=1.8.1\n",
            "  Downloading onnxruntime-1.14.1-cp38-cp38-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjnius>=1.4.0\n",
            "  Downloading pyjnius-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=1.4.0\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nmslib>=2.1.1\n",
            "  Downloading nmslib-2.1.1-cp38-cp38-manylinux2010_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (2.4.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (3.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (3.1.2)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (1.0.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (8.1.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (3.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.7.0->pygaggle==0.0.3.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.7.0->pygaggle==0.0.3.1) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.7.0->pygaggle==0.0.3.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.7.0->pygaggle==0.0.3.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard==2.7.0->pygaggle==0.0.3.1) (6.0.0)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from nmslib>=2.1.1->pyserini>=0.16.0->pygaggle==0.0.3.1) (5.4.8)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini>=0.16.0->pygaggle==0.0.3.1) (1.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini>=0.16.0->pygaggle==0.0.3.1) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini>=0.16.0->pygaggle==0.0.3.1) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.7.0->pygaggle==0.0.3.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.7.0->pygaggle==0.0.3.1) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.7.0->pygaggle==0.0.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.7.0->pygaggle==0.0.3.1) (4.0.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pygaggle==0.0.3.1) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pygaggle==0.0.3.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.1->pygaggle==0.0.3.1) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=0.11.15->tensorboard==2.7.0->pygaggle==0.0.3.1) (2.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence_transformers==2.0.0->pygaggle==0.0.3.1) (8.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.7.0->pygaggle==0.0.3.1) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.7.0->pygaggle==0.0.3.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.7.0->pygaggle==0.0.3.1) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini>=0.16.0->pygaggle==0.0.3.1) (1.2.1)\n",
            "Building wheels for collected packages: pygaggle, sentence_transformers, sacremoses\n",
            "  Building wheel for pygaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygaggle: filename=pygaggle-0.0.3.1-py3-none-any.whl size=75889 sha256=52033f9def102650e1dea0e4178c51ba9413a83acc275939f303bf8757f79808\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wqm80b8j/wheels/3e/3f/f4/4b5a7cd54450cf49522bc9e76a0e57cea70a9f731fc4ff0257\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126709 sha256=fb3349a613048991bb51e47e3f8bcb9beb17aff11d10d2875b10ef1b92d666a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/b7/50/451c9a52a337aac5521dbc10544a69e1447d28012feba30742\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d7ddfbe94438a0d1692487e9d982fb4cfa3fbcb3d9800a7b3824d16f2c8e816a\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built pygaggle sentence_transformers sacremoses\n",
            "Installing collected packages: tokenizers, tensorflow-estimator, sentencepiece, keras, flatbuffers, tqdm, scipy, pyjnius, pydantic, pybind11, keras-preprocessing, humanfriendly, scikit-learn, sacremoses, pandas, nmslib, huggingface-hub, coloredlogs, transformers, onnxruntime, lightgbm, tensorboard, sentence_transformers, tensorflow, pyserini, pygaggle\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.1.21\n",
            "    Uninstalling flatbuffers-23.1.21:\n",
            "      Successfully uninstalled flatbuffers-23.1.21\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.5\n",
            "    Uninstalling pydantic-1.10.5:\n",
            "      Successfully uninstalled pydantic-1.10.5\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.1\n",
            "    Uninstalling scikit-learn-1.2.1:\n",
            "      Successfully uninstalled scikit-learn-1.2.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.11.2\n",
            "    Uninstalling tensorboard-2.11.2:\n",
            "      Successfully uninstalled tensorboard-2.11.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.11.0\n",
            "    Uninstalling tensorflow-2.11.0:\n",
            "      Successfully uninstalled tensorflow-2.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed coloredlogs-14.0 flatbuffers-2.0.7 huggingface-hub-0.0.8 humanfriendly-10.0 keras-2.7.0 keras-preprocessing-1.1.2 lightgbm-3.3.5 nmslib-2.1.1 onnxruntime-1.14.1 pandas-1.5.3 pybind11-2.6.1 pydantic-1.7.4 pygaggle-0.0.3.1 pyjnius-1.4.2 pyserini-0.20.0 sacremoses-0.0.53 scikit-learn-0.24.2 scipy-1.5.4 sentence_transformers-2.0.0 sentencepiece-0.1.95 tensorboard-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tokenizers-0.10.2 tqdm-4.56.0 transformers-4.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyserini"
      ],
      "metadata": {
        "id": "WTTVf-nYmc0w",
        "outputId": "7db3e6ac-fc6c-4113-dabe-ea1f5eea7bc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyserini in /usr/local/lib/python3.8/dist-packages (0.20.0)\n",
            "Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.8/dist-packages (from pyserini) (0.29.33)\n",
            "Requirement already satisfied: sentencepiece>=0.1.95 in /usr/local/lib/python3.8/dist-packages (from pyserini) (0.1.95)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (0.24.2)\n",
            "Requirement already satisfied: onnxruntime>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.14.1)\n",
            "Requirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (3.4.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pyserini) (4.56.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.22.4)\n",
            "Requirement already satisfied: lightgbm>=3.3.2 in /usr/local/lib/python3.8/dist-packages (from pyserini) (3.3.5)\n",
            "Requirement already satisfied: transformers>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from pyserini) (4.6.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.5.4)\n",
            "Requirement already satisfied: pyjnius>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.4.2)\n",
            "Requirement already satisfied: nmslib>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (2.1.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=3.3.2->pyserini) (0.38.4)\n",
            "Requirement already satisfied: pybind11<2.6.2 in /usr/local/lib/python3.8/dist-packages (from nmslib>=2.1.1->pyserini) (2.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.7.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (2.0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (14.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini) (2.8.2)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (6.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (8.1.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.7.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.4.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.12)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.25.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.7.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (0.0.53)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (0.0.8)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (0.10.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.1->pyserini) (8.1.3)\n",
            "Requirement already satisfied: humanfriendly>=7.1 in /usr/local/lib/python3.8/dist-packages (from coloredlogs->onnxruntime>=1.8.1->pyserini) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu -q"
      ],
      "metadata": {
        "id": "F3U_q5n1n_BW",
        "outputId": "f7c0b34d-e8a1-413b-f6ff-3711e52ec145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/17.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/17.0 MB\u001b[0m \u001b[31m171.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/17.0 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m15.7/17.0 MB\u001b[0m \u001b[31m142.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m186.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m186.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baixando o repositório do pyserini para usara seus scripts"
      ],
      "metadata": {
        "id": "iMp1ME6UK8vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_pyserini = '/content/drive/MyDrive/treinamento/202301_IA368DD/code/pyserini'\n",
        "path_pyserini_tools = path_pyserini + '/pyserini-master/anserini-tools-master'\n",
        "path_pyserini_eval = path_pyserini + '/pyserini-master/pyserini/eval'"
      ],
      "metadata": {
        "id": "aGyBaf54LwCp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(path_pyserini):\n",
        "    os.makedirs(path_pyserini)\n",
        "    print('pasta criada')\n",
        "    !wget -q https://github.com/castorini/pyserini/archive/refs/heads/master.zip -O pyserini.zip \n",
        "    !unzip -q pyserini.zip -d  {path_pyserini}\n",
        "    # Baixando tools que é um atalho para https://github.com/castorini/anserini-tools\n",
        "    !wget -q https://github.com/castorini/anserini-tools/archive/refs/heads/master.zip -O anserini-tools.zip \n",
        "    !unzip -q anserini-tools.zip -d  {path_pyserini}\n",
        "path_pyserini = path_pyserini + '/pyserini-master'"
      ],
      "metadata": {
        "id": "vVBzuIuVMCqK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " assert os.path.exists(path_pyserini), f\"Pasta {path_pyserini} não criada!\""
      ],
      "metadata": {
        "id": "CLHh0Nh8PW2E"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " assert os.path.exists(path_pyserini_tools), f\"Pasta {path_pyserini_tools} não criada!\""
      ],
      "metadata": {
        "id": "30pi-eYwQ4zo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " assert os.path.exists(path_pyserini_eval), f\"Pasta {path_pyserini_eval} não criada!\""
      ],
      "metadata": {
        "id": "kF1v31OuUzpM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga dos dados da TREC 2020 usando pyserini"
      ],
      "metadata": {
        "id": "MBfxPDhaFq5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g4gKjhiICmAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtendo dados a partir do pyserini\n",
        "\n",
        "\n",
        "[Dicas aqui](https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md)"
      ],
      "metadata": {
        "id": "hGPQPU38MbZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_data = '/content/drive/MyDrive/treinamento/202301_IA368DD/collections/msmarco-passage'"
      ],
      "metadata": {
        "id": "2WGHMsGcB7Ep"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if not os.path.exists(path_data):\n",
        "  os.makedirs(path_data)\n",
        "  print('pasta criada')\n",
        "  !wget https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz -P {path_data}\n",
        "  !tar xvfz {path_data}/collectionandqueries.tar.gz -C {path_data}\n",
        "  os.remove(f'{path_data}/collectionandqueries.tar.gz')\n",
        "  print(\"Dados carregados!\")\n",
        "else:\n",
        "  print(\"Dados já existiam!\")    "
      ],
      "metadata": {
        "id": "tDb6qDbsA38j"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " assert os.path.exists(path_data), f\"Pasta {path_data} não criada!\""
      ],
      "metadata": {
        "id": "B5g4HhyAPx-4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo anterior gera os seguintes arquivos:\n",
        "\n",
        "* collection.tsv\n",
        "* qrels.dev.small.tsv\n",
        "* qrels.train.tsv\n",
        "* queries.dev.small.tsv\n",
        "* queries.dev.tsv\n",
        "* queries.eval.small.tsv\n",
        "* queries.eval.tsv\n",
        "* queries.train.tsv"
      ],
      "metadata": {
        "id": "VzPgONt7ERjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to convert the MS MARCO tsv collection into Pyserini's jsonl files (which have one json object per line):"
      ],
      "metadata": {
        "id": "oiNtb0oVDTPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baixando o programa do github do pyserini"
      ],
      "metadata": {
        "id": "QBvD2wMwEaVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if not os.path.exists(f'{path_data}/collection_jsonl'):\n",
        "  !python {path_pyserini_tools}/tools/scripts/msmarco/convert_collection_to_jsonl.py \\\n",
        "  --collection-path {path_data}/collection.tsv \\\n",
        "  --output-folder {path_data}/collection_jsonl\n",
        "  print(\"Dados carregados!\")\n",
        "else:\n",
        "  print(\"Dados já existiam!\")    "
      ],
      "metadata": {
        "id": "3Cf9nEQS_iWs",
        "outputId": "601c3ea1-4e0a-4a06-bf0c-5324c509d3d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting collection...\n",
            "Converted 0 docs, writing into file 1\n",
            "Converted 100,000 docs, writing into file 1\n",
            "Converted 200,000 docs, writing into file 1\n",
            "Converted 300,000 docs, writing into file 1\n",
            "Converted 400,000 docs, writing into file 1\n",
            "Converted 500,000 docs, writing into file 1\n",
            "Converted 600,000 docs, writing into file 1\n",
            "Converted 700,000 docs, writing into file 1\n",
            "Converted 800,000 docs, writing into file 1\n",
            "Converted 900,000 docs, writing into file 1\n",
            "Converted 1,000,000 docs, writing into file 2\n",
            "Converted 1,100,000 docs, writing into file 2\n",
            "Converted 1,200,000 docs, writing into file 2\n",
            "Converted 1,300,000 docs, writing into file 2\n",
            "Converted 1,400,000 docs, writing into file 2\n",
            "Converted 1,500,000 docs, writing into file 2\n",
            "Converted 1,600,000 docs, writing into file 2\n",
            "Converted 1,700,000 docs, writing into file 2\n",
            "Converted 1,800,000 docs, writing into file 2\n",
            "Converted 1,900,000 docs, writing into file 2\n",
            "Converted 2,000,000 docs, writing into file 3\n",
            "Converted 2,100,000 docs, writing into file 3\n",
            "Converted 2,200,000 docs, writing into file 3\n",
            "Converted 2,300,000 docs, writing into file 3\n",
            "Converted 2,400,000 docs, writing into file 3\n",
            "Converted 2,500,000 docs, writing into file 3\n",
            "Converted 2,600,000 docs, writing into file 3\n",
            "Converted 2,700,000 docs, writing into file 3\n",
            "Converted 2,800,000 docs, writing into file 3\n",
            "Converted 2,900,000 docs, writing into file 3\n",
            "Converted 3,000,000 docs, writing into file 4\n",
            "Converted 3,100,000 docs, writing into file 4\n",
            "Converted 3,200,000 docs, writing into file 4\n",
            "Converted 3,300,000 docs, writing into file 4\n",
            "Converted 3,400,000 docs, writing into file 4\n",
            "Converted 3,500,000 docs, writing into file 4\n",
            "Converted 3,600,000 docs, writing into file 4\n",
            "Converted 3,700,000 docs, writing into file 4\n",
            "Converted 3,800,000 docs, writing into file 4\n",
            "Converted 3,900,000 docs, writing into file 4\n",
            "Converted 4,000,000 docs, writing into file 5\n",
            "Converted 4,100,000 docs, writing into file 5\n",
            "Converted 4,200,000 docs, writing into file 5\n",
            "Converted 4,300,000 docs, writing into file 5\n",
            "Converted 4,400,000 docs, writing into file 5\n",
            "Converted 4,500,000 docs, writing into file 5\n",
            "Converted 4,600,000 docs, writing into file 5\n",
            "Converted 4,700,000 docs, writing into file 5\n",
            "Converted 4,800,000 docs, writing into file 5\n",
            "Converted 4,900,000 docs, writing into file 5\n",
            "Converted 5,000,000 docs, writing into file 6\n",
            "Converted 5,100,000 docs, writing into file 6\n",
            "Converted 5,200,000 docs, writing into file 6\n",
            "Converted 5,300,000 docs, writing into file 6\n",
            "Converted 5,400,000 docs, writing into file 6\n",
            "Converted 5,500,000 docs, writing into file 6\n",
            "Converted 5,600,000 docs, writing into file 6\n",
            "Converted 5,700,000 docs, writing into file 6\n",
            "Converted 5,800,000 docs, writing into file 6\n",
            "Converted 5,900,000 docs, writing into file 6\n",
            "Converted 6,000,000 docs, writing into file 7\n",
            "Converted 6,100,000 docs, writing into file 7\n",
            "Converted 6,200,000 docs, writing into file 7\n",
            "Converted 6,300,000 docs, writing into file 7\n",
            "Converted 6,400,000 docs, writing into file 7\n",
            "Converted 6,500,000 docs, writing into file 7\n",
            "Converted 6,600,000 docs, writing into file 7\n",
            "Converted 6,700,000 docs, writing into file 7\n",
            "Converted 6,800,000 docs, writing into file 7\n",
            "Converted 6,900,000 docs, writing into file 7\n",
            "Converted 7,000,000 docs, writing into file 8\n",
            "Converted 7,100,000 docs, writing into file 8\n",
            "Converted 7,200,000 docs, writing into file 8\n",
            "Converted 7,300,000 docs, writing into file 8\n",
            "Converted 7,400,000 docs, writing into file 8\n",
            "Converted 7,500,000 docs, writing into file 8\n",
            "Converted 7,600,000 docs, writing into file 8\n",
            "Converted 7,700,000 docs, writing into file 8\n",
            "Converted 7,800,000 docs, writing into file 8\n",
            "Converted 7,900,000 docs, writing into file 8\n",
            "Converted 8,000,000 docs, writing into file 9\n",
            "Converted 8,100,000 docs, writing into file 9\n",
            "Converted 8,200,000 docs, writing into file 9\n",
            "Converted 8,300,000 docs, writing into file 9\n",
            "Converted 8,400,000 docs, writing into file 9\n",
            "Converted 8,500,000 docs, writing into file 9\n",
            "Converted 8,600,000 docs, writing into file 9\n",
            "Converted 8,700,000 docs, writing into file 9\n",
            "Converted 8,800,000 docs, writing into file 9\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert os.path.exists(f'{path_data}/collection_jsonl'), f\"Pasta {path_data}/collection_jsonl não criada!\""
      ],
      "metadata": {
        "id": "XWbCv1UAP3yc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above script should generate 9 jsonl files in collections/msmarco-passage/collection_jsonl, each with 1M lines (except for the last one, which should have 841,823 lines)."
      ],
      "metadata": {
        "id": "u4snYshcDmXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertendo as queries (small dev) para o formato trec para avaliações futuras"
      ],
      "metadata": {
        "id": "-wY35wjJNt99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(f'{path_data}/qrels.dev.small.trec'):\n",
        "  !python {path_pyserini_tools}/scripts/msmarco/convert_msmarco_to_trec_qrels.py \\\n",
        "  --input {path_pyserini_tools}/topics-and-qrels/qrels.msmarco-passage.dev-subset.txt \\\n",
        "  --output {path_data}/qrels.dev.small.trec\n",
        "  print(\"Conversão efetuada!\")\n",
        "else:\n",
        "  print(\"Arquivo já existia!\")\n"
      ],
      "metadata": {
        "id": "GXahbDquMWvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data in dicts\n",
        "\n",
        "The 6980 queries in the development set are already stored in the repo. Let's take a peek:"
      ],
      "metadata": {
        "id": "sTn273M0FTTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_pyserini_tools}/topics-and-qrels/topics.msmarco-passage.dev-subset.txt"
      ],
      "metadata": {
        "id": "t-WOE8VZPfzf",
        "outputId": "8905dbb6-4a87-49cf-890c-a22ed360af51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1048585\twhat is paula deen's brother\n",
            "2\t Androgen receptor define\n",
            "524332\ttreating tension headaches without medication\n",
            "1048642\twhat is paranoid sc\n",
            "524447\ttreatment of varicose veins in legs\n",
            "786674\twhat is prime rate in canada\n",
            "1048876\twho plays young dr mallard on ncis\n",
            "1048917\twhat is operating system misconfiguration\n",
            "786786\twhat is priority pass\n",
            "524699\ttricare service number\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_pyserini_tools}/topics-and-qrels/topics.dl20.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "418Ih9pyiABT",
        "outputId": "bce16c08-4e2e-41e0-b119-f574841309ee"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030303\twho is aziz hashim\r\n",
            "1037496\twho is rep scalise?\r\n",
            "1043135\twho killed nicholas ii of russia\r\n",
            "1045109\twho owns barnhart crane\r\n",
            "1049519\twho said no one can make you feel inferior\r\n",
            "1051399\twho sings monk theme song\r\n",
            "1056416\twho was the highest career passer  rating in the nfl\r\n",
            "1064670\twhy do hunters pattern their shotguns?\r\n",
            "1065636\twhy do some places on my scalp feel sore\r\n",
            "1071750\twhy is pete rose banned from hall of fame\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_data}/qrels.dev.small.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxlsspHzRu0o",
        "outputId": "d5b87b53-0be5-41b8-a63a-f1e939b66682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300674 0 7067032 1\n",
            "125705 0 7067056 1\n",
            "94798 0 7067181 1\n",
            "9083 0 7067274 1\n",
            "174249 0 7067348 1\n",
            "320792 0 7067677 1\n",
            "1090270 0 7067796 1\n",
            "1101279 0 7067891 1\n",
            "201376 0 7068066 1\n",
            "54544 0 7068203 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_pyserini_tools}/topics-and-qrels/qrels.msmarco-passage.dev-subset.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-mW3XUeauti",
        "outputId": "8d8fb576-5506-4559-fd5a-26e271fa8c16"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300674 0 7067032 1\n",
            "125705 0 7067056 1\n",
            "94798 0 7067181 1\n",
            "9083 0 7067274 1\n",
            "174249 0 7067348 1\n",
            "320792 0 7067677 1\n",
            "1090270 0 7067796 1\n",
            "1101279 0 7067891 1\n",
            "201376 0 7068066 1\n",
            "54544 0 7068203 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_pyserini_tools}/topics-and-qrels/qrels.dl20-passage.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoeVZrqXbGZo",
        "outputId": "3753d593-eecb-4d84-ae42-4a6262c6cd17"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 0 1020327 2\n",
            "23849 0 1034183 3\n",
            "23849 0 1120730 0\n",
            "23849 0 1139571 1\n",
            "23849 0 1143724 0\n",
            "23849 0 1147202 0\n",
            "23849 0 1150311 0\n",
            "23849 0 1158886 2\n",
            "23849 0 1175024 1\n",
            "23849 0 1201385 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each line contains a tab-delimited (query id, query) pair. Conveniently, Pyserini already knows how to load and iterate through these pairs. We can now perform retrieval using these queries:"
      ],
      "metadata": {
        "id": "-9XSzW8uHtic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carregando queries"
      ],
      "metadata": {
        "id": "4qiloI8loxJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ler_arquivo_query_trec20(file_path:str):\n",
        "  \"\"\"\n",
        "  Função para ler um arquivo de queries TREC 2020 e retorná-las em um dicionário.\n",
        "\n",
        "  Args:\n",
        "    file_path (str): Caminho do arquivo de queries TREC 2020\n",
        "\n",
        "  Returns:\n",
        "    dict: Dicionário em que as chaves são os IDs das queries e os valores são os\n",
        "          textos das queries correspondentes.\n",
        "  \"\"\"\n",
        "\n",
        "  # Cria um dicionário vazio para armazenar as queries\n",
        "  query_dict = {}\n",
        "\n",
        "  # Abre o arquivo em modo leitura\n",
        "  with open(file_path, 'r') as f:\n",
        "      \n",
        "      # Itera sobre as linhas do arquivo\n",
        "      for line in f:\n",
        "\n",
        "          # Separa a linha em duas partes (id e texto), considerando que são separadas por uma tabulação\n",
        "          query_id, query_text = line.strip().split('\\t')\n",
        "          query_id = int(query_id)\n",
        "          # Adiciona a query ao dicionário, usando o id como chave e o texto como valor\n",
        "          query_dict[query_id] = query_text\n",
        "\n",
        "  # Retorna o dicionário com as queries\n",
        "  return query_dict"
      ],
      "metadata": {
        "id": "G6ktuslxQ7QL"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando queries de todo o dev dataset (total 6980)"
      ],
      "metadata": {
        "id": "VDnaMYIji-NL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_dev_dict = ler_arquivo_query_trec20(f'{path_pyserini_tools}/topics-and-qrels/topics.msmarco-passage.dev-subset.txt')"
      ],
      "metadata": {
        "id": "NAxjWWwoRR8a"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(query_dev_dict),list(query_dev_dict.items())[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM9c3tbeidhU",
        "outputId": "041784f6-0b42-4917-b7ca-648871d76343"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6980,\n",
              " [(1048585, \"what is paula deen's brother\"),\n",
              "  (2, ' Androgen receptor define'),\n",
              "  (524332, 'treating tension headaches without medication'),\n",
              "  (1048642, 'what is paranoid sc')])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando o queries do trec20 dataset (total 200)"
      ],
      "metadata": {
        "id": "R4ns_AJ7jDGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_dev_dict = ler_arquivo_query_trec20(f'{path_pyserini_tools}/topics-and-qrels/topics.dl20.txt')"
      ],
      "metadata": {
        "id": "NrNCbYWpiHE5"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(query_dev_dict),list(query_dev_dict.items())[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7kG-2z0iMQ7",
        "outputId": "019dc6c3-c042-4c4d-f2aa-b5bcea3d2c5b"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,\n",
              " [(1030303, 'who is aziz hashim'),\n",
              "  (1037496, 'who is rep scalise?'),\n",
              "  (1043135, 'who killed nicholas ii of russia'),\n",
              "  (1045109, 'who owns barnhart crane')])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando usando get_topics:"
      ],
      "metadata": {
        "id": "emUYIElNoHmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyserini.search import get_topics"
      ],
      "metadata": {
        "id": "Ipt1M8UBoSiP"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = get_topics('dl20')\n",
        "print(f'{len(topics)} queries total')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei_BuJtsoTjm",
        "outputId": "6ad2b2c1-4d7e-4af2-9bd5-8bbb0958a246"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 queries total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(topics), list(topics.items())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m7xTZe-oVNF",
        "outputId": "682ef9e9-79f1-4694-d862-9b0b585f56ac"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, (735922, {'title': 'what is crimp oil'}))"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carregando qrel (relevância por query)"
      ],
      "metadata": {
        "id": "pw6AV1W3osR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ler_arquivo_qrels_trec20(file_path:str) -> dict:\n",
        "    \"\"\"\n",
        "    Lê um arquivo TSV contendo a avaliação de relevância de documentos para cada consulta.\n",
        "    \n",
        "    Args:\n",
        "    file_path: str - O caminho do arquivo a ser lido.\n",
        "    \n",
        "    Returns:\n",
        "    dict - Um dicionário onde as chaves são os IDs das consultas e os valores são \n",
        "           dicionários em que as chaves são os IDs dos documentos e os valores são \n",
        "           os níveis de relevância (0, 1, 2, 3, ou 4) de cada documento para a consulta correspondente.\n",
        "    \"\"\"\n",
        "    qrels_dict = {}\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        # Itera sobre cada linha do arquivo\n",
        "        for line in f:\n",
        "            # Separa a linha em seus campos\n",
        "            query_id, _, doc_id, relevance = line.strip().split()\n",
        "            query_id = int(query_id)\n",
        "            doc_id = int(doc_id)\n",
        "            # Verifica se a consulta já existe no dicionário\n",
        "            if query_id not in qrels_dict:\n",
        "                qrels_dict[query_id] = {}\n",
        "            # Adiciona o ID do documento e seu nível de relevância\n",
        "            qrels_dict[query_id][doc_id] = int(relevance)\n",
        "    return qrels_dict"
      ],
      "metadata": {
        "id": "lOmEAdTNRkbB"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando qrel de todo o dev dataset"
      ],
      "metadata": {
        "id": "T9g2vYX4iwZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrel_dev_dict = ler_arquivo_qrels_trec20(f'{path_data}/qrels.dev.small.trec')"
      ],
      "metadata": {
        "id": "HWh0C-NkRkW8"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(qrel_dev_dict),list(qrel_dev_dict.items())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlwCxvUEdVUo",
        "outputId": "d8a5666a-e481-4cfb-f9d1-14539a6f271e"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6980, (300674, {7067032: 1}))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando o qrel do trec20 dataset"
      ],
      "metadata": {
        "id": "XvaowThZi0oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrel_dev_dict = ler_arquivo_qrels_trec20(f'{path_pyserini_tools}/topics-and-qrels/qrels.dl20-passage.txt')"
      ],
      "metadata": {
        "id": "QCcNt3BVbbFf"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(qrel_dev_dict),list(qrel_dev_dict.items())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WReZ3_qioXl",
        "outputId": "59da5b07-265d-4842-a26b-5bd512e1abc5"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54,\n",
              " (23849,\n",
              "  {1020327: 2,\n",
              "   1034183: 3,\n",
              "   1120730: 0,\n",
              "   1139571: 1,\n",
              "   1143724: 0,\n",
              "   1147202: 0,\n",
              "   1150311: 0,\n",
              "   1158886: 2,\n",
              "   1175024: 1,\n",
              "   1201385: 0,\n",
              "   1215556: 0,\n",
              "   1220759: 0,\n",
              "   1221770: 0,\n",
              "   1333480: 1,\n",
              "   1381453: 2,\n",
              "   1414114: 2,\n",
              "   1414115: 0,\n",
              "   1414120: 2,\n",
              "   1449780: 0,\n",
              "   146754: 0,\n",
              "   1493231: 0,\n",
              "   1532701: 0,\n",
              "   1535484: 0,\n",
              "   1605854: 1,\n",
              "   1605857: 1,\n",
              "   1622747: 1,\n",
              "   17118: 0,\n",
              "   17122: 0,\n",
              "   1714915: 0,\n",
              "   1714917: 1,\n",
              "   1724687: 0,\n",
              "   172488: 0,\n",
              "   178252: 0,\n",
              "   182049: 0,\n",
              "   1827512: 1,\n",
              "   1844627: 0,\n",
              "   188190: 0,\n",
              "   188246: 1,\n",
              "   1944730: 0,\n",
              "   2003292: 0,\n",
              "   2017213: 0,\n",
              "   2203364: 0,\n",
              "   2209883: 0,\n",
              "   2318793: 0,\n",
              "   2339898: 1,\n",
              "   2373852: 0,\n",
              "   2397072: 0,\n",
              "   2423771: 0,\n",
              "   2516458: 0,\n",
              "   2585563: 0,\n",
              "   2593928: 0,\n",
              "   2607127: 3,\n",
              "   2607128: 1,\n",
              "   2607129: 2,\n",
              "   2607130: 2,\n",
              "   2607131: 2,\n",
              "   2607132: 3,\n",
              "   2607134: 0,\n",
              "   2647769: 3,\n",
              "   2674124: 0,\n",
              "   2766280: 0,\n",
              "   282421: 0,\n",
              "   2838462: 3,\n",
              "   2880479: 0,\n",
              "   2934343: 0,\n",
              "   293608: 0,\n",
              "   293753: 0,\n",
              "   3008750: 1,\n",
              "   310272: 0,\n",
              "   3104533: 0,\n",
              "   3113002: 0,\n",
              "   314300: 0,\n",
              "   3185119: 1,\n",
              "   3341056: 0,\n",
              "   3342089: 0,\n",
              "   3374884: 0,\n",
              "   3376500: 0,\n",
              "   3678109: 0,\n",
              "   3687776: 0,\n",
              "   3698649: 0,\n",
              "   3799370: 0,\n",
              "   3878669: 1,\n",
              "   3978767: 2,\n",
              "   3978774: 1,\n",
              "   4016311: 2,\n",
              "   4016314: 1,\n",
              "   4016317: 3,\n",
              "   4065323: 1,\n",
              "   4091550: 0,\n",
              "   4091551: 0,\n",
              "   4104777: 0,\n",
              "   4138534: 2,\n",
              "   4188880: 1,\n",
              "   4281690: 1,\n",
              "   4344309: 1,\n",
              "   4348282: 0,\n",
              "   436721: 0,\n",
              "   4387499: 0,\n",
              "   441893: 0,\n",
              "   4482145: 0,\n",
              "   4527137: 0,\n",
              "   4556932: 3,\n",
              "   4556933: 3,\n",
              "   4556936: 0,\n",
              "   4556938: 0,\n",
              "   4556941: 0,\n",
              "   45662: 1,\n",
              "   4576574: 0,\n",
              "   4577479: 0,\n",
              "   4672905: 0,\n",
              "   4804092: 0,\n",
              "   4834498: 0,\n",
              "   4908953: 1,\n",
              "   4908957: 1,\n",
              "   4951252: 0,\n",
              "   5315510: 0,\n",
              "   5340997: 1,\n",
              "   5365059: 0,\n",
              "   5367780: 0,\n",
              "   542113: 0,\n",
              "   5529682: 0,\n",
              "   5597936: 1,\n",
              "   5633221: 0,\n",
              "   5740854: 2,\n",
              "   5740859: 1,\n",
              "   5809666: 0,\n",
              "   5824000: 0,\n",
              "   5835858: 0,\n",
              "   5862666: 0,\n",
              "   587451: 3,\n",
              "   5888570: 3,\n",
              "   590924: 0,\n",
              "   590926: 3,\n",
              "   590927: 1,\n",
              "   590929: 2,\n",
              "   5913890: 2,\n",
              "   5979591: 0,\n",
              "   599695: 0,\n",
              "   6037300: 0,\n",
              "   6180228: 2,\n",
              "   6264715: 3,\n",
              "   6277578: 1,\n",
              "   6338425: 0,\n",
              "   639564: 0,\n",
              "   640767: 3,\n",
              "   640772: 3,\n",
              "   640775: 0,\n",
              "   6493523: 0,\n",
              "   6515917: 1,\n",
              "   653142: 0,\n",
              "   6543413: 1,\n",
              "   6602616: 1,\n",
              "   6622147: 0,\n",
              "   6667419: 0,\n",
              "   6688736: 0,\n",
              "   6688737: 2,\n",
              "   6688738: 1,\n",
              "   6688739: 0,\n",
              "   6688741: 1,\n",
              "   6688742: 2,\n",
              "   6688743: 1,\n",
              "   6705133: 1,\n",
              "   67500: 0,\n",
              "   6803015: 1,\n",
              "   6970103: 0,\n",
              "   7008458: 1,\n",
              "   7014217: 0,\n",
              "   7039665: 2,\n",
              "   7039668: 0,\n",
              "   7098341: 1,\n",
              "   7119957: 0,\n",
              "   7153659: 0,\n",
              "   7186713: 3,\n",
              "   723681: 1,\n",
              "   7300641: 1,\n",
              "   7395195: 1,\n",
              "   7526373: 0,\n",
              "   7624167: 0,\n",
              "   7624168: 3,\n",
              "   7752628: 0,\n",
              "   7845081: 3,\n",
              "   7896999: 1,\n",
              "   7907569: 0,\n",
              "   794785: 0,\n",
              "   7987538: 2,\n",
              "   7987541: 2,\n",
              "   7987542: 3,\n",
              "   7991033: 0,\n",
              "   8010558: 2,\n",
              "   8010559: 2,\n",
              "   8010560: 3,\n",
              "   8010561: 3,\n",
              "   8010562: 3,\n",
              "   8010564: 1,\n",
              "   8010566: 1,\n",
              "   8017141: 2,\n",
              "   8052286: 1,\n",
              "   8059826: 1,\n",
              "   8133127: 0,\n",
              "   8135871: 0,\n",
              "   8140319: 0,\n",
              "   8163080: 0,\n",
              "   8177749: 1,\n",
              "   8246990: 1,\n",
              "   8336161: 2,\n",
              "   836559: 2,\n",
              "   8379423: 1,\n",
              "   8420441: 0,\n",
              "   8466750: 0,\n",
              "   8534117: 1,\n",
              "   8547803: 0,\n",
              "   8707726: 0,\n",
              "   8737814: 0,\n",
              "   958491: 0,\n",
              "   958495: 1,\n",
              "   970243: 0,\n",
              "   970247: 0}))"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todas as 54 queries possuem informação de relevância"
      ],
      "metadata": {
        "id": "7CYRf021d0-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[query for query, doc_rel in list(qrel_dev_dict.items()) if len(doc_rel)==0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO2VRwxAUWZb",
        "outputId": "013a1d1c-f1f1-434b-b00d-fe8a545b9495"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexando Trec 2020 Collection using Pyserini"
      ],
      "metadata": {
        "id": "_fCVAuEgMaYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if not os.path.exists('./indexes/lucene-index-msmarco-passage'):\n",
        "  !python -m pyserini.index.lucene \\\n",
        "  --collection JsonCollection \\\n",
        "  --input {path_data}/collection_jsonl \\\n",
        "  --index indexes/lucene-index-msmarco-passage \\\n",
        "  --generator DefaultLuceneDocumentGenerator \\\n",
        "  --threads 9 \\\n",
        "  --storePositions --storeDocvectors --storeRaw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvftkvDAFdKr",
        "outputId": "4ce547b8-1a65-4ecb-da4a-6fcb2a904ec2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
            "2023-03-04 15:30:08,085 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Setting log level to INFO\n",
            "2023-03-04 15:30:08,087 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Starting indexer...\n",
            "2023-03-04 15:30:08,087 INFO  [main] index.IndexCollection (IndexCollection.java:395) - ============ Loading Parameters ============\n",
            "2023-03-04 15:30:08,088 INFO  [main] index.IndexCollection (IndexCollection.java:396) - DocumentCollection path: /content/drive/MyDrive/treinamento/202301_IA368DD/collections/msmarco-passage/collection_jsonl\n",
            "2023-03-04 15:30:08,088 INFO  [main] index.IndexCollection (IndexCollection.java:397) - CollectionClass: JsonCollection\n",
            "2023-03-04 15:30:08,088 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Generator: DefaultLuceneDocumentGenerator\n",
            "2023-03-04 15:30:08,089 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Threads: 9\n",
            "2023-03-04 15:30:08,089 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Language: en\n",
            "2023-03-04 15:30:08,089 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Stemmer: porter\n",
            "2023-03-04 15:30:08,089 INFO  [main] index.IndexCollection (IndexCollection.java:402) - Keep stopwords? false\n",
            "2023-03-04 15:30:08,090 INFO  [main] index.IndexCollection (IndexCollection.java:403) - Stopwords: null\n",
            "2023-03-04 15:30:08,090 INFO  [main] index.IndexCollection (IndexCollection.java:404) - Store positions? true\n",
            "2023-03-04 15:30:08,090 INFO  [main] index.IndexCollection (IndexCollection.java:405) - Store docvectors? true\n",
            "2023-03-04 15:30:08,090 INFO  [main] index.IndexCollection (IndexCollection.java:406) - Store document \"contents\" field? false\n",
            "2023-03-04 15:30:08,091 INFO  [main] index.IndexCollection (IndexCollection.java:407) - Store document \"raw\" field? true\n",
            "2023-03-04 15:30:08,091 INFO  [main] index.IndexCollection (IndexCollection.java:408) - Additional fields to index: []\n",
            "2023-03-04 15:30:08,091 INFO  [main] index.IndexCollection (IndexCollection.java:409) - Optimize (merge segments)? false\n",
            "2023-03-04 15:30:08,091 INFO  [main] index.IndexCollection (IndexCollection.java:410) - Whitelist: null\n",
            "2023-03-04 15:30:08,092 INFO  [main] index.IndexCollection (IndexCollection.java:411) - Pretokenized?: false\n",
            "2023-03-04 15:30:08,092 INFO  [main] index.IndexCollection (IndexCollection.java:412) - Index path: indexes/lucene-index-msmarco-passage\n",
            "2023-03-04 15:30:08,097 INFO  [main] index.IndexCollection (IndexCollection.java:450) - ============ Indexing Collection ============\n",
            "2023-03-04 15:30:08,404 INFO  [main] index.IndexCollection (IndexCollection.java:565) - Thread pool with 9 threads initialized.\n",
            "2023-03-04 15:30:08,405 INFO  [main] index.IndexCollection (IndexCollection.java:567) - Initializing collection in /content/drive/MyDrive/treinamento/202301_IA368DD/collections/msmarco-passage/collection_jsonl\n",
            "2023-03-04 15:30:08,410 INFO  [main] index.IndexCollection (IndexCollection.java:576) - 9 files found\n",
            "2023-03-04 15:30:08,410 INFO  [main] index.IndexCollection (IndexCollection.java:577) - Starting to index...\n",
            "2023-03-04 15:31:08,419 INFO  [main] index.IndexCollection (IndexCollection.java:591) - 0.00% of files completed, 4,410,000 documents indexed\n",
            "2023-03-04 15:31:44,140 DEBUG [pool-2-thread-9] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - collection_jsonl/docs08.json: 841823 docs added.\n",
            "2023-03-04 15:31:56,099 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - collection_jsonl/docs00.json: 1000000 docs added.\n",
            "2023-03-04 15:32:00,996 DEBUG [pool-2-thread-3] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - collection_jsonl/docs02.json: 1000000 docs added.\n",
            "2023-03-04 15:32:01,385 DEBUG [pool-2-thread-8] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - collection_jsonl/docs07.json: 1000000 docs added.\n",
            "2023-03-04 15:32:01,488 DEBUG [pool-2-thread-5] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - collection_jsonl/docs04.json: 1000000 docs added.\n",
            "2023-03-04 15:32:02,664 DEBUG [pool-2-thread-4] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - collection_jsonl/docs03.json: 1000000 docs added.\n",
            "2023-03-04 15:32:03,072 DEBUG [pool-2-thread-6] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - collection_jsonl/docs05.json: 1000000 docs added.\n",
            "2023-03-04 15:32:03,295 DEBUG [pool-2-thread-2] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - collection_jsonl/docs01.json: 1000000 docs added.\n",
            "2023-03-04 15:32:07,357 DEBUG [pool-2-thread-7] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - collection_jsonl/docs06.json: 1000000 docs added.\n",
            "2023-03-04 15:33:05,048 INFO  [main] index.IndexCollection (IndexCollection.java:633) - Indexing Complete! 8,841,823 documents indexed\n",
            "2023-03-04 15:33:05,049 INFO  [main] index.IndexCollection (IndexCollection.java:634) - ============ Final Counter Values ============\n",
            "2023-03-04 15:33:05,049 INFO  [main] index.IndexCollection (IndexCollection.java:635) - indexed:        8,841,823\n",
            "2023-03-04 15:33:05,049 INFO  [main] index.IndexCollection (IndexCollection.java:636) - unindexable:            0\n",
            "2023-03-04 15:33:05,049 INFO  [main] index.IndexCollection (IndexCollection.java:637) - empty:                  0\n",
            "2023-03-04 15:33:05,049 INFO  [main] index.IndexCollection (IndexCollection.java:638) - skipped:                0\n",
            "2023-03-04 15:33:05,049 INFO  [main] index.IndexCollection (IndexCollection.java:639) - errors:                 0\n",
            "2023-03-04 15:33:05,054 INFO  [main] index.IndexCollection (IndexCollection.java:642) - Total 8,841,823 documents indexed in 00:02:56\n",
            "CPU times: user 1.66 s, sys: 198 ms, total: 1.86 s\n",
            "Wall time: 2min 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -hs './indexes/lucene-index-msmarco-passage'"
      ],
      "metadata": {
        "id": "u9LG2KrpGpaO",
        "outputId": "b0447e48-c5cc-4a66-f4e1-405388b630db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3G\t./indexes/lucene-index-msmarco-passage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculando ndcg@10 pelo pyserini no trec 2020 (small dev)"
      ],
      "metadata": {
        "id": "c-EQ6_F2VktR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Com script"
      ],
      "metadata": {
        "id": "8y_HkjXlPTuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the official TREC evaluation tool, trec_eval, to compute metrics other than MRR@10. For that we first need to convert the run file into TREC format:\n",
        "\n"
      ],
      "metadata": {
        "id": "cYrRnzZ7Sn3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trocar abaixo se for para realizar o search todo o dev dataset\n",
        "# file_topics = 'msmarco-passage-dev-subset'\n",
        "file_topics_search = 'dl20'\n",
        "print(f'file_topics_search: {file_topics_search}')\n",
        "\n",
        "# trocar abaixo se for para realizar o eval todo o dev dataset\n",
        "#file_topics_eval = {path_data}/qrels.dev.small.trec\n",
        "file_topics_eval = 'dl20-passage'\n",
        "print(f'file_topics_eval: {file_topics_eval}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5WQoUwId-QY",
        "outputId": "617f0425-f86f-4f15-fe65-bd7256797a4d"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_topics_search: dl20\n",
            "file_topics_eval: dl20-passage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_max_hits = 100"
      ],
      "metadata": {
        "id": "jbJjFHO4HY_4"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python -m pyserini.search.lucene \\\n",
        "  --index indexes/lucene-index-msmarco-passage \\\n",
        "  --topics {file_topics_search} \\\n",
        "  --output runs/run.msmarco-passage.bm25.trec \\\n",
        "  --output-format msmarco \\\n",
        "  --hits {num_max_hits} \\\n",
        "  --bm25 --k1 0.82 --b 0.68"
      ],
      "metadata": {
        "id": "iWYHSXe3Hw9o",
        "outputId": "2c8bb952-4a74-4e06-f77e-e9ebf14849fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting BM25 parameters: k1=0.82, b=0.68\n",
            "Running dl20 topics, saving to runs/run.msmarco-passage.bm25.trec...\n",
            "100% 200/200 [00:06<00:00, 28.65it/s]\n",
            "CPU times: user 174 ms, sys: 36.7 ms, total: 211 ms\n",
            "Wall time: 14 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we set the BM25 parameters to k1=0.82, b=0.68 (tuned by grid search). The option --output-format msmarco says to generate output in the MS MARCO output format. The option --hits specifies the number of documents to return per query. Thus, the output file should have approximately 6980 × num_max_hits (698.000, if it is 100) lines.\n",
        "\n",
        "Retrieval speed will vary by hardware: On a reasonably modern CPU with an SSD, we might get around 13 qps (queries per second), and so the entire run should finish in under ten minutes (using a single thread). We can perform multi-threaded retrieval by using the --threads and --batch-size arguments. For example, setting --threads 16 --batch-size 64 on a CPU with sufficient cores, the entire run will finish in a couple of minutes."
      ],
      "metadata": {
        "id": "5Hegn5wfmjp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos parâmetro -l 2 seguindo orientação em pyserini\\docs\\experiments-msmarco-irst.md\n",
        "\n",
        "(...)\n",
        "Similarly, for TREC DL 2020:\n",
        "\n",
        "```bash\n",
        "python -m pyserini.eval.trec_eval -c -m map -m ndcg_cut.10 -l 2 \\\n",
        "  dl20-passage runs/run.irst-sum.passage.dl20.txt\n",
        "```\n"
      ],
      "metadata": {
        "id": "h1GVBSGarYMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 -mrecall.100 -mmap -l 2 {file_topics_eval} runs/run.dl20-passage.bm25.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W55iQ9twkfUa",
        "outputId": "b807b0f0-c821-4e35-ebe5-0e07b18c93d7"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
            "/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
            "Skipping download.\n",
            "msmarco run detected. Converting to trec...\n",
            "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '-mrecall.100', '-mmap', '-l', '2', '/root/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', '/tmp/tmp_4ap4b29']\n",
            "Results:\n",
            "map                   \tall\t0.2695\n",
            "recall_100            \tall\t0.5669\n",
            "ndcg_cut_10           \tall\t0.4876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pyserini.search.lucene \\\n",
        "  --index indexes/lucene-index-msmarco-passage \\\n",
        "  --topics {file_topics} \\\n",
        "  --output runs/run.dl20-passage.bm25.trec \\\n",
        "  --output-format msmarco \\\n",
        "  --hits {num_max_hits} \\\n",
        "  --bm25 --k1 0.82 --b 0.68"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiCRWGDZftVH",
        "outputId": "1c71f4e2-3197-48dc-a6b5-83e97c002581"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting BM25 parameters: k1=0.82, b=0.68\n",
            "Running dl20 topics, saving to runs/run.dl20-passage.bm25.trec...\n",
            "100% 200/200 [00:07<00:00, 28.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gfXHH9upIVrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_memoria()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTQQt-qSINsY",
        "outputId": "e3bfb480-b6b0-4696-a430-c7045d2f98d2"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 89.64\n",
            " available 87.14\n",
            " used 1.61\n",
            " free 54.17\n",
            " cached 33.39\n",
            " buffers 0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Com código\n",
        "\n",
        "Adaptado do [caderno do colega Gustavo Bartz Guedes](https://colab.research.google.com/drive/10z86PObSxqbXczZ9pz0T-QurL21oMShf?usp=sharing)"
      ],
      "metadata": {
        "id": "waqMpGVHPVoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code from https://colab.research.google.com/github/castorini/anserini-notebooks/blob/master/pyserini_msmarco_passage_demo.ipynb\n",
        "from pyserini.search import SimpleSearcher\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "1z9TOmGucGBi"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run all queries in topics, retrive top 1k for each query\n",
        "def run_all_queries(file, topics, searcher, num_max_hits=100):\n",
        "    with open(file, 'w') as runfile:\n",
        "        cnt = 0\n",
        "        print('Running {} queries in total'.format(len(topics)))\n",
        "        for id in tqdm(topics, desc='Running Queries'):\n",
        "            query = topics[id]['title']\n",
        "            hits = searcher.search(query, num_max_hits)\n",
        "            for i in range(0, len(hits)):\n",
        "                _ = runfile.write('{} Q0 {} {} {:.6f} Pyserini\\n'.format(id, hits[i].docid, i+1, hits[i].score))\n",
        "            cnt += 1\n",
        "            if cnt % 100 == 0:\n",
        "                print(f'{cnt} queries completed')\n"
      ],
      "metadata": {
        "id": "dUJuMaOKPmoZ"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "searcher = LuceneSearcher('./indexes/lucene-index-msmarco-passage')\n",
        "searcher.set_bm25(k1=0.82, b=0.68)\n"
      ],
      "metadata": {
        "id": "bkpqRcVwneUh"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_all_queries('run-msmarco-passage-bm25.txt', topics, searcher, num_max_hits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yBalAPOnfv_",
        "outputId": "429ce3a2-06e3-47ef-8af6-56c97aaea033"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running Queries:   2%|▏         | 4/200 [00:00<00:05, 38.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 200 queries in total\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running Queries:  50%|█████     | 101/200 [00:03<00:02, 35.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 queries completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running Queries: 100%|██████████| 200/200 [00:06<00:00, 31.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 queries completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head run-msmarco-passage-bm25.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8Qp6adrpQh1",
        "outputId": "31bacfe3-9227-4e04-ed59-b70830d7659f"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "735922 Q0 7307871 1 10.128700 Pyserini\n",
            "735922 Q0 7307863 2 10.118800 Pyserini\n",
            "735922 Q0 8626892 3 10.041000 Pyserini\n",
            "735922 Q0 8626890 4 9.854300 Pyserini\n",
            "735922 Q0 2766952 5 9.461000 Pyserini\n",
            "735922 Q0 8734268 6 9.248000 Pyserini\n",
            "735922 Q0 8626887 7 8.954300 Pyserini\n",
            "735922 Q0 7307868 8 8.540100 Pyserini\n",
            "735922 Q0 180247 9 8.508000 Pyserini\n",
            "735922 Q0 1428024 10 8.493600 Pyserini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Eval"
      ],
      "metadata": {
        "id": "BJAEtyT_e5wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 -mrecall.100 -mmap -l 2 {file_topics_eval} run-msmarco-passage-bm25.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR7eFP_6ehXY",
        "outputId": "12a59e8d-d320-4288-e37e-8e26da21ee83"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
            "/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
            "Skipping download.\n",
            "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '-mrecall.100', '-mmap', '-l', '2', '/root/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', 'run-msmarco-passage-bm25.txt']\n",
            "Results:\n",
            "map                   \tall\t0.2695\n",
            "recall_100            \tall\t0.5669\n",
            "ndcg_cut_10           \tall\t0.4876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qs-31jR1pyas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD CODE"
      ],
      "metadata": {
        "id": "H5PP9YCdF5rP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eaTvJd3MF5ni"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L6Y2H8MH14s"
      },
      "source": [
        "## Carga dos dados da TREC 2020 \n",
        "\n",
        "Fonte: [Repositório do projeto Robustez query](https://github.com/leonardo3108/robustez-query)\n",
        "\n",
        "\n",
        "Final Project at Discipline IA376, Deep Learning for NLP, Turma E - Tópicos em Engenharia de Computação VII - 2021.2S\n",
        "\n",
        "Authors: Leonardo Augusto da Silva Pacheco e Marcus Vinícius Borela de Castro\n",
        "\n",
        "[Mais sobre o dataset](https://microsoft.github.io/msmarco/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extração dos julgamentos\n",
        "\n",
        "\n",
        "Obtidos dados de teste do arquivo 2020qrels-pass.txt\n",
        "\n",
        "Só para ciência, também há arquivos com relevância: \n",
        "\n",
        ". Dev: qrels.dev.tsv\n",
        "\n",
        ". Train: qrels.train.tsv "
      ],
      "metadata": {
        "id": "qXX-w6KeydjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -nc https://trec.nist.gov/data/deep/2020qrels-pass.txt"
      ],
      "metadata": {
        "id": "0FH8TFArxdO_",
        "outputId": "640208e8-abb8-40b8-f31a-4e2d4b6657ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-03 23:16:29--  https://trec.nist.gov/data/deep/2020qrels-pass.txt\n",
            "Resolving trec.nist.gov (trec.nist.gov)... 132.163.4.175, 2610:20:6b01:4::175\n",
            "Connecting to trec.nist.gov (trec.nist.gov)|132.163.4.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 218617 (213K) [text/plain]\n",
            "Saving to: ‘2020qrels-pass.txt’\n",
            "\n",
            "2020qrels-pass.txt  100%[===================>] 213.49K  1.19MB/s    in 0.2s    \n",
            "\n",
            "2023-03-03 23:16:29 (1.19 MB/s) - ‘2020qrels-pass.txt’ saved [218617/218617]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passages** were judged on a four-point scale of:\n",
        "* Not Relevant (0), \n",
        "* Related (1), \n",
        "* Highly Relevant (2), and \n",
        "* Perfect (3), \n",
        "\n",
        "where 'Related' is actually NOT Relevant---it means that the passage was on the same general topic, but did not answer the question. \n",
        "\n",
        "Thus, for Passage Ranking task runs (only), to compute evaluation measures that use binary relevance judgments using \n",
        "trec_eval, you either need to use \n",
        "```\n",
        "trec_eval's -l option [trec_eval -l 2 qrelsfile runfile]\n",
        "```\n",
        "or modify the qrels file to change all 1 judgments to 0."
      ],
      "metadata": {
        "id": "5oRR--L5ynlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('query_number passage_identifier judging')\n",
        "queries = []\n",
        "pids = []\n",
        "for i, line in enumerate(open('2020qrels-pass.txt')):\n",
        "    query_nr, _, pid, judging = line.rstrip().split()\n",
        "    if query_nr not in queries:\n",
        "        queries.append(query_nr)\n",
        "    if pid not in pids:\n",
        "        pids.append(pid)\n",
        "    if i < 20: print(query_nr, pid, judging)"
      ],
      "metadata": {
        "id": "MfxH4AphyjX9",
        "outputId": "af07df75-496e-4113-ef41-0d0c41411bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_number passage_identifier judging\n",
            "23849 1020327 2\n",
            "23849 1034183 3\n",
            "23849 1120730 0\n",
            "23849 1139571 1\n",
            "23849 1143724 0\n",
            "23849 1147202 0\n",
            "23849 1150311 0\n",
            "23849 1158886 2\n",
            "23849 1175024 1\n",
            "23849 1201385 0\n",
            "23849 1215556 0\n",
            "23849 1220759 0\n",
            "23849 1221770 0\n",
            "23849 1333480 1\n",
            "23849 1381453 2\n",
            "23849 1414114 2\n",
            "23849 1414115 0\n",
            "23849 1414120 2\n",
            "23849 1449780 0\n",
            "23849 146754 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{} queries:'.format(len(queries)))\n",
        "print(queries)"
      ],
      "metadata": {
        "id": "9Adf84JAyj_9",
        "outputId": "d95ccf5a-1d76-4650-9baa-85e821edf7bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54 queries:\n",
            "['23849', '42255', '47210', '67316', '118440', '121171', '135802', '141630', '156498', '169208', '174463', '258062', '324585', '330975', '332593', '336901', '390360', '405163', '555530', '583468', '640502', '673670', '701453', '730539', '768208', '877809', '911232', '914916', '938400', '940547', '997622', '1030303', '1037496', '1043135', '1051399', '1064670', '1071750', '1105792', '1106979', '1108651', '1109707', '1110678', '1113256', '1115210', '1116380', '1121353', '1122767', '1127540', '1131069', '1132532', '1133579', '1136043', '1136047', '1136962']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extração das Queries\n",
        "\n",
        "Datasets extraídos a partir de: [TREC 2020 Deep Learning Track Guidelines](https://microsoft.github.io/msmarco/TREC-Deep-Learning-2020)"
      ],
      "metadata": {
        "id": "1_k4m3xzy440"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -nc https://msmarco.blob.core.windows.net/msmarcoranking/queries.tar.gz"
      ],
      "metadata": {
        "id": "lyyaFzFsvVmJ",
        "outputId": "fef6eac1-8067-467d-ac09-2e6d3351a449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-03 23:23:09--  https://msmarco.blob.core.windows.net/msmarcoranking/queries.tar.gz\n",
            "Resolving msmarco.blob.core.windows.net (msmarco.blob.core.windows.net)... 20.150.34.4\n",
            "Connecting to msmarco.blob.core.windows.net (msmarco.blob.core.windows.net)|20.150.34.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18882551 (18M) [application/gzip]\n",
            "Saving to: ‘queries.tar.gz’\n",
            "\n",
            "queries.tar.gz      100%[===================>]  18.01M  9.58MB/s    in 1.9s    \n",
            "\n",
            "2023-03-03 23:23:11 (9.58 MB/s) - ‘queries.tar.gz’ saved [18882551/18882551]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "\n",
        "query_text = {}\n",
        "\n",
        "for i, line in enumerate(gzip.open('queries.tar.gz', mode='rt')):\n",
        "    fields = line.strip().split()\n",
        "    #if i not in [0, 101093, 202185]:\n",
        "    #if i > 202185: print(i)\n",
        "    number = fields[0]\n",
        "    text = ' '.join(fields[1:])\n",
        "    if number in queries:\n",
        "        query_text[number] = text\n",
        "for query in queries:\n",
        "    print(query, query_text.get(query, '?????'))"
      ],
      "metadata": {
        "id": "lNLkcLXGzFLA",
        "outputId": "4e88c9ba-5444-4ee5-dfd2-5aab8bbf4703",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 are naturalization records public information\n",
            "42255 average salary for dental hygienist in nebraska\n",
            "47210 average wedding dress alteration cost\n",
            "67316 can fever cause miscarriage early pregnancy\n",
            "118440 define bmt medical\n",
            "121171 define etruscans\n",
            "135802 definition of laudable\n",
            "141630 describe how muscles and bones work together to produce movement\n",
            "156498 do google docs auto save\n",
            "169208 does mississippi have an income tax\n",
            "174463 dog day afternoon meaning\n",
            "258062 how long does it take to remove wisdom tooth\n",
            "324585 how much money do motivational speakers make\n",
            "330975 how much would it cost to install my own wind turbine\n",
            "332593 how often to button quail lay eggs\n",
            "336901 how old is vanessa redgrave\n",
            "390360 ia suffix meaning\n",
            "405163 is caffeine an narcotic\n",
            "555530 what are best foods to lower cholesterol\n",
            "583468 what carvedilol used for\n",
            "640502 what does it mean if your tsh is low\n",
            "673670 what is a alm\n",
            "701453 what is a statutory deed\n",
            "730539 what is chronometer who invented it\n",
            "768208 what is mamey\n",
            "877809 what metal are hip replacements made of\n",
            "911232 what type of conflict does della face in o, henry the gift of the magi\n",
            "914916 what type of tissue are bronchioles\n",
            "938400 when did family feud come out?\n",
            "940547 when did rock n roll begin?\n",
            "997622 where is the show shameless filmed\n",
            "1030303 who is aziz hashim\n",
            "1037496 who is rep scalise?\n",
            "1043135 who killed nicholas ii of russia\n",
            "1051399 who sings monk theme song\n",
            "1064670 why do hunters pattern their shotguns?\n",
            "1071750 why is pete rose banned from hall of fame\n",
            "1105792 define: geon\n",
            "1106979 define pareto chart in statistics\n",
            "1108651 what the best way to get clothes white\n",
            "1109707 what medium do radio waves travel through\n",
            "1110678 what is the un fao\n",
            "1113256 what is reba mcentire's net worth\n",
            "1115210 what is chaff and flare\n",
            "1116380 what is a nonconformity? earth science\n",
            "1121353 what can you do about discrimination in the workplace in oklahoma city\n",
            "1122767 what amino produces carnitine\n",
            "1127540 meaning of shebang\n",
            "1131069 how many sons robert kraft has\n",
            "1132532 average annual income data analyst\n",
            "1133579 how does granulation tissue start\n",
            "1136043 difference between a hotel and motel\n",
            "1136047 difference between a company's strategy and business model is\n",
            "1136962 why did the ancient egyptians call their land kemet, or black land?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(queries), len(query_text)"
      ],
      "metadata": {
        "id": "tRon5GAKzGwU",
        "outputId": "a6fa715b-303b-4eb6-d9a8-c3f602144c6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54, 54)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extração das passagens do MsMarco"
      ],
      "metadata": {
        "id": "qirqA5Y0zep9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -nc https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz"
      ],
      "metadata": {
        "id": "SmOnTax9zXAU",
        "outputId": "ea0417a8-1590-46dd-b0f7-7b46603db72d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-03 23:25:32--  https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz\n",
            "Resolving msmarco.blob.core.windows.net (msmarco.blob.core.windows.net)... 20.150.34.4\n",
            "Connecting to msmarco.blob.core.windows.net (msmarco.blob.core.windows.net)|20.150.34.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1035009698 (987M) [application/octet-stream]\n",
            "Saving to: ‘collection.tar.gz’\n",
            "\n",
            "collection.tar.gz   100%[===================>] 987.06M  6.73MB/s    in 1m 57s  \n",
            "\n",
            "2023-03-03 23:27:30 (8.44 MB/s) - ‘collection.tar.gz’ saved [1035009698/1035009698]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "61qyv5ob2hqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "passage_text = {}\n",
        "\n",
        "for line in tqdm(gzip.open('collection.tar.gz', mode='rt'), unit='B', unit_scale=True, total=os.path.getsize('collection.tar.gz')):\n",
        "    fields = line.strip().split()\n",
        "    pid = fields[0]\n",
        "    text = ' '.join(fields[1:])\n",
        "    if pid in pids:\n",
        "        passage_text[pid] = text\n",
        "for ndx, pid in enumerate(pids):\n",
        "    print(pid, passage_text.get(pid, '?????'))\n",
        "    if ndx > 10: \n",
        "      break"
      ],
      "metadata": {
        "id": "EvKBXl4-zxvQ",
        "outputId": "1cd8355f-bcc1-4da3-9671-fa5c80b8e2b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 5.39M/1.04G [13:33<43:11:55, 6.62kB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pids), len(passage_text)"
      ],
      "metadata": {
        "id": "edStuwPBzoNg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}