{
  "cells": [
    {
      "attachments": {
        "image.png": {
          "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAAjCAMAAAA5bpjbAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAB7UExURQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAL14HLAAAAAodFJOUwAECAoOFRoeITY3PEdYWWJtdHmAjZiZpauvsrO4u8XN1drh4ufu9PnTFncfAAAACXBIWXMAABcRAAAXEQHKJvM/AAAD80lEQVRoQ+2W63baMBCEgTQNqZu6Le4FeklCCsn7P2FnZlc32xga6D995ySW5dVqdiTLzCqVSqVSqVQqlcp/o3m581aku7/y1iTL3fNts7/2ux7dixjkHgXBK2tYuu5lzctiq8uAob7GZgN3PnHUpfq8U5P0A0hSu9i6lFYaWvTyim5vjfF6D7v1fOMTDjE32pNMXO5ClImBYI0ekSbG9Xm0L0PEPFTnckcT+gEkqcXcll3r2KK+ho3m+ZadB3i9h5OYqkM7qSQJXO64Js3zB7najlRLXuth0S5Iahfbnw9qP3zjDeVTxiEpBvPONyvsZinj9Qtb3MUoqEV9iy0a3O6KwAOrOe8Z7Megiv0xkMk/qiV8XHw8gxA22v3bDcT7jSfvfmw4L1NQH9/esq4TPFTGKQ9XtK1jnmbdrf0FoQW4mcA8xD+ZzmQtK+JA7oo5quG6849tPdCqxJ7OQwtMVYuYLDAkN+K47EVhZk2Jq57FoM6c9BSszjyOnOChrv0AYn1UCxca+tXdRdvwcL757Us5innotZrxanAAK8KL9YdlaEX213KaCxZ7PDT5ILi5bKtkgWikwtO4zEPG8I9d/EtBKtNyQd/Ityx4GOZ1hh72AkhSi/qWT7g83gYPeSaqau2DUcxDPoU0cwLrYWVJsn8kEcRJrArDerLQDFNtp7gHWnLuSpHGWUtwdbhyvDIyBWlc1LfcmWMZwcPSnREPewEkqYVb8w0k3V+5h/qkGJnOktJD5YJGnkIE85s2rBRcyD0MPVMemmgPLJOvSg+tjyLeuBhd+x6GFFoWMy3Q99Az/oOHvHDHtThLsITyjrsw4DMMKT2U5LgPCcRigkapcg9jj4X28wdV+AkZAkf3IcelyXC/v9F3qNm/40wpqNyHDIWyfE5X0LdI3d6pV7IfQJJahiyfbh79M2KnsNOvMcIH0UNzSA0VAsmtilIt842fh4yPPQfOQ1fly2GBSH7kPETvV93hygzZechxUR9D/S5wgod5uyCpZX2Lx0+YgR62ltNnsrdghMJDfQYbfjrZUL4t9gnrV0YkCUWnHvt0MkOGqeIezAI5vP9dxsPcQ2wuBeCqjDHIjAv6NKRct+Me2tHWDyBJrW1V7j54aCsIZBB+AdrdgNJDHV6f2eBx4tK17XB7/17K/fdh0aMt71UI/9KxIwWi0358GnFc7kU4gFpPFoLMw6iP3RyW5pz0ENGgF5DGpufy0MbgYLRulx6jL8DyV3ShR3vCLHZUX45T5jzEOWPPo+F7Ocb8e7afhmh109pfhiNzTnLO2HPhGTlGc+i8cML7d0mOzTnFOWPPAz9vL/w6ViqVSqVSqVQqlUrlbGazv3vsl2/LSf0WAAAAAElFTkSuQmCC"
        }
      },
      "cell_type": "markdown",
      "metadata": {
        "id": "CcN_5-RDWeqV"
      },
      "source": [
        "# Busca simples\n",
        "\n",
        "Desenvolvimento de um buscador Simples: Booleano, TF-IDF, BM25\n",
        "\n",
        "Tópicos abordados: Indexação, Bag-of-Words, TF-IDF, BM25\n",
        "\n",
        "Aula 1 - [Unicamp - IA368DD: Deep Learning aplicado a sistemas de busca.](https://www.cpg.feec.unicamp.br/cpg/lista/caderno_horario_show.php?id=1779)\n",
        "\n",
        "Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "[Repositório no github](https://github.com/marcusborela/deep_learning_em_buscas_unicamp)\n",
        "\n",
        "[Link para chat de apoio com WebChatGPT](https://github.com/marcusborela/deep_learning_em_buscas_unicamp/blob/main/chat/CG%20uso%20no%20buscador%20aula%201.md)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ti1aFWTVgejM"
      },
      "source": [
        "[![Open In Colab latest github version](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcusborela/deep_learning_em_buscas_unicamp/blob/main/code/aula1_buscador_simples.ipynb) [Open In Colab latest github version]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VQxzYKGgMqce"
      },
      "source": [
        "Implementação de buscadores para o TREC-DL 2020\n",
        "\n",
        "Este projeto tem como objetivo implementar e avaliar diferentes algoritmos de busca para o TREC-DL 2020, utilizando a biblioteca Pyserini para implementar o BM25.\n",
        "\n",
        "Pré-requisitos\n",
        "\n",
        "Antes de começar, é necessário instalar a biblioteca Pyserini e baixar os dados do TREC-DL 2020. Para isso, siga as instruções descritas na documentação oficial do Pyserini.\n",
        "\n",
        "Implementação do buscador booleano/bag-of-words\n",
        "\n",
        "Para a implementação do buscador booleano/bag-of-words, será necessário criar um índice invertido a partir dos documentos e utilizar uma estrutura de dados para armazenar a matriz de termos por documentos.\n",
        "\n",
        "Em seguida, para cada consulta, será necessário realizar uma busca utilizando operadores booleanos ou uma representação bag-of-words. Para operadores booleanos, a busca pode ser realizada utilizando árvores de expressão booleana. Para a representação bag-of-words, pode ser utilizada uma matriz termo-documento.\n",
        "\n",
        "Implementação do buscador com TF-IDF\n",
        "\n",
        "Para a implementação do buscador com TF-IDF, será necessário criar um índice invertido a partir dos documentos e calcular a frequência de termos em cada documento. Em seguida, para cada consulta, será necessário calcular o peso TF-IDF de cada termo e realizar uma busca ordenando os documentos de acordo com o seu score.\n",
        "\n",
        "Avaliação dos buscadores\n",
        "\n",
        "Para avaliar os buscadores, será utilizado o conjunto de dados do TREC-DL 2020 e o métrica nDCG@10. Será necessário implementar um script para executar as buscas para cada um dos algoritmos implementados e calcular o nDCG@10 para cada consulta.\n",
        "\n",
        "Considerações finais\n",
        "\n",
        "A implementação dos buscadores deve levar em conta a eficiência na busca de milhões de documentos. Para isso, é recomendado utilizar estruturas de dados eficientes e técnicas de pré-processamento de texto para reduzir o tempo de busca. É importante lembrar que não será permitido o uso de bibliotecas como sklearn, que já implementam o BoW e TF-IDF."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2L6Y2H8MH14s"
      },
      "source": [
        "# Etapa 1: Coleta de dados da TREC Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HsZlZ7YlPi8"
      },
      "source": [
        "## Elaboração de Rotinas utilitárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ctvgk_oNlUPj"
      },
      "outputs": [],
      "source": [
        "def mostra_dict(dicionario: dict):\n",
        "    \"\"\"\n",
        "    Imprime informações sobre o dicionário recebido como parâmetro.\n",
        "\n",
        "    Argumentos:\n",
        "    - dicionario: um dicionário a ser impresso\n",
        "\n",
        "    Retorna:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # obtém a primeira e última chave do dicionário\n",
        "    primeiro_elemento = list(dicionario.keys())[0]\n",
        "    ultimo_elemento = list(dicionario.keys())[-1]\n",
        "\n",
        "    # imprime o tamanho do dicionário e as informações sobre seus limites\n",
        "    print(f\"O dicionário tem tamanho: {len(dicionario)}\")\n",
        "    print(f\"Seus limites:\\n {primeiro_elemento}:\\n {dicionario[primeiro_elemento]},\\n {ultimo_elemento}:\\n {dicionario[ultimo_elemento]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZMSV96MeO5R",
        "outputId": "3f2d9795-d611-4e78-b5be-5f574d6ba156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O dicionário tem tamanho: 76\n",
            "Seus limites:\n",
            " 1:\n",
            " [28, 35, 38, 42, 43, 52, 65, 76, 86, 150, 189, 192, 193, 195, 215, 269, 291, 320, 429, 465, 466, 482, 483, 510, 524, 541, 576, 582, 589, 603, 650, 680, 711, 722, 726, 783, 813, 820, 868, 869, 894, 1162, 1164, 1195, 1196, 1281],\n",
            " 111:\n",
            " [328, 422, 448, 485, 503, 509]\n"
          ]
        }
      ],
      "source": [
        "mostra_dict(relevancia_consulta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUtvq4hfLEVw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e007dYSoJ-zT"
      },
      "source": [
        "# Etapa 2: Pré-processamento dos textos de documentos e consultas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gu1iJ0WVWU3z"
      },
      "outputs": [],
      "source": [
        "# !pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KLONEn8nlxPF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer, PorterStemmer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "#stemmer = SnowballStemmer('english')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLgzi6qlt7UZ",
        "outputId": "48c1f024-6d64-4d78-9df1-9c14ac476f30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SoFU0laIrmuY"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZDdSQCjLH7p"
      },
      "source": [
        "## Desenvolvimento do código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "06S5t8XQpCoT"
      },
      "outputs": [],
      "source": [
        "def preprocessa_texto(texto,\n",
        "                      to_lower=True, \n",
        "                      remove_pontuacao=True,\n",
        "                      remove_stopwords=True,\n",
        "                      aplica_stemming=True,\n",
        "                      aplica_lematizacao=True):\n",
        "    \"\"\"\n",
        "    Função que realiza o pré-processamento de um texto.\n",
        "    \n",
        "    Parâmetros:\n",
        "    texto (str): Texto a ser pré-processado\n",
        "    to_lower (bool): Flag que indica se deve transformar o texto para lower case. Default: True\n",
        "    remove_pontuacao (bool): Flag que indica se deve remover a pontuação do texto. Default: True\n",
        "    remove_stopwords (bool): Flag que indica se deve remover as stop words do texto. Default: True\n",
        "    aplica_stemming (bool): Flag que indica se deve aplicar stemming no texto. Default: True\n",
        "    aplica_lematizacao (bool): Flag que indica se deve aplicar lematização no texto. Default: True\n",
        "    \n",
        "    Retorna:\n",
        "    str: Texto pré-processado\n",
        "    \"\"\"\n",
        "    # Transforma o texto em lower case\n",
        "    if to_lower:\n",
        "        texto = texto.lower()\n",
        "\n",
        "    # Substitute line breaks for space\n",
        "    texto = re.sub(r'\\n', ' ', texto)\n",
        "\n",
        "    # Remove pontuação\n",
        "    if remove_pontuacao:\n",
        "        texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "\n",
        "    palavras = texto.split()\n",
        "\n",
        "    # Remove stop words\n",
        "    if remove_stopwords:\n",
        "        palavras_sem_stopwords = [palavra for palavra in palavras if palavra not in stop_words]\n",
        "        palavras = palavras_sem_stopwords\n",
        "\n",
        "    # Aplica stemming\n",
        "    if aplica_stemming:\n",
        "        palavras_stemizadas = [stemmer.stem(palavra) for palavra in palavras]\n",
        "        palavras = palavras_stemizadas\n",
        "\n",
        "    # Aplica lematização\n",
        "    if aplica_lematizacao:\n",
        "        palavras_lematizadas = [lemmatizer.lemmatize(palavra) for palavra in palavras]\n",
        "        palavras = palavras_lematizadas\n",
        "\n",
        "    return ' '.join(palavras)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V2HwAWsksS1W",
        "outputId": "b90d8705-91f6-4516-a59f-e4d8d4487d5d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'exampl text'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessa_texto(\"This is an example of text.\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lWl3v9JEyA7E"
      },
      "outputs": [],
      "source": [
        "def preprocessa_texto_em_dict(parm_dict, \n",
        "                      to_lower=True, \n",
        "                      remove_pontuacao=True,\n",
        "                      remove_stopwords=True,\n",
        "                      aplica_stemming=True,\n",
        "                      aplica_lematizacao=True):\n",
        "  \"\"\"\n",
        "  Recebe um dicionário e retorna uma cópia do mesmo com os valores da chave \"text\" pré-processados.\n",
        "\n",
        "  Args:\n",
        "  parm_dict (dict): Dicionário com chaves de texto e valores em texto.\n",
        "  to_lower (bool): Transforma o texto em caixa baixa. Padrão é True.\n",
        "  remove_pontuacao (bool): Remove a pontuação do texto. Padrão é True.\n",
        "  remove_stopwords (bool): Remove as palavras de parada do texto. Padrão é True.\n",
        "  aplica_stemming (bool): Aplica a técnica de stemming no texto. Padrão é True.\n",
        "  aplica_lematizacao (bool): Aplica a técnica de lematização no texto. Padrão é True.\n",
        "\n",
        "  Returns:\n",
        "  dict: Novo dicionário com a nova chave 'texto_prep' e seus valores pré-processados.\n",
        "\n",
        "  new_dict = dict(parm_dict)  # cria uma cópia do dicionário\n",
        "  for elemento in new_dict:\n",
        "    for key in new_dict[elemento]:\n",
        "      if key == \"text\":\n",
        "          new_dict[elemento][\"text_prep\"] = preprocessa_texto(new_dict[elemento][\"text\"], to_lower=to_lower, \n",
        "                                                    remove_pontuacao=remove_pontuacao,\n",
        "                                                    remove_stopwords=remove_stopwords,\n",
        "                                                    aplica_stemming=aplica_stemming,\n",
        "                                                    aplica_lematizacao=aplica_lematizacao)\n",
        "  return new_dict\n",
        "  \"\"\"\n",
        "  new_dict = {}\n",
        "  for elemento in parm_dict:\n",
        "    for key in parm_dict[elemento]:\n",
        "      if key == \"text\":\n",
        "          new_dict[elemento] = preprocessa_texto(parm_dict[elemento][\"text\"], to_lower=to_lower, \n",
        "                                                    remove_pontuacao=remove_pontuacao,\n",
        "                                                    remove_stopwords=remove_stopwords,\n",
        "                                                    aplica_stemming=aplica_stemming,\n",
        "                                                    aplica_lematizacao=aplica_lematizacao)\n",
        "  return new_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPWyOfASYCZs"
      },
      "source": [
        "## Teste do código de pre-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pv_l-rptsSzJ"
      },
      "outputs": [],
      "source": [
        "assert preprocessa_texto(\"This is a simple text.\").split() == ['simpl', 'text']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "p0_NzgMIZ9NA"
      },
      "outputs": [],
      "source": [
        "assert preprocessa_texto(\"Hello! My name is John. Nice to meet you!\").split() == ['hello', 'name', 'john', 'nice', 'meet']\n",
        "assert preprocessa_texto(\"We are learning about Natural Language Processing.\").split() == ['learn', 'natur', 'languag', 'process']\n",
        "assert preprocessa_texto(\"The quick brown fox jumps over the lazy dog.\").split() == ['quick', 'brown', 'fox', 'jump', 'lazi', 'dog']\n",
        "assert preprocessa_texto(\"To be, or not to be: that is the question.\").split() == [\"question\"]\n",
        "assert preprocessa_texto(\"I'm a developer at OpenAI. I love working with AI and NLP technologies!\").split() == ['im', 'develop', 'openai', 'love', 'work', 'ai', 'nlp', 'technolog']\n",
        "assert preprocessa_texto(\"The cat is on the mat.\").split() == ['cat', 'mat']\n",
        "assert preprocessa_texto(\"An investment in knowledge pays the best interest.\").split() == ['invest', 'knowledg', 'pay', 'best', 'interest']\n",
        "assert preprocessa_texto(\"The quick brown fox jumps over the lazy dog.\").split() == ['quick', 'brown', 'fox', 'jump', 'lazi', 'dog']\n",
        "assert preprocessa_texto(\"To be, or not to be: that is the question.\").split() == [\"question\"]\n",
        "assert preprocessa_texto(\"I'm a developer at OpenAI. I love working with AI and NLP technologies!\").split() == ['im', 'develop', 'openai', 'love', 'work', 'ai', 'nlp', 'technolog']\n",
        "assert preprocessa_texto(\"The cat is on the mat.\").split() == ['cat', 'mat']\n",
        "assert preprocessa_texto(\"An investment in knowledge pays the best interest.\").split() == ['invest', 'knowledg', 'pay', 'best', 'interest']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ah6ynUi0qgpR"
      },
      "outputs": [],
      "source": [
        "assert preprocessa_texto(\"Hello World!\").split() == ['hello', 'world']\n",
        "assert preprocessa_texto(\"Hello, World!!!\").split() == ['hello', 'world']\n",
        "assert preprocessa_texto(\"Hello World\", remove_pontuacao=False).split() == ['hello', 'world']\n",
        "assert preprocessa_texto(\"Hello World\", remove_stopwords=False).split() == ['hello', 'world']\n",
        "assert preprocessa_texto(\"I am running in the park\", aplica_stemming=False).split() == ['running', 'park']\n",
        "assert preprocessa_texto(\"I am running in the park\", to_lower=False, remove_stopwords=False, aplica_stemming=False, aplica_lematizacao=False).split() == ['I', 'am', 'running', 'in', 'the', 'park']\n",
        "assert preprocessa_texto(\"I am running in the park\", aplica_lematizacao=False).split() == ['run', 'park']\n",
        "assert preprocessa_texto(\"I am running in the park\", to_lower=False).split() == ['i', 'run', 'park']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WsE6S-GyBBf",
        "outputId": "463ce7ad-e1bd-4367-da7e-b085de0fde22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': '18 Editions of the Dewey Decimal Classifications',\n",
              " 'author': 'Comaromi, J.P.',\n",
              " 'text': \"The present study is a history of the DEWEY Decimal\\nClassification.  The first edition of the DDC was published\\nin 1876, the eighteenth edition in 1971, and future editions\\nwill continue to appear as needed.  In spite of the DDC's\\nlong and healthy life, however, its full story has never\\nbeen told.  There have been biographies of Dewey\\nthat briefly describe his system, but this is the first\\nattempt to provide a detailed history of the work that\\nmore than any other has spurred the growth of\\nlibrarianship in this country and abroad.\",\n",
              " 'reference': '1\\t5\\t1\\n92\\t1\\t1\\n262\\t1\\t1\\n556\\t1\\t1\\n1004\\t1\\t1\\n1024\\t1\\t1\\n1024\\t1\\t1'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documentos[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OA77kPcYkdu"
      },
      "source": [
        "## Pré-processamento da coleção CISI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "84XwZTRoyA32"
      },
      "outputs": [],
      "source": [
        "consultas_prep = preprocessa_texto_em_dict(consultas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QpCBfYFjeT5i",
        "outputId": "8f3414fc-4ac7-41dc-b1b0-1de97912227f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'problem concern make descript titl difficulti involv automat retriev articl approxim titl usual relev content articl titl'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "consultas_prep[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXkJAX-hyA0b",
        "outputId": "1a7dc18c-3deb-40f8-d2fb-07f738ab9bb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1,\n",
              "  'problem concern make descript titl difficulti involv automat retriev articl approxim titl usual relev content articl titl'),\n",
              " (2,\n",
              "  'actual pertin data oppos refer entir articl retriev automat respons inform request'),\n",
              " (3, 'inform scienc give definit possibl'),\n",
              " (4, 'imag recognit method automat transform print text computerreadi form')]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(consultas_prep.items())[:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twibD5qsnCuP"
      },
      "source": [
        "Como o id do documento corresponde à posição do documento, para facilitar, considerarei uma lista de strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "V54X2a7j1rLS"
      },
      "outputs": [],
      "source": [
        "documentos_prep = preprocessa_texto_em_dict(documentos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "X0xJM9wM1vpm"
      },
      "outputs": [],
      "source": [
        "documentos_prep = list(documentos_prep.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "KTfuC8ABnOwu",
        "outputId": "72bd32d2-9d3d-4387-ada3-ad9974d11387"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'present studi histori dewey decim classif first edit ddc publish 1876 eighteenth edit 1971 futur edit continu appear need spite ddc long healthi life howev full stori never told biographi dewey briefli describ system first attempt provid detail histori work spur growth librarianship countri abroad'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documentos_prep[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9j_p52kx6MC"
      },
      "source": [
        "# Etapa 3: Implementação de dois mecanismos de busca com BM25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5RQAYeVWtUg"
      },
      "source": [
        "## Desenvolvimento de um mecanismo de busca baseado em bm25 puro\n",
        "\n",
        "Conforme site de referência:\n",
        "\n",
        "PAIVA, Clovis.Elasticsearch: entenda a teoria por trás do mecanismo de busca textual.In: medium.com.2020; Disponível em: [https://medium.com/tentando-ser-um-unic%C3%B3rnio/elasticsearch-entenda-a-teoria-por-tr%C3%A1s-do-mecanismo-de-busca-textual-86d11bd4f69d](https://medium.com/tentando-ser-um-unic%C3%B3rnio/elasticsearch-entenda-a-teoria-por-tr%C3%A1s-do-mecanismo-de-busca-textual-86d11bd4f69d). Acesso em: 22 fev. 2023. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gN78EvF8q2TI"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "scQZVa3MhFah"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "class BM25:\n",
        "\n",
        "    def __init__(self, documents: list, k1=1.5, b=0.75, epson=0.25):\n",
        "        \"\"\"\n",
        "        Inicializa um modelo BM25 com os parâmetros k1 e b definidos.\n",
        "\n",
        "        Args:\n",
        "            documents (dict): Dicionário contendo os documentos indexados por ID.\n",
        "            k1 (float): Parâmetro de ajuste da frequência de termos.\n",
        "            b (float): Parâmetro de ajuste do comprimento dos documentos.\n",
        "        \"\"\"\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.idf = {}\n",
        "        self.avgdl = 0\n",
        "        self.doc_len = {}\n",
        "        self.documents = documents\n",
        "        self.N = len(documents)\n",
        "        self.vectorizer = TfidfVectorizer(norm=None, smooth_idf=False)\n",
        "\n",
        "        # Constrói a matriz TF-IDF usando a biblioteca sklearn\n",
        "        self.tf_idf_matrix = self.vectorizer.fit_transform(self.documents)\n",
        "\n",
        "        # Calcula o comprimento médio dos documentos da coleção\n",
        "        self._calc_avgdl()\n",
        "\n",
        "    def _calc_avgdl(self):\n",
        "        \"\"\"\n",
        "        Calcula o comprimento médio dos documentos da coleção.\n",
        "        \"\"\"\n",
        "        self.avgdl = self.tf_idf_matrix.sum(axis=1).mean()\n",
        "\n",
        "        \n",
        "    def _score(self, query_tf_idf, index: int):\n",
        "        \"\"\"\n",
        "        Calcula o escore BM25 para um documento específico em relação a uma consulta.\n",
        "\n",
        "        Args:\n",
        "            query_tf_idf: TF-IDF da consulta.\n",
        "            index (int): Índice do documento.\n",
        "\n",
        "        Returns:\n",
        "            float: Escore BM25 para o documento em relação à consulta.\n",
        "        \"\"\"\n",
        "        # print('query_tf_idf')\n",
        "        # print(query_tf_idf)\n",
        "        # print('self.tf_idf_matrix[index].T')\n",
        "        # print(self.tf_idf_matrix[index].T)\n",
        "\n",
        "        \n",
        "        prod_query_docto = np.dot(query_tf_idf,self.tf_idf_matrix[index].T)\n",
        "\n",
        "        # print(prod_query_docto.toarray())\n",
        "        # print(prod_query_docto.toarray().item())\n",
        "        prod_query_docto = prod_query_docto.toarray().item()\n",
        "        # print(f\"type prod_query_docto {type(prod_query_docto)}\")\n",
        "        val_bm25 = ((self.k1 + 1)*prod_query_docto)/(self.k1+prod_query_docto)\n",
        "        return val_bm25\n",
        "\n",
        "    def search(self, query, top_k=5):\n",
        "        \"\"\"\n",
        "        Busca os k documentos mais relevantes para a consulta query.\n",
        "\n",
        "        Parâmetros\n",
        "        ----------\n",
        "        query: str\n",
        "            Consulta a ser pesquisada.\n",
        "        top_k: int, opcional (default=5)\n",
        "            Número de documentos mais relevantes a serem retornados.\n",
        "\n",
        "        Retorna\n",
        "        -------\n",
        "        list\n",
        "            Lista de tuplas contendo o id do documento e a pontuação BM25.\n",
        "        \"\"\"\n",
        "\n",
        "        # Separa as palavras da consulta em uma lista de tokens\n",
        "        # print(f\"Query: {query}\")\n",
        "        # query = query.split()\n",
        "\n",
        "        # Aplica o vetorizador na consulta\n",
        "        query_tf_idf = self.vectorizer.transform([query])\n",
        "\n",
        "        # Dicionário de pontuação de cada documento para a consulta\n",
        "        scores = {ndx+1: self._score(query_tf_idf, ndx) for ndx, doc in enumerate(self.documents)}\n",
        "  \n",
        "        # print(f\"scores[:5]  {list(scores)[:5]}\")\n",
        "        # Ordena os documentos por ordem decrescente de pontuação e retorna os k mais relevantes\n",
        "        return sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6fsB4OJThFXA"
      },
      "outputs": [],
      "source": [
        "mecanismo_bm25 = BM25(documentos_prep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFGE07rukSxu",
        "outputId": "2ecf7f9c-59b8-4bb9-bb83-e97ad5f8c50e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total doctos: 1460\n",
            "Tamanho médio: 281.56420071632516\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total doctos: {mecanismo_bm25.N}\\nTamanho médio: {mecanismo_bm25.avgdl}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urvtiTv2nubD",
        "outputId": "63ca097a-c689-4ccb-a621-c5f7ed113d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 6487)\t4.548522096419013\n",
            "  (0, 6161)\t10.373633932200244\n",
            "  (0, 5255)\t2.725510083686854\n",
            "  (0, 5163)\t3.5155070902367176\n",
            "  (0, 4847)\t2.599216358362562\n",
            "  (0, 3760)\t3.2235966816754154\n",
            "  (0, 3366)\t3.9167438622353608\n",
            "  (0, 1995)\t4.730843653212968\n",
            "  (0, 1943)\t3.7218435232345457\n",
            "  (0, 1642)\t4.009525595686327\n",
            "  (0, 1567)\t3.249239112288753\n",
            "  (0, 909)\t3.7535922215491264\n",
            "  (0, 824)\t6.821988783002461\n",
            "  (0, 785)\t4.457550318213287\n"
          ]
        }
      ],
      "source": [
        "print(mecanismo_bm25.vectorizer.transform([consultas_prep[1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwMOtSOKoCrm",
        "outputId": "1338e344-b2a6-49f5-f3c8-a47001c0bf64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(589, 2.4927852279328304),\n",
              " (722, 2.4886306108594023),\n",
              " (429, 2.488317120985585),\n",
              " (820, 2.488261730465691),\n",
              " (65, 2.4867478536555807),\n",
              " (1090, 2.485626364202991),\n",
              " (1091, 2.48513987052277),\n",
              " (603, 2.483178290444875),\n",
              " (17, 2.482872891017683),\n",
              " (813, 2.4819771674183744)]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mecanismo_bm25.search(consultas_prep[1],top_k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt2cYTJoWyAA"
      },
      "source": [
        "## Desenvolvimento de um mecanismo de busca baseado em bm25 com acréscimo de penalização para o tamanho dos documentos\n",
        "\n",
        "Usando library rank-bm25.BM25Okapi\n",
        "\n",
        "Nessa library python, há um ajuste que considera o tamanho do documento, como bem explicado na referência citada no início desta seção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NRIRaKP14In",
        "outputId": "526b1b17-b169-4782-a51e-3ee92e2bf4d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rank-bm25) (1.22.4)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rank-bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "RTDwvNu6UeO8"
      },
      "outputs": [],
      "source": [
        "from rank_bm25 import BM25Okapi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "HdqlNqHn7Y_T"
      },
      "outputs": [],
      "source": [
        "class BM25_Penaliza_Tamanho_Docto:\n",
        "    def __init__(self, documentos):\n",
        "        \"\"\"\n",
        "        Inicializa o indexador.\n",
        "\n",
        "        Args:\n",
        "            documentos (list): Lista com as informações dos documentos pré-processados.\n",
        "        \"\"\"\n",
        "        self.documentos = documentos\n",
        "        self.index = BM25Okapi(documentos)\n",
        "\n",
        "    def search(self, consulta, top_k=10):\n",
        "        \"\"\"\n",
        "        Realiza a busca BM25 para a consulta.\n",
        "\n",
        "        Args:\n",
        "            consulta (str): Consulta a ser buscada.\n",
        "            top_k (int): Número máximo de documentos a serem retornados. Padrão é 10.\n",
        "\n",
        "        Returns:\n",
        "            list: Lista com os índices dos documentos mais relevantes para a consulta, ordenados por relevância decrescente.\n",
        "        \"\"\"\n",
        "      \n",
        "        scores = self.index.get_scores(consulta)\n",
        "        # print(scores)\n",
        "        sorted_indexes = np.argsort(scores)[::-1]\n",
        "        # print(sorted_indexes)\n",
        "\n",
        "        # Get the top values and their indexes in a pair list\n",
        "        return [(i, scores[i]) for i in sorted_indexes[:top_k]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "L4kQ61HlUeL8"
      },
      "outputs": [],
      "source": [
        "mecanismo_bm25_penaliza_tamanho = BM25_Penaliza_Tamanho_Docto(documentos_prep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPAgnMC--wT0",
        "outputId": "ad776f00-090c-4121-8408-0a24d4849d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1283, -112.62650106298177),\n",
              " (1295, -117.00449081753162),\n",
              " (1099, -131.78342390793745),\n",
              " (1287, -135.45310000378092),\n",
              " (826, -145.30485984149763),\n",
              " (1085, -146.20343976246576),\n",
              " (1281, -146.46291901278508),\n",
              " (1319, -147.46108434334448),\n",
              " (1301, -148.7393105811567),\n",
              " (1311, -148.88804046312976)]"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mecanismo_bm25_penaliza_tamanho.search(consultas_prep[1], top_k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4B8UBzSltXV",
        "outputId": "36e35dc4-253f-43f5-ea8c-10c21757d0f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1295, -44.52016212496649),\n",
              " (1287, -50.02796368118334),\n",
              " (1311, -53.81120702212838),\n",
              " (1283, -57.28052043405227),\n",
              " (1085, -59.48953070998179),\n",
              " (1099, -59.64379437144702),\n",
              " (1301, -60.24307225207594),\n",
              " (1278, -64.93626423769038),\n",
              " (1288, -65.74799966419722),\n",
              " (826, -65.839006609229)]"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mecanismo_bm25_penaliza_tamanho.search(consultas_prep[6], top_k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54Slpwq_MjqH"
      },
      "source": [
        "# Etapa 4: Avaliação de mecanismos de busca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "XNKZxilKYlY4"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "D7UAQ1gTO4mN"
      },
      "outputs": [],
      "source": [
        "lista_mecanismo = {\"mecanismo_bm25\":mecanismo_bm25, \"mecanismo_bm25_penaliza_tamanho\":mecanismo_bm25_penaliza_tamanho}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HUsbv11s0Ce"
      },
      "source": [
        "## Definição e teste da métrica precisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "LChXWoc9MeXk"
      },
      "outputs": [],
      "source": [
        "def precisao(id_consulta, relevancia_consulta, mecanismo, top_k=10, debug:bool=False):\n",
        "    \"\"\"\n",
        "    Calcula a precisão do mecanismo de busca para a consulta especificada.\n",
        "\n",
        "    Parâmetros:\n",
        "        id_consulta (int): O id da consulta que se deseja avaliar.\n",
        "        relevancia_consulta (dict): Um dicionário onde a chave é o id da consulta e o valor é uma lista com os ids dos documentos relevantes.\n",
        "        mecanismo (objeto BM25): O mecanismo de busca a ser avaliado.\n",
        "        top_k (int, opcional): O número de documentos recuperados que se deseja considerar para o cálculo da métrica precision. O valor padrão é 10.\n",
        "\n",
        "    Retorna:\n",
        "        float: A precisão do mecanismo de busca para a consulta especificada.\n",
        "    \"\"\"  \n",
        "    # Obtém os ids dos documentos retornados pelo mecanismo de busca\n",
        "    ids_retornados = [doc_id for doc_id, score in mecanismo.search(consultas_prep[id_consulta], top_k=top_k)]\n",
        "    if debug:\n",
        "      print(\"ids_retornados\",ids_retornados)\n",
        "    # Obtém os ids dos documentos relevantes\n",
        "    ids_relevantes = relevancia_consulta[id_consulta]\n",
        "    if debug:\n",
        "      print(\"ids_relevantes\",ids_relevantes)\n",
        "    # Calcula a interseção entre os documentos retornados e os relevantes\n",
        "    documentos_relevantes_retornados = set(ids_relevantes).intersection(set(ids_retornados))\n",
        "    if debug:\n",
        "      print(\"documentos_relevantes_retornados\",documentos_relevantes_retornados)\n",
        "    # Calcula a precisão\n",
        "    prec = len(documentos_relevantes_retornados) / top_k\n",
        "    if debug:\n",
        "      print(\"prec\",prec)\n",
        "    return prec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqnRQrcbmWLE",
        "outputId": "c39afac8-221f-40cd-f551-9eea619c19ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ids_retornados [1295, 1283, 1287, 1099, 1085, 1301, 1311, 1319, 967, 54]\n",
            "ids_relevantes [19, 26, 28, 53, 176, 562, 644, 659, 1103, 1126, 1134]\n",
            "documentos_relevantes_retornados set()\n",
            "prec 0.0\n",
            "ids_retornados [894, 1415, 820, 603, 562, 489, 566, 812, 486, 512]\n",
            "ids_relevantes [19, 26, 28, 53, 176, 562, 644, 659, 1103, 1126, 1134]\n",
            "documentos_relevantes_retornados {562}\n",
            "prec 0.1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_consulta = 104\n",
        "precisao(id_consulta, relevancia_consulta, mecanismo_bm25_penaliza_tamanho, 10, debug=True)\n",
        "precisao(id_consulta, relevancia_consulta, mecanismo_bm25, 10, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ0eS10mnvQL",
        "outputId": "2704122e-4581-4462-93e5-4ce1ac1f9d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ids_retornados [1283, 1295, 1099, 1287, 826, 1085, 1281, 1319, 1301, 1311]\n",
            "ids_relevantes [28, 35, 38, 42, 43, 52, 65, 76, 86, 150, 189, 192, 193, 195, 215, 269, 291, 320, 429, 465, 466, 482, 483, 510, 524, 541, 576, 582, 589, 603, 650, 680, 711, 722, 726, 783, 813, 820, 868, 869, 894, 1162, 1164, 1195, 1196, 1281]\n",
            "documentos_relevantes_retornados {1281}\n",
            "prec 0.1\n",
            "ids_retornados [589, 722, 429, 820, 65, 1090, 1091, 603, 17, 813]\n",
            "ids_relevantes [28, 35, 38, 42, 43, 52, 65, 76, 86, 150, 189, 192, 193, 195, 215, 269, 291, 320, 429, 465, 466, 482, 483, 510, 524, 541, 576, 582, 589, 603, 650, 680, 711, 722, 726, 783, 813, 820, 868, 869, 894, 1162, 1164, 1195, 1196, 1281]\n",
            "documentos_relevantes_retornados {65, 813, 589, 429, 722, 820, 603}\n",
            "prec 0.7\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_consulta = 1\n",
        "precisao(id_consulta, relevancia_consulta, mecanismo_bm25_penaliza_tamanho, 10, debug=True)\n",
        "precisao(id_consulta, relevancia_consulta, mecanismo_bm25, 10, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqxP_4H_my6M",
        "outputId": "99a4677e-7c5e-425d-e0c7-a186c617c929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ids_retornados [1295, 1283, 1287, 1099, 1302, 1319, 826, 1301, 1085, 54]\n",
            "ids_relevantes [328, 422, 448, 485, 503, 509]\n",
            "documentos_relevantes_retornados set()\n",
            "prec 0.0\n",
            "ids_retornados [448, 570, 635, 566, 422, 894, 610, 1124, 636, 820]\n",
            "ids_relevantes [328, 422, 448, 485, 503, 509]\n",
            "documentos_relevantes_retornados {448, 422}\n",
            "prec 0.2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_consulta = 111\n",
        "precisao(id_consulta, relevancia_consulta, mecanismo_bm25_penaliza_tamanho, 10, debug=True)\n",
        "precisao(id_consulta, relevancia_consulta, mecanismo_bm25, 10, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejXoLLPls6p4"
      },
      "source": [
        "## Definição e teste da métrica r-precisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "kDQUorPnXpyx"
      },
      "outputs": [],
      "source": [
        "def r_precisao(id_consulta, relevancia_consulta, mecanismo, top_k=10, debug:bool=False):\n",
        "    \"\"\"\n",
        "    Calcula a R-precisão do mecanismo de busca para a consulta especificada.\n",
        "\n",
        "    Parâmetros:\n",
        "        id_consulta (int): O id da consulta que se deseja avaliar.\n",
        "        relevancia_consulta (dict): Um dicionário onde a chave é o id da consulta e o valor é uma lista com os ids dos documentos relevantes.\n",
        "        mecanismo (objeto BM25): O mecanismo de busca a ser avaliado.\n",
        "        top_k (int, opcional): O número de documentos recuperados que se deseja considerar para o cálculo da métrica R-precisão. O valor padrão é 10.\n",
        "\n",
        "    Retorna:\n",
        "        float: A R-precisão do mecanismo de busca para a consulta especificada.\n",
        "    \"\"\"\n",
        "    # Obtém os ids dos documentos retornados pelo mecanismo de busca\n",
        "    ids_retornados = [doc_id for doc_id, score in mecanismo.search(consultas_prep[id_consulta], top_k=top_k)]\n",
        "    if debug:\n",
        "      print(\"ids_retornados\",ids_retornados)    \n",
        "    # Obtém os ids dos documentos relevantes\n",
        "    ids_relevantes = relevancia_consulta[id_consulta]\n",
        "    if debug:\n",
        "      print(\"ids_relevantes\",ids_relevantes)    \n",
        "    # Calcula o número de documentos relevantes encontrados nos top_k documentos retornados\n",
        "    num_relevantes_retornados = len(set(ids_relevantes).intersection(set(ids_retornados)))\n",
        "    if debug:\n",
        "      print(\"num_relevantes_retornados\",num_relevantes_retornados)    \n",
        "    # Calcula o denominador correto para a R-precisão\n",
        "    num_relevantes = len(ids_relevantes)\n",
        "    if debug:\n",
        "      print(\"num_relevantes\",num_relevantes)    \n",
        "    denominador = min(num_relevantes, top_k)\n",
        "    if debug:\n",
        "      print(\"denominador = min\",denominador)    \n",
        "    # Calcula a R-precisão\n",
        "    r_prec = num_relevantes_retornados / denominador\n",
        "    if debug:\n",
        "      print(\"r_prec\",r_prec)    \n",
        "    return r_prec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVgOovsopWIx",
        "outputId": "0a79674d-4607-4bb9-dd40-cf8cb2d7de6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ids_retornados [1295, 1283, 1287, 1099, 1085, 1301, 1311, 1319, 967, 54]\n",
            "ids_relevantes [19, 26, 28, 53, 176, 562, 644, 659, 1103, 1126, 1134]\n",
            "num_relevantes_retornados 0\n",
            "num_relevantes 11\n",
            "denominador = min 10\n",
            "r_prec 0.0\n",
            "ids_retornados [894, 1415, 820, 603, 562, 489, 566, 812, 486, 512]\n",
            "ids_relevantes [19, 26, 28, 53, 176, 562, 644, 659, 1103, 1126, 1134]\n",
            "num_relevantes_retornados 1\n",
            "num_relevantes 11\n",
            "denominador = min 10\n",
            "r_prec 0.1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_consulta = 104\n",
        "r_precisao(id_consulta, relevancia_consulta, mecanismo_bm25_penaliza_tamanho, 10, debug=True)\n",
        "r_precisao(id_consulta, relevancia_consulta, mecanismo_bm25, 10, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu9ytUfSpWD7",
        "outputId": "5e6caf89-c3c5-4167-e373-6119f0788f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ids_retornados [1283, 1295, 1099, 1287, 826, 1085, 1281, 1319, 1301, 1311]\n",
            "ids_relevantes [28, 35, 38, 42, 43, 52, 65, 76, 86, 150, 189, 192, 193, 195, 215, 269, 291, 320, 429, 465, 466, 482, 483, 510, 524, 541, 576, 582, 589, 603, 650, 680, 711, 722, 726, 783, 813, 820, 868, 869, 894, 1162, 1164, 1195, 1196, 1281]\n",
            "num_relevantes_retornados 1\n",
            "num_relevantes 46\n",
            "denominador = min 10\n",
            "r_prec 0.1\n",
            "ids_retornados [589, 722, 429, 820, 65, 1090, 1091, 603, 17, 813]\n",
            "ids_relevantes [28, 35, 38, 42, 43, 52, 65, 76, 86, 150, 189, 192, 193, 195, 215, 269, 291, 320, 429, 465, 466, 482, 483, 510, 524, 541, 576, 582, 589, 603, 650, 680, 711, 722, 726, 783, 813, 820, 868, 869, 894, 1162, 1164, 1195, 1196, 1281]\n",
            "num_relevantes_retornados 7\n",
            "num_relevantes 46\n",
            "denominador = min 10\n",
            "r_prec 0.7\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_consulta = 1\n",
        "r_precisao(id_consulta, relevancia_consulta, mecanismo_bm25_penaliza_tamanho, 10, debug=True)\n",
        "r_precisao(id_consulta, relevancia_consulta, mecanismo_bm25, 10, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YyR2du_pWA4",
        "outputId": "c5a88061-9733-49c2-bdae-e606a8be178d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ids_retornados [1295, 1283, 1287, 1099, 1302, 1319, 826, 1301, 1085, 54]\n",
            "ids_relevantes [328, 422, 448, 485, 503, 509]\n",
            "num_relevantes_retornados 0\n",
            "num_relevantes 6\n",
            "denominador = min 6\n",
            "r_prec 0.0\n",
            "ids_retornados [448, 570, 635, 566, 422, 894, 610, 1124, 636, 820]\n",
            "ids_relevantes [328, 422, 448, 485, 503, 509]\n",
            "num_relevantes_retornados 2\n",
            "num_relevantes 6\n",
            "denominador = min 6\n",
            "r_prec 0.3333333333333333\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_consulta = 111\n",
        "r_precisao(id_consulta, relevancia_consulta, mecanismo_bm25_penaliza_tamanho, 10, debug=True)\n",
        "r_precisao(id_consulta, relevancia_consulta, mecanismo_bm25, 10, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RhnlnXs9pO"
      },
      "source": [
        "## Definição e teste da métrica ncg (Normalized Cumulative Gain)\n",
        "\n",
        "Essa métrica é de ranqueamento, pois considera a posição e o valor de relevância do documento.\n",
        "\n",
        "No caso da coleção CISI, como não há valor de relevância diferente de um, sua aplicabilidade fica comprometida. Algo a investigar é se nesses casos o valor de ncg se equivale ao de r-precision, conforme foi apurado nos cálculos abaixo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "Z9I0Rn_epV9R"
      },
      "outputs": [],
      "source": [
        "def ncg(id_consulta, relevancia_consulta, mecanismo, top_k=10, debug:bool=False):\n",
        "    \"\"\"\n",
        "    Calcula a métrica NCG (Normalized Cumulative Gain) do mecanismo de busca para a consulta especificada.\n",
        "\n",
        "    Parâmetros:\n",
        "        id_consulta (int): O id da consulta que se deseja avaliar.\n",
        "        relevancia_consulta (dict): Um dicionário onde a chave é o id da consulta e o valor é uma lista com os ids dos documentos relevantes.\n",
        "        mecanismo (objeto BM25): O mecanismo de busca a ser avaliado.\n",
        "        top_k (int, opcional): O número de documentos recuperados que se deseja considerar para o cálculo da métrica NCG. O valor padrão é 10.\n",
        "\n",
        "    Retorna:\n",
        "        float: A métrica NCG do mecanismo de busca para a consulta especificada.\n",
        "    \"\"\"\n",
        "    # Obtém os ids dos documentos retornados pelo mecanismo de busca\n",
        "    ids_retornados = [doc_id for doc_id, score in mecanismo.search(consultas_prep[id_consulta], top_k=top_k)]\n",
        "    if debug: \n",
        "      print('ids_retornados',ids_retornados)\n",
        "\n",
        "    # Obtém os relevâncias dos documentos retornados\n",
        "    relevancias = [1 if doc_id in relevancia_consulta[id_consulta] else 0 for doc_id in ids_retornados]\n",
        "    if debug: \n",
        "      print('relevancias',relevancias)\n",
        "    \n",
        "    # Calcula o NCG\n",
        "    cg_topk = relevancias[0]\n",
        "    for i in range(1, len(relevancias)):\n",
        "        cg_topk += relevancias[i]\n",
        "    if debug: \n",
        "      print('cg_topk',cg_topk)\n",
        "\n",
        "    # Calcula o ideal NCG\n",
        "    limite_superior = min(top_k, len(relevancia_consulta[id_consulta]))\n",
        "    if debug: \n",
        "      print('limite_superior',limite_superior)\n",
        "\n",
        "    ideal_relevancias = [1 for doc_id in relevancia_consulta[id_consulta][:limite_superior]]\n",
        "    if debug: \n",
        "      print('ideal_relevancias',ideal_relevancias)\n",
        "\n",
        "\n",
        "    ideal_cg_topk = ideal_relevancias[0]\n",
        "    for i in range(1, len(ideal_relevancias)):\n",
        "        ideal_cg_topk += ideal_relevancias[i]\n",
        "    if debug: \n",
        "      print('ideal_cg_topk',ideal_cg_topk)\n",
        "    # Calcula a NCG\n",
        "    val_ncg = cg_topk / ideal_cg_topk if ideal_cg_topk != 0 else 0\n",
        "    if debug: \n",
        "      print('val_ncg',val_ncg)\n",
        "    return val_ncg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRZkqEHMp6U5",
        "outputId": "7239a247-1b14-4aac-f30a-e51092821cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ids_retornados [1295, 1283, 1287, 1099, 1302, 1319, 826, 1301, 1085, 54]\n",
            "relevancias [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "cg_topk 0\n",
            "limite_superior 6\n",
            "ideal_relevancias [1, 1, 1, 1, 1, 1]\n",
            "ideal_cg_topk 6\n",
            "val_ncg 0.0\n",
            "ids_retornados [448, 570, 635, 566, 422, 894, 610, 1124, 636, 820]\n",
            "relevancias [1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "cg_topk 2\n",
            "limite_superior 6\n",
            "ideal_relevancias [1, 1, 1, 1, 1, 1]\n",
            "ideal_cg_topk 6\n",
            "val_ncg 0.3333333333333333\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# testando para consulta com 6 doctos relevantes (menor do que top_k)\n",
        "id_consulta = 111\n",
        "ncg(id_consulta,relevancia_consulta, mecanismo_bm25_penaliza_tamanho, top_k=10, debug=True)\n",
        "ncg(id_consulta,relevancia_consulta, mecanismo_bm25, top_k=10, debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0F6uYQrp6RQ",
        "outputId": "a9bdc636-b8ad-4e80-8205-242b76ecd679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ids_retornados [1283, 1295, 1099, 1287, 826, 1085, 1281, 1319, 1301, 1311]\n",
            "relevancias [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "cg_topk 1\n",
            "limite_superior 10\n",
            "ideal_relevancias [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "ideal_cg_topk 10\n",
            "val_ncg 0.1\n",
            "ids_retornados [589, 722, 429, 820, 65, 1090, 1091, 603, 17, 813]\n",
            "relevancias [1, 1, 1, 1, 1, 0, 0, 1, 0, 1]\n",
            "cg_topk 7\n",
            "limite_superior 10\n",
            "ideal_relevancias [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "ideal_cg_topk 10\n",
            "val_ncg 0.7\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# testando para consulta com mais de top_k doctos relevantes \n",
        "id_consulta = 1\n",
        "ncg(id_consulta,relevancia_consulta, mecanismo_bm25_penaliza_tamanho, top_k=10, debug=True)\n",
        "ncg(id_consulta,relevancia_consulta, mecanismo_bm25, top_k=10, debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjfdXeyAp6Ih"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "gS74bKSoMeUW"
      },
      "outputs": [],
      "source": [
        "def metrica_media(funcao_metrica, relevancia_consulta, mecanismo, top_k=10, debug:bool=False):\n",
        "    \"\"\"Calcula a média das precisões para todas as consultas com relevância conhecida.\n",
        "\n",
        "    Args:\n",
        "        relevancia_consulta (dict): Dicionário que mapeia ids de consulta em uma lista de ids de documentos relevantes.\n",
        "        mecanismo (BM25): Instância da classe BM25 ou BM25_Penaliza_Tamanho_Docto.\n",
        "        top_k (int): Número de documentos retornados pelo mecanismo de busca.\n",
        "\n",
        "    Returns:\n",
        "        float: Média das precisões.\n",
        "    \"\"\"\n",
        "    metricas = []\n",
        "    for id_consulta in relevancia_consulta.keys():\n",
        "        val_metrica = funcao_metrica(id_consulta, relevancia_consulta, mecanismo, top_k)\n",
        "        if debug:\n",
        "          print(f\"Apurada métrica {funcao_metrica} para consulta {id_consulta} com valor {val_metrica}\")        \n",
        "        metricas.append(val_metrica)\n",
        "\n",
        "    if len(metricas) == 0:\n",
        "        raise Exception(\"não foi montado array de métricas\")\n",
        "  \n",
        "    val_media = sum(metricas) / len(metricas)\n",
        "    if debug:\n",
        "      print(f\"Apurada val_media = {val_media} para métrica {funcao_metrica} para sum(metricas) {sum(metricas)} e  len(metricas) {len(metricas)}\")        \n",
        "\n",
        "    return val_media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IixAP61hre6i",
        "outputId": "1c33063a-7597-4362-e6c2-947316243549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 1 com valor 0.7\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 2 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 3 com valor 0.8\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 4 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 5 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 6 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 7 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 8 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 9 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 10 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 11 com valor 0.3\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 12 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 13 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 14 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 15 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 16 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 17 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 18 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 19 com valor 0.5\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 20 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 21 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 22 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 23 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 24 com valor 0.7\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 25 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 26 com valor 0.7\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 27 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 28 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 29 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 30 com valor 0.8\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 31 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 32 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 33 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 34 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 35 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 37 com valor 0.3\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 39 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 41 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 42 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 43 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 44 com valor 0.6\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 45 com valor 0.5\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 46 com valor 0.5\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 49 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 50 com valor 0.8\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 52 com valor 0.5\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 54 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 55 com valor 0.9\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 56 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 57 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 58 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 61 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 62 com valor 0.5\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 65 com valor 0.3\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 66 com valor 0.6\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 67 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 69 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 71 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 76 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 79 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 81 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 82 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 84 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 90 com valor 0.3\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 92 com valor 0.5\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 95 com valor 0.3\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 96 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 97 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 98 com valor 0.6\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 99 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 100 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 101 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 102 com valor 0.6\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 104 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 109 com valor 0.6\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 111 com valor 0.2\n",
            "Apurada val_media = 0.28684210526315806 para métrica <function precisao at 0x7fe55cdea4c0> para sum(metricas) 21.80000000000001 e  len(metricas) 76\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.28684210526315806"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrica_media(precisao, relevancia_consulta,mecanismo_bm25, 10, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJamzck_re4D",
        "outputId": "9d456e33-9030-46bb-9c01-3a04a19bb981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 1 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 2 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 3 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 4 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 5 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 6 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 7 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 8 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 9 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 10 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 11 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 12 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 13 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 14 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 15 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 16 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 17 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 18 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 19 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 20 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 21 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 22 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 23 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 24 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 25 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 26 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 27 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 28 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 29 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 30 com valor 0.4\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 31 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 32 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 33 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 34 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 35 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 37 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 39 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 41 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 42 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 43 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 44 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 45 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 46 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 49 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 50 com valor 0.1\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 52 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 54 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 55 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 56 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 57 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 58 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 61 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 62 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 65 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 66 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 67 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 69 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 71 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 76 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 79 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 81 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 82 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 84 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 90 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 92 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 95 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 96 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 97 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 98 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 99 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 100 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 101 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 102 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 104 com valor 0.0\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 109 com valor 0.2\n",
            "Apurada métrica <function precisao at 0x7fe55cdea4c0> para consulta 111 com valor 0.0\n",
            "Apurada val_media = 0.021052631578947368 para métrica <function precisao at 0x7fe55cdea4c0> para sum(metricas) 1.6 e  len(metricas) 76\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.021052631578947368"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrica_media(precisao, relevancia_consulta,mecanismo_bm25_penaliza_tamanho, 10, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "hk6y0EOJWB4f"
      },
      "outputs": [],
      "source": [
        "lista_metrica = {\"precisao\":precisao, \"r_precisao\":r_precisao, \"ncg\":ncg}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDRuvcgYOLHu",
        "outputId": "bf44d8b2-908b-44cd-e463-ab06d3f0700c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A média da métrica precisao para mecanismo_bm25 é : 0.28684210526315806\n",
            "A média da métrica r_precisao para mecanismo_bm25 é : 0.3016447368421054\n",
            "A média da métrica ncg para mecanismo_bm25 é : 0.3016447368421054\n",
            "A média da métrica precisao para mecanismo_bm25_penaliza_tamanho é : 0.021052631578947368\n",
            "A média da métrica r_precisao para mecanismo_bm25_penaliza_tamanho é : 0.021052631578947368\n",
            "A média da métrica ncg para mecanismo_bm25_penaliza_tamanho é : 0.021052631578947368\n"
          ]
        }
      ],
      "source": [
        "for nome_mecanismo, mecanismo_busca in lista_mecanismo.items():\n",
        "  for nome_metrica, metrica in lista_metrica.items():\n",
        "    print(f\"A média da métrica {nome_metrica} para {nome_mecanismo} é : {metrica_media(metrica,relevancia_consulta,mecanismo_busca, top_k=10)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e007dYSoJ-zT"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
