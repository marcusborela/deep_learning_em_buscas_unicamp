{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CcN_5-RDWeqV",
        "VQxzYKGgMqce",
        "r9xRdgUGMPgh",
        "achvQ78sa3p3",
        "8v2gtkEPhA0t",
        "anygzoSagczS",
        "O488oyu5l8kC",
        "T0GF6NqznpBk",
        "Y5MRuHo8md3Z",
        "iMp1ME6UK8vi",
        "MBfxPDhaFq5W",
        "hGPQPU38MbZc",
        "sTn273M0FTTH",
        "pw6AV1W3osR5",
        "4qiloI8loxJ2",
        "BJAEtyT_e5wv",
        "W13Q69XIxdPc",
        "sm0zUCrfS6NK",
        "ZvAci0iUiA7g",
        "tfTzMCRdXP5s",
        "lnhoAgvR1wCH",
        "17AcNhe2C4tb",
        "SBFVkGXG6Pbp",
        "5JKNuPSsn2xO"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5df526cb2bdf481480806fad6348b27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8064c16540404293b3e4968fd0229144",
              "IPY_MODEL_c784dea266464d228470c8f146e682bb",
              "IPY_MODEL_8bb8f80668da4e708d04fe9ef7a6b183"
            ],
            "layout": "IPY_MODEL_de1be7b088d84f879d48678f142aadb6"
          }
        },
        "8064c16540404293b3e4968fd0229144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2550930351954fdb817bcc04796bd47d",
            "placeholder": "​",
            "style": "IPY_MODEL_2aeae0a72a0f4b6f9aa625691f9f2728",
            "value": "Test: 100%"
          }
        },
        "c784dea266464d228470c8f146e682bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20361f3bf1f24cba9bacb573433ae203",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e268abe9b4d42cfae158a0debe4746f",
            "value": 32
          }
        },
        "8bb8f80668da4e708d04fe9ef7a6b183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ff9ad6df59c4f0dbf923324dd0e37ce",
            "placeholder": "​",
            "style": "IPY_MODEL_ae61115e87fc4dd786a4b713d1824a3c",
            "value": " 32/32 [00:06&lt;00:00,  4.60it/s]"
          }
        },
        "de1be7b088d84f879d48678f142aadb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2550930351954fdb817bcc04796bd47d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aeae0a72a0f4b6f9aa625691f9f2728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20361f3bf1f24cba9bacb573433ae203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e268abe9b4d42cfae158a0debe4746f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ff9ad6df59c4f0dbf923324dd0e37ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae61115e87fc4dd786a4b713d1824a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b9539203b44436bbfdc6b64cd254be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0f96070551f4f9eafe2afa055023e06",
              "IPY_MODEL_6af80f182c334f5ba9cc07a5b8f1da1a",
              "IPY_MODEL_1e452ebffd2240c48f89a5b48ddf2154"
            ],
            "layout": "IPY_MODEL_88b79520f2114e9b813d843ace054c24"
          }
        },
        "a0f96070551f4f9eafe2afa055023e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b2b1a4816444b9f8576a4c63c184292",
            "placeholder": "​",
            "style": "IPY_MODEL_fd1184354115408bb0850ff7a022657f",
            "value": "Downloading: 100%"
          }
        },
        "6af80f182c334f5ba9cc07a5b8f1da1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_586c2947176149e0a4b04ffa971befe2",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_204a1bf468354494845fb9e04fd1933e",
            "value": 385
          }
        },
        "1e452ebffd2240c48f89a5b48ddf2154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a1b460cb199470eacceeabc0ee04cbb",
            "placeholder": "​",
            "style": "IPY_MODEL_8acfc553a754407d9a7e418f8f805f6e",
            "value": " 385/385 [00:00&lt;00:00, 25.5kB/s]"
          }
        },
        "88b79520f2114e9b813d843ace054c24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2b1a4816444b9f8576a4c63c184292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd1184354115408bb0850ff7a022657f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "586c2947176149e0a4b04ffa971befe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "204a1bf468354494845fb9e04fd1933e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a1b460cb199470eacceeabc0ee04cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8acfc553a754407d9a7e418f8f805f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "969066989bd643318c444eb51e1a5d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f829f6641a034adc8c09b88a1bc0705d",
              "IPY_MODEL_2f4bd7038fdf458c9db6ab0f2834ad4f",
              "IPY_MODEL_ddbbf7586e0b4328a23ccb728b2f868e"
            ],
            "layout": "IPY_MODEL_68df54786e504ed8906901269b3890f5"
          }
        },
        "f829f6641a034adc8c09b88a1bc0705d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a9d4c5c1f4d48c392b6692922199216",
            "placeholder": "​",
            "style": "IPY_MODEL_018ce1dcee234e6183969f020c58f4f4",
            "value": "Downloading: 100%"
          }
        },
        "2f4bd7038fdf458c9db6ab0f2834ad4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9b3513a4f8b42ff9e99b30e4b488a37",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34648af0565444e884056ca536bfdd1f",
            "value": 231508
          }
        },
        "ddbbf7586e0b4328a23ccb728b2f868e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb5245a4efa46e6a7aaa0330eeda91b",
            "placeholder": "​",
            "style": "IPY_MODEL_e1530d9149a1435a8ab1710c84050ae1",
            "value": " 232k/232k [00:00&lt;00:00, 3.21MB/s]"
          }
        },
        "68df54786e504ed8906901269b3890f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9d4c5c1f4d48c392b6692922199216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "018ce1dcee234e6183969f020c58f4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9b3513a4f8b42ff9e99b30e4b488a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34648af0565444e884056ca536bfdd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bb5245a4efa46e6a7aaa0330eeda91b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1530d9149a1435a8ab1710c84050ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05d427375fdc425291c9f09fbb29a75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_725cb48f3c9042449f3238cc87f99e21",
              "IPY_MODEL_6dca8778da794783beb9e7f31a5510eb",
              "IPY_MODEL_86154bea52e94c1388ed05e8c0640967"
            ],
            "layout": "IPY_MODEL_9fb160f0b98345a6843d834492a75faa"
          }
        },
        "725cb48f3c9042449f3238cc87f99e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92c277b5f8543d199cf640fea4b149e",
            "placeholder": "​",
            "style": "IPY_MODEL_f327f39ea9af4122b006fef490e8e455",
            "value": "Downloading: 100%"
          }
        },
        "6dca8778da794783beb9e7f31a5510eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad7cb6910774079a51cb33e90306b01",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aabf472289c94721837f076c44dfb867",
            "value": 112
          }
        },
        "86154bea52e94c1388ed05e8c0640967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55e7a053fbd40e190c8c59d0459b531",
            "placeholder": "​",
            "style": "IPY_MODEL_366165e1cc8746078932dad0f93f79bc",
            "value": " 112/112 [00:00&lt;00:00, 7.98kB/s]"
          }
        },
        "9fb160f0b98345a6843d834492a75faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92c277b5f8543d199cf640fea4b149e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f327f39ea9af4122b006fef490e8e455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ad7cb6910774079a51cb33e90306b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aabf472289c94721837f076c44dfb867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c55e7a053fbd40e190c8c59d0459b531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366165e1cc8746078932dad0f93f79bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77c6ba61488a4b5fba5c86e65565013a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad74ef3fd4fd42e39f28bdcc47a4c956",
              "IPY_MODEL_9feda182b4254ad2b4c73615f0c97e09",
              "IPY_MODEL_960fadbc0426459392248d3502b5fa14"
            ],
            "layout": "IPY_MODEL_f300b74e613d4c9c8585460b8176861e"
          }
        },
        "ad74ef3fd4fd42e39f28bdcc47a4c956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a817cfd96a2f4c0e90e745c0a4db2176",
            "placeholder": "​",
            "style": "IPY_MODEL_a71bafedd02c4269a6661d92db864a19",
            "value": "Downloading: 100%"
          }
        },
        "9feda182b4254ad2b4c73615f0c97e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc0e2d8cae840ae85656961c6a441a0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03e2e531751145a6bf35d1de325513f7",
            "value": 2
          }
        },
        "960fadbc0426459392248d3502b5fa14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064147130b2d433394bb3ebc5f3ab290",
            "placeholder": "​",
            "style": "IPY_MODEL_f4f3125f6a8a4ff78d69d838c23daf5e",
            "value": " 2.00/2.00 [00:00&lt;00:00, 150B/s]"
          }
        },
        "f300b74e613d4c9c8585460b8176861e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a817cfd96a2f4c0e90e745c0a4db2176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71bafedd02c4269a6661d92db864a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dc0e2d8cae840ae85656961c6a441a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e2e531751145a6bf35d1de325513f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "064147130b2d433394bb3ebc5f3ab290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f3125f6a8a4ff78d69d838c23daf5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcN_5-RDWeqV"
      },
      "source": [
        "# Classificação de Texto e Reranqueadores\n",
        "\n",
        "Desenvolvimento de um buscador Simples: Booleano, TF-IDF, BM25\n",
        "\n",
        "Tópicos abordados: Indexação, Bag-of-Words, TF-IDF, BM25\n",
        "\n",
        "Aula 1 - [Unicamp - IA368DD: Deep Learning aplicado a sistemas de busca.](https://www.cpg.feec.unicamp.br/cpg/lista/caderno_horario_show.php?id=1779)\n",
        "\n",
        "Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "[Repositório no github](https://github.com/marcusborela/deep_learning_em_buscas_unicamp)\n",
        "\n",
        "[Link para chat de apoio com WebChatGPT](https://github.com/marcusborela/deep_learning_em_buscas_unicamp/blob/main/chat/CG%20uso%20aula_2_classificacao_de_texto_e_reranqueador.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti1aFWTVgejM"
      },
      "source": [
        "[![Open In Colab latest github version](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcusborela/deep_learning_em_buscas_unicamp/blob/main/code/aula_2_classificacao_de_texto_e_reranqueador.ipynb) [Open In Colab latest github version]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQxzYKGgMqce"
      },
      "source": [
        "# Enunciado exercício\n",
        "\n",
        "Aula 2 - Notebook: Classificação de Texto e Reranqueadores\n",
        "\n",
        "Data de entrega: 15 de mar., 23:59\n",
        "\n",
        "Reranqueamento usando um modelo estilo-BERT com o treinamento no dataset do MS MARCO e avaliação no TREC-DL 2020\n",
        "\n",
        "\n",
        "O treinamento é igual ao de um classificador binário, que será feito por vocês.\n",
        "\n",
        "\n",
        "O que muda é a forma de avaliação: reranqueadores precisam ser alimentados com documentos candidatos (ex: trazidos pelo BM25 - exercício aula 1)\n",
        "\n",
        "\n",
        "Sugestões:\n",
        "1. usar este dataset reduzido do MS MARCO como treinamento, com 10k triplas (query, passagem relevante, passagem não-relevante):\n",
        "https://storage.googleapis.com/unicamp-dl/ia368dd_2023s1/msmarco/msmarco_triples.train.tiny.tsv\n",
        "\n",
        "\n",
        "2. usar miniLM (modelo BERT pequeno, 5x mais rapido) para começar o finetuning: https://huggingface.co/nreimers/MiniLM-L6-H384-uncased pois oferece um bom compromisso entre qualidade e velocidade.\n",
        "\n",
        "\n",
        "3. usar este notebook como base\n",
        "Análise de sentimentos (dataset IMDB) usando um modelo estilo BERT: https://colab.research.google.com/drive/10etP7Lb915EC-uEuf1IKC8DYkyg_om6-?usp=sharing\n",
        "\n",
        "\n",
        "4. para debug: usar este minilm para ver se consegue ndcg ~0.70: https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2Sugestão: fazer overfit em um batch: treinar por 200 epocas um unico batch, e ver se consegue loss=0, e acuracia=100%, ou ndcg=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Organizando o ambiente"
      ],
      "metadata": {
        "id": "BmRLgbyi_Dvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns_pq59lAHke",
        "outputId": "675f2112-55e2-4a18-cab5-0dea04884552"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 12 09:44:35 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n"
      ],
      "metadata": {
        "id": "DKAZ8CWCAM3-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mostra_memoria(lista_mem=['cpu']):\n",
        "  \"\"\"\n",
        "  Esta função exibe informações de memória da CPU e/ou GPU, conforme parâmetros fornecidos.\n",
        "\n",
        "  Parâmetros:\n",
        "  -----------\n",
        "  lista_mem : list, opcional\n",
        "      Lista com strings 'cpu' e/ou 'gpu'. \n",
        "      'cpu' - exibe informações de memória da CPU.\n",
        "      'gpu' - exibe informações de memória da GPU (se disponível).\n",
        "      O valor padrão é ['cpu'].\n",
        "\n",
        "  Saída:\n",
        "  -------\n",
        "  A função não retorna nada, apenas exibe as informações na tela.\n",
        "\n",
        "  Exemplo de uso:\n",
        "  ---------------\n",
        "  Para exibir informações de memória da CPU:\n",
        "      mostra_memoria(['cpu'])\n",
        "\n",
        "  Para exibir informações de memória da CPU e GPU:\n",
        "      mostra_memoria(['cpu', 'gpu'])\n",
        "  \n",
        "  Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "  \"\"\"  \n",
        "  if 'cpu' in lista_mem:\n",
        "    vm = virtual_memory()\n",
        "    ram={}\n",
        "    ram['total']=round(vm.total / 1e9,2)\n",
        "    ram['available']=round(virtual_memory().available / 1e9,2)\n",
        "    # ram['percent']=round(virtual_memory().percent / 1e9,2)\n",
        "    ram['used']=round(virtual_memory().used / 1e9,2)\n",
        "    ram['free']=round(virtual_memory().free / 1e9,2)\n",
        "    ram['active']=round(virtual_memory().active / 1e9,2)\n",
        "    ram['inactive']=round(virtual_memory().inactive / 1e9,2)\n",
        "    ram['buffers']=round(virtual_memory().buffers / 1e9,2)\n",
        "    ram['cached']=round(virtual_memory().cached/1e9 ,2)\n",
        "    print(f\"Your runtime RAM in gb: \\n total {ram['total']}\\n available {ram['available']}\\n used {ram['used']}\\n free {ram['free']}\\n cached {ram['cached']}\\n buffers {ram['buffers']}\")\n",
        "    print('/nGPU')\n",
        "    gpu_info = !nvidia-smi\n",
        "  if 'gpu' in lista_mem:\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)\n"
      ],
      "metadata": {
        "id": "9XgIWvkkH-kn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_memoria(['cpu'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dri9iiMAvCT",
        "outputId": "b74b9b33-99b1-4cca-ca63-99aa7655ac17"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 27.33\n",
            " available 25.79\n",
            " used 1.18\n",
            " free 22.6\n",
            " cached 3.19\n",
            " buffers 0.37\n",
            "/nGPU\n",
            "Sun Mar 12 09:45:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vinculando pasta do google drive para salvar dados"
      ],
      "metadata": {
        "id": "r9xRdgUGMPgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "IsJiN6H8K6pe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ae-Iy2oz_9os",
        "outputId": "0d2e1225-1b04-4764-85b1-0dc79af53909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_dir = os.getcwd()\n",
        "print(\"Current directory:\", current_dir)"
      ],
      "metadata": {
        "id": "7GYGL4MV_yhQ",
        "outputId": "f2a8c554-811e-4d2b-dc3d-a6288c1ad22d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ukuG3WAMndbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achvQ78sa3p3"
      },
      "source": [
        "## Fixando as seeds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "AG9RjMb8Qlot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkETIyWGkbOf"
      },
      "outputs": [],
      "source": [
        "def inicializa_seed(num_semente:int=123):\n",
        "  \"\"\"\n",
        "  Inicializa as sementes para garantir a reprodutibilidade dos resultados do modelo.\n",
        "  Essa é uma prática recomendada, já que a geração de números aleatórios pode influenciar os resultados do modelo.\n",
        "  Além disso, a função também configura as sementes da GPU para garantir a reprodutibilidade quando se utiliza aceleração por GPU. \n",
        "  \n",
        "  Args:\n",
        "      num_semente (int): número da semente a ser utilizada para inicializar as sementes das bibliotecas.\n",
        "  \n",
        "  References:\n",
        "      http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "      https://github.com/CyberZHG/torch-multi-head-attention/blob/master/torch_multi_head_attention/multi_head_attention.py#L15\n",
        "  \n",
        "  Autor: Marcus Vinícius Borela de Castro\n",
        "  \"\"\"\n",
        "  # Define as sementes das bibliotecas random, numpy e pytorch\n",
        "  random.seed(num_semente)\n",
        "  np.random.seed(num_semente)\n",
        "  torch.manual_seed(num_semente)\n",
        "  \n",
        "  # Define as sementes da GPU\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "  #torch.cuda.manual_seed(num_semente)\n",
        "  #Cuda algorithms\n",
        "  #torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViMcw_kVkbOf"
      },
      "outputs": [],
      "source": [
        "num_semente=123\n",
        "inicializa_seed(num_semente)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hABkY5GRtH9H"
      },
      "source": [
        "## Definindo Hiperparâmetros iniciais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {
        "id": "6OOO6ogjtG3Y"
      },
      "outputs": [],
      "source": [
        "def inicia_hparam()->dict:\n",
        "  # Inicialização dos parâmetros\n",
        "  hparam = {}\n",
        "  hparam[\"num_workers_dataloader\"] = 0\n",
        "  hparam[\"device\"] = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "  if torch.cuda.is_available(): print(torch. cuda. get_device_name(hparam[\"device\"]))    \n",
        "  return hparam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkTH4FkstTFn",
        "outputId": "08355885-cd3c-42d1-c589-b28a2f7be1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "hparam=inicia_hparam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v2gtkEPhA0t"
      },
      "source": [
        "## Preparando para debug e display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BJ6S4P5Hw4iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZEqQ7mKg5fs"
      },
      "source": [
        "https://zohaib.me/debugging-in-google-collab-notebook/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjrlXHq1hC8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a45d1f1-072e-4873-8d22-43a9755d667e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.3/793.3 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 KB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 8.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq ipdb\n",
        "import ipdb\n",
        "# %pdb off # desativa debug em exceção\n",
        "# %pdb on  # ativa debug em exceção\n",
        "# ipdb.set_trace(context=8)  para execução nesse ponto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvnhYnu5UfsJ",
        "outputId": "951ff9a5-518d-4644-98ad-9149e2c0e064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Using cached huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Collecting tqdm>=4.62.1\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.25.1)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, tqdm, multidict, frozenlist, dill, charset-normalizer, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.56.0\n",
            "    Uninstalling tqdm-4.56.0:\n",
            "      Successfully uninstalled tqdm-4.56.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.0.8\n",
            "    Uninstalling huggingface-hub-0.0.8:\n",
            "      Successfully uninstalled huggingface-hub-0.0.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.6.1 requires huggingface-hub==0.0.8, but you have huggingface-hub 0.13.1 which is incompatible.\n",
            "pygaggle 0.0.3.1 requires tqdm==4.56.0, but you have tqdm 4.65.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.13.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 tqdm-4.65.0 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def config_display():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de display do Pandas.\n",
        "\n",
        "  Autor: Marcus Vinícius Borela de Castro\n",
        "  \"\"\"\n",
        "\n",
        "  # Configurando formato saída Pandas\n",
        "  # define o número máximo de colunas que serão exibidas\n",
        "  pd.options.display.max_columns = None\n",
        "\n",
        "  # define a largura máxima de uma linha\n",
        "  pd.options.display.width = 1000\n",
        "\n",
        "  # define o número máximo de linhas que serão exibidas\n",
        "  pd.options.display.max_rows = 10\n",
        "\n",
        "  # define o número máximo de caracteres por coluna\n",
        "  pd.options.display.max_colwidth = 50\n",
        "\n",
        "  # se deve exibir o número de linhas e colunas de um DataFrame.\n",
        "  pd.options.display.show_dimensions = True\n",
        "\n",
        "  # número de dígitos após a vírgula decimal a serem exibidos para floats.\n",
        "  pd.options.display.precision = 2\n"
      ],
      "metadata": {
        "id": "wQ5pmlOHxHhk"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def config_debug():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de debug do PyTorch e dos pacotes\n",
        "  transformers e datasets.\n",
        "\n",
        "  Autor: Marcus Vinícius Borela de Castro\n",
        "  \"\"\"\n",
        "\n",
        "  # Define opções de impressão de tensores para o modo científico\n",
        "  torch.set_printoptions(sci_mode=True) \n",
        "  \"\"\"\n",
        "    Significa que valores muito grandes ou muito pequenos são mostrados em notação científica.\n",
        "    Por exemplo, em vez de imprimir o número 0.0000012345 como 0.0000012345, \n",
        "    ele seria impresso como 1.2345e-06. Isso é útil em situações em que os valores dos tensores \n",
        "    envolvidos nas operações são muito grandes ou pequenos, e a notação científica permite \n",
        "    uma melhor compreensão dos números envolvidos.  \n",
        "  \"\"\"\n",
        "\n",
        "  # Habilita detecção de anomalias no autograd do PyTorch\n",
        "  torch.autograd.set_detect_anomaly(True)\n",
        "  \"\"\"\n",
        "    Permite identificar operações que podem causar problemas de estabilidade numérica, \n",
        "    como gradientes explodindo ou desaparecendo. Quando essa opção é ativada, \n",
        "    o PyTorch verifica se há operações que geram valores NaN ou infinitos nos tensores \n",
        "    envolvidos no cálculo do gradiente. Se for detectado um valor anômalo, o PyTorch \n",
        "    interrompe a execução e gera uma exceção, permitindo que o erro seja corrigido \n",
        "    antes que se torne um problema maior.\n",
        "\n",
        "    É importante notar que a detecção de anomalias pode ter um impacto significativo \n",
        "    no desempenho, especialmente em modelos grandes e complexos. Por esse motivo,\n",
        "    ela deve ser usada com cautela e apenas para depuração.\n",
        "  \"\"\"\n",
        "\n",
        "  # Configura variável de ambiente para habilitar a execução síncrona (bloqueante) das chamadas da API do CUDA.\n",
        "  os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "  \"\"\"\n",
        "    o Python aguarda o término da execução de uma chamada da API do CUDA antes de executar a próxima chamada. \n",
        "    Isso é útil para depurar erros no código que envolve operações na GPU, pois permite que o erro seja capturado \n",
        "    no momento em que ocorre, e não depois de uma sequência de operações que pode tornar a origem do erro mais difícil de determinar.\n",
        "    No entanto, é importante lembrar que esse modo de execução é significativamente mais lento do que a execução assíncrona, \n",
        "    que é o comportamento padrão do CUDA. Por isso, é recomendado utilizar esse comando apenas em situações de depuração \n",
        "    e removê-lo após a solução do problema.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define o nível de verbosity do pacote transformers para info\n",
        "  transformers.utils.logging.set_verbosity_info() \n",
        "  \n",
        "  \n",
        "  \"\"\"\n",
        "    Define o nível de detalhamento das mensagens de log geradas pela biblioteca Hugging Face Transformers \n",
        "    para o nível info. Isso significa que a biblioteca irá imprimir mensagens de log informativas sobre\n",
        "    o andamento da execução, tais como tempo de execução, tamanho de batches, etc.\n",
        "\n",
        "    Essas informações podem ser úteis para entender o que está acontecendo durante a execução da tarefa \n",
        "    e auxiliar no processo de debug. É importante notar que, em alguns casos, a quantidade de informações\n",
        "    geradas pode ser muito grande, o que pode afetar o desempenho do sistema e dificultar a visualização\n",
        "    das informações relevantes. Por isso, é importante ajustar o nível de detalhamento de acordo com a \n",
        "    necessidade de cada tarefa.\n",
        "  \n",
        "    Caso queira reduzir a quantidade de mensagens, comentar a linha acima e \n",
        "      descomentar as duas linhas abaixo, para definir o nível de verbosity como error ou warning\n",
        "  \n",
        "    transformers.utils.logging.set_verbosity_error()\n",
        "    transformers.utils.logging.set_verbosity_warning()\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Define o modo verbose do xmode, que é utilizado no debug\n",
        "  %xmode Verbose \n",
        "\n",
        "  \"\"\"\n",
        "    Comando usado no Jupyter Notebook para controlar o modo de exibição das informações de exceções.\n",
        "    O modo verbose é um modo detalhado que exibe informações adicionais ao imprimir as exceções.\n",
        "    Ele inclui as informações de pilha de chamadas completa e valores de variáveis locais e globais \n",
        "    no momento da exceção. Isso pode ser útil para depurar e encontrar a causa de exceções em seu código.\n",
        "    Ao usar %xmode Verbose, as informações de exceção serão impressas com mais detalhes e informações adicionais serão incluídas.\n",
        "\n",
        "    Caso queira desabilitar o modo verbose e utilizar o modo plain, \n",
        "    comentar a linha acima e descomentar a linha abaixo:\n",
        "    %xmode Plain\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "    Dica:\n",
        "    1.  pdb (Python Debugger)\n",
        "      Quando ocorre uma exceção em uma parte do código, o programa para a execução e exibe uma mensagem de erro \n",
        "      com informações sobre a exceção, como a linha do código em que ocorreu o erro e o tipo da exceção.\n",
        "\n",
        "      Se você estiver depurando o código e quiser examinar o estado das variáveis ​​e executar outras operações \n",
        "      no momento em que a exceção ocorreu, pode usar o pdb (Python Debugger). Para isso, é preciso colocar o comando %debug \n",
        "      logo após ocorrer a exceção. Isso fará com que o programa pare na linha em que ocorreu a exceção e abra o pdb,\n",
        "      permitindo que você explore o estado das variáveis, examine a pilha de chamadas e execute outras operações para depurar o código.\n",
        "\n",
        "\n",
        "    2. ipdb\n",
        "      O ipdb é um depurador interativo para o Python que oferece recursos mais avançados do que o pdb,\n",
        "      incluindo a capacidade de navegar pelo código fonte enquanto depura.\n",
        "      \n",
        "      Você pode começar a depurar seu código inserindo o comando ipdb.set_trace() em qualquer lugar do \n",
        "      seu código onde deseja pausar a execução e começar a depurar. Quando a execução chegar nessa linha, \n",
        "      o depurador entrará em ação, permitindo que você examine o estado atual do seu programa e execute \n",
        "      comandos para investigar o comportamento.\n",
        "\n",
        "      Durante a depuração, você pode usar comandos:\n",
        "        next (para executar a próxima linha de código), \n",
        "        step (para entrar em uma função chamada na próxima linha de código) \n",
        "        continue (para continuar a execução normalmente até o próximo ponto de interrupção).\n",
        "\n",
        "      Ao contrário do pdb, o ipdb é um depurador interativo que permite navegar pelo código fonte em que\n",
        "      está trabalhando enquanto depura, permitindo que você inspecione variáveis, defina pontos de interrupção\n",
        "      adicionais e até mesmo execute expressões Python no contexto do seu programa.\n",
        "  \"\"\"\n"
      ],
      "metadata": {
        "id": "b2tDy72ATNHs"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_display()"
      ],
      "metadata": {
        "id": "Tb4aqtcExR84"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5Bq4043fkfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d65803-1726-46be-e5b9-78f05c8f12d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception reporting mode: Verbose\n"
          ]
        }
      ],
      "source": [
        "config_debug()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wEkY_g7kgp-"
      },
      "source": [
        "## Rastro (neptune.ai)\n",
        "\n",
        "Gerado rastro da execução no Neptune (detalhes no artigo [Rastro-DM: Mineração de Dados com Rastro](https://revista.tcu.gov.br/ojs/index.php/RTCU/article/view/1664))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anygzoSagczS"
      },
      "source": [
        "### Importação de libraries para Rastro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhrnJyfgYCc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e74614-1e9c-4f58-ccdb-c39924fd11fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/neptune/internal/backends/hosted_client.py:48: NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n",
            "  from neptune.version import version as neptune_client_version\n",
            "<ipython-input-148-faf515e8cb50>:2: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
            "  import neptune.new as neptune\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import neptune.new as neptune  \n",
        "except ImportError:\n",
        "  !pip install neptune-client\n",
        "  raise Exception('Stopping RUNTIME! Please run again.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ncf5Ncupk4f",
        "outputId": "23e45056-38f2-4c8d-eee9-7bf201c717d3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from torchviz) (1.13.1+cu116)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4151 sha256=36d6ee20684eecf3e5a21e94d91b5007007da7c8e5d52424696ecd05c2b5b617\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/65/6e/db2515eb1dc760fecd36b40d54df65c1e18534013f1c037e2e\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot "
      ],
      "metadata": {
        "id": "7cQvuqrppnIZ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "DotwpZ4JdmsZ"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import copy\n",
        "import time\n",
        "import re\n",
        "import tempfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2glxk01UfDk"
      },
      "source": [
        "### Código Rastro\n",
        "\n",
        "Busca implementar o rastro proposto em [Rastro-DM: Mineração de Dados com Rastro](https://revista.tcu.gov.br/ojs/index.php/RTCU/article/view/1664), autores Marcus Vinícius Borela de Castro e Remis Balaniuk, com o apoio da [solução Neptune](https://app.neptune.ai/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-iQwMPiLXO3"
      },
      "outputs": [],
      "source": [
        "def converte_optimizer_state_dict(parm_optimizer)-> dict:\n",
        "  \"\"\"\n",
        "    Recebe um objeto \"parm_optimizer\" que é do tipo \"torch.optim.Optimizer\" e retorna um dicionário \n",
        "    com informações sobre o otimizador.\n",
        "\n",
        "    O dicionário de retorno é gerado a partir do estado do otimizador que é extraído da propriedade\n",
        "    \"state_dict()\" do objeto \"parm_optimizer\", seu primeiro grupo de parâmetros do otimizador.\n",
        "  \"\"\"\n",
        "  # return str(hparam['optimizer'])\n",
        "  return parm_optimizer.state_dict()['param_groups'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "def gera_tag_rastro_experiencia_treino(parm_aula: str, hparam: dict) -> str:\n",
        "    \"\"\"\n",
        "    Gera uma string formatada com informações de hiperparâmetros para ser usada como tag de rastro de experiência de treino.\n",
        "\n",
        "    Args:\n",
        "        parm_aula (str): Nome da aula que está sendo treinada.\n",
        "        hparam (dict): Dicionário contendo os hiperparâmetros utilizados no treinamento.\n",
        "\n",
        "    Returns:\n",
        "        str: String formatada com as informações de hiperparâmetros.\n",
        "\n",
        "    Uso: \n",
        "\n",
        "    hparam['lista_tag_rastro_experiencia_treino'] =        gera_tag_rastro_experiencia_treino(parm_aula='aula7', hparam=hparam)\n",
        "    \"\"\"\n",
        "    # Inicializa uma lista vazia para armazenar as tags\n",
        "    lista_tag = []\n",
        "    \n",
        "    # Lista com as chaves dos hiperparâmetros que serão utilizados\n",
        "    lista_chaves = ['embed_dim', 'dim_feedforward', 'ind_activation_function', 'batch_size', 'learning_rate', 'weight_decay', 'amsgrad', 'decrease_factor_lr', 'max_examples', 'eval_every_steps']\n",
        "    \n",
        "    # Itera pelas chaves da lista e cria uma string com a chave e o valor correspondente em hparam,\n",
        "    # adicionando essa string à lista_tag\n",
        "    for chave in lista_chaves:\n",
        "        tag = f\"{chave} {hparam[chave]}\"\n",
        "        lista_tag.append(tag)\n",
        "    \n",
        "    # Concatena a lista de tags em uma única string, separando cada tag por '|',\n",
        "    # e adicionando o nome da aula como prefixo\n",
        "    tag_formatada = f\"{parm_aula}|\" + \"|\".join(lista_tag)\n",
        "    \n",
        "    return tag_formatada\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TOrNttzncJ7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeptuneRastroRun():\n",
        "    \"\"\"\n",
        "    Classe para geração de rastro de experimento utilizando a ferramenta Neptune.\n",
        "\n",
        "    Busca implementar o rastro proposto em [Rastro-DM: Mineração de Dados com Rastro](https://revista.tcu.gov.br/ojs/index.php/RTCU/article/view/1664),\n",
        "    autores Marcus Vinícius Borela de Castro e Remis Balaniuk, com o apoio da [solução Neptune](https://app.neptune.ai/)\n",
        "\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    se_geracao_rastro : bool\n",
        "        Indica se deve ser gerado rastro de experimento. \n",
        "    neptune_project : str\n",
        "        Nome do projeto criado no Neptune. \n",
        "    tag_contexto_rastro : str\n",
        "        Nome da tag utilizada para identificar o experimento.\n",
        "    neptune_api_token : str\n",
        "        Token utilizado para autenticação na API do Neptune. \n",
        "    run_neptune : object\n",
        "        Objeto que representa o experimento no Neptune.\n",
        "    device : str\n",
        "        Dispositivo utilizado para o treinamento do modelo.\n",
        "    tmpDir : str\n",
        "        Diretório temporário utilizado para salvar gráfico do modelo.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "    __init__(parm_params:dict, parm_lista_tag:list = None)\n",
        "        Construtor da classe NeptuneRastroRun. \n",
        "    run()\n",
        "        Retorna objeto que representa o experimento no Neptune.\n",
        "    ativa_geracao_rastro()\n",
        "        Ativa a geração de rastro de experimento.\n",
        "    def_contexto()\n",
        "        Define o contexto para a geração de rastro de experimento.\n",
        "    desativa_geracao_rastro()\n",
        "        Desativa a geração de rastro de experimento.\n",
        "    retorna_status_geracao_rastro()\n",
        "        Retorna o status da geração de rastro de experimento.\n",
        "    retorna_tag_contexto_rastro()\n",
        "        Retorna o nome da tag utilizada para identificar o experimento.\n",
        "    inicia_contexto(neptune_project, tag_contexto_rastro, neptune_api_token)\n",
        "        Inicializa o contexto para a geração de rastro de experimento.\n",
        "    salva_metrica(parm_metricas={})\n",
        "        Salva métricas do experimento no Neptune.\n",
        "    gera_grafico_modelo(loader_train, model)\n",
        "        Gera um gráfico do modelo treinado.\n",
        "    stop()\n",
        "        Finaliza o experimento no Neptune.\n",
        "    \"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "_yncm5-tdWmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "GwnX3SrGfq4Z"
      },
      "outputs": [],
      "source": [
        "class NeptuneRastroRun():\n",
        "    \"\"\"\n",
        "      Classe para geração de rastro de experimento utilizando a ferramenta Neptune.\n",
        "\n",
        "      Busca implementar o rastro proposto em [Rastro-DM: Mineração de Dados com Rastro](https://revista.tcu.gov.br/ojs/index.php/RTCU/article/view/1664),\n",
        "      autores Marcus Vinícius Borela de Castro e Remis Balaniuk, com o apoio da [solução Neptune](https://app.neptune.ai/)\n",
        "\n",
        "\n",
        "      Attributes:\n",
        "      -----------\n",
        "      se_geracao_rastro : bool\n",
        "          Indica se deve ser gerado rastro de experimento. \n",
        "      neptune_project : str\n",
        "          Nome do projeto criado no Neptune. \n",
        "      tag_contexto_rastro : str\n",
        "          Nome da tag utilizada para identificar o experimento.\n",
        "      neptune_api_token : str\n",
        "          Token utilizado para autenticação na API do Neptune. \n",
        "      run_neptune : object\n",
        "          Objeto que representa o experimento no Neptune.\n",
        "      device : str\n",
        "          Dispositivo utilizado para o treinamento do modelo.\n",
        "      tmpDir : str\n",
        "        Diretório temporário utilizado para salvar gráfico do modelo.          \n",
        "    \"\"\"\n",
        "    se_geracao_rastro = True \n",
        "    neptune_project = \"\"\n",
        "    tag_contexto_rastro = \"\"\n",
        "    neptune_api_token = \"\"\n",
        "\n",
        "    def __init__(self, parm_params:dict,  parm_lista_tag:list = None):\n",
        "      \"\"\"\n",
        "        Método construtor da classe NeptuneRastroRun.\n",
        "        \n",
        "        Args:\n",
        "        - parm_params: dicionário contendo os parâmetros do modelo.\n",
        "        - parm_lista_tag: lista contendo tags adicionais para o experimento.\n",
        "      \"\"\"      \n",
        "      # print(f\"NeptuneRastroRun.init: se_geracao_rastro {self.__class__.se_geracao_rastro} parm_params `{parm_params} \")\n",
        "      if self.__class__.se_geracao_rastro:      \n",
        "        self.run_neptune = neptune.init(project=self.__class__.neptune_project, api_token=self.__class__.neptune_api_token, capture_hardware_metrics=True)\n",
        "        self.run_neptune['sys/name'] = self.__class__.tag_contexto_rastro\n",
        "        vparams = copy.deepcopy(parm_params)\n",
        "        if \"optimizer\" in vparams:\n",
        "          vparams[\"optimizer\"] = converte_optimizer_state_dict(vparams[\"optimizer\"])\n",
        "        if 'criterion'  in vparams:\n",
        "          vparams[\"criterion\"] = str(vparams[\"criterion\"])\n",
        "        if 'scheduler'  in vparams:\n",
        "          vparams[\"scheduler\"] = str(type(vparams[\"scheduler\"]))\n",
        "        if 'device' in vparams:\n",
        "          vparams['device'] = str(vparams[\"device\"])\n",
        "        self.device = vparams[\"device\"]\n",
        "        for tag in parm_lista_tag:\n",
        "          self.run_neptune['sys/tags'].add(tag)\n",
        "        self.run_neptune['parameters'] = vparams\n",
        "        # self.tmpDir = tempfile.mkdtemp()\n",
        "\n",
        "    @property\n",
        "    def run():\n",
        "      \"\"\"\n",
        "      Retorna a instância do objeto run_neptune.\n",
        "      \"\"\"      \n",
        "      return self.run_neptune\n",
        "\n",
        "    @classmethod\n",
        "    def ativa_geracao_rastro(cls):\n",
        "      \"\"\"\n",
        "      Ativa a geração de rastro.\n",
        "      \"\"\"      \n",
        "      cls.se_geracao_rastro = True      \n",
        "\n",
        "    @classmethod\n",
        "    def def_contexto(cls):\n",
        "      \"\"\"\n",
        "      Define o contexto para a geração de rastro.\n",
        "      \"\"\"      \n",
        "      cls.se_geracao_rastro = True      \n",
        "\n",
        "    @classmethod\n",
        "    def desativa_geracao_rastro(cls):\n",
        "      \"\"\"\n",
        "      Desativa a geração de rastro.\n",
        "      \"\"\"      \n",
        "      cls.se_geracao_rastro = False      \n",
        "\n",
        "    @classmethod\n",
        "    def retorna_status_geracao_rastro(cls):\n",
        "      \"\"\"\n",
        "        Retorna o status da geração de rastro.\n",
        "        \n",
        "        Returns:\n",
        "        - True se a geração de rastro está ativada, False caso contrário.\n",
        "      \"\"\"      \n",
        "      return cls.se_geracao_rastro      \n",
        "\n",
        "    @classmethod\n",
        "    def retorna_tag_contexto_rastro(cls):\n",
        "      \"\"\"\n",
        "        Retorna a tag do contexto de rastro.\n",
        "      \"\"\"      \n",
        "      return cls.tag_contexto_rastro \n",
        "\n",
        "    @classmethod\n",
        "    def inicia_contexto(cls, neptune_project, tag_contexto_rastro, neptune_api_token):\n",
        "      \"\"\"\n",
        "      Inicia o contexto de execução no Neptune.\n",
        "\n",
        "      Args:\n",
        "          neptune_project (str): Nome do projeto no Neptune.\n",
        "          tag_contexto_rastro (str): Tag que identifica o contexto de execução no Neptune.\n",
        "          neptune_api_token (str): Token de acesso à API do Neptune.\n",
        "\n",
        "      Raises:\n",
        "          AssertionError: Caso a tag_contexto_rastro possua um ponto (.), \n",
        "            o que pode gerar erros na gravação de arquivo.\n",
        "      \"\"\"      \n",
        "      assert '.' not in tag_contexto_rastro, \"NeptuneRastroRun.init(): tag_contexto_rastro não pode possuir ponto, pois será usado para gravar nome de arquivo\"      \n",
        "      cls.neptune_api_token = neptune_api_token\n",
        "      cls.tag_contexto_rastro = tag_contexto_rastro\n",
        "      cls.neptune_project = neptune_project\n",
        "\n",
        "    def salva_metrica(self, parm_metricas={}):\n",
        "      \"\"\"\n",
        "        Salva as métricas no Neptune Run caso a geração de rastro esteja ativa.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        parm_metricas: dict\n",
        "            Dicionário contendo as métricas a serem salvas. As chaves devem ser os nomes das métricas e os valores devem ser\n",
        "            os valores das métricas.\n",
        "      \"\"\"\n",
        "      #print(f\"NeptuneRastroRun.salva_metrica: se_geracao_rastro {self.__class__.se_geracao_rastro} parm_metricas:{parm_metricas} \")\n",
        "      if self.__class__.se_geracao_rastro:\n",
        "        for metrica, valor in parm_metricas.items(): \n",
        "          self.run_neptune[metrica].log(valor)\n",
        " \n",
        "    def gera_grafico_modelo(self, loader_train, model):\n",
        "      \"\"\"\n",
        "        Gera um gráfico do modelo e o envia para o Neptune. \n",
        "        Para gerar o gráfico, um forward pass é realizado em um batch de exemplos \n",
        "        de treino e o resultado é renderizado como um gráfico de nós conectados. \n",
        "        O gráfico é salvo em um arquivo .png e enviado para o Neptune como um arquivo anexo.\n",
        "\n",
        "        Args:\n",
        "            loader_train (torch.utils.data.DataLoader): DataLoader do conjunto de treinamento.\n",
        "            model (torch.nn.Module): Modelo a ser visualizado.\n",
        "        \n",
        "        Pendente:\n",
        "          Evolui para usar from io import StringIO (buffer = io.StringIO()) ao invés de tempdir \n",
        "      \"\"\"      \n",
        "      if self.__class__.se_geracao_rastro: \n",
        "        # efetuar um forward \n",
        "        \"\"\"\n",
        "        se dataloader devolver x e y:\n",
        "        \"\"\"\n",
        "        x_, y_ = next(iter(loader_train))\n",
        "        x_ = x_.to(self.device)\n",
        "        outputs = model(x_)\n",
        "        \"\"\"\n",
        "        # se dataloader devolver dict:\n",
        "        dados_ = next(iter(loader_train))\n",
        "        outputs = model(dados_['x'].to(self.device))\n",
        "        #outputs = model(x_['input_ids'].to(self.device), x_['attention_mask'].to(self.device))\n",
        "        \"\"\"\n",
        "        nome_arquivo = os.path.join(self.tmpDir, \"modelo \"+ self.__class__.tag_contexto_rastro + time.strftime(\"%Y-%b-%d %H:%M:%S\"))\n",
        "        make_dot(outputs, params=dict(model.named_parameters()), show_attrs=True, show_saved=True).render(nome_arquivo, format=\"png\")\n",
        "        self.run_neptune[\"parameters/model_graph\"].upload(nome_arquivo+'.png')\n",
        "        self.run_neptune['parameters/model'] = re.sub('<bound method Module.state_dict of ', '',str(model.state_dict))      \n",
        "\n",
        "\n",
        "\n",
        "    def stop(self):\n",
        "      \"\"\"\n",
        "        Para a execução do objeto Neptune. Todos os experimentos do Neptune são sincronizados com o servidor, e nenhum outro \n",
        "        experimento poderá ser adicionado a este objeto após a chamada a este método.\n",
        "      \"\"\"\n",
        "      if self.__class__.se_geracao_rastro:         \n",
        "        self.run_neptune.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O488oyu5l8kC"
      },
      "source": [
        "### Definindo parâmetros para o rastro\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY4Hjvp1wR9k",
        "outputId": "28610929-93d9-4d9f-99d1-b120ae8579bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Informe NEPTUNE_API_TOKEN··········\n"
          ]
        }
      ],
      "source": [
        "NeptuneRastroRun.inicia_contexto('marcusborela/IA386DD', 'Aula 10 - Modelo de linguagem treino auto-regressivo',   getpass.getpass('Informe NEPTUNE_API_TOKEN'))\n",
        "#NeptuneRastroRun.desativa_geracao_rastro()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurando Pyserini"
      ],
      "metadata": {
        "id": "T0GF6NqznpBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalações de libraries"
      ],
      "metadata": {
        "id": "Y5MRuHo8md3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/castorini/pygaggle.git"
      ],
      "metadata": {
        "id": "N2af9dTbmPff",
        "outputId": "47393aba-1719-4148-9c5c-40c13842b3e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/castorini/pygaggle.git\n",
            "  Cloning https://github.com/castorini/pygaggle.git to /tmp/pip-req-build-cd6wut9e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/castorini/pygaggle.git /tmp/pip-req-build-cd6wut9e\n",
            "  Resolved https://github.com/castorini/pygaggle.git to commit c285f6084684367dd07b608ef19c2722b5b0637e\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coloredlogs==14.0\n",
            "  Downloading coloredlogs-14.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.9/dist-packages (from pygaggle==0.0.3.1) (1.22.4)\n",
            "Collecting pydantic==1.7.4\n",
            "  Downloading pydantic-1.7.4-cp39-cp39-manylinux2014_x86_64.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyserini>=0.16.0\n",
            "  Downloading pyserini-0.20.0-py3-none-any.whl (137.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp39-cp39-manylinux2010_x86_64.whl (23.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp39-cp39-manylinux1_x86_64.whl (25.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.9/dist-packages (from pygaggle==0.0.3.1) (3.4.4)\n",
            "Collecting tensorboard==2.7.0\n",
            "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp39-cp39-manylinux2010_x86_64.whl (489.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.7/489.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.10.2\n",
            "  Downloading tokenizers-0.10.2-cp39-cp39-manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.56.0\n",
            "  Downloading tqdm-4.56.0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.6.1\n",
            "  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp39-cp39-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence_transformers==2.0.0\n",
            "  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from pygaggle==0.0.3.1) (1.13.1+cu116)\n",
            "Collecting humanfriendly>=7.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==0.24.2->pygaggle==0.0.3.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==0.24.2->pygaggle==0.0.3.1) (1.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.0.0->pygaggle==0.0.3.1) (0.14.1+cu116)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.0.0->pygaggle==0.0.3.1) (3.7)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (2.16.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (2.25.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (1.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (2.2.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (1.51.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.7.0->pygaggle==0.0.3.1) (0.6.1)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (0.31.0)\n",
            "Collecting flatbuffers<3.0,>=1.12\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (1.15.0)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (3.1.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (2.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 KB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0->pygaggle==0.0.3.1) (15.0.6.1)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.6.1->pygaggle==0.0.3.1) (3.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from transformers==4.6.1->pygaggle==0.0.3.1) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.6.1->pygaggle==0.0.3.1) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyjnius>=1.4.0\n",
            "  Downloading pyjnius-1.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.8.1\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.9/dist-packages (from pyserini>=0.16.0->pygaggle==0.0.3.1) (0.29.33)\n",
            "Collecting nmslib>=2.1.1\n",
            "  Downloading nmslib-2.1.1-cp39-cp39-manylinux2010_x86_64.whl (13.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=1.4.0\n",
            "  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (6.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (8.1.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (1.0.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (1.0.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (3.1.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (2.4.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (3.0.12)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pygaggle==0.0.3.1) (0.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.7.0->pygaggle==0.0.3.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.7.0->pygaggle==0.0.3.1) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.7.0->pygaggle==0.0.3.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.7.0->pygaggle==0.0.3.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard==2.7.0->pygaggle==0.0.3.1) (6.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from nmslib>=2.1.1->pyserini>=0.16.0->pygaggle==0.0.3.1) (5.4.8)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini>=0.16.0->pygaggle==0.0.3.1) (1.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.4.0->pyserini>=0.16.0->pygaggle==0.0.3.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.4.0->pyserini>=0.16.0->pygaggle==0.0.3.1) (2022.7.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.7.0->pygaggle==0.0.3.1) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.7.0->pygaggle==0.0.3.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.7.0->pygaggle==0.0.3.1) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.7.0->pygaggle==0.0.3.1) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pygaggle==0.0.3.1) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pygaggle==0.0.3.1) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.1->pygaggle==0.0.3.1) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=0.11.15->tensorboard==2.7.0->pygaggle==0.0.3.1) (2.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence_transformers==2.0.0->pygaggle==0.0.3.1) (8.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.7.0->pygaggle==0.0.3.1) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.7.0->pygaggle==0.0.3.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.7.0->pygaggle==0.0.3.1) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini>=0.16.0->pygaggle==0.0.3.1) (1.2.1)\n",
            "Building wheels for collected packages: pygaggle, sentence_transformers, sacremoses\n",
            "  Building wheel for pygaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygaggle: filename=pygaggle-0.0.3.1-py3-none-any.whl size=75889 sha256=61bc3e50793a58fbbae3214b581f3577594df743025d5706ae52c9e11cb47e16\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ttd4uj1r/wheels/f1/f6/86/98ae18cb92efe6913d607a03a0d61d24ae798346215b0cd95c\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126709 sha256=ebfc84f71c01a3c7fd3dfa2e37be2e55b612279304c3b5b4223f4267e632921a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/08/96/83cc9ff48d2ba543e7e041eaa085713a12006b5b7ba0039a64\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=df293da5378647219963e662c8422817186a555f131803d601e2032f19a8230d\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "Successfully built pygaggle sentence_transformers sacremoses\n",
            "Installing collected packages: tokenizers, tensorflow-estimator, sentencepiece, keras, flatbuffers, tqdm, scipy, pyjnius, pydantic, pybind11, keras-preprocessing, humanfriendly, scikit-learn, sacremoses, pandas, nmslib, huggingface-hub, coloredlogs, transformers, onnxruntime, lightgbm, tensorboard, sentence_transformers, tensorflow, pyserini, pygaggle\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.5\n",
            "    Uninstalling pydantic-1.10.5:\n",
            "      Successfully uninstalled pydantic-1.10.5\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.1\n",
            "    Uninstalling scikit-learn-1.2.1:\n",
            "      Successfully uninstalled scikit-learn-1.2.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.11.2\n",
            "    Uninstalling tensorboard-2.11.2:\n",
            "      Successfully uninstalled tensorboard-2.11.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.11.0\n",
            "    Uninstalling tensorflow-2.11.0:\n",
            "      Successfully uninstalled tensorflow-2.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed coloredlogs-14.0 flatbuffers-2.0.7 huggingface-hub-0.0.8 humanfriendly-10.0 keras-2.7.0 keras-preprocessing-1.1.2 lightgbm-3.3.5 nmslib-2.1.1 onnxruntime-1.14.1 pandas-1.5.3 pybind11-2.6.1 pydantic-1.7.4 pygaggle-0.0.3.1 pyjnius-1.4.2 pyserini-0.20.0 sacremoses-0.0.53 scikit-learn-0.24.2 scipy-1.5.4 sentence_transformers-2.0.0 sentencepiece-0.1.95 tensorboard-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tokenizers-0.10.2 tqdm-4.56.0 transformers-4.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyserini"
      ],
      "metadata": {
        "id": "WTTVf-nYmc0w",
        "outputId": "0042995b-9a26-4b7d-d129-9377e7524429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyserini in /usr/local/lib/python3.9/dist-packages (0.20.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (0.24.2)\n",
            "Requirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (3.4.4)\n",
            "Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.9/dist-packages (from pyserini) (0.29.33)\n",
            "Requirement already satisfied: sentencepiece>=0.1.95 in /usr/local/lib/python3.9/dist-packages (from pyserini) (0.1.95)\n",
            "Requirement already satisfied: pyjnius>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from pyserini) (1.4.2)\n",
            "Requirement already satisfied: lightgbm>=3.3.2 in /usr/local/lib/python3.9/dist-packages (from pyserini) (3.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (1.5.4)\n",
            "Requirement already satisfied: onnxruntime>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (1.14.1)\n",
            "Requirement already satisfied: transformers>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from pyserini) (4.6.1)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pyserini) (4.56.0)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from pyserini) (1.5.3)\n",
            "Requirement already satisfied: nmslib>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from pyserini) (2.1.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm>=3.3.2->pyserini) (0.38.4)\n",
            "Requirement already satisfied: pybind11<2.6.2 in /usr/local/lib/python3.9/dist-packages (from nmslib>=2.1.1->pyserini) (2.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.7.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini) (2.0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini) (14.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.19.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.4.0->pyserini) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.4.0->pyserini) (2.8.2)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (1.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (3.1.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (2.25.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (6.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (3.0.12)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (2.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (1.7.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (2.4.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (8.1.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.1->pyserini) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.6.0->pyserini) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.6.0->pyserini) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/dist-packages (from transformers>=4.6.0->pyserini) (0.0.53)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.6.0->pyserini) (0.0.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (4.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.1->pyserini) (8.1.3)\n",
            "Requirement already satisfied: humanfriendly>=7.1 in /usr/local/lib/python3.9/dist-packages (from coloredlogs->onnxruntime>=1.8.1->pyserini) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu -q"
      ],
      "metadata": {
        "id": "F3U_q5n1n_BW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ef135f-326b-4c04-dc41-57322c680667"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baixando o repositório do pyserini para usara seus scripts"
      ],
      "metadata": {
        "id": "iMp1ME6UK8vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_pyserini = '/content/drive/MyDrive/treinamento/202301_IA368DD/code/pyserini'\n",
        "path_pyserini_tools = path_pyserini + '/pyserini-master/anserini-tools-master'\n",
        "path_pyserini_eval = path_pyserini + '/pyserini-master/pyserini/eval'"
      ],
      "metadata": {
        "id": "aGyBaf54LwCp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(path_pyserini):\n",
        "    os.makedirs(path_pyserini)\n",
        "    print('pasta criada')\n",
        "    !wget -q https://github.com/castorini/pyserini/archive/refs/heads/master.zip -O pyserini.zip \n",
        "    !unzip -q pyserini.zip -d  {path_pyserini}\n",
        "    # Baixando tools que é um atalho para https://github.com/castorini/anserini-tools\n",
        "    !wget -q https://github.com/castorini/anserini-tools/archive/refs/heads/master.zip -O anserini-tools.zip \n",
        "    !unzip -q anserini-tools.zip -d  {path_pyserini}\n"
      ],
      "metadata": {
        "id": "vVBzuIuVMCqK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_pyserini = path_pyserini + '/pyserini-master'"
      ],
      "metadata": {
        "id": "wD6XUMH80aZI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " assert os.path.exists(path_pyserini), f\"Pasta {path_pyserini} não criada!\""
      ],
      "metadata": {
        "id": "CLHh0Nh8PW2E"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " assert os.path.exists(path_pyserini_tools), f\"Pasta {path_pyserini_tools} não criada!\""
      ],
      "metadata": {
        "id": "30pi-eYwQ4zo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " assert os.path.exists(path_pyserini_eval), f\"Pasta {path_pyserini_eval} não criada!\""
      ],
      "metadata": {
        "id": "kF1v31OuUzpM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga dos dados da TREC 2020 usando pyserini"
      ],
      "metadata": {
        "id": "MBfxPDhaFq5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtendo dados dos documentos a partir do pyserini\n",
        "\n",
        "\n",
        "[Dicas aqui](https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md)"
      ],
      "metadata": {
        "id": "hGPQPU38MbZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_data = '/content/drive/MyDrive/treinamento/202301_IA368DD/collections/msmarco-passage'"
      ],
      "metadata": {
        "id": "2WGHMsGcB7Ep"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if not os.path.exists(path_data):\n",
        "  os.makedirs(path_data)\n",
        "  print('pasta criada')\n",
        "  !wget https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz -P {path_data}\n",
        "  !tar xvfz {path_data}/collectionandqueries.tar.gz -C {path_data}\n",
        "  os.remove(f'{path_data}/collectionandqueries.tar.gz')\n",
        "  print(\"Dados carregados!\")\n",
        "else:\n",
        "  print(\"Dados já existiam!\")    "
      ],
      "metadata": {
        "id": "tDb6qDbsA38j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebba0ebe-d522-4273-fd8f-61f7aa9994a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados já existiam!\n",
            "CPU times: user 1.09 ms, sys: 0 ns, total: 1.09 ms\n",
            "Wall time: 830 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert os.path.exists(path_data), f\"Pasta {path_data} não criada!\""
      ],
      "metadata": {
        "id": "B5g4HhyAPx-4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo anterior gera os seguintes arquivos:\n",
        "\n",
        "* collection.tsv\n",
        "* qrels.dev.small.tsv\n",
        "* qrels.train.tsv\n",
        "* queries.dev.small.tsv\n",
        "* queries.dev.tsv\n",
        "* queries.eval.small.tsv\n",
        "* queries.eval.tsv\n",
        "* queries.train.tsv"
      ],
      "metadata": {
        "id": "VzPgONt7ERjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to convert the MS MARCO tsv collection into Pyserini's jsonl files (which have one json object per line):"
      ],
      "metadata": {
        "id": "oiNtb0oVDTPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if not os.path.exists(f'{path_data}/collection_jsonl'):\n",
        "  !python {path_pyserini_tools}/tools/scripts/msmarco/convert_collection_to_jsonl.py \\\n",
        "  --collection-path {path_data}/collection.tsv \\\n",
        "  --output-folder {path_data}/collection_jsonl\n",
        "  print(\"Dados carregados!\")\n",
        "else:\n",
        "  print(\"Dados já existiam!\")    "
      ],
      "metadata": {
        "id": "3Cf9nEQS_iWs",
        "outputId": "2bcda176-06e0-4b38-e7af-7c79aaac4a33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados já existiam!\n",
            "CPU times: user 1.71 ms, sys: 103 µs, total: 1.82 ms\n",
            "Wall time: 284 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert os.path.exists(f'{path_data}/collection_jsonl'), f\"Pasta {path_data}/collection_jsonl não criada!\""
      ],
      "metadata": {
        "id": "XWbCv1UAP3yc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above script should generate 9 jsonl files in collections/msmarco-passage/collection_jsonl, each with 1M lines (except for the last one, which should have 841,823 lines)."
      ],
      "metadata": {
        "id": "u4snYshcDmXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data in dicts\n",
        "\n",
        "The 6980 queries in the development set are already stored in the repo. Let's take a peek:"
      ],
      "metadata": {
        "id": "sTn273M0FTTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_pyserini_tools}/topics-and-qrels/topics.msmarco-passage.dev-subset.txt"
      ],
      "metadata": {
        "id": "t-WOE8VZPfzf",
        "outputId": "4fcd1006-1884-4e45-8457-bce811066d7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1048585\twhat is paula deen's brother\n",
            "2\t Androgen receptor define\n",
            "524332\ttreating tension headaches without medication\n",
            "1048642\twhat is paranoid sc\n",
            "524447\ttreatment of varicose veins in legs\n",
            "786674\twhat is prime rate in canada\n",
            "1048876\twho plays young dr mallard on ncis\n",
            "1048917\twhat is operating system misconfiguration\n",
            "786786\twhat is priority pass\n",
            "524699\ttricare service number\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_pyserini_tools}/topics-and-qrels/topics.dl20.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "418Ih9pyiABT",
        "outputId": "dfa2f581-0162-48d5-fd4d-23e00123f266"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030303\twho is aziz hashim\r\n",
            "1037496\twho is rep scalise?\r\n",
            "1043135\twho killed nicholas ii of russia\r\n",
            "1045109\twho owns barnhart crane\r\n",
            "1049519\twho said no one can make you feel inferior\r\n",
            "1051399\twho sings monk theme song\r\n",
            "1056416\twho was the highest career passer  rating in the nfl\r\n",
            "1064670\twhy do hunters pattern their shotguns?\r\n",
            "1065636\twhy do some places on my scalp feel sore\r\n",
            "1071750\twhy is pete rose banned from hall of fame\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_data}/qrels.dev.small.trec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxlsspHzRu0o",
        "outputId": "2238bd33-91a8-43c5-965c-9af5a4c1a3f3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300674 0 7067032 1\n",
            "125705 0 7067056 1\n",
            "94798 0 7067181 1\n",
            "9083 0 7067274 1\n",
            "174249 0 7067348 1\n",
            "320792 0 7067677 1\n",
            "1090270 0 7067796 1\n",
            "1101279 0 7067891 1\n",
            "201376 0 7068066 1\n",
            "54544 0 7068203 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_pyserini_tools}/topics-and-qrels/qrels.dl20-passage.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoeVZrqXbGZo",
        "outputId": "dd0ddd3e-2c96-4c3b-806e-4997d101a482"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 0 1020327 2\n",
            "23849 0 1034183 3\n",
            "23849 0 1120730 0\n",
            "23849 0 1139571 1\n",
            "23849 0 1143724 0\n",
            "23849 0 1147202 0\n",
            "23849 0 1150311 0\n",
            "23849 0 1158886 2\n",
            "23849 0 1175024 1\n",
            "23849 0 1201385 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each line contains a tab-delimited (query id, query) pair. Conveniently, Pyserini already knows how to load and iterate through these pairs. We can now perform retrieval using these queries:"
      ],
      "metadata": {
        "id": "-9XSzW8uHtic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carregando qrel (relevância por query)\n",
        "\n",
        "##### Carregando usando get_qrels"
      ],
      "metadata": {
        "id": "pw6AV1W3osR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyserini.search import get_qrels"
      ],
      "metadata": {
        "id": "FSq2Y3xavsFr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qrels = get_qrels('dl20-passage')"
      ],
      "metadata": {
        "id": "CR6PwgD2vv0Y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(qrels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htSknV23wOuX",
        "outputId": "04399633-bfd2-44f5-d6f2-5aca3a96e14e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(qrels.items())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oriPlWVulBFe",
        "outputId": "5dc5930a-fd50-4dc6-ccda-0141fc63e49a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23849,\n",
              " {1020327: '2',\n",
              "  1034183: '3',\n",
              "  1120730: '0',\n",
              "  1139571: '1',\n",
              "  1143724: '0',\n",
              "  1147202: '0',\n",
              "  1150311: '0',\n",
              "  1158886: '2',\n",
              "  1175024: '1',\n",
              "  1201385: '0',\n",
              "  1215556: '0',\n",
              "  1220759: '0',\n",
              "  1221770: '0',\n",
              "  1333480: '1',\n",
              "  1381453: '2',\n",
              "  1414114: '2',\n",
              "  1414115: '0',\n",
              "  1414120: '2',\n",
              "  1449780: '0',\n",
              "  146754: '0',\n",
              "  1493231: '0',\n",
              "  1532701: '0',\n",
              "  1535484: '0',\n",
              "  1605854: '1',\n",
              "  1605857: '1',\n",
              "  1622747: '1',\n",
              "  17118: '0',\n",
              "  17122: '0',\n",
              "  1714915: '0',\n",
              "  1714917: '1',\n",
              "  1724687: '0',\n",
              "  172488: '0',\n",
              "  178252: '0',\n",
              "  182049: '0',\n",
              "  1827512: '1',\n",
              "  1844627: '0',\n",
              "  188190: '0',\n",
              "  188246: '1',\n",
              "  1944730: '0',\n",
              "  2003292: '0',\n",
              "  2017213: '0',\n",
              "  2203364: '0',\n",
              "  2209883: '0',\n",
              "  2318793: '0',\n",
              "  2339898: '1',\n",
              "  2373852: '0',\n",
              "  2397072: '0',\n",
              "  2423771: '0',\n",
              "  2516458: '0',\n",
              "  2585563: '0',\n",
              "  2593928: '0',\n",
              "  2607127: '3',\n",
              "  2607128: '1',\n",
              "  2607129: '2',\n",
              "  2607130: '2',\n",
              "  2607131: '2',\n",
              "  2607132: '3',\n",
              "  2607134: '0',\n",
              "  2647769: '3',\n",
              "  2674124: '0',\n",
              "  2766280: '0',\n",
              "  282421: '0',\n",
              "  2838462: '3',\n",
              "  2880479: '0',\n",
              "  2934343: '0',\n",
              "  293608: '0',\n",
              "  293753: '0',\n",
              "  3008750: '1',\n",
              "  310272: '0',\n",
              "  3104533: '0',\n",
              "  3113002: '0',\n",
              "  314300: '0',\n",
              "  3185119: '1',\n",
              "  3341056: '0',\n",
              "  3342089: '0',\n",
              "  3374884: '0',\n",
              "  3376500: '0',\n",
              "  3678109: '0',\n",
              "  3687776: '0',\n",
              "  3698649: '0',\n",
              "  3799370: '0',\n",
              "  3878669: '1',\n",
              "  3978767: '2',\n",
              "  3978774: '1',\n",
              "  4016311: '2',\n",
              "  4016314: '1',\n",
              "  4016317: '3',\n",
              "  4065323: '1',\n",
              "  4091550: '0',\n",
              "  4091551: '0',\n",
              "  4104777: '0',\n",
              "  4138534: '2',\n",
              "  4188880: '1',\n",
              "  4281690: '1',\n",
              "  4344309: '1',\n",
              "  4348282: '0',\n",
              "  436721: '0',\n",
              "  4387499: '0',\n",
              "  441893: '0',\n",
              "  4482145: '0',\n",
              "  4527137: '0',\n",
              "  4556932: '3',\n",
              "  4556933: '3',\n",
              "  4556936: '0',\n",
              "  4556938: '0',\n",
              "  4556941: '0',\n",
              "  45662: '1',\n",
              "  4576574: '0',\n",
              "  4577479: '0',\n",
              "  4672905: '0',\n",
              "  4804092: '0',\n",
              "  4834498: '0',\n",
              "  4908953: '1',\n",
              "  4908957: '1',\n",
              "  4951252: '0',\n",
              "  5315510: '0',\n",
              "  5340997: '1',\n",
              "  5365059: '0',\n",
              "  5367780: '0',\n",
              "  542113: '0',\n",
              "  5529682: '0',\n",
              "  5597936: '1',\n",
              "  5633221: '0',\n",
              "  5740854: '2',\n",
              "  5740859: '1',\n",
              "  5809666: '0',\n",
              "  5824000: '0',\n",
              "  5835858: '0',\n",
              "  5862666: '0',\n",
              "  587451: '3',\n",
              "  5888570: '3',\n",
              "  590924: '0',\n",
              "  590926: '3',\n",
              "  590927: '1',\n",
              "  590929: '2',\n",
              "  5913890: '2',\n",
              "  5979591: '0',\n",
              "  599695: '0',\n",
              "  6037300: '0',\n",
              "  6180228: '2',\n",
              "  6264715: '3',\n",
              "  6277578: '1',\n",
              "  6338425: '0',\n",
              "  639564: '0',\n",
              "  640767: '3',\n",
              "  640772: '3',\n",
              "  640775: '0',\n",
              "  6493523: '0',\n",
              "  6515917: '1',\n",
              "  653142: '0',\n",
              "  6543413: '1',\n",
              "  6602616: '1',\n",
              "  6622147: '0',\n",
              "  6667419: '0',\n",
              "  6688736: '0',\n",
              "  6688737: '2',\n",
              "  6688738: '1',\n",
              "  6688739: '0',\n",
              "  6688741: '1',\n",
              "  6688742: '2',\n",
              "  6688743: '1',\n",
              "  6705133: '1',\n",
              "  67500: '0',\n",
              "  6803015: '1',\n",
              "  6970103: '0',\n",
              "  7008458: '1',\n",
              "  7014217: '0',\n",
              "  7039665: '2',\n",
              "  7039668: '0',\n",
              "  7098341: '1',\n",
              "  7119957: '0',\n",
              "  7153659: '0',\n",
              "  7186713: '3',\n",
              "  723681: '1',\n",
              "  7300641: '1',\n",
              "  7395195: '1',\n",
              "  7526373: '0',\n",
              "  7624167: '0',\n",
              "  7624168: '3',\n",
              "  7752628: '0',\n",
              "  7845081: '3',\n",
              "  7896999: '1',\n",
              "  7907569: '0',\n",
              "  794785: '0',\n",
              "  7987538: '2',\n",
              "  7987541: '2',\n",
              "  7987542: '3',\n",
              "  7991033: '0',\n",
              "  8010558: '2',\n",
              "  8010559: '2',\n",
              "  8010560: '3',\n",
              "  8010561: '3',\n",
              "  8010562: '3',\n",
              "  8010564: '1',\n",
              "  8010566: '1',\n",
              "  8017141: '2',\n",
              "  8052286: '1',\n",
              "  8059826: '1',\n",
              "  8133127: '0',\n",
              "  8135871: '0',\n",
              "  8140319: '0',\n",
              "  8163080: '0',\n",
              "  8177749: '1',\n",
              "  8246990: '1',\n",
              "  8336161: '2',\n",
              "  836559: '2',\n",
              "  8379423: '1',\n",
              "  8420441: '0',\n",
              "  8466750: '0',\n",
              "  8534117: '1',\n",
              "  8547803: '0',\n",
              "  8707726: '0',\n",
              "  8737814: '0',\n",
              "  958491: '0',\n",
              "  958495: '1',\n",
              "  970243: '0',\n",
              "  970247: '0'})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carregando queries\n",
        "\n",
        "##### Carregando usando get_topics"
      ],
      "metadata": {
        "id": "4qiloI8loxJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyserini.search import get_topics"
      ],
      "metadata": {
        "id": "Ipt1M8UBoSiP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = get_topics('dl20')\n",
        "print(f'{len(topics)} queries total')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei_BuJtsoTjm",
        "outputId": "78f40663-1a26-4177-8305-c8512ecf9b49"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 queries total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(topics), list(topics.items())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m7xTZe-oVNF",
        "outputId": "c2755c92-94e8-4d5f-917b-53ae2fff3f3c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, (735922, {'title': 'what is crimp oil'}))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deixando apenas queries com relevância"
      ],
      "metadata": {
        "id": "JDqkcXALfrBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = {key:value for key, value in topics.items() if key in qrels}"
      ],
      "metadata": {
        "id": "dpNEkfpzfhej"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(topics), list(topics.items())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBOv-3pzfudk",
        "outputId": "93993143-aee7-4b55-b4c9-b52dcb612879"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54, (23849, {'title': 'are naturalization records public information'}))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Executando 1o estágio: exact match com BM25"
      ],
      "metadata": {
        "id": "c-EQ6_F2VktR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_max_hits = 1000"
      ],
      "metadata": {
        "id": "NSvo8UOug2j6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Com código para retornar o score do bm25"
      ],
      "metadata": {
        "id": "waqMpGVHPVoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "4AJiH6lQQHc5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run all queries in topics, retrive top 1k for each query\n",
        "def run_all_queries(file, topics, searcher, num_max_hits=100):\n",
        "  \"\"\"\n",
        "  A função run_all_queries é responsável por realizar todas as consultas armazenadas no dicionário topics utilizando o objeto searcher fornecido e salvar os resultados em um arquivo de texto.\n",
        "\n",
        "  Parâmetros:\n",
        "\n",
        "  file: caminho do arquivo de saída onde serão salvos os resultados das consultas.\n",
        "  topics: dicionário contendo as consultas a serem executadas. Cada consulta é representada por uma chave única no dicionário. O valor correspondente a cada chave é um outro dicionário contendo as informações da consulta, como seu título e outras informações relevantes.\n",
        "  searcher: objeto do tipo Searcher que será utilizado para realizar as consultas.\n",
        "  num_max_hits: número máximo de documentos relevantes que serão retornados para cada consulta.\n",
        "  Retorno:\n",
        "\n",
        "  A função não retorna nenhum valor, mas salva os resultados das consultas no arquivo especificado em file.\n",
        "  Comentário:\n",
        "\n",
        "  A função usa a biblioteca tqdm para exibir uma barra de progresso enquanto executa as consultas.\n",
        "  O número de consultas concluídas é impresso a cada 100 consultas.\n",
        "  \"\"\"\n",
        "  print(f'Running {len(topics)} queries in total')\n",
        "  with open(file, 'w') as runfile:\n",
        "      cnt = 0\n",
        "      for id in tqdm(topics, desc='Running Queries'):\n",
        "          query = topics[id]['title']\n",
        "          hits = searcher.search(query, num_max_hits)\n",
        "          for i in range(0, len(hits)):\n",
        "              _ = runfile.write(f'{id} Q0 {hits[i].docid} {i+1} {hits[i].score:.6f} Etapa_EM\\n')\n",
        "              # = runfile.write('{} Q0 {} {} {:.6f} Pyserini\\n'.format(id, hits[i].docid, i+1, hits[i].score))\n",
        "          cnt += 1\n",
        "          if cnt % 100 == 0:\n",
        "              print(f'{cnt} queries completed')"
      ],
      "metadata": {
        "id": "dUJuMaOKPmoZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_run = path_data + '/runs'\n",
        "path_run_estagio1 = path_run + '/run-msmarco-passage-bm25-estagio1.txt'"
      ],
      "metadata": {
        "id": "zwyzd_W8gOAL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_run, path_run_estagio1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAjYClsNjHoi",
        "outputId": "d738980e-d294-49e3-d8bf-b7e5a812923e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/treinamento/202301_IA368DD/collections/msmarco-passage/runs',\n",
              " '/content/drive/MyDrive/treinamento/202301_IA368DD/collections/msmarco-passage/runs/run-msmarco-passage-bm25-estagio1.txt')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if not os.path.exists(path_run):\n",
        "  os.makedirs(path_run)\n",
        "  print('pasta criada!')\n",
        "else:\n",
        "  print('pasta já existia!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c7b6d1-8e46-4b5e-b8b1-fd6648939569",
        "id": "6KSZkPHbgOAL"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pasta já existia!\n",
            "CPU times: user 1.2 ms, sys: 0 ns, total: 1.2 ms\n",
            "Wall time: 4.65 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(path_run_estagio1):\n",
        "  # roda 1o estágio de busca por bm25\n",
        "  # code from https://colab.research.google.com/github/castorini/anserini-notebooks/blob/master/pyserini_msmarco_passage_demo.ipynb\n",
        "  from pyserini.search import SimpleSearcher\n",
        "  from pyserini.search.lucene import LuceneSearcher\n",
        "\n",
        "\n",
        "  # Indexando Trec 2020 Collection using Pyserini\n",
        "  !python -m pyserini.index.lucene \\\n",
        "    --collection JsonCollection \\\n",
        "    --input {path_data}/collection_jsonl \\\n",
        "    --index indexes/lucene-index-msmarco-passage \\\n",
        "    --generator DefaultLuceneDocumentGenerator \\\n",
        "    --threads 9 \\\n",
        "    --storePositions --storeDocvectors --storeRaw\n",
        "\n",
        "  # realizando busca e salvando dados do estágio 1\n",
        "  searcher = LuceneSearcher('./indexes/lucene-index-msmarco-passage')\n",
        "  searcher.set_bm25(k1=0.82, b=0.68)  \n",
        "  run_all_queries(path_run_estagio1, topics, searcher, num_max_hits)\n",
        "  \n",
        "  print(\"Dados estágio 1 (bm25) carregados!\")\n",
        "else:\n",
        "  print(\"Dados estágio 1 (bm25) já existiam!\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFrh5kiXjKg0",
        "outputId": "8d715b44-9e63-4811-fa65-885aad532ede"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados estágio 1 (bm25) já existiam!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert os.path.exists(path_run_estagio1), f\"Pasta {path_run_estagio1} não criada!\""
      ],
      "metadata": {
        "id": "x37emunogOAL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head {path_run_estagio1}"
      ],
      "metadata": {
        "id": "bkpqRcVwneUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016a333e-144c-4a75-b3ef-2fa2cffee070"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23849 Q0 4348282 1 10.738400 Etapa_EM\n",
            "23849 Q0 2674124 2 10.426600 Etapa_EM\n",
            "23849 Q0 542113 3 9.687200 Etapa_EM\n",
            "23849 Q0 8246990 4 9.641500 Etapa_EM\n",
            "23849 Q0 8133127 5 9.566500 Etapa_EM\n",
            "23849 Q0 2647769 6 9.547200 Etapa_EM\n",
            "23849 Q0 2017213 7 9.504800 Etapa_EM\n",
            "23849 Q0 7119957 8 9.500700 Etapa_EM\n",
            "23849 Q0 964148 9 9.476800 Etapa_EM\n",
            "23849 Q0 436721 10 9.464000 Etapa_EM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Eval"
      ],
      "metadata": {
        "id": "BJAEtyT_e5wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 -mrecall.1000 -mmap -l 2 'dl20-passage' {path_run_estagio1}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw_7OL1XuwxN",
        "outputId": "e9063357-0eb2-4130-bca9-bba15f41e0ba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
            "jtreceval-0.0.5-jar-with-dependencies.jar: 1.79MB [00:01, 946kB/s]                 \n",
            "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '-mrecall.1000', '-mmap', '-l', '2', '/root/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', '/content/drive/MyDrive/treinamento/202301_IA368DD/collections/msmarco-passage/runs/run-msmarco-passage-bm25-estagio1.txt']\n",
            "Results:\n",
            "map                   \tall\t0.2876\n",
            "recall_1000           \tall\t0.8031\n",
            "ndcg_cut_10           \tall\t0.4876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ80hHaftwUd"
      },
      "source": [
        "# Treinamento do ranqueador\n",
        "\n",
        "Fonte: https://colab.research.google.com/drive/10etP7Lb915EC-uEuf1IKC8DYkyg_om6-?usp=sharing\n",
        "\n",
        "In this notebook, we will finetuned and evaluate a BERT-based model on a document classification task.\n",
        "\n",
        "Our dataset will be a smaller version of the IMDB Sentiment Analysis dataset.\n",
        "\n",
        "To finetune and evaluate faster, we will be using [miniLM](https://huggingface.co/microsoft/MiniLM-L12-H384-uncased), which is small BERT-like model distilled from a larger one."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_memoria(('cpu','gpu'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rk4ytk_QVXs",
        "outputId": "8131995c-352b-4369-e176-5ed0bddf2bb5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 27.33\n",
            " available 25.23\n",
            " used 1.71\n",
            " free 10.54\n",
            " cached 14.61\n",
            " buffers 0.47\n",
            "/nGPU\n",
            "Sun Mar 12 11:52:22 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q"
      ],
      "metadata": {
        "id": "kebsl1uQDFUf"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "rnR2kDS_2FgZ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_memoria(('cpu','gpu'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaUCMGdD2vkX",
        "outputId": "b6807af4-0ddc-4103-85e1-9cf4cfb4aefb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 27.33\n",
            " available 25.31\n",
            " used 1.62\n",
            " free 10.82\n",
            " cached 14.45\n",
            " buffers 0.44\n",
            "/nGPU\n",
            "Sun Mar 12 09:55:34 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXFdJz2KVeQw"
      },
      "source": [
        "## Preparando dados de treinamento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga dos dados"
      ],
      "metadata": {
        "id": "W13Q69XIxdPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_data_train = path_data + '/train'\n",
        "path_data_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2_KYzw0S66eR",
        "outputId": "9e6e9394-21fd-42d6-edb4-f83b225d87e9"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/treinamento/202301_IA368DD/collections/msmarco-passage/train'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if not os.path.exists(path_data_train):\n",
        "  os.makedirs(path_data_train)\n",
        "  print(f'{path_data_train} pasta criada!')\n",
        "else:\n",
        "  print(f'{path_data_train} pasta já existia!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBD909R38DlP",
        "outputId": "a9f110a9-7b97-4482-fb40-838119a4921d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/treinamento/202301_IA368DD/collections/msmarco-passage/train pasta já existia!\n",
            "CPU times: user 0 ns, sys: 572 µs, total: 572 µs\n",
            "Wall time: 485 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert os.path.exists(path_data_train), f\"Path {path_data_train} não existe!\""
      ],
      "metadata": {
        "id": "2mJclLeEsFwS"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(path_data_train+'/msmarco_triples.train.tiny.tsv'):\n",
        "  !wget -P {path_data_train} https://storage.googleapis.com/unicamp-dl/ia368dd_2023s1/msmarco/msmarco_triples.train.tiny.tsv  \n",
        "  print(f'arquivo baixado!')"
      ],
      "metadata": {
        "id": "hKE1qwkG_m2Q"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert os.path.exists(path_data_train+'/msmarco_triples.train.tiny.tsv'), f\"Path {path_data_train+'/msmarco_triples.train.tiny.tsv'} não existe!\""
      ],
      "metadata": {
        "id": "E-mynCXQsPpz"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 2 {path_data_train+'/msmarco_triples.train.tiny.tsv'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lGK99gS_8Qh",
        "outputId": "46677072-4ce6-4d7b-817e-423c78302f93"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is a little caffeine ok during pregnancy\tWe donât know a lot about the effects of caffeine during pregnancy on you and your baby. So itâs best to limit the amount you get each day. If youâre pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1Â½ 8-ounce cups of coffee or one 12-ounce cup of coffee.\tIt is generally safe for pregnant women to eat chocolate because studies have shown to prove certain benefits of eating chocolate during pregnancy. However, pregnant women should ensure their caffeine intake is below 200 mg per day.\n",
            "what fruit is native to australia\tPassiflora herbertiana. A rare passion fruit native to Australia. Fruits are green-skinned, white fleshed, with an unknown edible rating. Some sources list the fruit as edible, sweet and tasty, while others list the fruits as being bitter and inedible.assiflora herbertiana. A rare passion fruit native to Australia. Fruits are green-skinned, white fleshed, with an unknown edible rating. Some sources list the fruit as edible, sweet and tasty, while others list the fruits as being bitter and inedible.\tThe kola nut is the fruit of the kola tree, a genus (Cola) of trees that are native to the tropical rainforests of Africa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A6DF5hstQK1l"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path_data_train+'/msmarco_triples.train.tiny.tsv', sep='\\t', header=None)"
      ],
      "metadata": {
        "id": "9Dv1sjfrPnJO"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['query', 'positive', 'negative']"
      ],
      "metadata": {
        "id": "LqdOpg5kQD9Q"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "igtPldcHPwCS",
        "outputId": "569581ae-a0fb-4423-8c67-9d61913c2dfa"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            query  \\\n",
              "0        is a little caffeine ok during pregnancy   \n",
              "1               what fruit is native to australia   \n",
              "2              how large is the canadian military   \n",
              "3                            types of fruit trees   \n",
              "4  how many calories a day are lost breastfeeding   \n",
              "\n",
              "                                            positive  \\\n",
              "0  We donât know a lot about the effects of caf...   \n",
              "1  Passiflora herbertiana. A rare passion fruit n...   \n",
              "2  The Canadian Armed Forces. 1  The first large-...   \n",
              "3  Cherry. Cherry trees are found throughout the ...   \n",
              "4  Not only is breastfeeding better for the baby,...   \n",
              "\n",
              "                                            negative  \n",
              "0  It is generally safe for pregnant women to eat...  \n",
              "1  The kola nut is the fruit of the kola tree, a ...  \n",
              "2  The Canadian Physician Health Institute (CPHI)...  \n",
              "3  The kola nut is the fruit of the kola tree, a ...  \n",
              "4  However, you still need some niacin each day; ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c548af4-b6b7-46ab-9e54-969a78570e6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is a little caffeine ok during pregnancy</td>\n",
              "      <td>We donât know a lot about the effects of caf...</td>\n",
              "      <td>It is generally safe for pregnant women to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what fruit is native to australia</td>\n",
              "      <td>Passiflora herbertiana. A rare passion fruit n...</td>\n",
              "      <td>The kola nut is the fruit of the kola tree, a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how large is the canadian military</td>\n",
              "      <td>The Canadian Armed Forces. 1  The first large-...</td>\n",
              "      <td>The Canadian Physician Health Institute (CPHI)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>types of fruit trees</td>\n",
              "      <td>Cherry. Cherry trees are found throughout the ...</td>\n",
              "      <td>The kola nut is the fruit of the kola tree, a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how many calories a day are lost breastfeeding</td>\n",
              "      <td>Not only is breastfeeding better for the baby,...</td>\n",
              "      <td>However, you still need some niacin each day; ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c548af4-b6b7-46ab-9e54-969a78570e6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c548af4-b6b7-46ab-9e54-969a78570e6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c548af4-b6b7-46ab-9e54-969a78570e6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua7i1BCTRTGx",
        "outputId": "d35c4b9e-8879-4623-bfbd-b20c0e7fe45b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "query       object\n",
              "positive    object\n",
              "negative    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando correção do arquivo!"
      ],
      "metadata": {
        "id": "bQ3S90BBTrKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm7ss2BfTlOu",
        "outputId": "bfd3db53-1bc5-4d30-b348-e1a73d9fcb91"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query       0\n",
            "positive    0\n",
            "negative    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratando qualidade dos dados"
      ],
      "metadata": {
        "id": "5yy7AivWxiCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ajustando o texto no dataframe"
      ],
      "metadata": {
        "id": "sm0zUCrfS6NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['query']=df['query'].astype(str)\n",
        "df['positive']=df['positive'].astype(str)\n",
        "df['negative']=df['negative'].astype(str)"
      ],
      "metadata": {
        "id": "HKwyHfD9RuuP"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = 'We donât know a lot about the effects'\n",
        "#x = x.encode('utf-8').decode('unicode_escape')\n",
        "x = x.replace('â', '\\'')\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07cWwKnHtKUs",
        "outputId": "5b7ae970-9edb-43fe-dcd6-f91a627d5d66"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We don't know a lot about the effects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['query'] = df['query'].apply(lambda x: x.replace('â', '\\''))\n",
        "df['positive'] = df['positive'].apply(lambda x: x.replace('â', '\\''))\n",
        "df['negative'] = df['negative'].apply(lambda x: x.replace('â', '\\''))\n"
      ],
      "metadata": {
        "id": "Lg0b1wj0SEsY"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfSKca4vQ8Ds",
        "outputId": "5cee1069-5a94-41a7-b3d6-d38dc126e643"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "a1al-ALzRotm",
        "outputId": "bbe71ab6-0096-4aed-cc74-058bb2b51bc6"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      query  \\\n",
              "0  is a little caffeine ok during pregnancy   \n",
              "1         what fruit is native to australia   \n",
              "2        how large is the canadian military   \n",
              "\n",
              "                                            positive  \\\n",
              "0  We don't know a lot about the effects of caffe...   \n",
              "1  Passiflora herbertiana. A rare passion fruit n...   \n",
              "2  The Canadian Armed Forces. 1  The first large-...   \n",
              "\n",
              "                                            negative  \n",
              "0  It is generally safe for pregnant women to eat...  \n",
              "1  The kola nut is the fruit of the kola tree, a ...  \n",
              "2  The Canadian Physician Health Institute (CPHI)...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-623e7802-83a1-431b-8b99-05b6e40c3d2d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is a little caffeine ok during pregnancy</td>\n",
              "      <td>We don't know a lot about the effects of caffe...</td>\n",
              "      <td>It is generally safe for pregnant women to eat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what fruit is native to australia</td>\n",
              "      <td>Passiflora herbertiana. A rare passion fruit n...</td>\n",
              "      <td>The kola nut is the fruit of the kola tree, a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how large is the canadian military</td>\n",
              "      <td>The Canadian Armed Forces. 1  The first large-...</td>\n",
              "      <td>The Canadian Physician Health Institute (CPHI)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-623e7802-83a1-431b-8b99-05b6e40c3d2d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-623e7802-83a1-431b-8b99-05b6e40c3d2d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-623e7802-83a1-431b-8b99-05b6e40c3d2d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['positive'].iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hQ6oOfZ70yjz",
        "outputId": "1fa43ed4-5235-4025-a9e5-3c504edfab08"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"We don't know a lot about the effects of caffeine during pregnancy on you and your baby. So it's best to limit the amount you get each day. If you're pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1Â½ 8-ounce cups of coffee or one 12-ounce cup of coffee.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = '1Â½ 8-ounce cups of coffee'"
      ],
      "metadata": {
        "id": "kpJ8NQ711BDo"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código abaixo não funcionou. A evoluir (se der tempo)!"
      ],
      "metadata": {
        "id": "E97nGG4u4TZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata"
      ],
      "metadata": {
        "id": "j4-arwgA3oRf"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = unicodedata.normalize(\"NFKD\", x)  # Normaliza a string"
      ],
      "metadata": {
        "id": "JTMeM2E33llW"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmKJjmwq3rCz",
        "outputId": "57f10987-624e-48a1-8ae6-68eb0a5bc7fb"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1Â1⁄2 8-ounce cups of coffee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[\\u00C2\\u00A0] = Â"
      ],
      "metadata": {
        "id": "C2foySiI27w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = re.sub(r'(\\d+)[\\u00C2\\u00A0]([\\u2150-\\u215E\\u2189])', r'\\1\\2', x, flags=re.UNICODE)\n",
        "print(s)  # \"1½ 8-ounce cups of coffee\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgzmHKDl1KU0",
        "outputId": "d0d31293-a313-4ae9-d629-e24366c00013"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1Â1⁄2 8-ounce cups of coffee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Verificando média de tamanho (em palavras, não em tokens)"
      ],
      "metadata": {
        "id": "ZvAci0iUiA7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.applymap(len).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "724bm6gyhQTX",
        "outputId": "e331938b-a7d5-4fe2-a7de-8ed2d624a58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "query        34.225455\n",
              "positive    353.499727\n",
              "negative    340.203909\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divisão em treino e validação (de forma estratificada)"
      ],
      "metadata": {
        "id": "tfTzMCRdXP5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.DataFrame()"
      ],
      "metadata": {
        "id": "K1ofJ30vU9BN"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data['query']=df['query']\n",
        "df_data['passage']=df['positive']\n",
        "df_data['classe']=1\n"
      ],
      "metadata": {
        "id": "8q465MNZUQg4"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['query','negative']].assign(classe=0).head(3)"
      ],
      "metadata": {
        "id": "HR4o0MqYtdO4",
        "outputId": "2ced2411-eae2-4cdb-ec8e-99ca77ec493d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      query                                           negative  classe\n",
              "0  is a little caffeine ok during pregnancy  It is generally safe for pregnant women to eat...       0\n",
              "1         what fruit is native to australia  The kola nut is the fruit of the kola tree, a ...       0\n",
              "2        how large is the canadian military  The Canadian Physician Health Institute (CPHI)...       0\n",
              "\n",
              "[3 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62d2580a-e34d-49d1-81dc-6391d879d034\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>negative</th>\n",
              "      <th>classe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is a little caffeine ok during pregnancy</td>\n",
              "      <td>It is generally safe for pregnant women to eat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what fruit is native to australia</td>\n",
              "      <td>The kola nut is the fruit of the kola tree, a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how large is the canadian military</td>\n",
              "      <td>The Canadian Physician Health Institute (CPHI)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62d2580a-e34d-49d1-81dc-6391d879d034')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62d2580a-e34d-49d1-81dc-6391d879d034 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62d2580a-e34d-49d1-81dc-6391d879d034');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = df_data.append(df[['query','negative']].rename(columns={'negative': 'passage'}).assign(classe=0), ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B15ilkySUQdf",
        "outputId": "c4ea5f8d-adf0-4d76-f4d9-f0bde3540b84"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-153-05336a35200b>:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_data = df_data.append(df[['query','negative']].rename(columns={'negative': 'passage'}).assign(classe=0), ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZN_dlJtUQK-",
        "outputId": "0cc64bad-b68f-4ef8-ea12-34bfcae68e96"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.head(3), df_data.tail(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY-HlsLJWrnJ",
        "outputId": "2a215a04-15fd-418c-bb60-d18fbe8f97ad"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                      query                                            passage  classe\n",
              " 0  is a little caffeine ok during pregnancy  We don't know a lot about the effects of caffe...       1\n",
              " 1         what fruit is native to australia  Passiflora herbertiana. A rare passion fruit n...       1\n",
              " 2        how large is the canadian military  The Canadian Armed Forces. 1  The first large-...       1\n",
              " \n",
              " [3 rows x 3 columns],\n",
              "                                                  query                                            passage  classe\n",
              " 21997              deloitte consulting or phone number  Virtual phone numbers are convenient for both ...       0\n",
              " 21998  how many hours a day to work to get lunch in ,a  1 Levaquin can be taken at any time of the day...       0\n",
              " 21999   what theatre company did shakespeare invest in  The Globe Theatre was constructed in 1599, out...       0\n",
              " \n",
              " [3 rows x 3 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "nbpIb5ADXUOF"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hparam['percent_test_size'] = .15 #@param [.10, .15, .20] {type:'raw'}"
      ],
      "metadata": {
        "id": "-Hhsa8DCaytA"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data[['query','passage']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lU8yYt-EySgo",
        "outputId": "eeef20c5-8491-4447-e35e-15371c011a38"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 query                                            passage\n",
              "0             is a little caffeine ok during pregnancy  We don't know a lot about the effects of caffe...\n",
              "1                    what fruit is native to australia  Passiflora herbertiana. A rare passion fruit n...\n",
              "2                   how large is the canadian military  The Canadian Armed Forces. 1  The first large-...\n",
              "3                                 types of fruit trees  Cherry. Cherry trees are found throughout the ...\n",
              "4       how many calories a day are lost breastfeeding  Not only is breastfeeding better for the baby,...\n",
              "...                                                ...                                                ...\n",
              "21995                       where is maramal in skyrim  One type of character isn't necessarily better...\n",
              "21996        which is a basic unit of a sugar molecule  According to Merriam-Webster and the Online Et...\n",
              "21997              deloitte consulting or phone number  Virtual phone numbers are convenient for both ...\n",
              "21998  how many hours a day to work to get lunch in ,a  1 Levaquin can be taken at any time of the day...\n",
              "21999   what theatre company did shakespeare invest in  The Globe Theatre was constructed in 1599, out...\n",
              "\n",
              "[22000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91509e8b-ac45-461a-a651-cbcfbfa413ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>passage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is a little caffeine ok during pregnancy</td>\n",
              "      <td>We don't know a lot about the effects of caffe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what fruit is native to australia</td>\n",
              "      <td>Passiflora herbertiana. A rare passion fruit n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how large is the canadian military</td>\n",
              "      <td>The Canadian Armed Forces. 1  The first large-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>types of fruit trees</td>\n",
              "      <td>Cherry. Cherry trees are found throughout the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how many calories a day are lost breastfeeding</td>\n",
              "      <td>Not only is breastfeeding better for the baby,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21995</th>\n",
              "      <td>where is maramal in skyrim</td>\n",
              "      <td>One type of character isn't necessarily better...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21996</th>\n",
              "      <td>which is a basic unit of a sugar molecule</td>\n",
              "      <td>According to Merriam-Webster and the Online Et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21997</th>\n",
              "      <td>deloitte consulting or phone number</td>\n",
              "      <td>Virtual phone numbers are convenient for both ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21998</th>\n",
              "      <td>how many hours a day to work to get lunch in ,a</td>\n",
              "      <td>1 Levaquin can be taken at any time of the day...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21999</th>\n",
              "      <td>what theatre company did shakespeare invest in</td>\n",
              "      <td>The Globe Theatre was constructed in 1599, out...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91509e8b-ac45-461a-a651-cbcfbfa413ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91509e8b-ac45-461a-a651-cbcfbfa413ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91509e8b-ac45-461a-a651-cbcfbfa413ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data[['query','passage']].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqzjVi8nyTyf",
        "outputId": "fa99b786-5aef-400c-81d9-e76e9ef8b392"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['is a little caffeine ok during pregnancy',\n",
              "        \"We don't know a lot about the effects of caffeine during pregnancy on you and your baby. So it's best to limit the amount you get each day. If you're pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1Â½ 8-ounce cups of coffee or one 12-ounce cup of coffee.\"],\n",
              "       ['what fruit is native to australia',\n",
              "        'Passiflora herbertiana. A rare passion fruit native to Australia. Fruits are green-skinned, white fleshed, with an unknown edible rating. Some sources list the fruit as edible, sweet and tasty, while others list the fruits as being bitter and inedible.assiflora herbertiana. A rare passion fruit native to Australia. Fruits are green-skinned, white fleshed, with an unknown edible rating. Some sources list the fruit as edible, sweet and tasty, while others list the fruits as being bitter and inedible.'],\n",
              "       ['how large is the canadian military',\n",
              "        \"The Canadian Armed Forces. 1  The first large-scale Canadian peacekeeping mission started in Egypt on November 24, 1956. 2  There are approximately 65,000 Regular Force and 25,000 reservist members in the Canadian military. 3  In Canada, August 9 is designated as National Peacekeepers' Day.\"],\n",
              "       ...,\n",
              "       ['deloitte consulting or phone number',\n",
              "        'Virtual phone numbers are convenient for both you and your callers. Your virtual phone from Malaysia number will be a local number, so no matter where you or your office is located, you can be accessible at local call rates. When someone dials your virtual phone number, your ring-to number will ring.'],\n",
              "       ['how many hours a day to work to get lunch in ,a',\n",
              "        '1 Levaquin can be taken at any time of the day; however, be sure to take it at the same time each day (to make sure there is approximately 24 hours between doses).  For the medication to work properly, it must be taken as prescribed. Levaquin will not work if you stop taking it too soon.'],\n",
              "       ['what theatre company did shakespeare invest in',\n",
              "        \"The Globe Theatre was constructed in 1599, out of timber taken from the Theatre. It stood next to the Rose, on the south side of the Thames, and was the most elaborate and attractive theatre yet built.he Globe was the primary home of Shakespeare's acting company beginning in late 1599, and it is a possibility that As You Like It was written especially for the occasion. On June 29, 1613, during a performance of Henry VIII, a misfired canon ball set the Globe's thatched roof on fire and the whole theatre was consumed.\"]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(df_data[['query','passage']].values, df_data['classe'].values, test_size=hparam['percent_test_size'], stratify=df_data['classe'].values, random_state=num_semente)"
      ],
      "metadata": {
        "id": "ZGO8xU6BXasq"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, type(X_valid), type(Y_valid), X_valid.shape, Y_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdqAE4tiXao0",
        "outputId": "5be1dc06-86cc-4b43-b819-9dfc5cf6a071"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((18700, 2), numpy.ndarray, numpy.ndarray, (3300, 2), (3300,))"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(Y_train, return_counts=True), '\\n', np.unique(Y_valid, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT1MHfqrXakV",
        "outputId": "9f27d42d-67fe-4073-e611-7593b28eaf6b"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([9350, 9350])) \n",
            " (array([0, 1]), array([1650, 1650]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y98qMz4W8mnA",
        "outputId": "b52a8294-614d-47b7-b45d-516bbe54ab8e"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['who is nucky thompson based on',\n",
              "        'Nolan Lyons (1884) Marc Pickering (1897) Enoch Malachi Nucky Thompson, played by Steve Buscemi, is the protagonist of the series Boardwalk Empire. He is very loosely based on the real New Jersey politician Enoch L. Johnson (1883-1968), who was in control of Atlantic City for two decades, between 1911 and 1931.'],\n",
              "       ['can i bury paper money',\n",
              "        \"They keep your tax return once filed and do NOT return the return to you. Are you asking about your refund? YOU had the problem which resulted in denial of efiling. Paper returns always take longer to process. I just got my federal refund for a paper return filed 4/15 and the state refund hasn't come yet. It takes as long as it takes, and there is nothing you can do about it, venting and ranting won't change anything. The state is out of money, so I don't expect anything anytime soon.\"]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqljfEA59zxz",
        "outputId": "b994f656-d6af-487c-e78c-e7dfc7bfeb96"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing input lengths"
      ],
      "metadata": {
        "id": "lnhoAgvR1wCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "const_nome_modelo = 'microsoft/MiniLM-L12-H384-uncased'"
      ],
      "metadata": {
        "id": "5-_sS1FAcIO5"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained(const_nome_modelo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842,
          "referenced_widgets": [
            "2b9539203b44436bbfdc6b64cd254be3",
            "a0f96070551f4f9eafe2afa055023e06",
            "6af80f182c334f5ba9cc07a5b8f1da1a",
            "1e452ebffd2240c48f89a5b48ddf2154",
            "88b79520f2114e9b813d843ace054c24",
            "0b2b1a4816444b9f8576a4c63c184292",
            "fd1184354115408bb0850ff7a022657f",
            "586c2947176149e0a4b04ffa971befe2",
            "204a1bf468354494845fb9e04fd1933e",
            "8a1b460cb199470eacceeabc0ee04cbb",
            "8acfc553a754407d9a7e418f8f805f6e",
            "969066989bd643318c444eb51e1a5d78",
            "f829f6641a034adc8c09b88a1bc0705d",
            "2f4bd7038fdf458c9db6ab0f2834ad4f",
            "ddbbf7586e0b4328a23ccb728b2f868e",
            "68df54786e504ed8906901269b3890f5",
            "3a9d4c5c1f4d48c392b6692922199216",
            "018ce1dcee234e6183969f020c58f4f4",
            "a9b3513a4f8b42ff9e99b30e4b488a37",
            "34648af0565444e884056ca536bfdd1f",
            "0bb5245a4efa46e6a7aaa0330eeda91b",
            "e1530d9149a1435a8ab1710c84050ae1",
            "05d427375fdc425291c9f09fbb29a75a",
            "725cb48f3c9042449f3238cc87f99e21",
            "6dca8778da794783beb9e7f31a5510eb",
            "86154bea52e94c1388ed05e8c0640967",
            "9fb160f0b98345a6843d834492a75faa",
            "e92c277b5f8543d199cf640fea4b149e",
            "f327f39ea9af4122b006fef490e8e455",
            "6ad7cb6910774079a51cb33e90306b01",
            "aabf472289c94721837f076c44dfb867",
            "c55e7a053fbd40e190c8c59d0459b531",
            "366165e1cc8746078932dad0f93f79bc",
            "77c6ba61488a4b5fba5c86e65565013a",
            "ad74ef3fd4fd42e39f28bdcc47a4c956",
            "9feda182b4254ad2b4c73615f0c97e09",
            "960fadbc0426459392248d3502b5fa14",
            "f300b74e613d4c9c8585460b8176861e",
            "a817cfd96a2f4c0e90e745c0a4db2176",
            "a71bafedd02c4269a6661d92db864a19",
            "7dc0e2d8cae840ae85656961c6a441a0",
            "03e2e531751145a6bf35d1de325513f7",
            "064147130b2d433394bb3ebc5f3ab290",
            "f4f3125f6a8a4ff78d69d838c23daf5e"
          ]
        },
        "id": "rsngiRh3NjDE",
        "outputId": "6405bae1-1398-4f32-fb9a-6cf59dbed0fd"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpka2vv3lz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b9539203b44436bbfdc6b64cd254be3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/ceb753d3f27a8c0d09184f35884666cda91b8ae610cd2a54d89793ac7663f1f9.13815020fd994b27db9974c0ce0ec4c47dfac6c8f11bf1a35a0a06d5b165665a\n",
            "creating metadata file for /root/.cache/huggingface/transformers/ceb753d3f27a8c0d09184f35884666cda91b8ae610cd2a54d89793ac7663f1f9.13815020fd994b27db9974c0ce0ec4c47dfac6c8f11bf1a35a0a06d5b165665a\n",
            "loading configuration file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ceb753d3f27a8c0d09184f35884666cda91b8ae610cd2a54d89793ac7663f1f9.13815020fd994b27db9974c0ce0ec4c47dfac6c8f11bf1a35a0a06d5b165665a\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1536,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.6.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp246hs02b\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "969066989bd643318c444eb51e1a5d78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/49c302ee103bf6737d0877cfbd658563cf4bbc4b7914363ca419ce8a3d8a4c51.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "creating metadata file for /root/.cache/huggingface/transformers/49c302ee103bf6737d0877cfbd658563cf4bbc4b7914363ca419ce8a3d8a4c51.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpjzkvjfzt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05d427375fdc425291c9f09fbb29a75a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/1e5909e4dfaa904617797ed35a6105a23daa56cbefca48fef329f772584699fb.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "creating metadata file for /root/.cache/huggingface/transformers/1e5909e4dfaa904617797ed35a6105a23daa56cbefca48fef329f772584699fb.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpgqotddd4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77c6ba61488a4b5fba5c86e65565013a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/29039dfe8c131360348e9f5ebecd464478cec7576c9af532b55ddcf9d4ec8d1e.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "creating metadata file for /root/.cache/huggingface/transformers/29039dfe8c131360348e9f5ebecd464478cec7576c9af532b55ddcf9d4ec8d1e.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "loading file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/49c302ee103bf6737d0877cfbd658563cf4bbc4b7914363ca419ce8a3d8a4c51.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/1e5909e4dfaa904617797ed35a6105a23daa56cbefca48fef329f772584699fb.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/29039dfe8c131360348e9f5ebecd464478cec7576c9af532b55ddcf9d4ec8d1e.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hparam['vocab_size']=tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "3XRMsdktDe58"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_memoria(['cpu','gpu'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqHpWcGzd9Nc",
        "outputId": "dad7368b-983c-46f0-ebb4-57899ddc987e"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 27.33\n",
            " available 24.66\n",
            " used 2.27\n",
            " free 9.91\n",
            " cached 14.67\n",
            " buffers 0.48\n",
            "/nGPU\n",
            "Sun Mar 12 12:59:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id,tokenizer.cls_token_id,tokenizer.sep_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L0L55t6kehj",
        "outputId": "40eec8b5-5a2a-4859-8426-65f646b0de3f"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 101, 102)"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x='x, it is just a test!'\n",
        "y='y, it is just a continuation!'"
      ],
      "metadata": {
        "id": "6jbz_kpbkFw2"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(x,y)['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfNd5cqkkCKH",
        "outputId": "65d25bf0-de81-40bd-9215-67901d6b21cd"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 1060,\n",
              " 1010,\n",
              " 2009,\n",
              " 2003,\n",
              " 2074,\n",
              " 1037,\n",
              " 3231,\n",
              " 999,\n",
              " 102,\n",
              " 1061,\n",
              " 1010,\n",
              " 2009,\n",
              " 2003,\n",
              " 2074,\n",
              " 1037,\n",
              " 13633,\n",
              " 999,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode_plus(x,y)['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTqMh2S36uhN",
        "outputId": "cc5a5771-23e8-4dfb-bb63-1c060efe0fed"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 1060,\n",
              " 1010,\n",
              " 2009,\n",
              " 2003,\n",
              " 2074,\n",
              " 1037,\n",
              " 3231,\n",
              " 999,\n",
              " 102,\n",
              " 1061,\n",
              " 1010,\n",
              " 2009,\n",
              " 2003,\n",
              " 2074,\n",
              " 1037,\n",
              " 13633,\n",
              " 999,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenizado = df.applymap(lambda x: tokenizer(x)['input_ids'])"
      ],
      "metadata": {
        "id": "UnxAH2xFjbMV"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenizado.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "FkBddAx2jbBO",
        "outputId": "0860254f-2078-420e-9009-42b92e4492ff"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               query                                           positive                                           negative\n",
              "0  [101, 2003, 1037, 2210, 24689, 7959, 3170, 792...  [101, 2057, 2123, 1005, 1056, 2113, 1037, 2843...  [101, 2009, 2003, 3227, 3647, 2005, 6875, 2308...\n",
              "1     [101, 2054, 5909, 2003, 3128, 2000, 2660, 102]  [101, 3413, 10128, 10626, 2050, 7253, 11410, 1...  [101, 1996, 12849, 2721, 17490, 2003, 1996, 59...\n",
              "2     [101, 2129, 2312, 2003, 1996, 3010, 2510, 102]  [101, 1996, 3010, 4273, 2749, 1012, 1015, 1996...  [101, 1996, 3010, 7522, 2740, 2820, 1006, 1813...\n",
              "3                 [101, 4127, 1997, 5909, 3628, 102]  [101, 9115, 1012, 9115, 3628, 2024, 2179, 2802...  [101, 1996, 12849, 2721, 17490, 2003, 1996, 59...\n",
              "4  [101, 2129, 2116, 10250, 18909, 1037, 2154, 20...  [101, 2025, 2069, 2003, 7388, 7959, 17819, 248...  [101, 2174, 1010, 2017, 2145, 2342, 2070, 9152...\n",
              "\n",
              "[5 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1e24ca8-a63a-4fe9-abd7-d704ea544fb1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[101, 2003, 1037, 2210, 24689, 7959, 3170, 792...</td>\n",
              "      <td>[101, 2057, 2123, 1005, 1056, 2113, 1037, 2843...</td>\n",
              "      <td>[101, 2009, 2003, 3227, 3647, 2005, 6875, 2308...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[101, 2054, 5909, 2003, 3128, 2000, 2660, 102]</td>\n",
              "      <td>[101, 3413, 10128, 10626, 2050, 7253, 11410, 1...</td>\n",
              "      <td>[101, 1996, 12849, 2721, 17490, 2003, 1996, 59...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[101, 2129, 2312, 2003, 1996, 3010, 2510, 102]</td>\n",
              "      <td>[101, 1996, 3010, 4273, 2749, 1012, 1015, 1996...</td>\n",
              "      <td>[101, 1996, 3010, 7522, 2740, 2820, 1006, 1813...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[101, 4127, 1997, 5909, 3628, 102]</td>\n",
              "      <td>[101, 9115, 1012, 9115, 3628, 2024, 2179, 2802...</td>\n",
              "      <td>[101, 1996, 12849, 2721, 17490, 2003, 1996, 59...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[101, 2129, 2116, 10250, 18909, 1037, 2154, 20...</td>\n",
              "      <td>[101, 2025, 2069, 2003, 7388, 7959, 17819, 248...</td>\n",
              "      <td>[101, 2174, 1010, 2017, 2145, 2342, 2070, 9152...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1e24ca8-a63a-4fe9-abd7-d704ea544fb1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1e24ca8-a63a-4fe9-abd7-d704ea544fb1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1e24ca8-a63a-4fe9-abd7-d704ea544fb1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('max:', '\\n', df_tokenizado.applymap(len).max(), '\\n','mean:', '\\n', df_tokenizado.applymap(len).mean(), '\\n', 'std:', '\\n', df_tokenizado.applymap(len).std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Gp-yOik3zH",
        "outputId": "53580a21-fde7-4861-afbe-33f6a615a324"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max: \n",
            " query        43\n",
            "positive    280\n",
            "negative    249\n",
            "Length: 3, dtype: int64 \n",
            " mean: \n",
            " query        9.10\n",
            "positive    80.88\n",
            "negative    77.52\n",
            "Length: 3, dtype: float64 \n",
            " std: \n",
            " query        2.85\n",
            "positive    32.58\n",
            "negative    31.12\n",
            "Length: 3, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logo: max_seq_length pode ser 322 (43 + 280 - 1 [sep comum aos 2])"
      ],
      "metadata": {
        "id": "FuvrxS5Ek76R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo o prefixo de nome do arquivo "
      ],
      "metadata": {
        "id": "M3T6XZiw6ah7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_aula = '/content/drive/MyDrive/treinamento/202301_IA368DD/aula2/'\n",
        "if not os.path.exists(path_aula):\n",
        "  os.makedirs(path_aula)\n",
        "  print(f'{path_aula} pasta criada!')\n",
        "else: \n",
        "  print(f'{path_aula} pasta já existia!')\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNBiIjGBdbJN",
        "outputId": "d1d049fe-509b-4777-82c7-57a3575dcd0a"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/treinamento/202301_IA368DD/aula2/ pasta já existia!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "infixo_nome= 'rerank_max_seq_'+ str(hparam['max_seq_length'])+'_text_'\n",
        "print(path_aula + infixo_nome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "813v7JPPcyHg",
        "outputId": "455250bd-c2b0-4a5a-bc37-8c2618a124b3"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/treinamento/202301_IA368DD/aula2/rerank_max_seq_322_text_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definindo parâmetros e informações para o rastro (hparam)"
      ],
      "metadata": {
        "id": "NMWN6z3PY2dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visto que \"max_position_embeddings\": 512 em https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/blob/main/config.json\n",
        "hparam['max_seq_length'] = 322  #@param {type:\"slider\", min:100, max:512, step:1} \n",
        "hparam['num_sentenca_train'] = X_train.shape[0]\n",
        "hparam['num_sentenca_valid'] = X_valid.shape[0]\n",
        "hparam['num_epochs'] = 3  #@param {type:\"slider\", min:1, max:100, step:1} \n",
        "hparam['model_name'] = const_nome_modelo"
      ],
      "metadata": {
        "id": "qNtjJwDQYz65"
      },
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.model_input_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbqC8PSdbDBX",
        "outputId": "78cc3ca2-4ed4-4301-cd8d-832ecd816198"
      },
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['input_ids', 'token_type_ids', 'attention_mask']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando código para o Dataset"
      ],
      "metadata": {
        "id": "_hs0ZWBmeOAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(hparam['device'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4iOQ64bRcMo",
        "outputId": "a3a89cb3-86ac-4fbb-aa25-db0493395237"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.device"
            ]
          },
          "metadata": {},
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List"
      ],
      "metadata": {
        "id": "TEdYwhXKgPbL"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset():\n",
        "    \"\"\"\n",
        "      Classe para representar um dataset de texto e classes.\n",
        "    \"\"\"  \n",
        "    def __init__(self, texts: np.ndarray, classes:list[int], tokenizer, max_seq_length: int, parm_device:torch.device):\n",
        "      \"\"\"\n",
        "      Inicializa um novo objeto MyDataset.\n",
        "\n",
        "      Args:\n",
        "          texts (np.ndarray): um array com as strings de texto. Cada linha deve ter 2 strings.\n",
        "          classes (np.ndarray): um array com as classes de cada texto.\n",
        "          tokenizer: um objeto tokenizer do Hugging Face Transformers.\n",
        "          max_seq_length (int): o tamanho máximo da sequência a ser considerado.\n",
        "          parm_device: indica se é para salvar os tensores na CPU ou na GPU\n",
        "      Raises:\n",
        "          AssertionError: se os parâmetros não estiverem no formato esperado.\n",
        "      \"\"\"\n",
        "      # Verifica se os parâmetros são do tipo esperado\n",
        "      assert isinstance(texts, np.ndarray), f\"Parâmetro texts deve ser do tipo np.ndarray e não {type(texts)}\"\n",
        "      assert texts.shape[1] == 2, \"Array must have 2 columns\"\n",
        "      for row in texts:\n",
        "          assert isinstance(row, np.ndarray) and row.shape == (2,), f\"Each row in texts must have 2 elements\"\n",
        "          assert isinstance(row[0], str) and isinstance(row[1], str), f\"Each element in texts.row must be a string e não {type(row[0])}\"\n",
        "      assert isinstance(classes,np.ndarray), f'classes deve ser do tipo np.ndarray e não {type(classes)}'\n",
        "      assert isinstance(classes[0],np.int64), f'classes[0] deve ser do tipo numpy.int64 e não {type(classe[0])} '\n",
        "      assert isinstance(max_seq_length, int), f'max_seq_length deve ser do tipo int e não {type(max_seq_length)}'\n",
        "      assert max_seq_length > 100, f'max_seq_length deve ser maior do que 100'\n",
        "      assert isinstance(parm_device, torch.device), f'parm_device deve ser do tipo torch.device e não {type(parm_device)}'\n",
        "\n",
        "      self.texts = texts\n",
        "      self.classes = classes\n",
        "      self.tokenizer = tokenizer\n",
        "      self.max_seq_length = max_seq_length\n",
        "      self.device = parm_device\n",
        "\n",
        "      # Salvar os dados dos tensores\n",
        "      x_data_input_ids = []\n",
        "      x_data_attention_masks = []\n",
        "      for text_pair in tqdm(texts, desc='encoding text pair'):\n",
        "          encoding = tokenizer.encode_plus(\n",
        "              text_pair[0],\n",
        "              text_pair[1],\n",
        "              add_special_tokens=True,\n",
        "              max_length=self.max_seq_length,\n",
        "              padding='max_length',\n",
        "              return_tensors = 'pt',\n",
        "              truncation=True,\n",
        "              return_attention_mask=True,\n",
        "              return_token_type_ids=True\n",
        "          )\n",
        "          x_data_input_ids.append(encoding['input_ids'].long())\n",
        "          x_data_attention_masks.append(encoding['attention_mask'].long())\n",
        "      print(F'\\tVou converter lista para tensor;  Momento: {time.strftime(\"[%Y-%b-%d %H:%M:%S]\")}')\n",
        "      self.x_tensor_input_ids = torch.stack(x_data_input_ids).to(self.device)\n",
        "      self.x_tensor_attention_masks = torch.stack(x_data_attention_masks).to(self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "          Retorna o tamanho do dataset (= tamanho do array texts)\n",
        "        \"\"\"\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "          Retorna um dicionário com os dados do texto e sua classe correspondente, em um formato que pode \n",
        "          ser usado pelo dataloader do PyTorch para alimentar um modelo de aprendizado de máquina.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'input_ids': self.x_tensor_input_ids[idx],\n",
        "            'attention_mask': self.x_tensor_attention_masks[idx],\n",
        "            'label': int(self.classes[idx])\n",
        "        }"
      ],
      "metadata": {
        "id": "XeakUpqJeQpz"
      },
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testando o MyDataset e o Dataloader"
      ],
      "metadata": {
        "id": "17AcNhe2C4tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "1I2n6puOGgPX"
      },
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria dados fictícios\n",
        "texts = np.array([['This is the first text', 'This is the second text'],\n",
        "                  ['This is text 2.1', 'This is text 2.2'],\n",
        "                  ['This is text 3.1', 'This is text 3.2'],\n",
        "                  ['This is text 4.1', 'This is text 4.2'],\n",
        "                  ['This is text 5.1', 'This is text 5.2'],\n",
        "                  ['This is text 6.1', 'This is text 6.2'],\n",
        "                  ['This is text 7.1', 'This is text 7.2']])\n",
        "classes = np.array([1, 0, 1, 0, 1, 0, 1])\n"
      ],
      "metadata": {
        "id": "_tNkc8kmC8ie"
      },
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um objeto da classe MyDataset\n",
        "dummy_dataset = MyDataset(texts=texts, classes=classes, tokenizer=tokenizer, max_seq_length=hparam['max_seq_length'], parm_device=hparam['device'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbaCMoKRDy20",
        "outputId": "59b96efe-d1d4-4e77-ea62-471e4005b189"
      },
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "encoding text pair: 100%|██████████| 7/7 [00:00<00:00, 1504.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVou converter lista para tensor;  Momento: [2023-Mar-12 15:12:22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testa o método __len__()\n",
        "assert len(dummy_dataset) == 7\n",
        "\n",
        "# Testa o método __getitem__()\n",
        "sample = dummy_dataset[0]\n",
        "assert set(sample.keys()) == {'input_ids', 'attention_mask', 'label'}\n",
        "assert isinstance(sample['input_ids'], torch.Tensor)\n",
        "assert sample['input_ids'].shape == (1, hparam['max_seq_length'])\n",
        "assert isinstance(sample['attention_mask'], torch.Tensor)\n",
        "assert sample['attention_mask'].shape == (1, hparam['max_seq_length'])\n",
        "assert isinstance(sample['label'], int)"
      ],
      "metadata": {
        "id": "xFNuWyMYDz7v"
      },
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9ng05CvFu1t",
        "outputId": "4de82992-5558-4cfa-ae92-f7d7f8a1cfe7"
      },
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 2023, 2003, 1996, 2034, 3793,  102, 2023, 2003, 1996, 2117, 3793,\n",
            "          102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'label': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_loader = DataLoader(dummy_dataset, batch_size=2, shuffle=False, num_workers=hparam['num_workers_dataloader'] )"
      ],
      "metadata": {
        "id": "5INVpV1RGuau"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_memoria(['cpu','gpu'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTaEmFP4WC2b",
        "outputId": "a1d833f1-f253-49ef-ac80-f297fb52cdd6"
      },
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 27.33\n",
            " available 22.3\n",
            " used 4.62\n",
            " free 6.71\n",
            " cached 15.5\n",
            " buffers 0.51\n",
            "/nGPU\n",
            "Sun Mar 12 15:12:33 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    27W /  70W |    789MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch = next(iter(dummy_loader))"
      ],
      "metadata": {
        "id": "TeyvxkA3G93w"
      },
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRdGtm3_G9lv",
        "outputId": "277bc5ab-23df-4672-e3ad-3e61441ae9fb"
      },
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[[ 101, 2023, 2003, 1996, 2034, 3793,  102, 2023, 2003, 1996, 2117,\n",
              "           3793,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0]],\n",
              " \n",
              "         [[ 101, 2023, 2003, 3793, 1016, 1012, 1015,  102, 2023, 2003, 3793,\n",
              "           1016, 1012, 1016,  102,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "              0,    0,    0]]], device='cuda:0'),\n",
              " 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              " \n",
              "         [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
              "        device='cuda:0'),\n",
              " 'label': tensor([1, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirmando efeito do parâmetro shuffle em DataLoader"
      ],
      "metadata": {
        "id": "Jm53nP5pKW44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_loader = DataLoader(dummy_dataset, batch_size=2, shuffle=False, num_workers=hparam['num_workers_dataloader'])\n",
        "for ndx, epoch in tqdm(enumerate(range(hparam['num_epochs'])), desc='Epochs'):\n",
        "  for batch in dummy_loader:\n",
        "    print(batch['label'])\n",
        "  print(f\"Fim época {ndx}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCy-mUJDIiGj",
        "outputId": "01015e9b-06a5-41f4-c2ba-ba7505e91144"
      },
      "execution_count": 392,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 3it [00:00, 215.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0])\n",
            "tensor([1, 0])\n",
            "tensor([1, 0])\n",
            "tensor([1])\n",
            "Fim época 0\n",
            "tensor([1, 0])\n",
            "tensor([1, 0])\n",
            "tensor([1, 0])\n",
            "tensor([1])\n",
            "Fim época 1\n",
            "tensor([1, 0])\n",
            "tensor([1, 0])\n",
            "tensor([1, 0])\n",
            "tensor([1])\n",
            "Fim época 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_loader = DataLoader(dummy_dataset, batch_size=2, shuffle=True, num_workers=hparam['num_workers_dataloader'])\n",
        "for ndx, epoch in tqdm(enumerate(range(hparam['num_epochs'])), desc='Epochs'):\n",
        "  for batch in dummy_loader:\n",
        "    print(batch['label'])\n",
        "  print(f\"Fim época {ndx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sq54U35KGTI",
        "outputId": "c00e06ca-4044-4be0-dc2b-5b9ac84d4c5c"
      },
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 3it [00:00, 253.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0])\n",
            "tensor([0, 0])\n",
            "tensor([1, 1])\n",
            "tensor([1])\n",
            "Fim época 0\n",
            "tensor([1, 1])\n",
            "tensor([0, 1])\n",
            "tensor([0, 0])\n",
            "tensor([1])\n",
            "Fim época 1\n",
            "tensor([0, 1])\n",
            "tensor([1, 0])\n",
            "tensor([1, 0])\n",
            "tensor([1])\n",
            "Fim época 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Giyi5Rv_NIm"
      },
      "source": [
        "### Carregando o Dataset e os Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dataset_train = MyDataset(texts=X_train, classes=Y_train, tokenizer=tokenizer, max_seq_length=hparam['max_seq_length'], parm_device=hparam['device'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJOMxKHwW9-u",
        "outputId": "ef0b076f-d65f-43f7-efd1-5592b08920a8"
      },
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "encoding text pair: 100%|██████████| 18700/18700 [00:30<00:00, 615.36it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVou converter lista para tensor;  Momento: [2023-Mar-12 15:14:37]\n",
            "CPU times: user 14.9 s, sys: 131 ms, total: 15 s\n",
            "Wall time: 30.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dataset_valid = MyDataset(texts=X_valid, classes=Y_valid, tokenizer=tokenizer, max_seq_length=hparam['max_seq_length'], parm_device=hparam['device'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx7EP3ygZccm",
        "outputId": "fbd59dfa-4ed8-4b5d-8c83-e96004c99dbc"
      },
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "encoding text pair: 100%|██████████| 3300/3300 [00:02<00:00, 1307.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVou converter lista para tensor;  Momento: [2023-Mar-12 15:14:50]\n",
            "CPU times: user 2.57 s, sys: 428 µs, total: 2.57 s\n",
            "Wall time: 2.56 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "ZVmbQFB7W96V"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PAREI AQUI"
      ],
      "metadata": {
        "id": "WJM2pTJXCps6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning"
      ],
      "metadata": {
        "id": "tCiefXKDtV3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Conta o número de parâmetros treináveis em um modelo PyTorch.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): O modelo PyTorch a ser avaliado.\n",
        "\n",
        "    Returns:\n",
        "        int: O número de parâmetros treináveis do modelo.\n",
        "\n",
        "    \"\"\"\n",
        "    # Retorna a soma do número de elementos em cada tensor de parâmetro que requer gradiente.\n",
        "    # A propriedade \"requires_grad\" é definida como True para todos os tensores de parâmetro que \n",
        "    # precisam ser treinados, enquanto que para aqueles que não precisam, ela é definida como False.\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "ch7FNPEXdyD5"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We first define the evaluation function to measure accuracy and loss\n",
        "def evaluate(model, dataloader, set_name):\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, mininterval=0.5, desc=set_name, disable=False):\n",
        "            outputs = model(**batch.to(device))\n",
        "            loss_val = outputs.loss\n",
        "            losses.append(loss_val.cpu().item())\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            correct += (preds == batch['labels']).sum().item()\n",
        "\n",
        "    print(f'{set_name} loss: {mean(losses):0.3f}; {set_name} accuracy: {correct / len(dataloader.dataset):0.3f}')"
      ],
      "metadata": {
        "id": "E2V21tzWAUQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch import optim\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "H1P8TKmCWblx"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(hparam['model_name'], num_labels=2).to(hparam['device'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDSbEIgTeFnS",
        "outputId": "714e295d-b44a-473f-bfcd-765496eea2bd"
      },
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ceb753d3f27a8c0d09184f35884666cda91b8ae610cd2a54d89793ac7663f1f9.13815020fd994b27db9974c0ce0ec4c47dfac6c8f11bf1a35a0a06d5b165665a\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1536,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.6.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/b774244369e464de2c660477b70bae7c3223fa7250aa1c8fc0b0f037ed58418a.087808d17814e241e9352c5ce0fea1a7d05e5b0f020d44b42b5f05922e96c923\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois tentar definir: hparam['dim_feedforward']=256"
      ],
      "metadata": {
        "id": "iW5oCtCQe8GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'learning_rate': [ 1e-4]\n"
      ],
      "metadata": {
        "id": "zcFPmU98fT2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim.AdamW(model.parameters(), lr=5e-5)\n",
        "hparam['num_params'] = count_parameters(model)\n",
        "print(f\"Number of model parameters: {hparam['num_params']}\")num_training_steps = hparam['num_epochs'] * len(dataloader_train)\n",
        "# hparam['learning_rate'] =  3e-5 # 1e-3\n",
        "# hparam['weight_decay'] = 1e-4\n",
        "params = add_param_weight_decay(model, hparam['weight_decay'])\n",
        "hparam['amsgrad']=False\n",
        "hparam['optimizer'] = torch.optim.Adam(params, lr=hparam['learning_rate'], weight_decay= hparam['weight_decay'], amsgrad=hparam['amsgrad'])\n",
        "hparam['scheduler'] = get_linear_schedule_with_warmup(hparam['optimizer'], num_warmup_steps, num_training_steps)\n",
        "\n"
      ],
      "metadata": {
        "id": "bnbzyzJbcmUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating on the test set"
      ],
      "metadata": {
        "id": "SBFVkGXG6Pbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model=model, dataloader=dataloader_test, set_name='Test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5df526cb2bdf481480806fad6348b27f",
            "8064c16540404293b3e4968fd0229144",
            "c784dea266464d228470c8f146e682bb",
            "8bb8f80668da4e708d04fe9ef7a6b183",
            "de1be7b088d84f879d48678f142aadb6",
            "2550930351954fdb817bcc04796bd47d",
            "2aeae0a72a0f4b6f9aa625691f9f2728",
            "20361f3bf1f24cba9bacb573433ae203",
            "6e268abe9b4d42cfae158a0debe4746f",
            "4ff9ad6df59c4f0dbf923324dd0e37ce",
            "ae61115e87fc4dd786a4b713d1824a3c"
          ]
        },
        "id": "Sd3VKiG0tkzC",
        "outputId": "2e1f2555-4db2-414c-c496-cd1995f65ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Test:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5df526cb2bdf481480806fad6348b27f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.331; Test accuracy: 0.872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reranking a partir da saída do BM25"
      ],
      "metadata": {
        "id": "5JKNuPSsn2xO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zV7oabDnn6UP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}