{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcN_5-RDWeqV"
      },
      "source": [
        "# Aula3 - Resolvendo Tarefas com LLM (Large Language Model) de Maneira Zero e Few-shot\n",
        "\n",
        "[Unicamp - IA368DD: Deep Learning aplicado a sistemas de busca.](https://www.cpg.feec.unicamp.br/cpg/lista/caderno_horario_show.php?id=1779)\n",
        "\n",
        "Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "[Repositório no github](https://github.com/marcusborela/deep_learning_em_buscas_unicamp)\n",
        "\n",
        "[Link para chat de apoio com WebChatGPT (sistema está com falha temporária para acesso aos chats](https://github.com/marcusborela/deep_learning_em_buscas_unicamp/blob/main/chat/aula3_resolvendo_tarefas_com_llm_de_maneira_zero_e_few_shot.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti1aFWTVgejM"
      },
      "source": [
        "[![Open In Colab latest github version](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcusborela/deep_learning_em_buscas_unicamp/blob/main/code/aula_2_classificacao_de_texto_e_reranqueador.ipynb) [Open In Colab latest github version]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQxzYKGgMqce"
      },
      "source": [
        "# Enunciado exercício\n",
        "O aluno irá escolher uma tarefa para resolver de maneira zero ou few-shot. Sugestões:\n",
        "- Classificação de textos (ex: análise de sentimos (IMDB))\n",
        "- Predizer se uma passagem/parágrafo é relevante para uma pergunta/query\n",
        "- Se uma resposta predita por um sistema de QA ou sumarizador é semanticamente igual à resposta ground-truth\n",
        "\n",
        "\n",
        "É importante ter uma função de avaliação da qualidade das respostas do modelo few-shot. Por exemplo, acurácia.\n",
        "\n",
        "\n",
        "É possível criar um pequeno dataset de teste manualmente (ex: com 10 à 100 exemplos)\n",
        "\n",
        "\n",
        "- Usar a API do LLAMA fornecida por nós (licença exclusiva para pesquisa). [Colab demo da API do LLAMA](https://colab.research.google.com/drive/1zZ-ch29LTicNPA62t2MaOwMROywnqUxf?usp=sharing) (obrigado, Thales Rogério)\n",
        "- Opcionalmente, usar a API do code-davinci-002, que é de graça e trás resultados muito bons.\n",
        "CUIDADO: NÃO USAR O TEXT-DAVINCI-002/003, que é pago\n",
        "\n",
        "- Opcionalmente, usar a API do ChatGPT (gpt-3.5-turbo) que é barata: ~1 centavo de real por 1000 tokens (uma página)\n",
        "- Opcionalmente, usar o Alpaca: https://alpaca-ai.ngrok.io/\n",
        "\n",
        "\n",
        "Dicas:\n",
        "- Teste com zero-shot E few-shot.\n",
        "- No few-shot, faça testes com e sem instruções no cabeçalho (explicação da tarefa, ex: \"Traduza de Ingles para Portugues\"). Pode ser que sem a instrução o modelo até funcione melhor.\n",
        "- Siga sempre um padrão ao criar os exemplos few-shot. Aqui tem uma pagina com dicas para prompt engineering: https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dicas\n",
        "\n",
        "[Exemplos de prompt](https://platform.openai.com/examples) \n"
      ],
      "metadata": {
        "id": "r_EIoey0Rqi2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmRLgbyi_Dvg"
      },
      "source": [
        "# Organizando o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns_pq59lAHke",
        "outputId": "54633d88-64ba-45b4-9f7a-5d3181056d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DKAZ8CWCAM3-"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9XgIWvkkH-kn"
      },
      "outputs": [],
      "source": [
        "def mostra_memoria(lista_mem=['cpu']):\n",
        "  \"\"\"\n",
        "  Esta função exibe informações de memória da CPU e/ou GPU, conforme parâmetros fornecidos.\n",
        "\n",
        "  Parâmetros:\n",
        "  -----------\n",
        "  lista_mem : list, opcional\n",
        "      Lista com strings 'cpu' e/ou 'gpu'. \n",
        "      'cpu' - exibe informações de memória da CPU.\n",
        "      'gpu' - exibe informações de memória da GPU (se disponível).\n",
        "      O valor padrão é ['cpu'].\n",
        "\n",
        "  Saída:\n",
        "  -------\n",
        "  A função não retorna nada, apenas exibe as informações na tela.\n",
        "\n",
        "  Exemplo de uso:\n",
        "  ---------------\n",
        "  Para exibir informações de memória da CPU:\n",
        "      mostra_memoria(['cpu'])\n",
        "\n",
        "  Para exibir informações de memória da CPU e GPU:\n",
        "      mostra_memoria(['cpu', 'gpu'])\n",
        "  \n",
        "  Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "  \"\"\"  \n",
        "  if 'cpu' in lista_mem:\n",
        "    vm = virtual_memory()\n",
        "    ram={}\n",
        "    ram['total']=round(vm.total / 1e9,2)\n",
        "    ram['available']=round(virtual_memory().available / 1e9,2)\n",
        "    # ram['percent']=round(virtual_memory().percent / 1e9,2)\n",
        "    ram['used']=round(virtual_memory().used / 1e9,2)\n",
        "    ram['free']=round(virtual_memory().free / 1e9,2)\n",
        "    ram['active']=round(virtual_memory().active / 1e9,2)\n",
        "    ram['inactive']=round(virtual_memory().inactive / 1e9,2)\n",
        "    ram['buffers']=round(virtual_memory().buffers / 1e9,2)\n",
        "    ram['cached']=round(virtual_memory().cached/1e9 ,2)\n",
        "    print(f\"Your runtime RAM in gb: \\n total {ram['total']}\\n available {ram['available']}\\n used {ram['used']}\\n free {ram['free']}\\n cached {ram['cached']}\\n buffers {ram['buffers']}\")\n",
        "    print('/nGPU')\n",
        "    gpu_info = !nvidia-smi\n",
        "  if 'gpu' in lista_mem:\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dri9iiMAvCT",
        "outputId": "bc0d4be1-babb-4a9e-f0db-f3fe246c6008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 27.33\n",
            " available 26.04\n",
            " used 0.91\n",
            " free 22.0\n",
            " cached 4.06\n",
            " buffers 0.37\n",
            "/nGPU\n"
          ]
        }
      ],
      "source": [
        "mostra_memoria(['cpu'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9xRdgUGMPgh"
      },
      "source": [
        "### Vinculando pasta do google drive para salvar dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IsJiN6H8K6pe"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae-Iy2oz_9os",
        "outputId": "73e90d02-0c45-47a1-bb1d-a9b313c2048e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achvQ78sa3p3"
      },
      "source": [
        "## Fixando as seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AG9RjMb8Qlot"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bkETIyWGkbOf"
      },
      "outputs": [],
      "source": [
        "def inicializa_seed(num_semente:int=123):\n",
        "  \"\"\"\n",
        "  Inicializa as sementes para garantir a reprodutibilidade dos resultados do modelo.\n",
        "  Essa é uma prática recomendada, já que a geração de números aleatórios pode influenciar os resultados do modelo.\n",
        "  Além disso, a função também configura as sementes da GPU para garantir a reprodutibilidade quando se utiliza aceleração por GPU. \n",
        "  \n",
        "  Args:\n",
        "      num_semente (int): número da semente a ser utilizada para inicializar as sementes das bibliotecas.\n",
        "  \n",
        "  References:\n",
        "      http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "      https://github.com/CyberZHG/torch-multi-head-attention/blob/master/torch_multi_head_attention/multi_head_attention.py#L15\n",
        "  \"\"\"\n",
        "  # Define as sementes das bibliotecas random, numpy e pytorch\n",
        "  random.seed(num_semente)\n",
        "  np.random.seed(num_semente)\n",
        "  torch.manual_seed(num_semente)\n",
        "  \n",
        "  # Define as sementes da GPU\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "  #torch.cuda.manual_seed(num_semente)\n",
        "  #Cuda algorithms\n",
        "  #torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UJGxQIrdaVp4"
      },
      "outputs": [],
      "source": [
        "num_semente=123\n",
        "inicializa_seed(num_semente)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v2gtkEPhA0t"
      },
      "source": [
        "## Preparando para debug e display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BJ6S4P5Hw4iG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kebsl1uQDFUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133cd786-17f7-4f3e-d99c-2bd4e14ca9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rnR2kDS_2FgZ"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZEqQ7mKg5fs"
      },
      "source": [
        "Dicas em https://zohaib.me/debugging-in-google-collab-notebook/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LjrlXHq1hC8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23134ec-56a8-4b1d-f720-8711c414b2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.3/793.3 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 KB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 8.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq ipdb\n",
        "import ipdb\n",
        "# %pdb off # desativa debug em exceção\n",
        "# %pdb on  # ativa debug em exceção\n",
        "# ipdb.set_trace(context=8)  para execução nesse ponto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wQ5pmlOHxHhk"
      },
      "outputs": [],
      "source": [
        "def config_display():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de display do Pandas.\n",
        "  \"\"\"\n",
        "\n",
        "  # Configurando formato saída Pandas\n",
        "  # define o número máximo de colunas que serão exibidas\n",
        "  pd.options.display.max_columns = None\n",
        "\n",
        "  # define a largura máxima de uma linha\n",
        "  pd.options.display.width = 1000\n",
        "\n",
        "  # define o número máximo de linhas que serão exibidas\n",
        "  pd.options.display.max_rows = 100\n",
        "\n",
        "  # define o número máximo de caracteres por coluna\n",
        "  pd.options.display.max_colwidth = 50\n",
        "\n",
        "  # se deve exibir o número de linhas e colunas de um DataFrame.\n",
        "  pd.options.display.show_dimensions = True\n",
        "\n",
        "  # número de dígitos após a vírgula decimal a serem exibidos para floats.\n",
        "  pd.options.display.precision = 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b2tDy72ATNHs"
      },
      "outputs": [],
      "source": [
        "def config_debug():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de debug do PyTorch e dos pacotes\n",
        "  transformers e datasets.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define opções de impressão de tensores para o modo científico\n",
        "  torch.set_printoptions(sci_mode=True) \n",
        "  \"\"\"\n",
        "    Significa que valores muito grandes ou muito pequenos são mostrados em notação científica.\n",
        "    Por exemplo, em vez de imprimir o número 0.0000012345 como 0.0000012345, \n",
        "    ele seria impresso como 1.2345e-06. Isso é útil em situações em que os valores dos tensores \n",
        "    envolvidos nas operações são muito grandes ou pequenos, e a notação científica permite \n",
        "    uma melhor compreensão dos números envolvidos.  \n",
        "  \"\"\"\n",
        "\n",
        "  # Habilita detecção de anomalias no autograd do PyTorch\n",
        "  torch.autograd.set_detect_anomaly(True)\n",
        "  \"\"\"\n",
        "    Permite identificar operações que podem causar problemas de estabilidade numérica, \n",
        "    como gradientes explodindo ou desaparecendo. Quando essa opção é ativada, \n",
        "    o PyTorch verifica se há operações que geram valores NaN ou infinitos nos tensores \n",
        "    envolvidos no cálculo do gradiente. Se for detectado um valor anômalo, o PyTorch \n",
        "    interrompe a execução e gera uma exceção, permitindo que o erro seja corrigido \n",
        "    antes que se torne um problema maior.\n",
        "\n",
        "    É importante notar que a detecção de anomalias pode ter um impacto significativo \n",
        "    no desempenho, especialmente em modelos grandes e complexos. Por esse motivo,\n",
        "    ela deve ser usada com cautela e apenas para depuração.\n",
        "  \"\"\"\n",
        "\n",
        "  # Configura variável de ambiente para habilitar a execução síncrona (bloqueante) das chamadas da API do CUDA.\n",
        "  os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "  \"\"\"\n",
        "    o Python aguarda o término da execução de uma chamada da API do CUDA antes de executar a próxima chamada. \n",
        "    Isso é útil para depurar erros no código que envolve operações na GPU, pois permite que o erro seja capturado \n",
        "    no momento em que ocorre, e não depois de uma sequência de operações que pode tornar a origem do erro mais difícil de determinar.\n",
        "    No entanto, é importante lembrar que esse modo de execução é significativamente mais lento do que a execução assíncrona, \n",
        "    que é o comportamento padrão do CUDA. Por isso, é recomendado utilizar esse comando apenas em situações de depuração \n",
        "    e removê-lo após a solução do problema.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define o nível de verbosity do pacote transformers para info\n",
        "  transformers.utils.logging.set_verbosity_info() \n",
        "  \n",
        "  \n",
        "  \"\"\"\n",
        "    Define o nível de detalhamento das mensagens de log geradas pela biblioteca Hugging Face Transformers \n",
        "    para o nível info. Isso significa que a biblioteca irá imprimir mensagens de log informativas sobre\n",
        "    o andamento da execução, tais como tempo de execução, tamanho de batches, etc.\n",
        "\n",
        "    Essas informações podem ser úteis para entender o que está acontecendo durante a execução da tarefa \n",
        "    e auxiliar no processo de debug. É importante notar que, em alguns casos, a quantidade de informações\n",
        "    geradas pode ser muito grande, o que pode afetar o desempenho do sistema e dificultar a visualização\n",
        "    das informações relevantes. Por isso, é importante ajustar o nível de detalhamento de acordo com a \n",
        "    necessidade de cada tarefa.\n",
        "  \n",
        "    Caso queira reduzir a quantidade de mensagens, comentar a linha acima e \n",
        "      descomentar as duas linhas abaixo, para definir o nível de verbosity como error ou warning\n",
        "  \n",
        "    transformers.utils.logging.set_verbosity_error()\n",
        "    transformers.utils.logging.set_verbosity_warning()\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Define o modo verbose do xmode, que é utilizado no debug\n",
        "  %xmode Verbose \n",
        "\n",
        "  \"\"\"\n",
        "    Comando usado no Jupyter Notebook para controlar o modo de exibição das informações de exceções.\n",
        "    O modo verbose é um modo detalhado que exibe informações adicionais ao imprimir as exceções.\n",
        "    Ele inclui as informações de pilha de chamadas completa e valores de variáveis locais e globais \n",
        "    no momento da exceção. Isso pode ser útil para depurar e encontrar a causa de exceções em seu código.\n",
        "    Ao usar %xmode Verbose, as informações de exceção serão impressas com mais detalhes e informações adicionais serão incluídas.\n",
        "\n",
        "    Caso queira desabilitar o modo verbose e utilizar o modo plain, \n",
        "    comentar a linha acima e descomentar a linha abaixo:\n",
        "    %xmode Plain\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "    Dica:\n",
        "    1.  pdb (Python Debugger)\n",
        "      Quando ocorre uma exceção em uma parte do código, o programa para a execução e exibe uma mensagem de erro \n",
        "      com informações sobre a exceção, como a linha do código em que ocorreu o erro e o tipo da exceção.\n",
        "\n",
        "      Se você estiver depurando o código e quiser examinar o estado das variáveis ​​e executar outras operações \n",
        "      no momento em que a exceção ocorreu, pode usar o pdb (Python Debugger). Para isso, é preciso colocar o comando %debug \n",
        "      logo após ocorrer a exceção. Isso fará com que o programa pare na linha em que ocorreu a exceção e abra o pdb,\n",
        "      permitindo que você explore o estado das variáveis, examine a pilha de chamadas e execute outras operações para depurar o código.\n",
        "\n",
        "\n",
        "    2. ipdb\n",
        "      O ipdb é um depurador interativo para o Python que oferece recursos mais avançados do que o pdb,\n",
        "      incluindo a capacidade de navegar pelo código fonte enquanto depura.\n",
        "      \n",
        "      Você pode começar a depurar seu código inserindo o comando ipdb.set_trace() em qualquer lugar do \n",
        "      seu código onde deseja pausar a execução e começar a depurar. Quando a execução chegar nessa linha, \n",
        "      o depurador entrará em ação, permitindo que você examine o estado atual do seu programa e execute \n",
        "      comandos para investigar o comportamento.\n",
        "\n",
        "      Durante a depuração, você pode usar comandos:\n",
        "        next (para executar a próxima linha de código), \n",
        "        step (para entrar em uma função chamada na próxima linha de código) \n",
        "        continue (para continuar a execução normalmente até o próximo ponto de interrupção).\n",
        "\n",
        "      Ao contrário do pdb, o ipdb é um depurador interativo que permite navegar pelo código fonte em que\n",
        "      está trabalhando enquanto depura, permitindo que você inspecione variáveis, defina pontos de interrupção\n",
        "      adicionais e até mesmo execute expressões Python no contexto do seu programa.\n",
        "  \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Tb4aqtcExR84"
      },
      "outputs": [],
      "source": [
        "config_display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5Bq4043fkfh",
        "outputId": "9efb3c2e-a99e-4222-a6d5-a69876858047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception reporting mode: Verbose\n"
          ]
        }
      ],
      "source": [
        "config_debug()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importações"
      ],
      "metadata": {
        "id": "MjCY6qqxCXrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests  # para Llama\n",
        "import time # para Llama"
      ],
      "metadata": {
        "id": "gHPHUE5PCZdu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentando chamadas aos LLM"
      ],
      "metadata": {
        "id": "4WJ9VOUMHFz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat GPT (Modelo gpt-3.5-turbo)"
      ],
      "metadata": {
        "id": "RSL3JJSRHPgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para uso do gpt-3.5-turbo, usamos como referência o caderno da [openai: How_to_format_inputs_to_ChatGPT_models.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb)"
      ],
      "metadata": {
        "id": "J2gFIL0xIPk0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPPjYkUTCG3X"
      },
      "source": [
        "### How to format inputs to ChatGPT models\n",
        "\n",
        "ChatGPT is powered by `gpt-3.5-turbo`, OpenAI's most advanced model.\n",
        "\n",
        "You can build your own applications with `gpt-3.5-turbo` using the OpenAI API.\n",
        "\n",
        "Chat models take a series of messages as input, and return an AI-written message as output.\n",
        "\n",
        "This guide illustrates the chat format with a few example API calls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9bepRrfCG3a"
      },
      "source": [
        "### Import the openai library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UA9ergb1CG3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea38adc-f151-46ee-9ce1-c5ea28a89142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
        "%pip install --upgrade openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2e7MPhAdCG3c"
      },
      "outputs": [],
      "source": [
        "# import the OpenAI Python library for calling the OpenAI API\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G0Sd0Y5FQn2",
        "outputId": "f5eb7e1e-797a-4f73-c6b7-1d126f0c98e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xxl5YAOjCG3j"
      },
      "outputs": [],
      "source": [
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42EWgSy0CG3d"
      },
      "source": [
        "### An example chat API call\n",
        "\n",
        "A chat API call has two required inputs:\n",
        "- `model`: the name of the model you want to use (e.g., `gpt-3.5-turbo`)\n",
        "- `messages`: a list of message objects, where each object has at least two fields:\n",
        "    - `role`: the role of the messenger (either `system`, `user`, or `assistant`)\n",
        "    - `content`: the content of the message (e.g., `Write me a beautiful poem`)\n",
        "\n",
        "Typically, a conversation will start with a system message, followed by alternating user and assistant messages, but you are not required to follow this format.\n",
        "\n",
        "Let's look at an example chat API calls to see how the chat format works in practice."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass"
      ],
      "metadata": {
        "id": "4fhQJQgkEAfY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = getpass.getpass(\"Entre a OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrefch9xDnso",
        "outputId": "61d8b74a-dc79-4aee-a627-34e5280f6636"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entre a OPENAI_API_KEY··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSgy_fuXCG3d"
      },
      "outputs": [],
      "source": [
        "MODEL = \"gpt-3.5-turbo\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Marcus.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")"
      ],
      "metadata": {
        "id": "u4sbukooCcYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhCsPcVqCa_g",
        "outputId": "50d18048-932d-4dbd-8664-6871b23a48f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-6w8sJPUH6CkXDCC8O0TEWzRkOuxvY at 0x7fac7482e180> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"content\": \"Marcus who?\",\n",
              "        \"role\": \"assistant\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1679315159,\n",
              "  \"id\": \"chatcmpl-6w8sJPUH6CkXDCC8O0TEWzRkOuxvY\",\n",
              "  \"model\": \"gpt-3.5-turbo-0301\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 4,\n",
              "    \"prompt_tokens\": 38,\n",
              "    \"total_tokens\": 42\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll0CNznzCG3e"
      },
      "source": [
        "As you can see, the response object has a few fields:\n",
        "- `id`: the ID of the request\n",
        "- `object`: the type of object returned (e.g., `chat.completion`)\n",
        "- `created`: the timestamp of the request\n",
        "- `model`: the full name of the model used to generate the response\n",
        "- `usage`: the number of tokens used to generate the replies, counting prompt, completion, and total\n",
        "- `choices`: a list of completion objects (only one, unless you set `n` greater than 1)\n",
        "    - `message`: the message object generated by the model, with `role` and `content`\n",
        "    - `finish_reason`: the reason the model stopped generating text (either `stop`, or `length` if `max_tokens` limit was reached)\n",
        "    - `index`: the index of the completion in the list of choices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPknWoscCG3f"
      },
      "source": [
        "Extract just the reply with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzJWlWJQCG3f",
        "outputId": "c5f47a3c-097a-494f-b34f-25fd2a14f060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Marcus who?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "response['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tZSva3FCG3g"
      },
      "source": [
        "Even non-conversation-based tasks can fit into the chat format, by placing the instruction in the first user message.\n",
        "\n",
        "For example, to ask the model to explain asynchronous programming in the style of the pirate Blackbeard, we can structure conversation as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "824RhtrqCG3h"
      },
      "source": [
        "### Tips for instructing gpt-3.5-turbo-0301\n",
        "\n",
        "Best practices for instructing models may change from model version to model version. The advice that follows applies to `gpt-3.5-turbo-0301` and may not apply to future models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-lPZSqfCG3h"
      },
      "source": [
        "#### System messages\n",
        "\n",
        "The system message can be used to prime the assistant with different personalities or behaviors.\n",
        "\n",
        "However, the model does not generally pay as much attention to the system message, and therefore we recommend placing important instructions in the user message instead."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of a system message that primes the assistant to explain concepts in great depth\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a friendly and helpful teaching assistant. You explain concepts in great depth using simple terms, and you give examples to help people learn. At the end of each explanation, you ask a question to check for understanding\"},\n",
        "        {\"role\": \"user\", \"content\": \"Can you explain how fractions work?\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "id": "MdoD0GmzCG3h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_VhnkQ0CG3i",
        "outputId": "5b242939-5a9b-4944-e6f7-8f93886474b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fractions represent a part of a whole. They consist of a numerator (top number) and a denominator (bottom number) separated by a line. The numerator represents how many parts of the whole are being considered, while the denominator represents the total number of equal parts that make up the whole.\n"
          ]
        }
      ],
      "source": [
        "# An example of a system message that primes the assistant to give brief, to-the-point answers\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a laconic assistant. You reply with brief, to-the-point answers with no elaboration.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Can you explain how fractions work?\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTUWsG7RCG3i"
      },
      "source": [
        "#### Few-shot prompting\n",
        "\n",
        "In some cases, it's easier to show the model what you want rather than tell the model what you want.\n",
        "\n",
        "One way to show the model what you want is with faked example messages.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of a faked few-shot conversation to prime the model into translating business jargon to simpler speech\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Help me translate the following corporate jargon into plain English.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Sure, I'd be happy to!\"},\n",
        "        {\"role\": \"user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
        "        {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "id": "qgWLtb92CG3i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfC1CF9bCG3i"
      },
      "source": [
        "To help clarify that the example messages are not part of a real conversation, and shouldn't be referred back to by the model, you can instead set the `name` field of `system` messages to `example_user` and `example_assistant`.\n",
        "\n",
        "Transforming the few-shot example above, we could write:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The business jargon translation example, but with example names for the example messages\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant that translates corporate jargon into plain English.\"},\n",
        "        {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
        "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
        "        {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
        "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
        "        {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "id": "hULcxYX8CG3j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KzutVliCG3j"
      },
      "source": [
        "Not every attempt at engineering conversations will succeed at first.\n",
        "\n",
        "If your first attempts fail, don't be afraid to experiment with different ways of priming or conditioning the model.\n",
        "\n",
        "As an example, one developer discovered an increase in accuracy when they inserted a user message that said \"Great job so far, these have been perfect\" to help condition the model into providing higher quality responses.\n",
        "\n",
        "For more ideas on how to lift the reliability of the models, consider reading our guide on [techniques to increase reliability](../techniques_to_improve_reliability.md). It was written for non-chat models, but many of its principles still apply."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbCTtNFWCG3j"
      },
      "source": [
        "## Counting tokens OpenAI Models\n",
        "\n",
        "Mais detalhes em [OpenAI: How_to_count_tokens_with_tiktoken.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)\n",
        "\n",
        "When you submit your request, the API transforms the messages into a sequence of tokens.\n",
        "\n",
        "The number of tokens used affects:\n",
        "- the cost of the request\n",
        "- the time it takes to generate the response\n",
        "- when the reply gets cut off from hitting the maximum token limit (4096 for `gpt-3.5-turbo`)\n",
        "\n",
        "As of Mar 01, 2023, you can use the following function to count the number of tokens that a list of messages will use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFVFizlyCG3k"
      },
      "outputs": [],
      "source": [
        "# example token count from the OpenAI API\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=messages,\n",
        "    temperature=0,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69ncUkSxFql1",
        "outputId": "8b5f80be-8100-440d-bd9b-aefef72703e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-6w8ut6RDJgaIG4Ga5rFkaNq5BtOyZ at 0x7fad189dc180> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"content\": \"This sudden change in plans means we don't have enough time to do everything for the client's project.\",\n",
              "        \"role\": \"assistant\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1679315319,\n",
              "  \"id\": \"chatcmpl-6w8ut6RDJgaIG4Ga5rFkaNq5BtOyZ\",\n",
              "  \"model\": \"gpt-3.5-turbo-0301\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 22,\n",
              "    \"prompt_tokens\": 126,\n",
              "    \"total_tokens\": 148\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{response[\"usage\"][\"prompt_tokens\"]} prompt tokens used.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goDW5l1jFpGl",
        "outputId": "011b152c-1015-475f-bac8-1db45dfa3415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126 prompt tokens used.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ3ZmEDkCG3k"
      },
      "outputs": [],
      "source": [
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding.encode(\"tiktoken is great!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjtWUNbFUusD",
        "outputId": "03937d03-824b-4704-c23b-aba117885a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[83, 1609, 5963, 374, 2294, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[encoding.decode_single_token_bytes(token) for token in [83, 1609, 5963, 374, 2294, 0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOBFhOkAVRZq",
        "outputId": "f942e49d-13cd-428f-95c9-ac3495380a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b't', b'ik', b'token', b' is', b' great', b'!']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens"
      ],
      "metadata": {
        "id": "rOXZ3gibUycK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens_from_string(\"tiktoken is great!\", \"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuCoumBTU1hy",
        "outputId": "28591c78-1bd4-4464-ced7-32c2b7ad6a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## code-davinci-002"
      ],
      "metadata": {
        "id": "8rE1ZbFvH-fL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para uso do code-davinci-00, usamos como referência o caderno da [openai: Unit_test_writing_using_a_multi-step_prompt.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Unit_test_writing_using_a_multi-step_prompt.ipynb)"
      ],
      "metadata": {
        "id": "VlmQYjBHIS57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dicas para iteração com esse modelo em https://platform.openai.com/docs/guides/code/best-practices"
      ],
      "metadata": {
        "id": "SYFNiURiMb3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"code-davinci-002\""
      ],
      "metadata": {
        "id": "UBi552vwIF6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_teste = 'Write a function in python that calculates fibonacci'"
      ],
      "metadata": {
        "id": "QdF_JFnAMmhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens:int = 1000\n",
        "temperature:float = 1.0"
      ],
      "metadata": {
        "id": "ufDazzgSM23n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "        model=MODEL,\n",
        "        prompt=prompt_teste,\n",
        "        stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\", \"```\"],\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        stream=False)"
      ],
      "metadata": {
        "id": "dRmTl06rLgFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6-judNTNWew",
        "outputId": "85f0002f-38df-452d-b058-af687bc7a496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-6vwsEdg2uKVnloyeSQezXvG21ODqQ at 0x7ff7ac25ac70> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \" series up to n\\nAnd sum it up (optional)\\nAll for this Fibonacci number challenge feature on https://dev.to\\nUpdate July 2019: fix a bug when n is 0\\n<code>def fibonacci(n):\\nf0 = 0;\\nf1 = 1;\\nseries = {}\\nsum_series = 0\\nj = 1;\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1679269026,\n",
              "  \"id\": \"cmpl-6vwsEdg2uKVnloyeSQezXvG21ODqQ\",\n",
              "  \"model\": \"code-davinci-002\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 78,\n",
              "    \"prompt_tokens\": 10,\n",
              "    \"total_tokens\": 88\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_teste = 'Meu nome é Marcus. Moro no Brasil. A capital do Brasil é: '"
      ],
      "metadata": {
        "id": "6OY-hayXNjfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "        model=MODEL,\n",
        "        prompt=prompt_teste,\n",
        "        stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\", \"```\"],\n",
        "        max_tokens=10,\n",
        "        temperature=temperature,\n",
        "        stream=False)"
      ],
      "metadata": {
        "id": "GbGiI_q9NiUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab647f3-125e-442c-d2c7-50e40712ee9d",
        "id": "1nQ4ctVzNiUY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-6vwrqVbXKVNNyOCsaqyiKk3Z0yxxA at 0x7ff733ecf040> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"length\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"${heroi.name}.\\nEle parte\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1679269002,\n",
              "  \"id\": \"cmpl-6vwrqVbXKVNNyOCsaqyiKk3Z0yxxA\",\n",
              "  \"model\": \"code-davinci-002\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 10,\n",
              "    \"prompt_tokens\": 20,\n",
              "    \"total_tokens\": 30\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLAMA "
      ],
      "metadata": {
        "id": "TKh6Zj9FH5Zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Colab demo da API do LLAMA](https://colab.research.google.com/drive/1zZ-ch29LTicNPA62t2MaOwMROywnqUxf?usp=sharing) (obrigado, Thales Rogério)"
      ],
      "metadata": {
        "id": "x2C983lKXdIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_url=\"http://143.106.167.108/api\""
      ],
      "metadata": {
        "id": "9xyqOr8MH9jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FhyvNKBkXoXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data={\n",
        "\t\"prompt\":\"\"\"Given table, specify which rows have repeated values for both \"Item number\" and \"Local\". If no row is repeated say \"no repeats\".\n",
        "\n",
        "Example 1:\n",
        "|Row | Item number | Local |\n",
        "|1 |  3 5 7 | New York |\n",
        "|2|  5 8 2 | Madagascar |\n",
        "|3|  3 4 5 | New York |\n",
        "|4|  3 4 5 | Paris |\n",
        "\n",
        "Explanation: Rows 1 and 3 have the same local \"New York\" and the same item number \"3 4 5\". Therefore they are repeated.\n",
        "\n",
        "Answer: (1,3).\n",
        "\n",
        "Example 2:\n",
        "|Row | Item number | Local |\n",
        "|1 |  0 9 2 4 | Amsterdam |\n",
        "|2|  9 4 2 4 | Barcelona |\n",
        "|3|  7 3 2 | London |\n",
        "|4|  7 3 1 | London |\n",
        "|5|  7 3 2 | London |\n",
        "|6|  7 3 2 | London |\n",
        "|7|  7 3 2 | London |\n",
        "|8|  7 3  2 |  New York |\n",
        "|9 |  0 9 2 4 | Amsterdam |\n",
        "\n",
        "Explanation:\"\"\",\n",
        "\n",
        "\"temperature\": 0.0,\n",
        "\"top_p\": 1,\n",
        "\"max_length\": 250\n",
        "}\n",
        "\n",
        "r=requests.post(f\"{base_url}/complete\", json=data)"
      ],
      "metadata": {
        "id": "XO3YNLXsIG2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if r.ok:\n",
        "  response=r.json()\n",
        "  print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71W7rBZXYOV4",
        "outputId": "919ddf7e-fc3c-4905-d198-c716eb1a8f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': 'Given table, specify which rows have repeated values for both \"Item number\" and \"Local\". If no row is repeated say \"no repeats\".\\n\\nExample 1:\\n|Row | Item number | Local |\\n|1 |  3 5 7 | New York |\\n|2|  5 8 2 | Madagascar |\\n|3|  3 4 5 | New York |\\n|4|  3 4 5 | Paris |\\n\\nExplanation: Rows 1 and 3 have the same local \"New York\" and the same item number \"3 4 5\". Therefore they are repeated.\\n\\nAnswer: (1,3).\\n\\nExample 2:\\n|Row | Item number | Local |\\n|1 |  0 9 2 4 | Amsterdam |\\n|2|  9 4 2 4 | Barcelona |\\n|3|  7 3 2 | London |\\n|4|  7 3 1 | London |\\n|5|  7 3 2 | London |\\n|6|  7 3 2 | London |\\n|7|  7 3 2 | London |\\n|8|  7 3  2 |  New York |\\n|9 |  0 9 2 4 | Amsterdam |\\n\\nExplanation:', 'temperature': 0.0, 'top_p': 1.0, 'max_length': 250, 'stopping_tokens': [], 'request_uuid': '403647f2-fd6d-40e6-a21c-098ea4870703'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiNo-zmnYLmo",
        "outputId": "46824015-ae4a-4724-db6e-5509d21cccb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': 'Given table, specify which rows have repeated values for both \"Item number\" and \"Local\". If no row is repeated say \"no repeats\".\\n\\nExample 1:\\n|Row | Item number | Local |\\n|1 |  3 5 7 | New York |\\n|2|  5 8 2 | Madagascar |\\n|3|  3 4 5 | New York |\\n|4|  3 4 5 | Paris |\\n\\nExplanation: Rows 1 and 3 have the same local \"New York\" and the same item number \"3 4 5\". Therefore they are repeated.\\n\\nAnswer: (1,3).\\n\\nExample 2:\\n|Row | Item number | Local |\\n|1 |  0 9 2 4 | Amsterdam |\\n|2|  9 4 2 4 | Barcelona |\\n|3|  7 3 2 | London |\\n|4|  7 3 1 | London |\\n|5|  7 3 2 | London |\\n|6|  7 3 2 | London |\\n|7|  7 3 2 | London |\\n|8|  7 3  2 |  New York |\\n|9 |  0 9 2 4 | Amsterdam |\\n\\nExplanation:',\n",
              " 'temperature': 0.0,\n",
              " 'top_p': 1.0,\n",
              " 'max_length': 250,\n",
              " 'stopping_tokens': [],\n",
              " 'request_uuid': '403647f2-fd6d-40e6-a21c-098ea4870703'}"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the request_uuid to check if the completion job is done"
      ],
      "metadata": {
        "id": "H-kEgjHqImqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "request_uuid=response[\"request_uuid\"]"
      ],
      "metadata": {
        "id": "Minx0TGWIu-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "lkLZZTcOIRIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ready = False\n",
        "while not ready:\n",
        "    r = requests.get(f\"{base_url}/get_result/{request_uuid}\")\n",
        "    response = r.json()\n",
        "    ready = response['ready']\n",
        "    if ready:\n",
        "        print(response['generated_text'])\n",
        "        break\n",
        "    # Wait 10 seconds before checking again\n",
        "    print(f\"Aguardando 10 segundos\")\n",
        "    time.sleep(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr0aQCoNYfmQ",
        "outputId": "b5f08b26-b973-40de-971a-600773e6ecc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Rows 3-7 all have the same local \"London\", but their item numbers differ. Therefore there are no repeats in this example.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "when consulting the result you may find 3 scenarios\n",
        "- Your job did not run yet, you should try again in a couple of seconds (Ready=False, message=None)\n",
        "- Your job did run and everything worked (Ready=True, message=your response)\n",
        "- Your job did run but it failed (Ready=True, message=None)"
      ],
      "metadata": {
        "id": "GkwfJwtnI3eC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rate limiting\n",
        "\n",
        "We may adjust this during the week, but due to computational constrains we will apply a rate limit of about 2 requests per 5 seconds. If you exceed this limit you will receive an error 429. You should adjust your code accordingly.\n",
        "\n",
        "Please remember that the whole class is using a shared resource, so avoid excessive requests even if they are under the rate limit.\n",
        "\n",
        "If you encounter any errors or problems, let us know in the classroom."
      ],
      "metadata": {
        "id": "ShA1aBfNJUI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "  r=requests.get(f\"{base_url}/get_result/{request_uuid}\")\n",
        "  print(i, \"->\", r.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z3s-PFPJSVm",
        "outputId": "ec8252e2-0d3d-4331-a9df-629f36677b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -> 200\n",
            "1 -> 200\n",
            "2 -> 200\n",
            "3 -> 429\n",
            "4 -> 429\n",
            "5 -> 429\n",
            "6 -> 429\n",
            "7 -> 429\n",
            "8 -> 429\n",
            "9 -> 429\n",
            "10 -> 429\n",
            "11 -> 429\n",
            "12 -> 200\n",
            "13 -> 429\n",
            "14 -> 429\n",
            "15 -> 429\n",
            "16 -> 429\n",
            "17 -> 429\n",
            "18 -> 429\n",
            "19 -> 429\n",
            "20 -> 429\n",
            "21 -> 429\n",
            "22 -> 429\n",
            "23 -> 200\n",
            "24 -> 429\n",
            "25 -> 429\n",
            "26 -> 429\n",
            "27 -> 429\n",
            "28 -> 429\n",
            "29 -> 429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "QGpuNTU3ZHMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definindo classes LLM_Model \n",
        "\n",
        "Para abstrair os detalhes de cada modelo\n",
        "\n",
        "LLM_Openai_Model_QA - classe mãe de modelos OpenAi"
      ],
      "metadata": {
        "id": "Mebj-4wbn9k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LLM_OpenAi_Model_QA:\n",
        "    def __init__(self, name:str, max_tokens:int, temperature:int=0, top_p:int=1):\n",
        "        \"\"\"\n",
        "        Inicializa um novo objeto LLM_Model_QA.\n",
        "        temperature = 0 (determinístico: sempre mesma saída para mesma entrada)\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.max_tokens = max_tokens\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        # self.stop=[\".\", \"\\n\",\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\", \"```\"]\n",
        "        # Up to 4 sequences where the API will stop generating further tokens\n",
        "        self.stop=[\".\", \"\\n\", \"!\", \"```\"]\n",
        "        self.max_tokens_resposta = 30       \n",
        "        self.encoding = tiktoken.encoding_for_model(self.name)\n",
        "        self.qtd_tokens_fixa = 0\n",
        "\n",
        "    def run_one_question(self, parm_prompt:str, parm_max_len_output:bool)->tuple:\n",
        "        pass\n",
        "\n",
        "    def answer_one_question(self, parm_prompt:str, parm_max_len_output:bool=None)->str:\n",
        "        answer, _ = self.run_one_question(parm_prompt, parm_max_len_output)\n",
        "        return answer\n",
        "\n",
        "    def assert_limite_respeitado(self, parm_text:str, tamanho_max_resposta):\n",
        "        tamanho_prompt = self.conta_token(parm_text)\n",
        "        total_uso = tamanho_prompt + tamanho_max_resposta + self.qtd_tokens_fixa\n",
        "        if (tamanho_prompt + tamanho_max_resposta + self.qtd_tokens_fixa) >  self.max_tokens:\n",
        "            raise Exception(f\"tamanho_prompt {tamanho_prompt} + tamanho_max_resposta {tamanho_max_resposta} + self.qtd_tokens_fixa {self.qtd_tokens_fixa} >  self.max_tokens :: {total_uso}  > {self.max_tokens}\")\n",
        "\n",
        "    def conta_token(self, parm_text:str):\n",
        "        \"\"\"\n",
        "        Retorna o número de tokens do texto conforme tokenizador do modelo\n",
        "        \"\"\"\n",
        "        qtd_token = len(self.encoding.encode(parm_text))\n",
        "        return qtd_token"
      ],
      "metadata": {
        "id": "x3YmWmUxJoHl"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatGPT_LLM_Model_QA(LLM_OpenAi_Model_QA):\n",
        "    # custo em 20/3/2023: $0.002 / 1K tokens\n",
        "    def __init__(self, parm_temperature:int=0, parm_top_p:int=1):\n",
        "        super().__init__(name=\"gpt-3.5-turbo\", max_tokens=4096, temperature=parm_temperature, top_p=parm_top_p)\n",
        "        # calculo do número de tokens usadas:\n",
        "        qtd_tokens_fixa = 0\n",
        "        qtd_tokens_fixa += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
        "        qtd_tokens_fixa += 2  # every reply is primed with <im_start>assistant\n",
        "        qtd_tokens_fixa += self.conta_token('system') \n",
        "        qtd_tokens_fixa += self.conta_token('user')         \n",
        "        qtd_tokens_fixa += self.conta_token('You are an assistant who will help me answer questions.') \n",
        "        self.qtd_tokens_fixa = qtd_tokens_fixa\n",
        "\n",
        "\n",
        "    def run_one_question(self, parm_prompt:str, parm_max_len_output:int=None)->tuple:\n",
        "        \"\"\"\n",
        "        Chama o modelo passando parm_prompt\n",
        "        \"\"\"\n",
        "        if parm_max_len_output is None:\n",
        "            tamanho_max_resposta = self.max_tokens_resposta\n",
        "        else:\n",
        "            tamanho_max_resposta = parm_max_len_output\n",
        "            \n",
        "        super().assert_limite_respeitado(parm_prompt, tamanho_max_resposta)\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=self.name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an assistant who will help me answer questions.\"},\n",
        "                {\"role\": \"user\", \"content\": parm_prompt},\n",
        "            ],\n",
        "            temperature=self.temperature,\n",
        "            top_p = self.top_p,\n",
        "            n =  1,\n",
        "            # stop = self.stop,\n",
        "            max_tokens = tamanho_max_resposta,\n",
        "            stream=False\n",
        "        )\n",
        "        resposta = response.choices[0].message.content  \n",
        "        return resposta, response\n",
        "    "
      ],
      "metadata": {
        "id": "qlBMf5oYJoCV"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Code_davinci_LLM_Model_QA(LLM_OpenAi_Model_QA):\n",
        "    # custo em 20/3/2023: gratuito\n",
        "    def __init__(self, parm_temperature:int=0, parm_top_p:int=1):\n",
        "        super().__init__(name=\"code-davinci-002\", max_tokens=8001, temperature=parm_temperature, top_p=parm_top_p)\n",
        "\n",
        "    def run_one_question(self, parm_prompt:str,parm_max_len_output:int=None)->tuple:\n",
        "        \"\"\"\n",
        "        Chama o modelo passando parm_prompt\n",
        "        \"\"\"\n",
        "        if parm_max_len_output is None:\n",
        "            tamanho_max_resposta = self.max_tokens_resposta\n",
        "        else:\n",
        "            tamanho_max_resposta = parm_max_len_output\n",
        "\n",
        "        super().assert_limite_respeitado(parm_prompt, tamanho_max_resposta)\n",
        "\n",
        "        response = openai.Completion.create(\n",
        "            model=self.name,\n",
        "            prompt= parm_prompt,\n",
        "            stop = self.stop,\n",
        "            temperature=self.temperature,\n",
        "            top_p = self.top_p,\n",
        "            # n =  1,\n",
        "            max_tokens = tamanho_max_resposta,\n",
        "            # stream=False\n",
        "            )\n",
        "        resposta = response.choices[0].text\n",
        "        return resposta, response\n",
        "    "
      ],
      "metadata": {
        "id": "fm8EsAwNKc8t"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Llama_LLM_Model_QA():\n",
        "    \"\"\"\n",
        "    Apoio código do Thales\n",
        "    Mais sobre o modelo: https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parm_temperature:int=0, parm_top_p:int=1):\n",
        "        \n",
        "        self.max_tokens_resposta = 30\n",
        "        self.name = 'llama'\n",
        "        # limite 2048 obtido em https://huggingface.co/decapoda-research/llama-65b-hf/blob/main/config.json\n",
        "        self.max_tokens = 2048\n",
        "        self.temperature = parm_temperature\n",
        "        self.top_p = parm_top_p\n",
        "        self.stop=[\".\", \"\\n\", \"!\", \"```\"]\n",
        "        self.max_tokens_resposta = 30\n",
        "        self.tempo_espera = 10\n",
        "\n",
        "    def answer_one_question(self, parm_prompt:str, parm_max_len_output:int=None):\n",
        "        \"\"\"\n",
        "        Chama o modelo passando parm_prompt\n",
        "        \"\"\"\n",
        "        if parm_max_len_output is None:\n",
        "            tamanho_max_resposta = self.max_tokens_resposta\n",
        "        else:\n",
        "            tamanho_max_resposta = parm_max_len_output\n",
        "\n",
        "        base_url=\"http://143.106.167.108/api\"\n",
        "        data={\n",
        "            \"prompt\":parm_prompt,\n",
        "            \"temperature\": self.temperature,\n",
        "            \"top_p\": self.top_p,\n",
        "            \"stop\": self.stop,\n",
        "            \"max_length\": tamanho_max_resposta\n",
        "          }\n",
        "          #register completion\n",
        "        while 1:\n",
        "            r=requests.post(f\"{base_url}/complete\", json=data)\n",
        "            if r.status_code==429:\n",
        "              print(f\"Esperando no 'complete' {self.tempo_espera} devido a erro 429\")\n",
        "              time.sleep(self.tempo_espera)\n",
        "              continue\n",
        "            break\n",
        "\n",
        "        if r.ok:\n",
        "            response=r.json()\n",
        "            request_uuid=response[\"request_uuid\"]\n",
        "            print(f\"Esperando antes do primeiro 'get_result' {self.tempo_espera} devido a erro 429\")\n",
        "            time.sleep(self.tempo_espera)\n",
        "            while 1:\n",
        "              r=requests.get(f\"{base_url}/get_result/{request_uuid}\")\n",
        "              if r.status_code==429:\n",
        "                print(f\"Esperando em outros 'get_result' {self.tempo_espera} devido a erro 429\")\n",
        "                time.sleep(self.tempo_espera)\n",
        "                continue\n",
        "\n",
        "              response=r.json()\n",
        "              if response[\"ready\"]==False:\n",
        "                print(f\"Llama Response not ready após 'get_result' {self.tempo_espera} sem erro 429\")\n",
        "                time.sleep(self.tempo_espera)\n",
        "                continue\n",
        "\n",
        "              if response[\"ready\"] and response[\"generated_text\"] == None:\n",
        "                raise ValueError(f\"something went wrong with llama call with data {data}\")\n",
        "              return response[\"generated_text\"]\n",
        "        else:\n",
        "            r.raise_for_status()\n",
        "\n",
        "\n",
        "        resposta = response[\"generated_text\"] \n",
        "        return resposta, response\n",
        "\n",
        "    def conta_token(self, parm_text:str):\n",
        "        \"\"\"\n",
        "        Retorna o número de tokens do texto conforme tokenizador do modelo\n",
        "        \"\"\"\n",
        "        raise Exception(f\"Não descobri qual tokenizador usado pelo Llama\")     "
      ],
      "metadata": {
        "id": "fRVC3f2DJn6l"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo de APIErro esporádico no OpenAI"
      ],
      "metadata": {
        "id": "TPtwChUMI6d5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID f9af83d5f361d8dddc598de67bb86735 in your email.) \n",
        "\n",
        "{\n",
        "  \"error\": {\n",
        "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID f9af83d5f361d8dddc598de67bb86735 in your email.)\",\n",
        "    \"type\": \"server_error\",\n",
        "    \"param\": null,\n",
        "    \"code\": null\n",
        "  }\n",
        "\n",
        "\n",
        "}\n",
        " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID f9af83d5f361d8dddc598de67bb86735 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sun, 19 Mar 2023 23:06:26 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'Access-Control-Allow-Origin': '*', 'Openai-Model': 'gpt-3.5-turbo-0301', 'Openai-Organization': 'user-0jnhur9aytg48d9jerr2jcsu', 'Openai-Processing-Ms': '669', 'Openai-Version': '2020-10-01', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains', 'X-Ratelimit-Limit-Requests': '3500', 'X-Ratelimit-Remaining-Requests': '3499', 'X-Ratelimit-Reset-Requests': '17ms', 'X-Request-Id': 'f9af83d5f361d8dddc598de67bb86735'}"
      ],
      "metadata": {
        "id": "ghD4YAquI62O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga dos dados"
      ],
      "metadata": {
        "id": "OyRNKuD7h6Fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte do código abaixo foi obtido do projeto \n",
        "\n",
        "exqa-complearning Extractive Q&A - Performance Comparison between Learning Methods: Context and Transfer\n",
        "\n",
        "Final Project at Discipline IA025, Introdução ao Aprendizado Profundo, Turma A\n",
        "\n",
        "Authors: Leonardo Augusto da Silva Pacheco e Marcus Vinícius Borela de Castro\n",
        "\n",
        "Teachers: Roberto de Alencar Lotufo e Rodrigo Frassetto Nogueira"
      ],
      "metadata": {
        "id": "j_2mMyONi1FC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2WGHMsGcB7Ep"
      },
      "outputs": [],
      "source": [
        "path_data = '/content/drive/MyDrive/treinamento/202301_IA368DD/collections/squad'\n",
        "path_squad = f'{path_data}/dev-v1.1.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDb6qDbsA38j",
        "outputId": "d999d6e8-8c76-4fde-8109-ea438d90b479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados já existiam!\n",
            "CPU times: user 7.58 ms, sys: 0 ns, total: 7.58 ms\n",
            "Wall time: 1.28 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if not os.path.exists(path_data):\n",
        "  os.makedirs(path_data)\n",
        "  print('pasta criada')\n",
        "if not os.path.exists(f'{path_data}/dev-v1.1.json'):\n",
        "  !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json -P {path_data}\n",
        "  print(\"Dados carregados!\")\n",
        "else:\n",
        "  print(\"Dados já existiam!\")    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "B5g4HhyAPx-4"
      },
      "outputs": [],
      "source": [
        "assert os.path.exists(path_squad), f\"Arquivo de dados {path_squad} não criada!\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "x8Jca7lNkd9f"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_squad) as dataset_file:\n",
        "    nested_json = json.load(dataset_file)\n"
      ],
      "metadata": {
        "id": "C2JYcWsymC7I"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nested_json.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFSwThHIm47d",
        "outputId": "982f8337-ebc7-4a1b-e5a7-95896fb07cea"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'version'])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _convert_json_in_dataset(parm_nested_json):\n",
        "\n",
        "    # Iterating through the json list\n",
        "    entry_list = list()\n",
        "\n",
        "    for row in nested_json['data']:\n",
        "        # print(row)\n",
        "        title = row['title']\n",
        "\n",
        "        for paragraph in row['paragraphs']:\n",
        "            context = paragraph['context']\n",
        "\n",
        "            for qa in paragraph['qas']:\n",
        "                entry = {}\n",
        "\n",
        "                qa_id = qa['id']\n",
        "                question = qa['question']\n",
        "                answers = qa['answers']\n",
        "\n",
        "                entry['id'] = qa_id\n",
        "                entry['title'] = title.strip()\n",
        "                entry['context'] = context.strip()\n",
        "                entry['question'] = question.strip()\n",
        "\n",
        "                answer_starts = [answer[\"answer_start\"] for answer in answers]\n",
        "                answer_texts = [answer[\"text\"].strip() for answer in answers]\n",
        "\n",
        "                entry['answer_start'] = answer_starts\n",
        "                entry['answer_text'] = answer_texts\n",
        "\n",
        "                entry_list.append(entry)\n",
        "    df = pd.DataFrame(entry_list)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "wfzhnU6amUZ_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = _convert_json_in_dataset(nested_json)"
      ],
      "metadata": {
        "id": "R4Ja4br4xGFB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgLA9LG9xJ_Y",
        "outputId": "421148c8-f9bf-48ab-8c7f-7e65e5f93e9c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10570, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_question_type(line):\n",
        "    line = line.lower()\n",
        "    list_words = line.split()\n",
        "    first_word = list_words[0]\n",
        "    first_2_word = list_words[0] + ' ' + list_words[1]\n",
        "    type_question = 'unknown'\n",
        "    if first_2_word in question_types_2_words:\n",
        "        type_question = first_2_word\n",
        "    elif first_word in question_types:\n",
        "            type_question = first_word\n",
        "    if type_question == 'unknown':\n",
        "        for type_question_punct in question_types_2_words_punctuation:\n",
        "            if type_question_punct in line:\n",
        "                type_question = question_types_2_words_punctuation[type_question_punct]\n",
        "                break\n",
        "    if type_question == 'unknown':\n",
        "        for type_question_punct in question_types_punctuation:\n",
        "            if type_question_punct in line:\n",
        "                type_question = question_types_punctuation[type_question_punct]\n",
        "                break\n",
        "    return type_question\n",
        "\n",
        "def add_punctuation_before_word_in_list(list_word):\n",
        "    new_dict = {}\n",
        "    for word in list_word:\n",
        "        new_dict[', ' + word] = word\n",
        "        new_dict[',' + word] = word\n",
        "        new_dict['.' + word] = word\n",
        "        new_dict['. ' + word] = word\n",
        "    return new_dict\n",
        "\n",
        "question_types = [\"are\", \"did\", \"does\", \"do\", \"is\", \"how\", \"since\",  \"was\", \"were\", \"what\", \"when\", \"where\", \"who\", \"which\", \"why\" ]\n",
        "question_types_2_words = [\"are there\", \"is there\" ]\n",
        "question_types_punctuation = add_punctuation_before_word_in_list(question_types)\n",
        "question_types_2_words_punctuation = add_punctuation_before_word_in_list(question_types_2_words)"
      ],
      "metadata": {
        "id": "JFq_T2empCQc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QPM_T8AonLxm",
        "outputId": "80f1f4b1-2b7c-469e-8395-04338f69ea34"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         id          title                                            context                                           question     answer_start                                        answer_text\n",
              "0  56be4db0acb8001400a502ec  Super_Bowl_50  Super Bowl 50 was an American football game to...  Which NFL team represented the AFC at Super Bo...  [177, 177, 177]   [Denver Broncos, Denver Broncos, Denver Broncos]\n",
              "1  56be4db0acb8001400a502ed  Super_Bowl_50  Super Bowl 50 was an American football game to...  Which NFL team represented the NFC at Super Bo...  [249, 249, 249]  [Carolina Panthers, Carolina Panthers, Carolin...\n",
              "2  56be4db0acb8001400a502ee  Super_Bowl_50  Super Bowl 50 was an American football game to...                Where did Super Bowl 50 take place?  [403, 355, 355]  [Santa Clara, California, Levi's Stadium, Levi...\n",
              "3  56be4db0acb8001400a502ef  Super_Bowl_50  Super Bowl 50 was an American football game to...                  Which NFL team won Super Bowl 50?  [177, 177, 177]   [Denver Broncos, Denver Broncos, Denver Broncos]\n",
              "\n",
              "[4 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7eabc946-3fc2-4c01-92e4-057f63649686\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be4db0acb8001400a502ec</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
              "      <td>[177, 177, 177]</td>\n",
              "      <td>[Denver Broncos, Denver Broncos, Denver Broncos]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be4db0acb8001400a502ed</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
              "      <td>[249, 249, 249]</td>\n",
              "      <td>[Carolina Panthers, Carolina Panthers, Carolin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be4db0acb8001400a502ee</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Where did Super Bowl 50 take place?</td>\n",
              "      <td>[403, 355, 355]</td>\n",
              "      <td>[Santa Clara, California, Levi's Stadium, Levi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56be4db0acb8001400a502ef</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which NFL team won Super Bowl 50?</td>\n",
              "      <td>[177, 177, 177]</td>\n",
              "      <td>[Denver Broncos, Denver Broncos, Denver Broncos]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7eabc946-3fc2-4c01-92e4-057f63649686')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7eabc946-3fc2-4c01-92e4-057f63649686 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7eabc946-3fc2-4c01-92e4-057f63649686');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aumentando as colunas do dataframe para seleção de registros"
      ],
      "metadata": {
        "id": "cpk8bnQ4xRgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['len_context'] = df['context'].apply(len)\n",
        "df['len_question'] = df['question'].apply(len)"
      ],
      "metadata": {
        "id": "F3x0hA8AnLnl"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['type_question'] = df['question'].apply(define_question_type)"
      ],
      "metadata": {
        "id": "O3laRs7np3aE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['qtd_dif_resposta'] = df['answer_text'].apply(lambda x: len(set(x)))"
      ],
      "metadata": {
        "id": "NPd0XMLbp1I0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['len_answer'] = df['answer_text'].apply(lambda x: len(x[0]))"
      ],
      "metadata": {
        "id": "qeFehD24xyAP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SVSrArsUp_pK",
        "outputId": "afe383f6-bf5b-4f2b-c22f-86abeea7cb88"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         id          title                                            context                                           question     answer_start                                        answer_text  len_context  len_question type_question  qtd_dif_resposta  len_answer\n",
              "0  56be4db0acb8001400a502ec  Super_Bowl_50  Super Bowl 50 was an American football game to...  Which NFL team represented the AFC at Super Bo...  [177, 177, 177]   [Denver Broncos, Denver Broncos, Denver Broncos]          775            52         which                 1          14\n",
              "1  56be4db0acb8001400a502ed  Super_Bowl_50  Super Bowl 50 was an American football game to...  Which NFL team represented the NFC at Super Bo...  [249, 249, 249]  [Carolina Panthers, Carolina Panthers, Carolin...          775            52         which                 1          17\n",
              "2  56be4db0acb8001400a502ee  Super_Bowl_50  Super Bowl 50 was an American football game to...                Where did Super Bowl 50 take place?  [403, 355, 355]  [Santa Clara, California, Levi's Stadium, Levi...          775            35         where                 3          23\n",
              "3  56be4db0acb8001400a502ef  Super_Bowl_50  Super Bowl 50 was an American football game to...                  Which NFL team won Super Bowl 50?  [177, 177, 177]   [Denver Broncos, Denver Broncos, Denver Broncos]          775            33         which                 1          14\n",
              "\n",
              "[4 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd7c8cb9-b16b-4cbb-b51a-a11625dd3a9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>len_context</th>\n",
              "      <th>len_question</th>\n",
              "      <th>type_question</th>\n",
              "      <th>qtd_dif_resposta</th>\n",
              "      <th>len_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be4db0acb8001400a502ec</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
              "      <td>[177, 177, 177]</td>\n",
              "      <td>[Denver Broncos, Denver Broncos, Denver Broncos]</td>\n",
              "      <td>775</td>\n",
              "      <td>52</td>\n",
              "      <td>which</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be4db0acb8001400a502ed</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
              "      <td>[249, 249, 249]</td>\n",
              "      <td>[Carolina Panthers, Carolina Panthers, Carolin...</td>\n",
              "      <td>775</td>\n",
              "      <td>52</td>\n",
              "      <td>which</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be4db0acb8001400a502ee</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Where did Super Bowl 50 take place?</td>\n",
              "      <td>[403, 355, 355]</td>\n",
              "      <td>[Santa Clara, California, Levi's Stadium, Levi...</td>\n",
              "      <td>775</td>\n",
              "      <td>35</td>\n",
              "      <td>where</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56be4db0acb8001400a502ef</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which NFL team won Super Bowl 50?</td>\n",
              "      <td>[177, 177, 177]</td>\n",
              "      <td>[Denver Broncos, Denver Broncos, Denver Broncos]</td>\n",
              "      <td>775</td>\n",
              "      <td>33</td>\n",
              "      <td>which</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd7c8cb9-b16b-4cbb-b51a-a11625dd3a9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd7c8cb9-b16b-4cbb-b51a-a11625dd3a9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd7c8cb9-b16b-4cbb-b51a-a11625dd3a9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by=['len_context', 'len_question', 'len_answer'], ascending=[True, True, False])"
      ],
      "metadata": {
        "id": "HB1fmwH6rAFS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LTli0Do-kaj5",
        "outputId": "6a92d656-9300-482a-98cd-d2705eb6615b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            id          title                                            context                                           question     answer_start                                        answer_text  len_context  len_question type_question  qtd_dif_resposta  len_answer\n",
              "1491  56e1011ecd28a01900c6740c   Nikola_Tesla  On 7 January 1900, Tesla left Colorado Springs...                          What happened to his lab?     [65, 77, 77]  [His lab was torn down, torn down, torn down i...          157            25          what                 3          21\n",
              "1492  56e1011ecd28a01900c6740d   Nikola_Tesla  On 7 January 1900, Tesla left Colorado Springs...                        When was his lab destroyed?     [90, 90, 90]                                 [1904, 1904, 1904]          157            27          when                 1           4\n",
              "1490  56e1011ecd28a01900c6740b   Nikola_Tesla  On 7 January 1900, Tesla left Colorado Springs...       When did Tesla depart from Colorado Springs?       [13, 0, 3]          [1900, On 7 January 1900, 7 January 1900]          157            44          when                 3           4\n",
              "1493  56e1011ecd28a01900c6740e   Nikola_Tesla  On 7 January 1900, Tesla left Colorado Springs...  What happened to the things inside the lab aft...  [118, 118, 118]                 [sold, sold, sold two years later]          157            66          what                 2           4\n",
              "2611  56f8ca289b226e1400dd1007  Martin_Luther  A piece of paper was later found on which Luth...       What was later discovered written by Luther?     [61, 61, 65]  [his last statement, his last statement, last ...          158            44          what                 2          18\n",
              "\n",
              "[5 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecf29946-cf01-4041-b9e8-7bb6e847ac7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>len_context</th>\n",
              "      <th>len_question</th>\n",
              "      <th>type_question</th>\n",
              "      <th>qtd_dif_resposta</th>\n",
              "      <th>len_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1491</th>\n",
              "      <td>56e1011ecd28a01900c6740c</td>\n",
              "      <td>Nikola_Tesla</td>\n",
              "      <td>On 7 January 1900, Tesla left Colorado Springs...</td>\n",
              "      <td>What happened to his lab?</td>\n",
              "      <td>[65, 77, 77]</td>\n",
              "      <td>[His lab was torn down, torn down, torn down i...</td>\n",
              "      <td>157</td>\n",
              "      <td>25</td>\n",
              "      <td>what</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1492</th>\n",
              "      <td>56e1011ecd28a01900c6740d</td>\n",
              "      <td>Nikola_Tesla</td>\n",
              "      <td>On 7 January 1900, Tesla left Colorado Springs...</td>\n",
              "      <td>When was his lab destroyed?</td>\n",
              "      <td>[90, 90, 90]</td>\n",
              "      <td>[1904, 1904, 1904]</td>\n",
              "      <td>157</td>\n",
              "      <td>27</td>\n",
              "      <td>when</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1490</th>\n",
              "      <td>56e1011ecd28a01900c6740b</td>\n",
              "      <td>Nikola_Tesla</td>\n",
              "      <td>On 7 January 1900, Tesla left Colorado Springs...</td>\n",
              "      <td>When did Tesla depart from Colorado Springs?</td>\n",
              "      <td>[13, 0, 3]</td>\n",
              "      <td>[1900, On 7 January 1900, 7 January 1900]</td>\n",
              "      <td>157</td>\n",
              "      <td>44</td>\n",
              "      <td>when</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>56e1011ecd28a01900c6740e</td>\n",
              "      <td>Nikola_Tesla</td>\n",
              "      <td>On 7 January 1900, Tesla left Colorado Springs...</td>\n",
              "      <td>What happened to the things inside the lab aft...</td>\n",
              "      <td>[118, 118, 118]</td>\n",
              "      <td>[sold, sold, sold two years later]</td>\n",
              "      <td>157</td>\n",
              "      <td>66</td>\n",
              "      <td>what</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2611</th>\n",
              "      <td>56f8ca289b226e1400dd1007</td>\n",
              "      <td>Martin_Luther</td>\n",
              "      <td>A piece of paper was later found on which Luth...</td>\n",
              "      <td>What was later discovered written by Luther?</td>\n",
              "      <td>[61, 61, 65]</td>\n",
              "      <td>[his last statement, his last statement, last ...</td>\n",
              "      <td>158</td>\n",
              "      <td>44</td>\n",
              "      <td>what</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecf29946-cf01-4041-b9e8-7bb6e847ac7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecf29946-cf01-4041-b9e8-7bb6e847ac7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecf29946-cf01-4041-b9e8-7bb6e847ac7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('type_question').size().reset_index(name='total')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "x9T5Uu5Wivy6",
        "outputId": "bfd7a87f-cdb7-4e2d-f70b-ca99d3fa3f23"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type_question  total\n",
              "0            are      4\n",
              "1      are there      2\n",
              "2            did      7\n",
              "3             do      3\n",
              "4           does      4\n",
              "5            how   1122\n",
              "6             is     12\n",
              "7          since     13\n",
              "8        unknown   1557\n",
              "9            was     12\n",
              "10          were      4\n",
              "11          what   4970\n",
              "12          when    700\n",
              "13         where    452\n",
              "14         which    475\n",
              "15           who   1081\n",
              "16           why    152\n",
              "\n",
              "[17 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-367ed77c-557a-4266-8182-c34da0b132c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type_question</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>are</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>are there</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>did</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>do</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>does</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>how</td>\n",
              "      <td>1122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>is</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>since</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>unknown</td>\n",
              "      <td>1557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>was</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>were</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>what</td>\n",
              "      <td>4970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>when</td>\n",
              "      <td>700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>where</td>\n",
              "      <td>452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>which</td>\n",
              "      <td>475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>who</td>\n",
              "      <td>1081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>why</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-367ed77c-557a-4266-8182-c34da0b132c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-367ed77c-557a-4266-8182-c34da0b132c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-367ed77c-557a-4266-8182-c34da0b132c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('qtd_dif_resposta').size().reset_index(name='total')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w9RbyVilrZ7x",
        "outputId": "01b2bdd2-330b-4cee-9321-914414f92690"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   qtd_dif_resposta  total\n",
              "0                 1   4945\n",
              "1                 2   4051\n",
              "2                 3   1368\n",
              "3                 4    166\n",
              "4                 5     40\n",
              "\n",
              "[5 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f10286f-a449-41c9-83d7-d98068af0ed0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qtd_dif_resposta</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f10286f-a449-41c9-83d7-d98068af0ed0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f10286f-a449-41c9-83d7-d98068af0ed0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f10286f-a449-41c9-83d7-d98068af0ed0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No trabalho citado, modelos com context-learn alcançaram bons resultados com perguntas do tipo who e what. Logo, filtrarei pore essas. "
      ],
      "metadata": {
        "id": "ZQZ4wLjkrgqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.query(\"qtd_dif_resposta == 1 and type_question in ['who', 'what']\").shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2-GrWNcjmdy",
        "outputId": "8c62b12c-b2a8-439c-982c-3bd9c5be5096"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2813, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seleção de queries"
      ],
      "metadata": {
        "id": "jOGRYPn-3bmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_selecao = df.query(\"qtd_dif_resposta == 1 and type_question in ['who', 'what'] and len_answer > 12\")"
      ],
      "metadata": {
        "id": "uRxmDJD_r9tY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_selecao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ktgp-K4UsCvY",
        "outputId": "adad876c-b03a-4dcc-a79c-62fd78a70ba5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            id               title                                            context                                           question              answer_start                                        answer_text  len_context  len_question type_question  qtd_dif_resposta  len_answer\n",
              "121   56beb03c3aeaaa14008c920d       Super_Bowl_50  The league eventually narrowed the bids to thr...  What site is located in the San Francisco Bay ...           [153, 153, 153]   [Levi's Stadium, Levi's Stadium, Levi's Stadium]          168            51          what                 1          14\n",
              "131   56d98db6dc89441400fdb552       Super_Bowl_50  The league eventually narrowed the bids to thr...  What Florida stadium was considered for Super ...           [102, 102, 102]  [Sun Life Stadium, Sun Life Stadium, Sun Life ...          168            54          what                 1          16\n",
              "128   56d6ee6e0d65d21400198256       Super_Bowl_50  The league eventually narrowed the bids to thr...  What is the name of the stadium in Miami that ...           [102, 102, 102]  [Sun Life Stadium, Sun Life Stadium, Sun Life ...          168            61          what                 1          16\n",
              "120   56beb03c3aeaaa14008c920b       Super_Bowl_50  The league eventually narrowed the bids to thr...  What venue in Miami was a candidate for the si...           [102, 102, 102]  [Sun Life Stadium, Sun Life Stadium, Sun Life ...          168            66          what                 1          16\n",
              "124   56bf3c633aeaaa14008c9582       Super_Bowl_50  The league eventually narrowed the bids to thr...  What was the given name of Miami's stadium at ...           [102, 102, 102]  [Sun Life Stadium, Sun Life Stadium, Sun Life ...          168            72          what                 1          16\n",
              "...                        ...                 ...                                                ...                                                ...                       ...                                                ...          ...           ...           ...               ...         ...\n",
              "2121  56e77a8700c9c71400d7718e             Teacher  In the past, teachers have been paid relativel...  What website are teachers using to sell their ...        [2142, 2142, 2142]  [TeachersPayTeachers.com, TeachersPayTeachers....         2166            59          what                 1          23\n",
              "4197  57269bb8708984140094cb97  European_Union_law  Although it is generally accepted that EU law ...          What type of company is Van Gend en Loos?           [487, 487, 487]  [a postal company, a postal company, a postal ...         2239            41          what                 1          16\n",
              "4259  5726b58f5951b619008f7b59  European_Union_law  While the concept of a \"social market economy\"...  What entity has taken the view that the goals ...        [2135, 2135, 2135]  [the Court of Justice, the Court of Justice, t...         2302           119          what                 1          20\n",
              "4182  57265e455951b619008f70bd  European_Union_law  Since its founding, the EU has operated among ...  What were the years two Regulations that confl...  [2214, 2214, 2214, 2214]  [1964 and 1968, 1964 and 1968, 1964 and 1968, ...         2820           109          what                 1          13\n",
              "4299  5726c3da708984140094d0db  European_Union_law  The \"freedom to provide services\" under TFEU a...  What did the Court of Justice reason were cont...        [2318, 2318, 2318]   [narcotic drugs, narcotic drugs, narcotic drugs]         4063           116          what                 1          14\n",
              "\n",
              "[1432 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-013b6369-9bad-4209-9862-a117704169ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>len_context</th>\n",
              "      <th>len_question</th>\n",
              "      <th>type_question</th>\n",
              "      <th>qtd_dif_resposta</th>\n",
              "      <th>len_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>56beb03c3aeaaa14008c920d</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>The league eventually narrowed the bids to thr...</td>\n",
              "      <td>What site is located in the San Francisco Bay ...</td>\n",
              "      <td>[153, 153, 153]</td>\n",
              "      <td>[Levi's Stadium, Levi's Stadium, Levi's Stadium]</td>\n",
              "      <td>168</td>\n",
              "      <td>51</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>56d98db6dc89441400fdb552</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>The league eventually narrowed the bids to thr...</td>\n",
              "      <td>What Florida stadium was considered for Super ...</td>\n",
              "      <td>[102, 102, 102]</td>\n",
              "      <td>[Sun Life Stadium, Sun Life Stadium, Sun Life ...</td>\n",
              "      <td>168</td>\n",
              "      <td>54</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>56d6ee6e0d65d21400198256</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>The league eventually narrowed the bids to thr...</td>\n",
              "      <td>What is the name of the stadium in Miami that ...</td>\n",
              "      <td>[102, 102, 102]</td>\n",
              "      <td>[Sun Life Stadium, Sun Life Stadium, Sun Life ...</td>\n",
              "      <td>168</td>\n",
              "      <td>61</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>56beb03c3aeaaa14008c920b</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>The league eventually narrowed the bids to thr...</td>\n",
              "      <td>What venue in Miami was a candidate for the si...</td>\n",
              "      <td>[102, 102, 102]</td>\n",
              "      <td>[Sun Life Stadium, Sun Life Stadium, Sun Life ...</td>\n",
              "      <td>168</td>\n",
              "      <td>66</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>56bf3c633aeaaa14008c9582</td>\n",
              "      <td>Super_Bowl_50</td>\n",
              "      <td>The league eventually narrowed the bids to thr...</td>\n",
              "      <td>What was the given name of Miami's stadium at ...</td>\n",
              "      <td>[102, 102, 102]</td>\n",
              "      <td>[Sun Life Stadium, Sun Life Stadium, Sun Life ...</td>\n",
              "      <td>168</td>\n",
              "      <td>72</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2121</th>\n",
              "      <td>56e77a8700c9c71400d7718e</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>In the past, teachers have been paid relativel...</td>\n",
              "      <td>What website are teachers using to sell their ...</td>\n",
              "      <td>[2142, 2142, 2142]</td>\n",
              "      <td>[TeachersPayTeachers.com, TeachersPayTeachers....</td>\n",
              "      <td>2166</td>\n",
              "      <td>59</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>57269bb8708984140094cb97</td>\n",
              "      <td>European_Union_law</td>\n",
              "      <td>Although it is generally accepted that EU law ...</td>\n",
              "      <td>What type of company is Van Gend en Loos?</td>\n",
              "      <td>[487, 487, 487]</td>\n",
              "      <td>[a postal company, a postal company, a postal ...</td>\n",
              "      <td>2239</td>\n",
              "      <td>41</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4259</th>\n",
              "      <td>5726b58f5951b619008f7b59</td>\n",
              "      <td>European_Union_law</td>\n",
              "      <td>While the concept of a \"social market economy\"...</td>\n",
              "      <td>What entity has taken the view that the goals ...</td>\n",
              "      <td>[2135, 2135, 2135]</td>\n",
              "      <td>[the Court of Justice, the Court of Justice, t...</td>\n",
              "      <td>2302</td>\n",
              "      <td>119</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4182</th>\n",
              "      <td>57265e455951b619008f70bd</td>\n",
              "      <td>European_Union_law</td>\n",
              "      <td>Since its founding, the EU has operated among ...</td>\n",
              "      <td>What were the years two Regulations that confl...</td>\n",
              "      <td>[2214, 2214, 2214, 2214]</td>\n",
              "      <td>[1964 and 1968, 1964 and 1968, 1964 and 1968, ...</td>\n",
              "      <td>2820</td>\n",
              "      <td>109</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4299</th>\n",
              "      <td>5726c3da708984140094d0db</td>\n",
              "      <td>European_Union_law</td>\n",
              "      <td>The \"freedom to provide services\" under TFEU a...</td>\n",
              "      <td>What did the Court of Justice reason were cont...</td>\n",
              "      <td>[2318, 2318, 2318]</td>\n",
              "      <td>[narcotic drugs, narcotic drugs, narcotic drugs]</td>\n",
              "      <td>4063</td>\n",
              "      <td>116</td>\n",
              "      <td>what</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1432 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-013b6369-9bad-4209-9862-a117704169ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-013b6369-9bad-4209-9862-a117704169ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-013b6369-9bad-4209-9862-a117704169ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_selecao.groupby('type_question').size().reset_index(name='total')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ilie0X7LycTn",
        "outputId": "b4e71927-74fa-4876-827d-db7aaefb339f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  type_question  total\n",
              "0          what   1103\n",
              "1           who    329\n",
              "\n",
              "[2 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5492a957-1012-46fb-951b-2b68c1dc9d72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type_question</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what</td>\n",
              "      <td>1103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>who</td>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5492a957-1012-46fb-951b-2b68c1dc9d72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5492a957-1012-46fb-951b-2b68c1dc9d72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5492a957-1012-46fb-951b-2b68c1dc9d72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_selecao = df_selecao.groupby('type_question').head(30)"
      ],
      "metadata": {
        "id": "FN2iUwYssDtw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_selecao.groupby('type_question').size().reset_index(name='total')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tZ-DzxBHsrWd",
        "outputId": "7d7e31ca-077f-49f5-84f9-859370e2f5a7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  type_question  total\n",
              "0          what     30\n",
              "1           who     30\n",
              "\n",
              "[2 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfcfc0f9-f8a7-443e-af5d-d607de55eebf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type_question</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>who</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfcfc0f9-f8a7-443e-af5d-d607de55eebf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfcfc0f9-f8a7-443e-af5d-d607de55eebf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfcfc0f9-f8a7-443e-af5d-d607de55eebf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_selecao.groupby('len_context').size().reset_index(name='total')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sDoD7IejsyYQ",
        "outputId": "a4a85cce-4470-4c58-f0a5-df999d97b7d3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    len_context  total\n",
              "0           168      6\n",
              "1           181      4\n",
              "2           187      3\n",
              "3           188      2\n",
              "4           198      1\n",
              "5           199      1\n",
              "6           206      3\n",
              "7           217      2\n",
              "8           220      1\n",
              "9           233      2\n",
              "10          238      1\n",
              "11          248      1\n",
              "12          255      2\n",
              "13          263      2\n",
              "14          264      4\n",
              "15          265      1\n",
              "16          275      1\n",
              "17          284      2\n",
              "18          286      1\n",
              "19          288      1\n",
              "20          289      1\n",
              "21          316      1\n",
              "22          326      1\n",
              "23          338      1\n",
              "24          341      2\n",
              "25          346      1\n",
              "26          351      1\n",
              "27          359      1\n",
              "28          394      1\n",
              "29          408      1\n",
              "30          410      1\n",
              "31          411      2\n",
              "32          432      1\n",
              "33          442      1\n",
              "34          446      1\n",
              "35          451      1\n",
              "36          454      1\n",
              "\n",
              "[37 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25a08462-2ba5-4143-afd2-6cc291e1a13a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>len_context</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>168</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>181</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>187</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>199</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>206</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>217</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>220</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>233</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>238</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>248</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>255</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>263</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>264</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>265</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>275</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>284</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>286</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>288</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>289</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>316</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>326</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>338</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>341</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>351</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>359</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>394</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>408</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>410</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>411</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>432</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>442</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>446</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>451</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>454</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25a08462-2ba5-4143-afd2-6cc291e1a13a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25a08462-2ba5-4143-afd2-6cc291e1a13a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25a08462-2ba5-4143-afd2-6cc291e1a13a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZSAIyRl3L-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engenharia de Prompt"
      ],
      "metadata": {
        "id": "YygV4s372xYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instrucao = 'Instruction: Based on the text below, answer the question succinctly, using some passage present in the text, avoiding repeating words from the question\\n\\n'\n",
        "exemplo1 = 'Example:\\n\\nText: Manoel was born in 1980. His friend Mauricio has worked at TCU since 1996.\\n\\nQuestion: Who was born in 1980?\\nAnswer: Manoel.\\n\\n'\n",
        "exemplo2 = 'Example:\\n\\nText: Manoel was born in 1980. His friend Mauricio has worked at TCU since 1996.\\n\\nQuestion: Who was born in 1980?\\nAnswer: Manoel.\\n\\nText: Joel has worked at TCU since 2005 and was born in 1980.\\n\\nQuestion: Where Joel work?\\nAnswer: TCU.\\n\\n'\n",
        "texto_questao_resposta = 'Text: {context}\\n\\nQuestion: {question}\\nAnswer:'\n"
      ],
      "metadata": {
        "id": "vevzNkrIuH8r"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_prompt_format ={\n",
        "0: {\"prompt\": instrucao + texto_questao_resposta},\n",
        "1: {\"prompt\": instrucao + exemplo1 + texto_questao_resposta},\n",
        "2: {\"prompt\": instrucao + exemplo2 + texto_questao_resposta},\n",
        "}"
      ],
      "metadata": {
        "id": "6zt_Pp7kqdIb"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_pergunta = [\n",
        "    {'id':0,\n",
        "     'text': 'In the morning there were 2 birds on my window. The weather was sunny. Unfortunately my cat Ton killed one of the birds.',\n",
        "     'question': 'What animal killed a bird?', \n",
        "     'answer': ['Ton.', 'The cat Ton.']}\n",
        "]"
      ],
      "metadata": {
        "id": "-loXDmmd2tU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_teste = instrucao + ' ' + lista_pergunta[0]['text']+ ' ' + lista_pergunta[0]['question']"
      ],
      "metadata": {
        "id": "HdByA3Mu5LMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "AKcKQzOe561K",
        "outputId": "f440f5df-1d3a-4f71-e32c-b11b799e8898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Instruction: Based on the text below, answer the question succinctly, using some passage present in the text, avoiding repeating words from the question\\n\\n In the morning there were 2 birds on my window. The weather was sunny. Unfortunately my cat Ton killed one of the birds. What animal killed a bird?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicação do Prompt"
      ],
      "metadata": {
        "id": "3vpwy9Ks21fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retorna_prompt(cod_prompt: int, texto_pergunta: str, texto_contexto: str) -> str:\n",
        "    \"\"\"\n",
        "    Retorna texto_questao_resposta substituindo os parâmetros em\n",
        "    'Text:{context}\\n\\nQuestion:{question}\\nAnswer:'\n",
        "    \"\"\"\n",
        "    global dict_prompt_format\n",
        "    assert isinstance(texto_pergunta, str), f\"Expected just one question, not {type(texto_pergunta)}\"\n",
        "    assert isinstance(texto_contexto, str), f\"Expected just one context, not {type(texto_contexto)}\"\n",
        "    assert isinstance(cod_prompt, int), f\"Expected just one context, not {type(cod_prompt)}\"\n",
        "    prompt = dict_prompt_format[cod_prompt]['prompt'].replace('{context}', texto_contexto).replace('{question}', texto_pergunta)\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "vROEU6tUs3o5"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimentando para subconjunto"
      ],
      "metadata": {
        "id": "zfnJDub59_ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ndx, row in df_selecao.iloc[2:4].iterrows():\n",
        "  prompt_aux = retorna_prompt(cod_prompt=0, texto_pergunta=row['question'], texto_contexto=row['context'])\n",
        "  print(prompt_aux)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t75pUGTPu3O3",
        "outputId": "9a59f7d1-93c9-4561-8bde-c93bf00b89c5"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction: Based on the text below, answer the question succinctly, using some passage present in the text, avoiding repeating words from the question\n",
            "\n",
            "Text:The league eventually narrowed the bids to three sites: New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium.\n",
            "\n",
            "Question:What is the name of the stadium in Miami that was considered?\n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_davinci_model = Code_davinci_LLM_Model_QA()\n",
        "llama_model = Llama_LLM_Model_QA()\n",
        "chatgpt_model = ChatGPT_LLM_Model_QA()"
      ],
      "metadata": {
        "id": "GplFMLcH-UL6"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_davinci_model.answer_one_question(prompt_aux)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kpNfB1VhG18p",
        "outputId": "74b74873-2f69-4088-f47e-3f1ea20fa972"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sun Life Stadium'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_davinci_model.run_one_question(prompt_aux)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qczySgLm-DjT",
        "outputId": "39d0a791-35e2-4ea4-e3c9-afc2fd05cd6d"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' Sun Life Stadium',\n",
              " <OpenAIObject text_completion id=cmpl-6wMHUBU2TCAZzxzHZxGTBPYt02nFO at 0x7fd4fe5394a0> JSON: {\n",
              "   \"choices\": [\n",
              "     {\n",
              "       \"finish_reason\": \"stop\",\n",
              "       \"index\": 0,\n",
              "       \"logprobs\": null,\n",
              "       \"text\": \" Sun Life Stadium\"\n",
              "     }\n",
              "   ],\n",
              "   \"created\": 1679366692,\n",
              "   \"id\": \"cmpl-6wMHUBU2TCAZzxzHZxGTBPYt02nFO\",\n",
              "   \"model\": \"code-davinci-002\",\n",
              "   \"object\": \"text_completion\",\n",
              "   \"usage\": {\n",
              "     \"completion_tokens\": 4,\n",
              "     \"prompt_tokens\": 89,\n",
              "     \"total_tokens\": 93\n",
              "   }\n",
              " })"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llama_model.run_one_question(prompt_aux)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "oihR_vzM_d8B",
        "outputId": "c1ff567c-4e07-467c-ad3f-80a62600d739"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sun life stadium\\n\\nComment: I don't understand what you are asking here.  Are you looking for a way to extract the\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt_model.answer_one_question(prompt_aux)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VeKNZeUoHGVx",
        "outputId": "2cb24f87-1fb7-4f2c-b1c4-9f42371bfc7e"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The stadium in Miami that was considered is called Sun Life Stadium.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt_model.run_one_question(prompt_aux)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9-rdccTDJrW",
        "outputId": "c66c9536-f140-4e7d-d165-69910b389b3e"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The stadium in Miami that was considered is called Sun Life Stadium.',\n",
              " <OpenAIObject chat.completion id=chatcmpl-6wMHZ1EQdodvNhuQu96ZKoaBa4K68 at 0x7fd4ff325db0> JSON: {\n",
              "   \"choices\": [\n",
              "     {\n",
              "       \"finish_reason\": \"stop\",\n",
              "       \"index\": 0,\n",
              "       \"message\": {\n",
              "         \"content\": \"The stadium in Miami that was considered is called Sun Life Stadium.\",\n",
              "         \"role\": \"assistant\"\n",
              "       }\n",
              "     }\n",
              "   ],\n",
              "   \"created\": 1679366697,\n",
              "   \"id\": \"chatcmpl-6wMHZ1EQdodvNhuQu96ZKoaBa4K68\",\n",
              "   \"model\": \"gpt-3.5-turbo-0301\",\n",
              "   \"object\": \"chat.completion\",\n",
              "   \"usage\": {\n",
              "     \"completion_tokens\": 14,\n",
              "     \"prompt_tokens\": 106,\n",
              "     \"total_tokens\": 120\n",
              "   }\n",
              " })"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt_model.run_one_question(prompt_aux)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlHIgil58Hol",
        "outputId": "58524229-3e21-407b-c4bc-72ae8e1785df"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The stadium in Miami that was considered is called Sun Life Stadium.',\n",
              " <OpenAIObject chat.completion id=chatcmpl-6wMBBFH2ceEq28SHHsrCdlbaOZNrH at 0x7fd4ff9aea90> JSON: {\n",
              "   \"choices\": [\n",
              "     {\n",
              "       \"finish_reason\": \"stop\",\n",
              "       \"index\": 0,\n",
              "       \"message\": {\n",
              "         \"content\": \"The stadium in Miami that was considered is called Sun Life Stadium.\",\n",
              "         \"role\": \"assistant\"\n",
              "       }\n",
              "     }\n",
              "   ],\n",
              "   \"created\": 1679366301,\n",
              "   \"id\": \"chatcmpl-6wMBBFH2ceEq28SHHsrCdlbaOZNrH\",\n",
              "   \"model\": \"gpt-3.5-turbo-0301\",\n",
              "   \"object\": \"chat.completion\",\n",
              "   \"usage\": {\n",
              "     \"completion_tokens\": 14,\n",
              "     \"prompt_tokens\": 106,\n",
              "     \"total_tokens\": 120\n",
              "   }\n",
              " })"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execuções"
      ],
      "metadata": {
        "id": "lcf4EzA9EhC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_modelo = {'Code_DaVinci':code_davinci_model,\n",
        "               'LLaMa': llama_model,\n",
        "               #'chatgpt': chatgpt_model\n",
        "                }"
      ],
      "metadata": {
        "id": "X3NgiU33Erpi"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_resposta = []\n",
        "lista_erro = []\n",
        "for nome_modelo, modelo in dict_modelo.items():\n",
        "  for cod_prompt in [0, 1, 2]:\n",
        "    for ndx, row in df_selecao.reset_index().iterrows():\n",
        "      try:\n",
        "        prompt_aux = retorna_prompt(cod_prompt=cod_prompt, texto_pergunta=row['question'], texto_contexto=row['context'])\n",
        "        resposta = modelo.answer_one_question(prompt_aux)\n",
        "        resultado = (row['id'], cod_prompt, nome_modelo, resposta)\n",
        "        print(f'ndx {ndx} {row[\"question\"]} {resultado}')\n",
        "        lista_resposta.append(resultado)\n",
        "        time.sleep(20)\n",
        "      except Exception as e:\n",
        "        print(f'Erro em ndx {ndx} id: {row[\"id\"]} nome_modelo: {nome_modelo} cod_prompt: {cod_prompt}')\n",
        "        print(f'Erro: {e}')\n",
        "        lista_erro.append((row[\"id\"], cod_prompt, nome_modelo))\n",
        "        continue        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u1iOjTw817U",
        "outputId": "42ec3a85-64db-4083-91d0-35032a9fa547"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndx 0 What site is located in the San Francisco Bay Area? ('56beb03c3aeaaa14008c920d', 0, 'Code_DaVinci', \" Levi's Stadium\")\n",
            "ndx 1 What Florida stadium was considered for Super Bowl 50? ('56d98db6dc89441400fdb552', 0, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 2 What is the name of the stadium in Miami that was considered? ('56d6ee6e0d65d21400198256', 0, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 3 What venue in Miami was a candidate for the site of Super Bowl 50? ('56beb03c3aeaaa14008c920b', 0, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 4 What was the given name of Miami's stadium at the time of Super Bowl 50? ('56bf3c633aeaaa14008c9582', 0, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 5 What was the name of New Orleans' superdome at the time that Super Bowl 50 took place? ('56bf3c633aeaaa14008c9581', 0, 'Code_DaVinci', ' Mercedes-Benz Superdome')\n",
            "ndx 6 What award has Marlee Matlin won? ('56bec6ac3aeaaa14008c93ff', 0, 'Code_DaVinci', ' Academy Award')\n",
            "ndx 7 What actress did the ASL translation for the game? ('56d20650e7d4791d00902615', 0, 'Code_DaVinci', ' Marlee Matlin')\n",
            "ndx 8 Who did the sign language of the National Anthem at Super Bowl 50? ('56d9c455dc89441400fdb7c6', 0, 'Code_DaVinci', ' Marlee Matlin')\n",
            "ndx 9 What actor did sign language for the National Anthem at Superbowl 50? ('56d7253b0d65d214001983d5', 0, 'Code_DaVinci', ' Marlee Matlin')\n",
            "ndx 10 What became the foundation of the Reformation? ('56f80e1daef2371900625d8e', 0, 'Code_DaVinci', 'Luther\\'s rediscovery of \"Christ and His salvation\"')\n",
            "ndx 11 What fueled Luther's  concept of Christ and His Salvation? ('56f80e1daef2371900625d8f', 0, 'Code_DaVinci', 'Luther\\'s rediscovery of \"Christ and His salvation\" was the first of two points that became the foundation for the Reformation')\n",
            "ndx 12 What position did Tesla hold in the American Institute of Electrical Engineers? ('56e0f019231d4119001ac470', 0, 'Code_DaVinci', 'vice president')\n",
            "ndx 13 What did Luther do at the end of his speech? ('56f82549a6d7ea1400e17415', 0, 'Code_DaVinci', 'He raised his arm')\n",
            "ndx 14 Who considers Luther's speech a world classic? ('56f82549a6d7ea1400e17417', 0, 'Code_DaVinci', ' Michael Mullett')\n",
            "ndx 15 What are two examples of measurements are bound within algorithms to establish complexity classes? ('56e1c3e1e3433e1400423148', 0, 'Code_DaVinci', ' Time and space')\n",
            "ndx 16 What is similar to vocational training? ('56e748a200c9c71400d76f39', 0, 'Code_DaVinci', ' craftsmanship')\n",
            "ndx 17 What is the role of teachers in education? ('56e7504437bdd419002c3e5e', 0, 'Code_DaVinci', 'Teachers facilitate student learning')\n",
            "ndx 18 Aside from BBC Radio 5, what radio station will broadcast the game? ('56bec5ff3aeaaa14008c93e4', 0, 'Code_DaVinci', ' 5 Live Sports Extra')\n",
            "ndx 19 Who makes up the BBC commentary team with Greg Brady and Rocky Boiman? ('56bec5ff3aeaaa14008c93e5', 0, 'Code_DaVinci', ' Darren Fletcher')\n",
            "ndx 20 Who sold the rights? ('56de49a8cffd8e1900b4b7a9', 0, 'Code_DaVinci', ' Maciot de Bethencourt')\n",
            "ndx 21 Who bought the rights? ('56de49a8cffd8e1900b4b7a8', 0, 'Code_DaVinci', ' Enrique Pérez de Guzmán, 2nd Count de Niebla')\n",
            "ndx 22 What kind of media can references to Tesla be found in ('56e126dae3433e1400422c7d', 0, 'Code_DaVinci', ' books, films, radio, TV, music, live theater, comics and video games')\n",
            "ndx 23 What does CBD stand for? ('57060a6e52bb8914006897f9', 0, 'Code_DaVinci', ' Central business districts')\n",
            "ndx 24 What is the only district in the CBD to not have \"downtown\" in it's name? ('57060a6e52bb8914006897fa', 0, 'Code_DaVinci', ' South Coast Metro')\n",
            "ndx 25 What religion did Tesla grow up in? ('56e124f1cd28a01900c6764f', 0, 'Code_DaVinci', ' Orthodox Christian')\n",
            "ndx 26 What was the teacher's role while the child was with them? ('56e7578a37bdd419002c3eaa', 0, 'Code_DaVinci', ' The teacher was expected to act as a substitute parent')\n",
            "ndx 27 Who is most likely to teach a child at home? ('56e749dd00c9c71400d76f51', 0, 'Code_DaVinci', ' A family member')\n",
            "ndx 28 If someone is being taught at their place of residence, what is it called? ('56e749dd00c9c71400d76f52', 0, 'Code_DaVinci', ' Home schooling')\n",
            "ndx 29 Who won the competition to get a free Super Bowl commercial aired? ('56d9be16dc89441400fdb771', 0, 'Code_DaVinci', ' Death Wish Coffee')\n",
            "ndx 30 What company won a free advertisement due to the QuickBooks contest? ('56bec38b3aeaaa14008c9398', 0, 'Code_DaVinci', ' Death Wish Coffee')\n",
            "ndx 31 Who were the Westwood one color analysts? ('56d9c049dc89441400fdb78f', 0, 'Code_DaVinci', ' Boomer Esiason and Dan Fouts')\n",
            "ndx 32 Who were the Westwood One sideline announcers? ('56d9c049dc89441400fdb790', 0, 'Code_DaVinci', ' Lofton and Malone')\n",
            "ndx 33 What area did the Westwood One broadcast cover? ('56d9c049dc89441400fdb792', 0, 'Code_DaVinci', ' North America')\n",
            "ndx 34 Along with Dan Fouts, who served as a color analyst for the radio broadcast? ('56bec4a33aeaaa14008c93b4', 0, 'Code_DaVinci', ' Boomer Esiason')\n",
            "ndx 35 Who was Tesla prejudiced against? ('56e12005cd28a01900c67617', 0, 'Code_DaVinci', ' overweight people')\n",
            "ndx 36 What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P? ('56e1f10ee3433e1400423226', 0, 'Code_DaVinci', '')\n",
            "ndx 37 What did he hope to locate underground? ('56e10d2dcd28a01900c674da', 0, 'Code_DaVinci', 'mineral deposits')\n",
            "ndx 38 What did Tesla claim to be able to transmit? ('56e10d2dcd28a01900c674d7', 0, 'Code_DaVinci', ' Mechanical energy')\n",
            "ndx 39 What was another use for the weapon? ('56e10e73cd28a01900c674ee', 0, 'Code_DaVinci', ' anti-aircraft purposes')\n",
            "ndx 40 What does AC stand for? ('56e0b94b7aa994140058e6bb', 0, 'Code_DaVinci', 'Alternating Current')\n",
            "ndx 41 Who published Tesla's writings? ('56e125b6e3433e1400422c6d', 0, 'Code_DaVinci', ' Ben Johnston and David Hatcher Childress')\n",
            "ndx 42 Who made Ralph earl? ('56de3d594396321400ee26cc', 0, 'Code_DaVinci', ' Edward the Confessor')\n",
            "ndx 43 Who cannot be employed by a school in any manner? ('56e772bf37bdd419002c3fbf', 0, 'Code_DaVinci', ' Those who refuse vetting')\n",
            "ndx 44 Who patronized the monks in Italy? ('56de52614396321400ee27fd', 0, 'Code_DaVinci', ' Robert Guiscard')\n",
            "ndx 45 Who was Tesla's nephew? ('56e1127bcd28a01900c6754a', 0, 'Code_DaVinci', ' Sava Kosanović')\n",
            "ndx 46 Who transported Tesla's ashes from the US. ('56e1127bcd28a01900c6754b', 0, 'Code_DaVinci', ' Charlotte Muzar')\n",
            "ndx 47 Who translated and printed Luther's 95 These? ('56f8074faef2371900625d7b', 0, 'Code_DaVinci', ' Friends of Luther')\n",
            "ndx 48 Who called their system the \"Tesla Polyphase System\"? ('56e0e69b7aa994140058e797', 0, 'Code_DaVinci', ' Westinghouse Electric')\n",
            "ndx 49 Who was Philip I? ('56f88c37aef2371900626177', 0, 'Code_DaVinci', ' Philip I, Landgrave of Hesse')\n",
            "ndx 50 Who were special guests for the Super Bowl halftime show? ('56d602631c85041400946edb', 0, 'Code_DaVinci', ' Beyoncé and Bruno Mars')\n",
            "ndx 51 Who did Tesla partner with in 1886? ('56dfb5777aa994140058e021', 0, 'Code_DaVinci', ' Robert Lane and Benjamin Vail')\n",
            "ndx 52 Who did Luther banish? ('56f84b68aef2371900625fa9', 0, 'Code_DaVinci', ' Zwickau prophets')\n",
            "ndx 53 Who hired Tesla in New York? ('56e0d54a7aa994140058e76c', 0, 'Code_DaVinci', ' Thomas Edison')\n",
            "ndx 54 Who hired Tesla when he moved to New York? ('56dfb0c8231d4119001abc86', 0, 'Code_DaVinci', ' Thomas Edison')\n",
            "ndx 55 Who conducted this survey? ('56e7673a37bdd419002c3f57', 0, 'Code_DaVinci', ' The American Association of University Women')\n",
            "ndx 56 Who was in charge of the papal army in the War of Barbastro? ('56de3e414396321400ee26d9', 0, 'Code_DaVinci', ' William of Montreuil')\n",
            "ndx 57 Who presided over the assembly? ('56f8225ea6d7ea1400e173f4', 0, 'Code_DaVinci', ' Emperor Charles V')\n",
            "ndx 58 Who defeated the rebels at the Battle of Frankenhausen? ('56f851b1a6d7ea1400e1755e', 0, 'Code_DaVinci', ' The Swabian League')\n",
            "ndx 59 Who performed the funeral for Martin Luther? ('56f8c9719e9bad19000a04e4', 0, 'Code_DaVinci', ' Johannes Bugenhagen and Philipp Melanchthon')\n",
            "ndx 0 What site is located in the San Francisco Bay Area? ('56beb03c3aeaaa14008c920d', 1, 'Code_DaVinci', \" Levi's Stadium\")\n",
            "ndx 1 What Florida stadium was considered for Super Bowl 50? ('56d98db6dc89441400fdb552', 1, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 2 What is the name of the stadium in Miami that was considered? ('56d6ee6e0d65d21400198256', 1, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 3 What venue in Miami was a candidate for the site of Super Bowl 50? ('56beb03c3aeaaa14008c920b', 1, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 4 What was the given name of Miami's stadium at the time of Super Bowl 50? ('56bf3c633aeaaa14008c9582', 1, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 5 What was the name of New Orleans' superdome at the time that Super Bowl 50 took place? ('56bf3c633aeaaa14008c9581', 1, 'Code_DaVinci', ' Mercedes-Benz Superdome')\n",
            "ndx 6 What award has Marlee Matlin won? ('56bec6ac3aeaaa14008c93ff', 1, 'Code_DaVinci', ' Academy Award')\n",
            "ndx 7 What actress did the ASL translation for the game? ('56d20650e7d4791d00902615', 1, 'Code_DaVinci', ' Marlee Matlin')\n",
            "ndx 8 Who did the sign language of the National Anthem at Super Bowl 50? ('56d9c455dc89441400fdb7c6', 1, 'Code_DaVinci', ' Marlee Matlin')\n",
            "ndx 9 What actor did sign language for the National Anthem at Superbowl 50? ('56d7253b0d65d214001983d5', 1, 'Code_DaVinci', ' Marlee Matlin')\n",
            "ndx 10 What became the foundation of the Reformation? ('56f80e1daef2371900625d8e', 1, 'Code_DaVinci', ' Christ and His salvation')\n",
            "ndx 11 What fueled Luther's  concept of Christ and His Salvation? ('56f80e1daef2371900625d8f', 1, 'Code_DaVinci', ' The sale of indulgences')\n",
            "ndx 12 What position did Tesla hold in the American Institute of Electrical Engineers? ('56e0f019231d4119001ac470', 1, 'Code_DaVinci', ' vice president')\n",
            "ndx 13 What did Luther do at the end of his speech? ('56f82549a6d7ea1400e17415', 1, 'Code_DaVinci', ' He raised his arm')\n",
            "ndx 14 Who considers Luther's speech a world classic? ('56f82549a6d7ea1400e17417', 1, 'Code_DaVinci', ' Michael Mullett')\n",
            "ndx 15 What are two examples of measurements are bound within algorithms to establish complexity classes? ('56e1c3e1e3433e1400423148', 1, 'Code_DaVinci', ' Time and space')\n",
            "ndx 16 What is similar to vocational training? ('56e748a200c9c71400d76f39', 1, 'Code_DaVinci', ' Craftsmanship')\n",
            "ndx 17 What is the role of teachers in education? ('56e7504437bdd419002c3e5e', 1, 'Code_DaVinci', ' Facilitate student learning')\n",
            "ndx 18 Aside from BBC Radio 5, what radio station will broadcast the game? ('56bec5ff3aeaaa14008c93e4', 1, 'Code_DaVinci', ' 5 Live Sports Extra')\n",
            "ndx 19 Who makes up the BBC commentary team with Greg Brady and Rocky Boiman? ('56bec5ff3aeaaa14008c93e5', 1, 'Code_DaVinci', ' Darren Fletcher')\n",
            "ndx 20 Who sold the rights? ('56de49a8cffd8e1900b4b7a9', 1, 'Code_DaVinci', ' Maciot de Bethencourt')\n",
            "ndx 21 Who bought the rights? ('56de49a8cffd8e1900b4b7a8', 1, 'Code_DaVinci', ' Enrique Pérez de Guzmán')\n",
            "ndx 22 What kind of media can references to Tesla be found in ('56e126dae3433e1400422c7d', 1, 'Code_DaVinci', ' Books, films, radio, TV, music, live theater, comics and video games')\n",
            "ndx 23 What does CBD stand for? ('57060a6e52bb8914006897f9', 1, 'Code_DaVinci', ' Central business districts')\n",
            "ndx 24 What is the only district in the CBD to not have \"downtown\" in it's name? ('57060a6e52bb8914006897fa', 1, 'Code_DaVinci', ' South Coast Metro')\n",
            "ndx 25 What religion did Tesla grow up in? ('56e124f1cd28a01900c6764f', 1, 'Code_DaVinci', ' Orthodox Christian')\n",
            "ndx 26 What was the teacher's role while the child was with them? ('56e7578a37bdd419002c3eaa', 1, 'Code_DaVinci', ' Substitute parent')\n",
            "ndx 27 Who is most likely to teach a child at home? ('56e749dd00c9c71400d76f51', 1, 'Code_DaVinci', ' A family member')\n",
            "ndx 28 If someone is being taught at their place of residence, what is it called? ('56e749dd00c9c71400d76f52', 1, 'Code_DaVinci', ' Home schooling')\n",
            "ndx 29 Who won the competition to get a free Super Bowl commercial aired? ('56d9be16dc89441400fdb771', 1, 'Code_DaVinci', ' Death Wish Coffee')\n",
            "ndx 30 What company won a free advertisement due to the QuickBooks contest? ('56bec38b3aeaaa14008c9398', 1, 'Code_DaVinci', ' Death Wish Coffee')\n",
            "ndx 31 Who were the Westwood one color analysts? ('56d9c049dc89441400fdb78f', 1, 'Code_DaVinci', ' Boomer Esiason and Dan Fouts')\n",
            "ndx 32 Who were the Westwood One sideline announcers? ('56d9c049dc89441400fdb790', 1, 'Code_DaVinci', ' James Lofton and Mark Malone')\n",
            "ndx 33 What area did the Westwood One broadcast cover? ('56d9c049dc89441400fdb792', 1, 'Code_DaVinci', ' North America')\n",
            "ndx 34 Along with Dan Fouts, who served as a color analyst for the radio broadcast? ('56bec4a33aeaaa14008c93b4', 1, 'Code_DaVinci', ' Boomer Esiason')\n",
            "ndx 35 Who was Tesla prejudiced against? ('56e12005cd28a01900c67617', 1, 'Code_DaVinci', ' Overweight people')\n",
            "ndx 36 What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P? ('56e1f10ee3433e1400423226', 1, 'Code_DaVinci', ' Whether they are distinct or equal classes')\n",
            "ndx 37 What did he hope to locate underground? ('56e10d2dcd28a01900c674da', 1, 'Code_DaVinci', ' Mineral deposits')\n",
            "ndx 38 What did Tesla claim to be able to transmit? ('56e10d2dcd28a01900c674d7', 1, 'Code_DaVinci', ' Mechanical energy')\n",
            "ndx 39 What was another use for the weapon? ('56e10e73cd28a01900c674ee', 1, 'Code_DaVinci', ' Anti-aircraft')\n",
            "ndx 40 What does AC stand for? ('56e0b94b7aa994140058e6bb', 1, 'Code_DaVinci', ' Alternating Current')\n",
            "ndx 41 Who published Tesla's writings? ('56e125b6e3433e1400422c6d', 1, 'Code_DaVinci', ' Ben Johnston and David Hatcher Childress')\n",
            "ndx 42 Who made Ralph earl? ('56de3d594396321400ee26cc', 1, 'Code_DaVinci', ' Edward the Confessor')\n",
            "ndx 43 Who cannot be employed by a school in any manner? ('56e772bf37bdd419002c3fbf', 1, 'Code_DaVinci', ' Those who refuse vetting')\n",
            "ndx 44 Who patronized the monks in Italy? ('56de52614396321400ee27fd', 1, 'Code_DaVinci', ' Robert Guiscard')\n",
            "ndx 45 Who was Tesla's nephew? ('56e1127bcd28a01900c6754a', 1, 'Code_DaVinci', ' Sava Kosanović')\n",
            "ndx 46 Who transported Tesla's ashes from the US. ('56e1127bcd28a01900c6754b', 1, 'Code_DaVinci', ' Charlotte Muzar')\n",
            "ndx 47 Who translated and printed Luther's 95 These? ('56f8074faef2371900625d7b', 1, 'Code_DaVinci', \" Luther's friends\")\n",
            "ndx 48 Who called their system the \"Tesla Polyphase System\"? ('56e0e69b7aa994140058e797', 1, 'Code_DaVinci', ' Westinghouse Electric')\n",
            "ndx 49 Who was Philip I? ('56f88c37aef2371900626177', 1, 'Code_DaVinci', ' Landgrave of Hesse')\n",
            "ndx 50 Who were special guests for the Super Bowl halftime show? ('56d602631c85041400946edb', 1, 'Code_DaVinci', ' Beyoncé and Bruno Mars')\n",
            "ndx 51 Who did Tesla partner with in 1886? ('56dfb5777aa994140058e021', 1, 'Code_DaVinci', ' Robert Lane and Benjamin Vail')\n",
            "ndx 52 Who did Luther banish? ('56f84b68aef2371900625fa9', 1, 'Code_DaVinci', ' The Zwickau prophets')\n",
            "ndx 53 Who hired Tesla in New York? ('56e0d54a7aa994140058e76c', 1, 'Code_DaVinci', ' Edison')\n",
            "ndx 54 Who hired Tesla when he moved to New York? ('56dfb0c8231d4119001abc86', 1, 'Code_DaVinci', ' Thomas Edison')\n",
            "ndx 55 Who conducted this survey? ('56e7673a37bdd419002c3f57', 1, 'Code_DaVinci', ' The American Association of University Women')\n",
            "ndx 56 Who was in charge of the papal army in the War of Barbastro? ('56de3e414396321400ee26d9', 1, 'Code_DaVinci', ' William of Montreuil')\n",
            "ndx 57 Who presided over the assembly? ('56f8225ea6d7ea1400e173f4', 1, 'Code_DaVinci', ' Emperor Charles V')\n",
            "ndx 58 Who defeated the rebels at the Battle of Frankenhausen? ('56f851b1a6d7ea1400e1755e', 1, 'Code_DaVinci', ' The Swabian League')\n",
            "ndx 59 Who performed the funeral for Martin Luther? ('56f8c9719e9bad19000a04e4', 1, 'Code_DaVinci', ' Johannes Bugenhagen and Philipp Melanchthon')\n",
            "ndx 0 What site is located in the San Francisco Bay Area? ('56beb03c3aeaaa14008c920d', 2, 'Code_DaVinci', \" Levi's Stadium\")\n",
            "ndx 1 What Florida stadium was considered for Super Bowl 50? ('56d98db6dc89441400fdb552', 2, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 2 What is the name of the stadium in Miami that was considered? ('56d6ee6e0d65d21400198256', 2, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 3 What venue in Miami was a candidate for the site of Super Bowl 50? ('56beb03c3aeaaa14008c920b', 2, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 4 What was the given name of Miami's stadium at the time of Super Bowl 50? ('56bf3c633aeaaa14008c9582', 2, 'Code_DaVinci', ' Sun Life Stadium')\n",
            "ndx 5 What was the name of New Orleans' superdome at the time that Super Bowl 50 took place? ('56bf3c633aeaaa14008c9581', 2, 'Code_DaVinci', ' Mercedes-Benz Superdome')\n",
            "ndx 6 What award has Marlee Matlin won? ('56bec6ac3aeaaa14008c93ff', 2, 'Code_DaVinci', ' Academy Award')\n",
            "ndx 7 What actress did the ASL translation for the game? ('56d20650e7d4791d00902615', 2, 'Code_DaVinci', ' Marlee Matlin')\n",
            "ndx 8 Who did the sign language of the National Anthem at Super Bowl 50? ('56d9c455dc89441400fdb7c6', 2, 'Code_DaVinci', ' Marlee Matlin')\n",
            "ndx 9 What actor did sign language for the National Anthem at Superbowl 50? ('56d7253b0d65d214001983d5', 2, 'Code_DaVinci', ' Marlee Matlin')\n",
            "ndx 10 What became the foundation of the Reformation? ('56f80e1daef2371900625d8e', 2, 'Code_DaVinci', ' Christ and His salvation')\n",
            "ndx 11 What fueled Luther's  concept of Christ and His Salvation? ('56f80e1daef2371900625d8f', 2, 'Code_DaVinci', ' The Reformation')\n",
            "ndx 12 What position did Tesla hold in the American Institute of Electrical Engineers? ('56e0f019231d4119001ac470', 2, 'Code_DaVinci', ' vice president')\n",
            "ndx 13 What did Luther do at the end of his speech? ('56f82549a6d7ea1400e17415', 2, 'Code_DaVinci', ' Raised his arm')\n",
            "ndx 14 Who considers Luther's speech a world classic? ('56f82549a6d7ea1400e17417', 2, 'Code_DaVinci', ' Michael Mullett')\n",
            "ndx 15 What are two examples of measurements are bound within algorithms to establish complexity classes? ('56e1c3e1e3433e1400423148', 2, 'Code_DaVinci', ' Time and space')\n",
            "ndx 16 What is similar to vocational training? ('56e748a200c9c71400d76f39', 2, 'Code_DaVinci', ' craftsmanship')\n",
            "ndx 17 What is the role of teachers in education? ('56e7504437bdd419002c3e5e', 2, 'Code_DaVinci', ' Facilitate student learning')\n",
            "ndx 18 Aside from BBC Radio 5, what radio station will broadcast the game? ('56bec5ff3aeaaa14008c93e4', 2, 'Code_DaVinci', ' 5 Live Sports Extra')\n",
            "ndx 19 Who makes up the BBC commentary team with Greg Brady and Rocky Boiman? ('56bec5ff3aeaaa14008c93e5', 2, 'Code_DaVinci', ' Darren Fletcher')\n",
            "ndx 20 Who sold the rights? ('56de49a8cffd8e1900b4b7a9', 2, 'Code_DaVinci', ' Maciot de Bethencourt')\n",
            "ndx 21 Who bought the rights? ('56de49a8cffd8e1900b4b7a8', 2, 'Code_DaVinci', ' Enrique Pérez de Guzmán, 2nd Count de Niebla')\n",
            "ndx 22 What kind of media can references to Tesla be found in ('56e126dae3433e1400422c7d', 2, 'Code_DaVinci', ' books, films, radio, TV, music, live theater, comics and video games')\n",
            "ndx 23 What does CBD stand for? ('57060a6e52bb8914006897f9', 2, 'Code_DaVinci', ' Central business districts')\n",
            "ndx 24 What is the only district in the CBD to not have \"downtown\" in it's name? ('57060a6e52bb8914006897fa', 2, 'Code_DaVinci', ' South Coast Metro')\n",
            "ndx 25 What religion did Tesla grow up in? ('56e124f1cd28a01900c6764f', 2, 'Code_DaVinci', ' Orthodox Christian')\n",
            "ndx 26 What was the teacher's role while the child was with them? ('56e7578a37bdd419002c3eaa', 2, 'Code_DaVinci', ' Substitute parent')\n",
            "ndx 27 Who is most likely to teach a child at home? ('56e749dd00c9c71400d76f51', 2, 'Code_DaVinci', ' A family member')\n",
            "ndx 28 If someone is being taught at their place of residence, what is it called? ('56e749dd00c9c71400d76f52', 2, 'Code_DaVinci', ' Home schooling')\n",
            "ndx 29 Who won the competition to get a free Super Bowl commercial aired? ('56d9be16dc89441400fdb771', 2, 'Code_DaVinci', ' Death Wish Coffee')\n",
            "ndx 30 What company won a free advertisement due to the QuickBooks contest? ('56bec38b3aeaaa14008c9398', 2, 'Code_DaVinci', ' Death Wish Coffee')\n",
            "ndx 31 Who were the Westwood one color analysts? ('56d9c049dc89441400fdb78f', 2, 'Code_DaVinci', ' Boomer Esiason and Dan Fouts')\n",
            "ndx 32 Who were the Westwood One sideline announcers? ('56d9c049dc89441400fdb790', 2, 'Code_DaVinci', ' James Lofton and Mark Malone')\n",
            "ndx 33 What area did the Westwood One broadcast cover? ('56d9c049dc89441400fdb792', 2, 'Code_DaVinci', ' North America')\n",
            "ndx 34 Along with Dan Fouts, who served as a color analyst for the radio broadcast? ('56bec4a33aeaaa14008c93b4', 2, 'Code_DaVinci', ' Boomer Esiason')\n",
            "ndx 35 Who was Tesla prejudiced against? ('56e12005cd28a01900c67617', 2, 'Code_DaVinci', ' overweight people')\n",
            "ndx 36 What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P? ('56e1f10ee3433e1400423226', 2, 'Code_DaVinci', ' if they are distinct or equal classes')\n",
            "ndx 37 What did he hope to locate underground? ('56e10d2dcd28a01900c674da', 2, 'Code_DaVinci', ' Mineral deposits')\n",
            "ndx 38 What did Tesla claim to be able to transmit? ('56e10d2dcd28a01900c674d7', 2, 'Code_DaVinci', ' Mechanical energy')\n",
            "ndx 39 What was another use for the weapon? ('56e10e73cd28a01900c674ee', 2, 'Code_DaVinci', ' anti-aircraft purposes')\n",
            "ndx 40 What does AC stand for? ('56e0b94b7aa994140058e6bb', 2, 'Code_DaVinci', ' Alternating Current')\n",
            "ndx 41 Who published Tesla's writings? ('56e125b6e3433e1400422c6d', 2, 'Code_DaVinci', ' Ben Johnston')\n",
            "ndx 42 Who made Ralph earl? ('56de3d594396321400ee26cc', 2, 'Code_DaVinci', ' Edward the Confessor')\n",
            "ndx 43 Who cannot be employed by a school in any manner? ('56e772bf37bdd419002c3fbf', 2, 'Code_DaVinci', ' Those who refuse vetting')\n",
            "ndx 44 Who patronized the monks in Italy? ('56de52614396321400ee27fd', 2, 'Code_DaVinci', ' Robert Guiscard')\n",
            "ndx 45 Who was Tesla's nephew? ('56e1127bcd28a01900c6754a', 2, 'Code_DaVinci', ' Sava Kosanović')\n",
            "ndx 46 Who transported Tesla's ashes from the US. ('56e1127bcd28a01900c6754b', 2, 'Code_DaVinci', ' Charlotte Muzar')\n",
            "ndx 47 Who translated and printed Luther's 95 These? ('56f8074faef2371900625d7b', 2, 'Code_DaVinci', ' Friends of Luther')\n",
            "ndx 48 Who called their system the \"Tesla Polyphase System\"? ('56e0e69b7aa994140058e797', 2, 'Code_DaVinci', ' Westinghouse Electric')\n",
            "ndx 49 Who was Philip I? ('56f88c37aef2371900626177', 2, 'Code_DaVinci', ' Landgrave of Hesse')\n",
            "ndx 50 Who were special guests for the Super Bowl halftime show? ('56d602631c85041400946edb', 2, 'Code_DaVinci', ' Beyoncé and Bruno Mars')\n",
            "ndx 51 Who did Tesla partner with in 1886? ('56dfb5777aa994140058e021', 2, 'Code_DaVinci', ' Robert Lane and Benjamin Vail')\n",
            "ndx 52 Who did Luther banish? ('56f84b68aef2371900625fa9', 2, 'Code_DaVinci', ' Zwickau prophets')\n",
            "ndx 53 Who hired Tesla in New York? ('56e0d54a7aa994140058e76c', 2, 'Code_DaVinci', ' Edison')\n",
            "ndx 54 Who hired Tesla when he moved to New York? ('56dfb0c8231d4119001abc86', 2, 'Code_DaVinci', ' Edison')\n",
            "ndx 55 Who conducted this survey? ('56e7673a37bdd419002c3f57', 2, 'Code_DaVinci', ' American Association of University Women')\n",
            "ndx 56 Who was in charge of the papal army in the War of Barbastro? ('56de3e414396321400ee26d9', 2, 'Code_DaVinci', ' William of Montreuil')\n",
            "ndx 57 Who presided over the assembly? ('56f8225ea6d7ea1400e173f4', 2, 'Code_DaVinci', ' Charles V')\n",
            "ndx 58 Who defeated the rebels at the Battle of Frankenhausen? ('56f851b1a6d7ea1400e1755e', 2, 'Code_DaVinci', ' The Swabian League')\n",
            "ndx 59 Who performed the funeral for Martin Luther? ('56f8c9719e9bad19000a04e4', 2, 'Code_DaVinci', ' Johannes Bugenhagen and Philipp Melanchthon')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 0 What site is located in the San Francisco Bay Area? ('56beb03c3aeaaa14008c920d', 0, 'LLaMa', 'Levis stadium\\n\\nComment: I think you need to be more specific about what you want to do with this data.  Do you just')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 1 What Florida stadium was considered for Super Bowl 50? ('56d98db6dc89441400fdb552', 0, 'LLaMa', 'Sun Life Stadium\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 2 What is the name of the stadium in Miami that was considered? ('56d6ee6e0d65d21400198256', 0, 'LLaMa', \"Sun life stadium\\n\\nComment: I don't understand what you are asking here.  Are you looking for a way to extract the\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 3 What venue in Miami was a candidate for the site of Super Bowl 50? ('56beb03c3aeaaa14008c920b', 0, 'LLaMa', 'Sun Life Stadium\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 4 What was the given name of Miami's stadium at the time of Super Bowl 50? ('56bf3c633aeaaa14008c9582', 0, 'LLaMa', 'Sun Life Stadium\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 5 What was the name of New Orleans' superdome at the time that Super Bowl 50 took place? ('56bf3c633aeaaa14008c9581', 0, 'LLaMa', \"Mercedes Benz Super Dome\\n\\nComment: I don't understand what you are asking here. Are you trying to get a list of\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 6 What award has Marlee Matlin won? ('56bec6ac3aeaaa14008c93ff', 0, 'LLaMa', 'Academy Award\\n\\n### Question 2\\n\\nThe second question was a multiple choice question with four options. The correct option is highlighted')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 7 What actress did the ASL translation for the game? ('56d20650e7d4791d00902615', 0, 'LLaMa', 'Marlee Matlin\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 8 Who did the sign language of the National Anthem at Super Bowl 50? ('56d9c455dc89441400fdb7c6', 0, 'LLaMa', 'Marlee Matlin\\n\\n### Questions with multiple answers\\n\\nQuestions can have more than one correct answer. For example, a question')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 9 What actor did sign language for the National Anthem at Superbowl 50? ('56d7253b0d65d214001983d5', 0, 'LLaMa', 'Marlee Matlin\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 10 What became the foundation of the Reformation? ('56f80e1daef2371900625d8e', 0, 'LLaMa', \" Luther's rediscovery of Christ and his salvation\\n\\nComment: I don't understand your question. What do you mean by *\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 11 What fueled Luther's  concept of Christ and His Salvation? ('56f80e1daef2371900625d8f', 0, 'LLaMa', '\\n\\nComment: I don’t understand your question. What do you mean by “fueled”?\\n\\nComment: @Xanne')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 12 What position did Tesla hold in the American Institute of Electrical Engineers? ('56e0f019231d4119001ac470', 0, 'LLaMa', 'Vice President\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 13 What did Luther do at the end of his speech? ('56f82549a6d7ea1400e17415', 0, 'LLaMa', 'Luther raised his arm.\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 14 Who considers Luther's speech a world classic? ('56f82549a6d7ea1400e17417', 0, 'LLaMa', 'Michael Mullet.\\n\\n### Question 2 (1984)\\n\\nThe following is an extract from a letter written by Mah')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 15 What are two examples of measurements are bound within algorithms to establish complexity classes? ('56e1c3e1e3433e1400423148', 0, 'LLaMa', 'Time and Space\\n\\\\end{code}\\n\\nI am trying to extract \"time\" and \"space\". I have tried with regex but it')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 16 What is similar to vocational training? ('56e748a200c9c71400d76f39', 0, 'LLaMa', 'craftsmanship\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 17 What is the role of teachers in education? ('56e7504437bdd419002c3e5e', 0, 'LLaMa', 'Teachers facilitate student learning.\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 18 Aside from BBC Radio 5, what radio station will broadcast the game? ('56bec5ff3aeaaa14008c93e4', 0, 'LLaMa', 'BBC Radio 5 Live and 5 Live Sports Extra\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 19 Who makes up the BBC commentary team with Greg Brady and Rocky Boiman? ('56bec5ff3aeaaa14008c93e5', 0, 'LLaMa', 'Darren Fletcher\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 20 Who sold the rights? ('56de49a8cffd8e1900b4b7a9', 0, 'LLaMa', 'Maciot de Bethencourt\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 21 Who bought the rights? ('56de49a8cffd8e1900b4b7a8', 0, 'LLaMa', 'Enrique Pérez de Guzmán, 2nd Count de Niebla\\n\\nComment: I think you should add more details about your problem')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 22 What kind of media can references to Tesla be found in ('56e126dae3433e1400422c7d', 0, 'LLaMa', 'Books, Films, Radio, TV, Music, Live Theater, Comics and Video Games\\n\\n### Question 2 (Science)\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 23 What does CBD stand for? ('57060a6e52bb8914006897f9', 0, 'LLaMa', 'Central Business District\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 24 What is the only district in the CBD to not have \"downtown\" in it's name? ('57060a6e52bb8914006897fa', 0, 'LLaMa', 'South Coast Metro\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 25 What religion did Tesla grow up in? ('56e124f1cd28a01900c6764f', 0, 'LLaMa', 'Orthodox Christian\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 26 What was the teacher's role while the child was with them? ('56e7578a37bdd419002c3eaa', 0, 'LLaMa', 'The teacher acted as a substitute parent.\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 27 Who is most likely to teach a child at home? ('56e749dd00c9c71400d76f51', 0, 'LLaMa', 'Family Member\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 28 If someone is being taught at their place of residence, what is it called? ('56e749dd00c9c71400d76f52', 0, 'LLaMa', 'Home Schooling\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 29 Who won the competition to get a free Super Bowl commercial aired? ('56d9be16dc89441400fdb771', 0, 'LLaMa', 'Death Wish Coffee\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 30 What company won a free advertisement due to the QuickBooks contest? ('56bec38b3aeaaa14008c9398', 0, 'LLaMa', 'Death Wish Coffee\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 31 Who were the Westwood one color analysts? ('56d9c049dc89441400fdb78f', 0, 'LLaMa', \"Boomer Esiason and Dan Fouts\\n\\nComment: I'm voting to close this question as off-topic because it is not about\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 32 Who were the Westwood One sideline announcers? ('56d9c049dc89441400fdb790', 0, 'LLaMa', 'James Lofton and Mark Malone\\n\\n### Question 20 (5 points)\\n\\nInstructions: Answer the following questions')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 33 What area did the Westwood One broadcast cover? ('56d9c049dc89441400fdb792', 0, 'LLaMa', 'North America\\n\\n### Question 2 (10 points)\\n\\nThe following is a list of questions that were asked during Super Bowl')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 34 Along with Dan Fouts, who served as a color analyst for the radio broadcast? ('56bec4a33aeaaa14008c93b4', 0, 'LLaMa', 'Boomer Esiason\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 35 Who was Tesla prejudiced against? ('56e12005cd28a01900c67617', 0, 'LLaMa', 'Overweight People.\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 36 What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P? ('56e1f10ee3433e1400423226', 0, 'LLaMa', \"\\n\\nComment: I'm voting to close this question as off-topic because it belongs on cs.stackexchange.com\\n\\nComment: @\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 37 What did he hope to locate underground? ('56e10d2dcd28a01900c674da', 0, 'LLaMa', \"minerals\\n\\nComment: I'm voting to close this question as off-topic because it is about English language usage rather than programming.\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 38 What did Tesla claim to be able to transmit? ('56e10d2dcd28a01900c674d7', 0, 'LLaMa', ' Mechanical Energy\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 39 What was another use for the weapon? ('56e10e73cd28a01900c674ee', 0, 'LLaMa', '\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 40 What does AC stand for? ('56e0b94b7aa994140058e6bb', 0, 'LLaMa', 'Alternate Current\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 41 Who published Tesla's writings? ('56e125b6e3433e1400422c6d', 0, 'LLaMa', 'Ben Johnson,David Hatcher Childress\\n\\nComment: I think you should add more details to your question. What have you tried so far')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 42 Who made Ralph earl? ('56de3d594396321400ee26cc', 0, 'LLaMa', \"Edward the confessor\\n\\nComment: I'm voting to close this question as off-topic because it is about English language usage rather than\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 43 Who cannot be employed by a school in any manner? ('56e772bf37bdd419002c3fbf', 0, 'LLaMa', 'Those who refuse vetting\\n\\n### Questions based on tables/graphs\\n\\nQuestions are asked based on data presented in')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 44 Who patronized the monks in Italy? ('56de52614396321400ee27fd', 0, 'LLaMa', 'Robert Guiscard\\n\\n### Question 2 (10 marks)\\n\\nThe following is an extract from a letter written by a')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 45 Who was Tesla's nephew? ('56e1127bcd28a01900c6754a', 0, 'LLaMa', 'Sava Kosanovic\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 46 Who transported Tesla's ashes from the US. ('56e1127bcd28a01900c6754b', 0, 'LLaMa', 'Charlotte Muzar\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 47 Who translated and printed Luther's 95 These? ('56f8074faef2371900625d7b', 0, 'LLaMa', 'Friends of Luther\\n\\nComment: I think you should ask this at https://codereview.stackexchange.com/\\n\\nComment: @')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 48 Who called their system the \"Tesla Polyphase System\"? ('56e0e69b7aa994140058e797', 0, 'LLaMa', 'Westinghouse Electric\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 49 Who was Philip I? ('56f88c37aef2371900626177', 0, 'LLaMa', 'Landgrave of Hesse\\n\\nComment: What is your question?\\n\\nComment: How can i extract the answer \"landgrave of')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 50 Who were special guests for the Super Bowl halftime show? ('56d602631c85041400946edb', 0, 'LLaMa', 'Beyonce and Bruno Mars\\n\\n### Question Answering (QA)\\n\\nThe task is to find answers to questions posed in')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 51 Who did Tesla partner with in 1886? ('56dfb5777aa994140058e021', 0, 'LLaMa', 'Robert Lane and Benjamin Vail\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 52 Who did Luther banish? ('56f84b68aef2371900625fa9', 0, 'LLaMa', 'Zwickau Prophets\\n\\n### Question 2 (10 marks)\\n\\nThe second question is based on an extract of a')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 53 Who hired Tesla in New York? ('56e0d54a7aa994140058e76c', 0, 'LLaMa', 'Thomas Edison\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 54 Who hired Tesla when he moved to New York? ('56dfb0c8231d4119001abc86', 0, 'LLaMa', 'Thomas Edison\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 55 Who conducted this survey? ('56e7673a37bdd419002c3f57', 0, 'LLaMa', 'American Association of University Women\\n\\n### Reading Comprehension (RC)\\n\\nThe RC section consists of four passages each followed by')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 56 Who was in charge of the papal army in the War of Barbastro? ('56de3e414396321400ee26d9', 0, 'LLaMa', 'William of Montreuil\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 57 Who presided over the assembly? ('56f8225ea6d7ea1400e173f4', 0, 'LLaMa', 'Emperor Charles V\\n\\\\end{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 58 Who defeated the rebels at the Battle of Frankenhausen? ('56f851b1a6d7ea1400e1755e', 0, 'LLaMa', 'Swabian league\\n\\n### Question type 4: Match the following\\n\\nBased on the text below, match List-I with')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 59 Who performed the funeral for Martin Luther? ('56f8c9719e9bad19000a04e4', 0, 'LLaMa', 'Johannes Bugenhagen and Philipp Melanchthon\\n\\n### Question type 3: Multiple choice questions with one correct option\\n\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 0 What site is located in the San Francisco Bay Area? ('56beb03c3aeaaa14008c920d', 1, 'LLaMa', \"Levi's Stadium.\\n\\\\end{blockquote}\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 1 What Florida stadium was considered for Super Bowl 50? ('56d98db6dc89441400fdb552', 1, 'LLaMa', \"Miami's Sun Life Stadium.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 2 What is the name of the stadium in Miami that was considered? ('56d6ee6e0d65d21400198256', 1, 'LLaMa', \"Sun Life Stadium.\\n\\\\end{blockquote}\\n\\nI have tried this code but it doesn't work for me.\\n\\n\\\\\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 3 What venue in Miami was a candidate for the site of Super Bowl 50? ('56beb03c3aeaaa14008c920b', 1, 'LLaMa', 'Sun Life Stadium.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 4 What was the given name of Miami's stadium at the time of Super Bowl 50? ('56bf3c633aeaaa14008c9582', 1, 'LLaMa', 'Sun Life Stadium.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 5 What was the name of New Orleans' superdome at the time that Super Bowl 50 took place? ('56bf3c633aeaaa14008c9581', 1, 'LLaMa', 'Mercedes-Benz Superdome.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 6 What award has Marlee Matlin won? ('56bec6ac3aeaaa14008c93ff', 1, 'LLaMa', 'Academy Award\\n\\n### Reading Comprehension\\n\\nThe reading comprehension section consists of three texts with a total of 24')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 7 What actress did the ASL translation for the game? ('56d20650e7d4791d00902615', 1, 'LLaMa', \"Marlee Matlin.\\n\\\\end{blockquote}\\n\\nI have tried to use this code but it doesn't work properly. I need\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 8 Who did the sign language of the National Anthem at Super Bowl 50? ('56d9c455dc89441400fdb7c6', 1, 'LLaMa', 'Marlee Matlin.\\n\\\\end{blockquote}\\n\\nI have tried to use the following code but it is not working as expected.\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 9 What actor did sign language for the National Anthem at Superbowl 50? ('56d7253b0d65d214001983d5', 1, 'LLaMa', 'Marlee Matlin.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 10 What became the foundation of the Reformation? ('56f80e1daef2371900625d8e', 1, 'LLaMa', \" Luther's rediscovery of Christ and his salvation.\\n\\\\end{blockquote}\\n\\nI have tried to use `nltk\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 11 What fueled Luther's  concept of Christ and His Salvation? ('56f80e1daef2371900625d8f', 1, 'LLaMa', ' The rediscovery of Christ and his salvation.\\n\\\\end{blockquote}\\n\\nI have tried to use this code but I am not')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 12 What position did Tesla hold in the American Institute of Electrical Engineers? ('56e0f019231d4119001ac470', 1, 'LLaMa', ' Vice President.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 13 What did Luther do at the end of his speech? ('56f82549a6d7ea1400e17415', 1, 'LLaMa', ' He raised his arm.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 14 Who considers Luther's speech a world classic? ('56f82549a6d7ea1400e17417', 1, 'LLaMa', 'Michael Mullet.\\n\\\\end{blockquote}\\n\\nI have tried to use `nltk` and `spacy`, but I couldn')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 15 What are two examples of measurements are bound within algorithms to establish complexity classes? ('56e1c3e1e3433e1400423148', 1, 'LLaMa', ' Time and Space.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 16 What is similar to vocational training? ('56e748a200c9c71400d76f39', 1, 'LLaMa', ' Craftsmanship.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 17 What is the role of teachers in education? ('56e7504437bdd419002c3e5e', 1, 'LLaMa', ' Teachers facilitate student learning.\\n\\\\end{blockquote}\\n\\nI have tried to use the following code but it does not work properly')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 18 Aside from BBC Radio 5, what radio station will broadcast the game? ('56bec5ff3aeaaa14008c93e4', 1, 'LLaMa', 'BBC Radio 5 Live and 5 Live Sports Extra.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 19 Who makes up the BBC commentary team with Greg Brady and Rocky Boiman? ('56bec5ff3aeaaa14008c93e5', 1, 'LLaMa', \"Darren Fletcher.\\n\\\\end{blockquote}\\n\\nI'm trying to use a regex like this one:\\n\\n\\\\\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 20 Who sold the rights? ('56de49a8cffd8e1900b4b7a9', 1, 'LLaMa', 'Maciot de Betancourt.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 21 Who bought the rights? ('56de49a8cffd8e1900b4b7a8', 1, 'LLaMa', 'Enrique Pérez de Guzmán, 2nd Count de Niebla.\\n\\\\end{blockquote}\\n\\nI have tried this code')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 22 What kind of media can references to Tesla be found in ('56e126dae3433e1400422c7d', 1, 'LLaMa', ' Books, Films, Radio, TV, Music, Live Theater, Comics and Video Games.\\n\\\\end{blockquote}\\n\\nI have tried to')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 23 What does CBD stand for? ('57060a6e52bb8914006897f9', 1, 'LLaMa', \"Central Business Districts.\\n\\\\end{blockquote}\\n\\nI have tried this code but it doesn't work properly.\\n\\n\\\\\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 24 What is the only district in the CBD to not have \"downtown\" in it's name? ('57060a6e52bb8914006897fa', 1, 'LLaMa', \" South Coast Metro.\\n\\\\end{blockquote}\\n\\nI am trying to solve this problem with a neural network but I don't know how\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 25 What religion did Tesla grow up in? ('56e124f1cd28a01900c6764f', 1, 'LLaMa', 'Orthodox Christian.\\n\\\\end{blockquote}\\n\\nI have tried to use the following code but it is giving me wrong answers. I')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 26 What was the teacher's role while the child was with them? ('56e7578a37bdd419002c3eaa', 1, 'LLaMa', ' The teacher acted as a substitute parent.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 27 Who is most likely to teach a child at home? ('56e749dd00c9c71400d76f51', 1, 'LLaMa', \" Family members.\\n\\\\end{blockquote}\\n\\nI have tried this code but it doesn't work for me. I am getting an error\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 28 If someone is being taught at their place of residence, what is it called? ('56e749dd00c9c71400d76f52', 1, 'LLaMa', ' Home Schooling.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 29 Who won the competition to get a free Super Bowl commercial aired? ('56d9be16dc89441400fdb771', 1, 'LLaMa', 'Death Wish Coffee\\n\\n### Reading Comprehension\\n\\nThe reading comprehension section consists of three texts and questions about')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 30 What company won a free advertisement due to the QuickBooks contest? ('56bec38b3aeaaa14008c9398', 1, 'LLaMa', 'Death Wish Coffee.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 31 Who were the Westwood one color analysts? ('56d9c049dc89441400fdb78f', 1, 'LLaMa', 'Boomer Esiason and Dan Fouts.\\n\\\\end{blockquote}\\n\\nI have tried to use this code but it is not working')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 32 Who were the Westwood One sideline announcers? ('56d9c049dc89441400fdb790', 1, 'LLaMa', \"James Lofton and Mark Malone.\\n\\\\end{blockquote}\\n\\nI have tried to use this code but it doesn't work\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 33 What area did the Westwood One broadcast cover? ('56d9c049dc89441400fdb792', 1, 'LLaMa', 'North America.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 34 Along with Dan Fouts, who served as a color analyst for the radio broadcast? ('56bec4a33aeaaa14008c93b4', 1, 'LLaMa', \"Boomer Esiason.\\n\\\\end{blockquote}\\n\\nI have tried to use this code but it doesn't work properly.\\n\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 35 Who was Tesla prejudiced against? ('56e12005cd28a01900c67617', 1, 'LLaMa', ' Overweight People.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 36 What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P? ('56e1f10ee3433e1400423226', 1, 'LLaMa', ' It is not known whether these classes are distinct or equal.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 37 What did he hope to locate underground? ('56e10d2dcd28a01900c674da', 1, 'LLaMa', ' Minerals.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{code')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 38 What did Tesla claim to be able to transmit? ('56e10d2dcd28a01900c674d7', 1, 'LLaMa', ' Mechanical Energy\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 39 What was another use for the weapon? ('56e10e73cd28a01900c674ee', 1, 'LLaMa', ' Anti-Aircraft Purposes.\\n\\\\end{blockquote}\\n\\nI have tried this code but I am not getting any output. Can anyone')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 40 What does AC stand for? ('56e0b94b7aa994140058e6bb', 1, 'LLaMa', 'Alternate Current\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 41 Who published Tesla's writings? ('56e125b6e3433e1400422c6d', 1, 'LLaMa', 'Ben Johnson, David Hatcher Childress\\n\\\\end{blockquote}\\n\\nI have tried to solve this problem with the following code but it')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 42 Who made Ralph earl? ('56de3d594396321400ee26cc', 1, 'LLaMa', 'Edward the confessor.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 43 Who cannot be employed by a school in any manner? ('56e772bf37bdd419002c3fbf', 1, 'LLaMa', ' Those who refuse vetting.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 44 Who patronized the monks in Italy? ('56de52614396321400ee27fd', 1, 'LLaMa', 'Robert Guiscard.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 45 Who was Tesla's nephew? ('56e1127bcd28a01900c6754a', 1, 'LLaMa', 'Sava Kosanovic.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 46 Who transported Tesla's ashes from the US. ('56e1127bcd28a01900c6754b', 1, 'LLaMa', 'Charlotte Muzar.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 47 Who translated and printed Luther's 95 These? ('56f8074faef2371900625d7b', 1, 'LLaMa', ' Friends of Luther.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is giving me wrong answers. I am new to')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 48 Who called their system the \"Tesla Polyphase System\"? ('56e0e69b7aa994140058e797', 1, 'LLaMa', 'Westinghouse Electric.\\n\\\\end{blockquote}\\n\\nI have tried to use the following code but it is not working properly.\\n\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 49 Who was Philip I? ('56f88c37aef2371900626177', 1, 'LLaMa', 'Landgrave of Hesse.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 50 Who were special guests for the Super Bowl halftime show? ('56d602631c85041400946edb', 1, 'LLaMa', 'Beyonce and Bruno Mars.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 51 Who did Tesla partner with in 1886? ('56dfb5777aa994140058e021', 1, 'LLaMa', 'Robert Lane and Benjamin Vail.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 52 Who did Luther banish? ('56f84b68aef2371900625fa9', 1, 'LLaMa', ' The Zwickau Prophets.\\n\\\\end{blockquote}\\n\\nI have tried this code so far:\\n\\n\\\\begin{code')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 53 Who hired Tesla in New York? ('56e0d54a7aa994140058e76c', 1, 'LLaMa', 'Thomas Edison\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not giving me the desired output.\\n\\n\\\\')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 54 Who hired Tesla when he moved to New York? ('56dfb0c8231d4119001abc86', 1, 'LLaMa', 'Thomas Edison\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not giving me the desired output. I am getting')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 55 Who conducted this survey? ('56e7673a37bdd419002c3f57', 1, 'LLaMa', 'American Association of University Women.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 56 Who was in charge of the papal army in the War of Barbastro? ('56de3e414396321400ee26d9', 1, 'LLaMa', 'William of Montreuil.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 57 Who presided over the assembly? ('56f8225ea6d7ea1400e173f4', 1, 'LLaMa', 'Emperor Charles V.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 58 Who defeated the rebels at the Battle of Frankenhausen? ('56f851b1a6d7ea1400e1755e', 1, 'LLaMa', ' The Swabian League.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 59 Who performed the funeral for Martin Luther? ('56f8c9719e9bad19000a04e4', 1, 'LLaMa', 'Johannes Bugenhagen and Philipp Melanchthon.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 0 What site is located in the San Francisco Bay Area? ('56beb03c3aeaaa14008c920d', 2, 'LLaMa', \"Levi's Stadium.\\n\\\\end{blockquote}\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 1 What Florida stadium was considered for Super Bowl 50? ('56d98db6dc89441400fdb552', 2, 'LLaMa', 'Sun Life Stadium.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 2 What is the name of the stadium in Miami that was considered? ('56d6ee6e0d65d21400198256', 2, 'LLaMa', \"Sun Life Stadium.\\n\\\\end{blockquote}\\n\\nI have tried this code but it doesn't seem to be working properly. I\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 3 What venue in Miami was a candidate for the site of Super Bowl 50? ('56beb03c3aeaaa14008c920b', 2, 'LLaMa', 'Sun Life Stadium.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 4 What was the given name of Miami's stadium at the time of Super Bowl 50? ('56bf3c633aeaaa14008c9582', 2, 'LLaMa', 'Sun Life Stadium.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 5 What was the name of New Orleans' superdome at the time that Super Bowl 50 took place? ('56bf3c633aeaaa14008c9581', 2, 'LLaMa', 'Mercedes-Benz Superdome.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 6 What award has Marlee Matlin won? ('56bec6ac3aeaaa14008c93ff', 2, 'LLaMa', 'Academy Award.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 7 What actress did the ASL translation for the game? ('56d20650e7d4791d00902615', 2, 'LLaMa', 'Marlee Matlin.\\n\\\\end{blockquote}\\n\\nI have tried to solve this problem by using a simple approach of finding the word that')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 8 Who did the sign language of the National Anthem at Super Bowl 50? ('56d9c455dc89441400fdb7c6', 2, 'LLaMa', 'Marlee Matlin.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 9 What actor did sign language for the National Anthem at Superbowl 50? ('56d7253b0d65d214001983d5', 2, 'LLaMa', 'Marlee Matlin.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 10 What became the foundation of the Reformation? ('56f80e1daef2371900625d8e', 2, 'LLaMa', ' Luther\\'s rediscovery of \"Christ and His salvation\".\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 11 What fueled Luther's  concept of Christ and His Salvation? ('56f80e1daef2371900625d8f', 2, 'LLaMa', ' The rediscovery of Christ and his salvation.\\n\\\\end{blockquote}\\n\\nI have tried to use this code but I am not')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 12 What position did Tesla hold in the American Institute of Electrical Engineers? ('56e0f019231d4119001ac470', 2, 'LLaMa', ' Vice President.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{code}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 13 What did Luther do at the end of his speech? ('56f82549a6d7ea1400e17415', 2, 'LLaMa', ' He raised his arm.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 14 Who considers Luther's speech a world classic? ('56f82549a6d7ea1400e17417', 2, 'LLaMa', 'Michael Mullet.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 15 What are two examples of measurements are bound within algorithms to establish complexity classes? ('56e1c3e1e3433e1400423148', 2, 'LLaMa', ' Time and Space.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 16 What is similar to vocational training? ('56e748a200c9c71400d76f39', 2, 'LLaMa', ' Craftsmanship.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 17 What is the role of teachers in education? ('56e7504437bdd419002c3e5e', 2, 'LLaMa', ' Teachers facilitate student learning.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 18 Aside from BBC Radio 5, what radio station will broadcast the game? ('56bec5ff3aeaaa14008c93e4', 2, 'LLaMa', \" 5 Live Sports Extra.\\n\\\\end{blockquote}\\n\\nI'm trying to use a regex like this one:\\n\\n\\\\\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 19 Who makes up the BBC commentary team with Greg Brady and Rocky Boiman? ('56bec5ff3aeaaa14008c93e5', 2, 'LLaMa', \"Darren Fletcher.\\n\\\\end{blockquote}\\n\\nI'm trying to use a regex like this one:\\n\\n\\\\\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 20 Who sold the rights? ('56de49a8cffd8e1900b4b7a9', 2, 'LLaMa', 'Maciot de Bettencourt.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 21 Who bought the rights? ('56de49a8cffd8e1900b4b7a8', 2, 'LLaMa', 'Enrique Pérez de Guzmán, 2nd Count de Niebla.\\n\\\\end{blockquote}\\n\\nI have tried with this')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 22 What kind of media can references to Tesla be found in ('56e126dae3433e1400422c7d', 2, 'LLaMa', ' Books, Films, Radio, TV, Music, Live Theater, Comics and Video Games.\\n\\\\end{blockquote}\\n\\nI have tried to')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 23 What does CBD stand for? ('57060a6e52bb8914006897f9', 2, 'LLaMa', 'Central Business Districts.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 24 What is the only district in the CBD to not have \"downtown\" in it's name? ('57060a6e52bb8914006897fa', 2, 'LLaMa', \" South Coast Metro.\\n\\\\end{blockquote}\\n\\nI am trying to solve this problem with a neural network but I don't know how\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 25 What religion did Tesla grow up in? ('56e124f1cd28a01900c6764f', 2, 'LLaMa', 'Orthodox Christian.\\n\\\\end{blockquote}\\n\\nI have tried to use the following code but it is not working as expected.\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 26 What was the teacher's role while the child was with them? ('56e7578a37bdd419002c3eaa', 2, 'LLaMa', ' A substitute parent.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{code')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 27 Who is most likely to teach a child at home? ('56e749dd00c9c71400d76f51', 2, 'LLaMa', \" Family Member.\\n\\\\end{blockquote}\\n\\nI have tried this code but it doesn't seem to work for me. I am not\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 28 If someone is being taught at their place of residence, what is it called? ('56e749dd00c9c71400d76f52', 2, 'LLaMa', ' Home Schooling.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 29 Who won the competition to get a free Super Bowl commercial aired? ('56d9be16dc89441400fdb771', 2, 'LLaMa', 'Death Wish Coffee.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 30 What company won a free advertisement due to the QuickBooks contest? ('56bec38b3aeaaa14008c9398', 2, 'LLaMa', 'Death Wish Coffee.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 31 Who were the Westwood one color analysts? ('56d9c049dc89441400fdb78f', 2, 'LLaMa', \"Boomer Esiason and Dan Fouts.\\n\\\\end{blockquote}\\n\\nI have tried to use this code but it doesn't\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 32 Who were the Westwood One sideline announcers? ('56d9c049dc89441400fdb790', 2, 'LLaMa', \"James Lofton and Mark Malone.\\n\\\\end{blockquote}\\n\\nI have tried to use this code but it doesn't work\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 33 What area did the Westwood One broadcast cover? ('56d9c049dc89441400fdb792', 2, 'LLaMa', 'North America.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 34 Along with Dan Fouts, who served as a color analyst for the radio broadcast? ('56bec4a33aeaaa14008c93b4', 2, 'LLaMa', \"Boomer Esiason.\\n\\\\end{blockquote}\\n\\nI have tried to use this code but it doesn't work properly.\\n\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 35 Who was Tesla prejudiced against? ('56e12005cd28a01900c67617', 2, 'LLaMa', \" Overweight People.\\n\\\\end{blockquote}\\n\\nI have tried to solve this problem by using NLTK's chunker but it\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 36 What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P? ('56e1f10ee3433e1400423226', 2, 'LLaMa', ' It is not known if L (the set of all problems that can be solved in logarithmic space) is strictly contained in P or equal to')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 37 What did he hope to locate underground? ('56e10d2dcd28a01900c674da', 2, 'LLaMa', ' Minerals.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n\\\\begin{code')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 38 What did Tesla claim to be able to transmit? ('56e10d2dcd28a01900c674d7', 2, 'LLaMa', ' Mechanical Energy.\\n\\\\end{blockquote}\\n\\nI have tried to use `spacy` but it is not working for me. I')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 39 What was another use for the weapon? ('56e10e73cd28a01900c674ee', 2, 'LLaMa', ' Anti-Aircraft Purposes.\\n\\\\end{blockquote}\\n\\nI have tried this code but I am not getting any output. Can anyone')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 40 What does AC stand for? ('56e0b94b7aa994140058e6bb', 2, 'LLaMa', ' Alternating Current.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 41 Who published Tesla's writings? ('56e125b6e3433e1400422c6d', 2, 'LLaMa', 'Ben Johnston and David Hatcher Childress.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 42 Who made Ralph earl? ('56de3d594396321400ee26cc', 2, 'LLaMa', 'Edward the confessor.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 43 Who cannot be employed by a school in any manner? ('56e772bf37bdd419002c3fbf', 2, 'LLaMa', ' Those who refuse vetting.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 44 Who patronized the monks in Italy? ('56de52614396321400ee27fd', 2, 'LLaMa', 'Robert Guiscard.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 45 Who was Tesla's nephew? ('56e1127bcd28a01900c6754a', 2, 'LLaMa', 'Sava Kosanovic.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 46 Who transported Tesla's ashes from the US. ('56e1127bcd28a01900c6754b', 2, 'LLaMa', 'Charlotte Muzar.\\n\\\\end{blockquote}\\n\\nI have tried with this code but it is not working properly.\\n\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 47 Who translated and printed Luther's 95 These? ('56f8074faef2371900625d7b', 2, 'LLaMa', ' Friends of Luther.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 48 Who called their system the \"Tesla Polyphase System\"? ('56e0e69b7aa994140058e797', 2, 'LLaMa', 'Westinghouse Electric.\\n\\\\end{blockquote}\\n\\nI have tried to use `nltk` but I am unable to find a')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 49 Who was Philip I? ('56f88c37aef2371900626177', 2, 'LLaMa', 'Landgrave of Hesse.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 50 Who were special guests for the Super Bowl halftime show? ('56d602631c85041400946edb', 2, 'LLaMa', 'Beyonce and Bruno Mars.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 51 Who did Tesla partner with in 1886? ('56dfb5777aa994140058e021', 2, 'LLaMa', 'Robert Lane and Benjamin Vail.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not working properly.\\n\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 52 Who did Luther banish? ('56f84b68aef2371900625fa9', 2, 'LLaMa', ' The Zwickau Prophets.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 53 Who hired Tesla in New York? ('56e0d54a7aa994140058e76c', 2, 'LLaMa', 'Thomas Edison.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 54 Who hired Tesla when he moved to New York? ('56dfb0c8231d4119001abc86', 2, 'LLaMa', 'Thomas Edison.\\n\\\\end{blockquote}\\n\\nI have tried this code but it is not giving me the desired output.\\n\\n')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 55 Who conducted this survey? ('56e7673a37bdd419002c3f57', 2, 'LLaMa', 'American Association of University Women.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 56 Who was in charge of the papal army in the War of Barbastro? ('56de3e414396321400ee26d9', 2, 'LLaMa', \"William of Montreuil.\\n\\\\end{blockquote}\\n\\nI'm trying to use this code:\\n\\n\\\\begin{code\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "Llama Response not ready após 'get_result' 10 sem erro 429\n",
            "ndx 57 Who presided over the assembly? ('56f8225ea6d7ea1400e173f4', 2, 'LLaMa', \"Emperor Charles V.\\n\\\\end{blockquote}\\n\\nI'm trying to use this code but it doesn't work properly because I\")\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 58 Who defeated the rebels at the Battle of Frankenhausen? ('56f851b1a6d7ea1400e1755e', 2, 'LLaMa', ' The Swabian League.\\n\\\\end{blockquote}')\n",
            "Esperando antes do primeiro 'get_result' 10 devido a erro 429\n",
            "ndx 59 Who performed the funeral for Martin Luther? ('56f8c9719e9bad19000a04e4', 2, 'LLaMa', 'Johannes Bugenhagen and Philipp Melanchthon.\\n\\\\end{blockquote}')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_erro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdndXamuMT2z",
        "outputId": "153850f4-49fe-41a2-a53f-8167105de49f"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_respostas = pd.DataFrame(lista_resposta, columns=['id_question', 'cod_prompt', 'nome_modelo', 'resposta'])"
      ],
      "metadata": {
        "id": "DcoAqVipIJDR"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_respostas.to_csv(f'{path_data}/df_respostas.csv')"
      ],
      "metadata": {
        "id": "Skpzkd23Jgt_"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_erro = pd.DataFrame(lista_erro, columns=['id_question', 'cod_prompt', 'nome_modelo'])"
      ],
      "metadata": {
        "id": "xhS_FPrFJhlu"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_erro.to_csv(f'{path_data}/df_erro.csv')"
      ],
      "metadata": {
        "id": "X6l9u81gLWG0"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complementando para o ChatGPT\n",
        "\n",
        "A execução anterior terminou 3h10, durando cerca de 3 horas (por causa do time.sleep(20)) "
      ],
      "metadata": {
        "id": "jkAo-YKkupJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_modelo = {# 'Code_DaVinci':code_davinci_model,\n",
        "               # 'LLaMa': llama_model,\n",
        "               'chatgpt': chatgpt_model\n",
        "                }"
      ],
      "metadata": {
        "id": "oogyHpLUusn2"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_resposta = []\n",
        "lista_erro = []\n",
        "for nome_modelo, modelo in dict_modelo.items():\n",
        "  for cod_prompt in [0, 1, 2]:\n",
        "    for ndx, row in df_selecao.reset_index().iterrows():\n",
        "      try:\n",
        "        prompt_aux = retorna_prompt(cod_prompt=cod_prompt, texto_pergunta=row['question'], texto_contexto=row['context'])\n",
        "        resposta = modelo.answer_one_question(prompt_aux)\n",
        "        resultado = (row['id'], cod_prompt, nome_modelo, resposta)\n",
        "        print(f'ndx {ndx} {row[\"question\"]} {resultado}')\n",
        "        lista_resposta.append(resultado)\n",
        "        time.sleep(5)\n",
        "      except Exception as e:\n",
        "        print(f'Erro em ndx {ndx} id: {row[\"id\"]} nome_modelo: {nome_modelo} cod_prompt: {cod_prompt}')\n",
        "        print(f'Erro: {e}')\n",
        "        lista_erro.append((row[\"id\"], cod_prompt, nome_modelo))\n",
        "        continue        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d59392e-f9b1-4e82-869b-5b3f77d129b0",
        "id": "orOo_DTzusn3"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndx 0 What site is located in the San Francisco Bay Area? ('56beb03c3aeaaa14008c920d', 0, 'chatgpt', \"Levi's Stadium is located in the San Francisco Bay Area.\")\n",
            "ndx 1 What Florida stadium was considered for Super Bowl 50? ('56d98db6dc89441400fdb552', 0, 'chatgpt', 'Sun Life Stadium in Miami was considered for Super Bowl 50.')\n",
            "ndx 2 What is the name of the stadium in Miami that was considered? ('56d6ee6e0d65d21400198256', 0, 'chatgpt', 'The stadium in Miami that was considered is called Sun Life Stadium.')\n",
            "ndx 3 What venue in Miami was a candidate for the site of Super Bowl 50? ('56beb03c3aeaaa14008c920b', 0, 'chatgpt', 'Sun Life Stadium.')\n",
            "ndx 4 What was the given name of Miami's stadium at the time of Super Bowl 50? ('56bf3c633aeaaa14008c9582', 0, 'chatgpt', \"Miami's stadium was called Sun Life Stadium at the time of Super Bowl 50.\")\n",
            "ndx 5 What was the name of New Orleans' superdome at the time that Super Bowl 50 took place? ('56bf3c633aeaaa14008c9581', 0, 'chatgpt', \"The name of New Orleans' superdome at the time of Super Bowl 50 was Mercedes-Benz Superdome.\")\n",
            "ndx 6 What award has Marlee Matlin won? ('56bec6ac3aeaaa14008c93ff', 0, 'chatgpt', 'Marlee Matlin has won an Academy Award.')\n",
            "ndx 7 What actress did the ASL translation for the game? ('56d20650e7d4791d00902615', 0, 'chatgpt', 'Marlee Matlin provided American Sign Language (ASL) translation.')\n",
            "ndx 8 Who did the sign language of the National Anthem at Super Bowl 50? ('56d9c455dc89441400fdb7c6', 0, 'chatgpt', 'Marlee Matlin provided American Sign Language (ASL) translation.')\n",
            "ndx 9 What actor did sign language for the National Anthem at Superbowl 50? ('56d7253b0d65d214001983d5', 0, 'chatgpt', 'Marlee Matlin provided American Sign Language (ASL) translation for the National Anthem at Superbowl 50.')\n",
            "ndx 10 What became the foundation of the Reformation? ('56f80e1daef2371900625d8e', 0, 'chatgpt', 'The foundation of the Reformation was Luther\\'s rediscovery of \"Christ and His salvation.\"')\n",
            "ndx 11 What fueled Luther's  concept of Christ and His Salvation? ('56f80e1daef2371900625d8f', 0, 'chatgpt', 'Luther\\'s rediscovery of \"Christ and His salvation\" fueled his concept of it.')\n",
            "ndx 12 What position did Tesla hold in the American Institute of Electrical Engineers? ('56e0f019231d4119001ac470', 0, 'chatgpt', 'Tesla served as a vice president of the American Institute of Electrical Engineers.')\n",
            "ndx 13 What did Luther do at the end of his speech? ('56f82549a6d7ea1400e17415', 0, 'chatgpt', 'Luther raised his arm \"in the traditional salute of a knight winning a bout.\"')\n",
            "ndx 14 Who considers Luther's speech a world classic? ('56f82549a6d7ea1400e17417', 0, 'chatgpt', 'Michael Mullett considers Luther\\'s speech a \"world classic of epoch-making oratory.\"')\n",
            "ndx 15 What are two examples of measurements are bound within algorithms to establish complexity classes? ('56e1c3e1e3433e1400423148', 0, 'chatgpt', 'Time and space are measurements bound within algorithms to establish complexity classes.')\n",
            "ndx 16 What is similar to vocational training? ('56e748a200c9c71400d76f39', 0, 'chatgpt', 'Craftsmanship is similar to vocational training.')\n",
            "ndx 17 What is the role of teachers in education? ('56e7504437bdd419002c3e5e', 0, 'chatgpt', 'Teachers facilitate student learning in various environments such as schools, academies, or outdoors. They may also be described as tutors when teaching on an individual')\n",
            "ndx 18 Aside from BBC Radio 5, what radio station will broadcast the game? ('56bec5ff3aeaaa14008c93e4', 0, 'chatgpt', 'BBC Radio 5 Live Sports Extra will also carry the contest.')\n",
            "ndx 19 Who makes up the BBC commentary team with Greg Brady and Rocky Boiman? ('56bec5ff3aeaaa14008c93e5', 0, 'chatgpt', 'Darren Fletcher is part of the BBC commentary team with Greg Brady and Rocky Boiman.')\n",
            "ndx 20 Who sold the rights? ('56de49a8cffd8e1900b4b7a9', 0, 'chatgpt', 'Maciot de Bethencourt sold the rights to the Canary Islands.')\n",
            "ndx 21 Who bought the rights? ('56de49a8cffd8e1900b4b7a8', 0, 'chatgpt', 'Enrique Pérez de Guzmán, 2nd Count de Niebla bought the rights.')\n",
            "ndx 22 What kind of media can references to Tesla be found in ('56e126dae3433e1400422c7d', 0, 'chatgpt', 'References to Tesla can be found in books, films, radio, TV, music, live theater, comics, and video games.')\n",
            "ndx 23 What does CBD stand for? ('57060a6e52bb8914006897f9', 0, 'chatgpt', 'CBD stands for Central Business District.')\n",
            "ndx 24 What is the only district in the CBD to not have \"downtown\" in it's name? ('57060a6e52bb8914006897fa', 0, 'chatgpt', 'South Coast Metro is the only district in the CBD to not have \"downtown\" in its name.')\n",
            "ndx 25 What religion did Tesla grow up in? ('56e124f1cd28a01900c6764f', 0, 'chatgpt', 'Tesla was raised an Orthodox Christian.')\n",
            "ndx 26 What was the teacher's role while the child was with them? ('56e7578a37bdd419002c3eaa', 0, 'chatgpt', 'The teacher was expected to act as a substitute parent, with all the normal forms of parental discipline open to them.')\n",
            "ndx 27 Who is most likely to teach a child at home? ('56e749dd00c9c71400d76f51', 0, 'chatgpt', 'A family member or anyone with knowledge or skills in the wider community setting is most likely to teach a child at home.')\n",
            "ndx 28 If someone is being taught at their place of residence, what is it called? ('56e749dd00c9c71400d76f52', 0, 'chatgpt', 'It is called home schooling.')\n",
            "ndx 29 Who won the competition to get a free Super Bowl commercial aired? ('56d9be16dc89441400fdb771', 0, 'chatgpt', 'Death Wish Coffee won the competition to get a free Super Bowl commercial aired.')\n",
            "ndx 30 What company won a free advertisement due to the QuickBooks contest? ('56bec38b3aeaaa14008c9398', 0, 'chatgpt', 'Death Wish Coffee won a free advertisement due to the QuickBooks contest.')\n",
            "ndx 31 Who were the Westwood one color analysts? ('56d9c049dc89441400fdb78f', 0, 'chatgpt', 'The Westwood one color analysts were Boomer Esiason and Dan Fouts.')\n",
            "ndx 32 Who were the Westwood One sideline announcers? ('56d9c049dc89441400fdb790', 0, 'chatgpt', 'James Lofton and Mark Malone were the Westwood One sideline reporters.')\n",
            "ndx 33 What area did the Westwood One broadcast cover? ('56d9c049dc89441400fdb792', 0, 'chatgpt', 'Westwood One will carry the game throughout North America.')\n",
            "ndx 34 Along with Dan Fouts, who served as a color analyst for the radio broadcast? ('56bec4a33aeaaa14008c93b4', 0, 'chatgpt', 'James Lofton and Mark Malone served as sideline reporters for the radio broadcast.')\n",
            "ndx 35 Who was Tesla prejudiced against? ('56e12005cd28a01900c67617', 0, 'chatgpt', 'Tesla was prejudiced against overweight people and had openly expressed disgust for them.')\n",
            "ndx 36 What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P? ('56e1f10ee3433e1400423226', 0, 'chatgpt', 'It is not known if the complexity classes between L and P, such as NL and NC, are distinct or equal classes.')\n",
            "ndx 37 What did he hope to locate underground? ('56e10d2dcd28a01900c674da', 0, 'chatgpt', 'Tesla hoped to accurately determine the location of underground mineral deposits.')\n",
            "ndx 38 What did Tesla claim to be able to transmit? ('56e10d2dcd28a01900c674d7', 0, 'chatgpt', 'Tesla claimed to be able to transmit mechanical energy with minimal loss over any terrestrial distance.')\n",
            "ndx 39 What was another use for the weapon? ('56e10e73cd28a01900c674ee', 0, 'chatgpt', 'Tesla described the weapon as capable of being used for anti-aircraft purposes.')\n",
            "ndx 40 What does AC stand for? ('56e0b94b7aa994140058e6bb', 0, 'chatgpt', 'AC stands for alternating current, as mentioned in the text.')\n",
            "ndx 41 Who published Tesla's writings? ('56e125b6e3433e1400422c6d', 0, 'chatgpt', \"Ben Johnston and David Hatcher Childress compiled and edited some of Tesla's books, while The Tesla Papers were also published.\")\n",
            "ndx 42 Who made Ralph earl? ('56de3d594396321400ee26cc', 0, 'chatgpt', 'Edward the Confessor made Ralph earl.')\n",
            "ndx 43 Who cannot be employed by a school in any manner? ('56e772bf37bdd419002c3fbf', 0, 'chatgpt', 'Those who refuse vetting \"cannot be appointed or engaged by the school in any capacity including in a voluntary role\".')\n",
            "ndx 44 Who patronized the monks in Italy? ('56de52614396321400ee27fd', 0, 'chatgpt', 'The monks in Italy were patronized by Robert Guiscard.')\n",
            "ndx 45 Who was Tesla's nephew? ('56e1127bcd28a01900c6754a', 0, 'chatgpt', \"Tesla's nephew was Sava Kosanović.\")\n",
            "ndx 46 Who transported Tesla's ashes from the US. ('56e1127bcd28a01900c6754b', 0, 'chatgpt', \"Tesla's ashes were transported from the United States to Belgrade by Sava Kosanović's secretary, Charlotte Muzar.\")\n",
            "ndx 47 Who translated and printed Luther's 95 These? ('56f8074faef2371900625d7b', 0, 'chatgpt', 'Friends of Luther translated the 95 Theses from Latin into German and printed and widely copied them.')\n",
            "ndx 48 Who called their system the \"Tesla Polyphase System\"? ('56e0e69b7aa994140058e797', 0, 'chatgpt', 'Westinghouse Electric called their complete polyphase AC system the \"Tesla Polyphase System\".')\n",
            "ndx 49 Who was Philip I? ('56f88c37aef2371900626177', 0, 'chatgpt', 'Philip I was the Landgrave of Hesse who convoked an assembly of German and Swiss theologians at the Marburg Colloquy in')\n",
            "ndx 50 Who were special guests for the Super Bowl halftime show? ('56d602631c85041400946edb', 0, 'chatgpt', 'Beyoncé and Bruno Mars were special guests for the Super Bowl halftime show.')\n",
            "ndx 51 Who did Tesla partner with in 1886? ('56dfb5777aa994140058e021', 0, 'chatgpt', 'Tesla partnered with Robert Lane and Benjamin Vail in 1886.')\n",
            "ndx 52 Who did Luther banish? ('56f84b68aef2371900625fa9', 0, 'chatgpt', 'Luther banished the Zwickau prophets.')\n",
            "ndx 53 Who hired Tesla in New York? ('56e0d54a7aa994140058e76c', 0, 'chatgpt', \"Tesla was hired by Thomas Edison to work at his Edison Machine Works on Manhattan's lower east side.\")\n",
            "ndx 54 Who hired Tesla when he moved to New York? ('56dfb0c8231d4119001abc86', 0, 'chatgpt', 'Thomas Edison hired Tesla when he moved to New York.')\n",
            "ndx 55 Who conducted this survey? ('56e7673a37bdd419002c3f57', 0, 'chatgpt', 'The survey was conducted by the American Association of University Women.')\n",
            "ndx 56 Who was in charge of the papal army in the War of Barbastro? ('56de3e414396321400ee26d9', 0, 'chatgpt', 'William of Montreuil led the papal army in the War of Barbastro.')\n",
            "ndx 57 Who presided over the assembly? ('56f8225ea6d7ea1400e173f4', 0, 'chatgpt', 'Emperor Charles V presided over the assembly.')\n",
            "ndx 58 Who defeated the rebels at the Battle of Frankenhausen? ('56f851b1a6d7ea1400e1755e', 0, 'chatgpt', 'The Swabian League defeated the rebels at the Battle of Frankenhausen.')\n",
            "ndx 59 Who performed the funeral for Martin Luther? ('56f8c9719e9bad19000a04e4', 0, 'chatgpt', 'Johannes Bugenhagen and Philipp Melanchthon performed the funeral for Martin Luther.')\n",
            "ndx 0 What site is located in the San Francisco Bay Area? ('56beb03c3aeaaa14008c920d', 1, 'chatgpt', \"Levi's Stadium.\")\n",
            "ndx 1 What Florida stadium was considered for Super Bowl 50? ('56d98db6dc89441400fdb552', 1, 'chatgpt', 'Sun Life Stadium.')\n",
            "ndx 2 What is the name of the stadium in Miami that was considered? ('56d6ee6e0d65d21400198256', 1, 'chatgpt', 'Sun Life Stadium.')\n",
            "ndx 3 What venue in Miami was a candidate for the site of Super Bowl 50? ('56beb03c3aeaaa14008c920b', 1, 'chatgpt', 'Sun Life Stadium.')\n",
            "ndx 4 What was the given name of Miami's stadium at the time of Super Bowl 50? ('56bf3c633aeaaa14008c9582', 1, 'chatgpt', 'Sun Life Stadium.')\n",
            "ndx 5 What was the name of New Orleans' superdome at the time that Super Bowl 50 took place? ('56bf3c633aeaaa14008c9581', 1, 'chatgpt', 'The text does not provide the name of the Superdome at the time of Super Bowl 50.')\n",
            "ndx 6 What award has Marlee Matlin won? ('56bec6ac3aeaaa14008c93ff', 1, 'chatgpt', 'Marlee Matlin has won an Academy Award.')\n",
            "ndx 7 What actress did the ASL translation for the game? ('56d20650e7d4791d00902615', 1, 'chatgpt', 'Marlee Matlin.')\n",
            "ndx 8 Who did the sign language of the National Anthem at Super Bowl 50? ('56d9c455dc89441400fdb7c6', 1, 'chatgpt', 'Marlee Matlin provided American Sign Language (ASL) translation.')\n",
            "ndx 9 What actor did sign language for the National Anthem at Superbowl 50? ('56d7253b0d65d214001983d5', 1, 'chatgpt', 'Marlee Matlin provided American Sign Language (ASL) translation for the National Anthem at Superbowl 50.')\n",
            "ndx 10 What became the foundation of the Reformation? ('56f80e1daef2371900625d8e', 1, 'chatgpt', 'Luther\\'s rediscovery of \"Christ and His salvation\".')\n",
            "ndx 11 What fueled Luther's  concept of Christ and His Salvation? ('56f80e1daef2371900625d8f', 1, 'chatgpt', 'Luther\\'s rediscovery of \"Christ and His salvation.\"')\n",
            "ndx 12 What position did Tesla hold in the American Institute of Electrical Engineers? ('56e0f019231d4119001ac470', 1, 'chatgpt', 'Tesla served as a vice president.')\n",
            "ndx 13 What did Luther do at the end of his speech? ('56f82549a6d7ea1400e17415', 1, 'chatgpt', 'Luther raised his arm \"in the traditional salute of a knight winning a bout.\"')\n",
            "ndx 14 Who considers Luther's speech a world classic? ('56f82549a6d7ea1400e17417', 1, 'chatgpt', 'Michael Mullett.')\n",
            "ndx 15 What are two examples of measurements are bound within algorithms to establish complexity classes? ('56e1c3e1e3433e1400423148', 1, 'chatgpt', 'Time and space.')\n",
            "ndx 16 What is similar to vocational training? ('56e748a200c9c71400d76f39', 1, 'chatgpt', 'Craftsmanship.')\n",
            "ndx 17 What is the role of teachers in education? ('56e7504437bdd419002c3e5e', 1, 'chatgpt', 'Teachers facilitate student learning.')\n",
            "ndx 18 Aside from BBC Radio 5, what radio station will broadcast the game? ('56bec5ff3aeaaa14008c93e4', 1, 'chatgpt', 'BBC Radio 5 Live Sports Extra.')\n",
            "ndx 19 Who makes up the BBC commentary team with Greg Brady and Rocky Boiman? ('56bec5ff3aeaaa14008c93e5', 1, 'chatgpt', 'Darren Fletcher.')\n",
            "ndx 20 Who sold the rights? ('56de49a8cffd8e1900b4b7a9', 1, 'chatgpt', 'Maciot de Bethencourt.')\n",
            "ndx 21 Who bought the rights? ('56de49a8cffd8e1900b4b7a8', 1, 'chatgpt', 'Enrique Pérez de Guzmán, 2nd Count de Niebla.')\n",
            "ndx 22 What kind of media can references to Tesla be found in ('56e126dae3433e1400422c7d', 1, 'chatgpt', \"Tesla's legacy can be found in books, films, radio, TV, music, live theater, comics and video games.\")\n",
            "ndx 23 What does CBD stand for? ('57060a6e52bb8914006897f9', 1, 'chatgpt', 'CBD stands for Central Business District.')\n",
            "ndx 24 What is the only district in the CBD to not have \"downtown\" in it's name? ('57060a6e52bb8914006897fa', 1, 'chatgpt', 'South Coast Metro.')\n",
            "ndx 25 What religion did Tesla grow up in? ('56e124f1cd28a01900c6764f', 1, 'chatgpt', 'Tesla was raised an Orthodox Christian.')\n",
            "ndx 26 What was the teacher's role while the child was with them? ('56e7578a37bdd419002c3eaa', 1, 'chatgpt', 'The teacher was expected to act as a substitute parent, with all the normal forms of parental discipline open to them.')\n",
            "ndx 27 Who is most likely to teach a child at home? ('56e749dd00c9c71400d76f51', 1, 'chatgpt', 'A family member or anyone with knowledge or skills in the wider community setting.')\n",
            "ndx 28 If someone is being taught at their place of residence, what is it called? ('56e749dd00c9c71400d76f52', 1, 'chatgpt', 'Home schooling.')\n",
            "ndx 29 Who won the competition to get a free Super Bowl commercial aired? ('56d9be16dc89441400fdb771', 1, 'chatgpt', 'Death Wish Coffee.')\n",
            "ndx 30 What company won a free advertisement due to the QuickBooks contest? ('56bec38b3aeaaa14008c9398', 1, 'chatgpt', 'Death Wish Coffee.')\n",
            "ndx 31 Who were the Westwood one color analysts? ('56d9c049dc89441400fdb78f', 1, 'chatgpt', 'Boomer Esiason and Dan Fouts.')\n",
            "ndx 32 Who were the Westwood One sideline announcers? ('56d9c049dc89441400fdb790', 1, 'chatgpt', 'James Lofton and Mark Malone.')\n",
            "ndx 33 What area did the Westwood One broadcast cover? ('56d9c049dc89441400fdb792', 1, 'chatgpt', 'Westwood One will carry the game throughout North America.')\n",
            "ndx 34 Along with Dan Fouts, who served as a color analyst for the radio broadcast? ('56bec4a33aeaaa14008c93b4', 1, 'chatgpt', 'Boomer Esiason.')\n",
            "ndx 35 Who was Tesla prejudiced against? ('56e12005cd28a01900c67617', 1, 'chatgpt', 'Tesla was prejudiced against overweight people.')\n",
            "ndx 36 What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P? ('56e1f10ee3433e1400423226', 1, 'chatgpt', 'It is not known if the complexity classes between L and P, such as NL and NC, are distinct or equal classes.')\n",
            "ndx 37 What did he hope to locate underground? ('56e10d2dcd28a01900c674da', 1, 'chatgpt', 'Tesla hoped to accurately determine the location of underground mineral deposits.')\n",
            "ndx 38 What did Tesla claim to be able to transmit? ('56e10d2dcd28a01900c674d7', 1, 'chatgpt', 'Tesla claimed to be able to transmit mechanical energy with minimal loss over any terrestrial distance.')\n",
            "ndx 39 What was another use for the weapon? ('56e10e73cd28a01900c674ee', 1, 'chatgpt', 'The weapon could be used for anti-aircraft purposes.')\n",
            "ndx 40 What does AC stand for? ('56e0b94b7aa994140058e6bb', 1, 'chatgpt', 'AC stands for alternating current.')\n",
            "ndx 41 Who published Tesla's writings? ('56e125b6e3433e1400422c6d', 1, 'chatgpt', \"Ben Johnston and David Hatcher Childress compiled and edited some of Tesla's books.\")\n",
            "ndx 42 Who made Ralph earl? ('56de3d594396321400ee26cc', 1, 'chatgpt', 'Edward the Confessor.')\n",
            "ndx 43 Who cannot be employed by a school in any manner? ('56e772bf37bdd419002c3fbf', 1, 'chatgpt', 'Those who refuse vetting.')\n",
            "ndx 44 Who patronized the monks in Italy? ('56de52614396321400ee27fd', 1, 'chatgpt', 'Robert Guiscard.')\n",
            "ndx 45 Who was Tesla's nephew? ('56e1127bcd28a01900c6754a', 1, 'chatgpt', \"Tesla's nephew was Sava Kosanović.\")\n",
            "ndx 46 Who transported Tesla's ashes from the US. ('56e1127bcd28a01900c6754b', 1, 'chatgpt', \"Tesla's ashes were transported from the United States to Belgrade by Kosanović's secretary Charlotte Muzar.\")\n",
            "ndx 47 Who translated and printed Luther's 95 These? ('56f8074faef2371900625d7b', 1, 'chatgpt', 'Friends of Luther.')\n",
            "ndx 48 Who called their system the \"Tesla Polyphase System\"? ('56e0e69b7aa994140058e797', 1, 'chatgpt', 'Westinghouse Electric.')\n",
            "ndx 49 Who was Philip I? ('56f88c37aef2371900626177', 1, 'chatgpt', 'Philip I was the Landgrave of Hesse who convoked an assembly of German and Swiss theologians at the Marburg Colloquy in')\n",
            "ndx 50 Who were special guests for the Super Bowl halftime show? ('56d602631c85041400946edb', 1, 'chatgpt', 'Beyoncé and Bruno Mars.')\n",
            "ndx 51 Who did Tesla partner with in 1886? ('56dfb5777aa994140058e021', 1, 'chatgpt', 'Tesla partnered with Robert Lane and Benjamin Vail in 1886.')\n",
            "ndx 52 Who did Luther banish? ('56f84b68aef2371900625fa9', 1, 'chatgpt', 'Luther banished the Zwickau prophets.')\n",
            "ndx 53 Who hired Tesla in New York? ('56e0d54a7aa994140058e76c', 1, 'chatgpt', 'Thomas Edison.')\n",
            "ndx 54 Who hired Tesla when he moved to New York? ('56dfb0c8231d4119001abc86', 1, 'chatgpt', 'Thomas Edison.')\n",
            "ndx 55 Who conducted this survey? ('56e7673a37bdd419002c3f57', 1, 'chatgpt', 'The American Association of University Women conducted the survey.')\n",
            "ndx 56 Who was in charge of the papal army in the War of Barbastro? ('56de3e414396321400ee26d9', 1, 'chatgpt', 'William of Montreuil.')\n",
            "ndx 57 Who presided over the assembly? ('56f8225ea6d7ea1400e173f4', 1, 'chatgpt', 'Emperor Charles V.')\n",
            "ndx 58 Who defeated the rebels at the Battle of Frankenhausen? ('56f851b1a6d7ea1400e1755e', 1, 'chatgpt', 'The Swabian League.')\n",
            "ndx 59 Who performed the funeral for Martin Luther? ('56f8c9719e9bad19000a04e4', 1, 'chatgpt', \"Martin Luther's friends Johannes Bugenhagen and Philipp Melanchthon performed his funeral.\")\n",
            "ndx 0 What site is located in the San Francisco Bay Area? ('56beb03c3aeaaa14008c920d', 2, 'chatgpt', \"Levi's Stadium.\")\n",
            "ndx 1 What Florida stadium was considered for Super Bowl 50? ('56d98db6dc89441400fdb552', 2, 'chatgpt', 'Sun Life Stadium.')\n",
            "ndx 2 What is the name of the stadium in Miami that was considered? ('56d6ee6e0d65d21400198256', 2, 'chatgpt', 'Sun Life Stadium.')\n",
            "ndx 3 What venue in Miami was a candidate for the site of Super Bowl 50? ('56beb03c3aeaaa14008c920b', 2, 'chatgpt', 'Sun Life Stadium.')\n",
            "ndx 4 What was the given name of Miami's stadium at the time of Super Bowl 50? ('56bf3c633aeaaa14008c9582', 2, 'chatgpt', 'Sun Life Stadium.')\n",
            "ndx 5 What was the name of New Orleans' superdome at the time that Super Bowl 50 took place? ('56bf3c633aeaaa14008c9581', 2, 'chatgpt', 'Mercedes-Benz Superdome.')\n",
            "ndx 6 What award has Marlee Matlin won? ('56bec6ac3aeaaa14008c93ff', 2, 'chatgpt', 'Marlee Matlin has won an Academy Award.')\n",
            "ndx 7 What actress did the ASL translation for the game? ('56d20650e7d4791d00902615', 2, 'chatgpt', 'Marlee Matlin.')\n",
            "ndx 8 Who did the sign language of the National Anthem at Super Bowl 50? ('56d9c455dc89441400fdb7c6', 2, 'chatgpt', 'Marlee Matlin.')\n",
            "ndx 9 What actor did sign language for the National Anthem at Superbowl 50? ('56d7253b0d65d214001983d5', 2, 'chatgpt', 'Marlee Matlin.')\n",
            "ndx 10 What became the foundation of the Reformation? ('56f80e1daef2371900625d8e', 2, 'chatgpt', 'Luther\\'s rediscovery of \"Christ and His salvation\".')\n",
            "ndx 11 What fueled Luther's  concept of Christ and His Salvation? ('56f80e1daef2371900625d8f', 2, 'chatgpt', \"Luther's rediscovery.\")\n",
            "ndx 12 What position did Tesla hold in the American Institute of Electrical Engineers? ('56e0f019231d4119001ac470', 2, 'chatgpt', 'Tesla served as a vice president.')\n",
            "ndx 13 What did Luther do at the end of his speech? ('56f82549a6d7ea1400e17415', 2, 'chatgpt', 'Luther raised his arm \"in the traditional salute of a knight winning a bout.\"')\n",
            "ndx 14 Who considers Luther's speech a world classic? ('56f82549a6d7ea1400e17417', 2, 'chatgpt', 'Michael Mullett.')\n",
            "ndx 15 What are two examples of measurements are bound within algorithms to establish complexity classes? ('56e1c3e1e3433e1400423148', 2, 'chatgpt', 'Time and space.')\n",
            "ndx 16 What is similar to vocational training? ('56e748a200c9c71400d76f39', 2, 'chatgpt', 'Craftsmanship.')\n",
            "ndx 17 What is the role of teachers in education? ('56e7504437bdd419002c3e5e', 2, 'chatgpt', 'Teachers facilitate student learning.')\n",
            "ndx 18 Aside from BBC Radio 5, what radio station will broadcast the game? ('56bec5ff3aeaaa14008c93e4', 2, 'chatgpt', '5 Live Sports Extra.')\n",
            "ndx 19 Who makes up the BBC commentary team with Greg Brady and Rocky Boiman? ('56bec5ff3aeaaa14008c93e5', 2, 'chatgpt', 'Darren Fletcher.')\n",
            "ndx 20 Who sold the rights? ('56de49a8cffd8e1900b4b7a9', 2, 'chatgpt', 'Maciot de Bethencourt.')\n",
            "ndx 21 Who bought the rights? ('56de49a8cffd8e1900b4b7a8', 2, 'chatgpt', 'Enrique Pérez de Guzmán, 2nd Count de Niebla.')\n",
            "ndx 22 What kind of media can references to Tesla be found in ('56e126dae3433e1400422c7d', 2, 'chatgpt', 'References to Tesla can be found in books, films, radio, TV, music, live theater, comics, and video games.')\n",
            "ndx 23 What does CBD stand for? ('57060a6e52bb8914006897f9', 2, 'chatgpt', 'CBD stands for Central Business District.')\n",
            "ndx 24 What is the only district in the CBD to not have \"downtown\" in it's name? ('57060a6e52bb8914006897fa', 2, 'chatgpt', 'South Coast Metro.')\n",
            "ndx 25 What religion did Tesla grow up in? ('56e124f1cd28a01900c6764f', 2, 'chatgpt', 'Tesla was raised an Orthodox Christian.')\n",
            "ndx 26 What was the teacher's role while the child was with them? ('56e7578a37bdd419002c3eaa', 2, 'chatgpt', 'The teacher was expected to act as a substitute parent, with all the normal forms of parental discipline open to them.')\n",
            "ndx 27 Who is most likely to teach a child at home? ('56e749dd00c9c71400d76f51', 2, 'chatgpt', 'A family member or anyone with knowledge or skills in the wider community setting.')\n",
            "ndx 28 If someone is being taught at their place of residence, what is it called? ('56e749dd00c9c71400d76f52', 2, 'chatgpt', 'Home schooling.')\n",
            "ndx 29 Who won the competition to get a free Super Bowl commercial aired? ('56d9be16dc89441400fdb771', 2, 'chatgpt', 'Death Wish Coffee.')\n",
            "ndx 30 What company won a free advertisement due to the QuickBooks contest? ('56bec38b3aeaaa14008c9398', 2, 'chatgpt', 'Death Wish Coffee.')\n",
            "ndx 31 Who were the Westwood one color analysts? ('56d9c049dc89441400fdb78f', 2, 'chatgpt', 'Boomer Esiason and Dan Fouts.')\n",
            "ndx 32 Who were the Westwood One sideline announcers? ('56d9c049dc89441400fdb790', 2, 'chatgpt', 'James Lofton and Mark Malone.')\n",
            "ndx 33 What area did the Westwood One broadcast cover? ('56d9c049dc89441400fdb792', 2, 'chatgpt', 'North America.')\n",
            "ndx 34 Along with Dan Fouts, who served as a color analyst for the radio broadcast? ('56bec4a33aeaaa14008c93b4', 2, 'chatgpt', 'Boomer Esiason.')\n",
            "ndx 35 Who was Tesla prejudiced against? ('56e12005cd28a01900c67617', 2, 'chatgpt', 'Tesla was prejudiced against overweight people.')\n",
            "ndx 36 What is unknown about the complexity classes between L and P that further prevents determining the value relationship between L and P? ('56e1f10ee3433e1400423226', 2, 'chatgpt', 'It is not known if the complexity classes between L and P, such as NL and NC, are distinct or equal classes.')\n",
            "ndx 37 What did he hope to locate underground? ('56e10d2dcd28a01900c674da', 2, 'chatgpt', 'Tesla hoped to accurately determine the location of underground mineral deposits.')\n",
            "ndx 38 What did Tesla claim to be able to transmit? ('56e10d2dcd28a01900c674d7', 2, 'chatgpt', 'Tesla claimed to be able to transmit mechanical energy with minimal loss over any terrestrial distance.')\n",
            "ndx 39 What was another use for the weapon? ('56e10e73cd28a01900c674ee', 2, 'chatgpt', 'The weapon could be used for anti-aircraft purposes.')\n",
            "ndx 40 What does AC stand for? ('56e0b94b7aa994140058e6bb', 2, 'chatgpt', 'AC stands for alternating current.')\n",
            "ndx 41 Who published Tesla's writings? ('56e125b6e3433e1400422c6d', 2, 'chatgpt', \"Ben Johnston and David Hatcher Childress compiled and edited some of Tesla's books.\")\n",
            "ndx 42 Who made Ralph earl? ('56de3d594396321400ee26cc', 2, 'chatgpt', 'Edward the Confessor.')\n",
            "ndx 43 Who cannot be employed by a school in any manner? ('56e772bf37bdd419002c3fbf', 2, 'chatgpt', 'Those who refuse vetting.')\n",
            "ndx 44 Who patronized the monks in Italy? ('56de52614396321400ee27fd', 2, 'chatgpt', 'Robert Guiscard.')\n",
            "ndx 45 Who was Tesla's nephew? ('56e1127bcd28a01900c6754a', 2, 'chatgpt', \"Tesla's nephew was Sava Kosanović.\")\n",
            "ndx 46 Who transported Tesla's ashes from the US. ('56e1127bcd28a01900c6754b', 2, 'chatgpt', \"Charlotte Muzar transported Tesla's ashes from the United States to Belgrade.\")\n",
            "ndx 47 Who translated and printed Luther's 95 These? ('56f8074faef2371900625d7b', 2, 'chatgpt', 'Friends of Luther.')\n",
            "ndx 48 Who called their system the \"Tesla Polyphase System\"? ('56e0e69b7aa994140058e797', 2, 'chatgpt', 'Westinghouse Electric.')\n",
            "ndx 49 Who was Philip I? ('56f88c37aef2371900626177', 2, 'chatgpt', 'Philip I was the Landgrave of Hesse who convoked an assembly of German and Swiss theologians at the Marburg Colloquy in')\n",
            "ndx 50 Who were special guests for the Super Bowl halftime show? ('56d602631c85041400946edb', 2, 'chatgpt', 'Beyoncé and Bruno Mars.')\n",
            "ndx 51 Who did Tesla partner with in 1886? ('56dfb5777aa994140058e021', 2, 'chatgpt', 'Tesla partnered with Robert Lane and Benjamin Vail in 1886.')\n",
            "ndx 52 Who did Luther banish? ('56f84b68aef2371900625fa9', 2, 'chatgpt', 'Luther banished the Zwickau prophets.')\n",
            "ndx 53 Who hired Tesla in New York? ('56e0d54a7aa994140058e76c', 2, 'chatgpt', 'Thomas Edison.')\n",
            "ndx 54 Who hired Tesla when he moved to New York? ('56dfb0c8231d4119001abc86', 2, 'chatgpt', 'Thomas Edison.')\n",
            "ndx 55 Who conducted this survey? ('56e7673a37bdd419002c3f57', 2, 'chatgpt', 'The American Association of University Women conducted the survey.')\n",
            "ndx 56 Who was in charge of the papal army in the War of Barbastro? ('56de3e414396321400ee26d9', 2, 'chatgpt', 'William of Montreuil.')\n",
            "ndx 57 Who presided over the assembly? ('56f8225ea6d7ea1400e173f4', 2, 'chatgpt', 'Emperor Charles V.')\n",
            "ndx 58 Who defeated the rebels at the Battle of Frankenhausen? ('56f851b1a6d7ea1400e1755e', 2, 'chatgpt', 'The Swabian League.')\n",
            "ndx 59 Who performed the funeral for Martin Luther? ('56f8c9719e9bad19000a04e4', 2, 'chatgpt', \"Martin Luther's friends Johannes Bugenhagen and Philipp Melanchthon performed his funeral.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uoHS3nKTy8Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_erro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e229501b-0b35-445f-92c5-311aefc7812b",
        "id": "30eLUrZuusn3"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_respostas = pd.DataFrame(lista_resposta, columns=['id_question', 'cod_prompt', 'nome_modelo', 'resposta'])"
      ],
      "metadata": {
        "id": "Kv-7FZhmusn3"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_respostas.to_csv(f'{path_data}/df_respostas_chatgpt.csv')"
      ],
      "metadata": {
        "id": "w2P9JCLLusn3"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_erro = pd.DataFrame(lista_erro, columns=['id_question', 'cod_prompt', 'nome_modelo'])"
      ],
      "metadata": {
        "id": "UMYmMrx2usn4"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_erro.to_csv(f'{path_data}/df_erro_chatgpt.csv')"
      ],
      "metadata": {
        "id": "laOdrsJ-usn4"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_resposta[1:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TwLF7Nfy-zF",
        "outputId": "503949b4-de90-4b1c-e83b-85bf35ad3505"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('56d98db6dc89441400fdb552',\n",
              "  0,\n",
              "  'chatgpt',\n",
              "  'Sun Life Stadium in Miami was considered for Super Bowl 50.'),\n",
              " ('56d6ee6e0d65d21400198256',\n",
              "  0,\n",
              "  'chatgpt',\n",
              "  'The stadium in Miami that was considered is called Sun Life Stadium.'),\n",
              " ('56beb03c3aeaaa14008c920b', 0, 'chatgpt', 'Sun Life Stadium.'),\n",
              " ('56bf3c633aeaaa14008c9582',\n",
              "  0,\n",
              "  'chatgpt',\n",
              "  \"Miami's stadium was called Sun Life Stadium at the time of Super Bowl 50.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apurando métricas"
      ],
      "metadata": {
        "id": "wo0XTioBv-R5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4OXVyzgbvexK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparando métricas"
      ],
      "metadata": {
        "id": "gp983YgDwBUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "para o chatgpt, ver se contém a resposta certa, não se é igual!\n",
        "\n",
        "Ou analisar uma a uma."
      ],
      "metadata": {
        "id": "BpD8MtGvzF_N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BhSEvjiGwDH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o Code_DaVinci precisei colocar um sleep maior (20 segundos), talvez porque é gratuito?\n",
        "Para o ChatGPT, usei 5. Mas não testei limites.\n",
        "\n"
      ],
      "metadata": {
        "id": "D0U-a3ASyd8t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMCBKYbcy0BO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "openai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VQxzYKGgMqce",
        "r_EIoey0Rqi2",
        "4WJ9VOUMHFz1",
        "GPPjYkUTCG3X",
        "42EWgSy0CG3d",
        "MdoD0GmzCG3h",
        "fbCTtNFWCG3j",
        "8rE1ZbFvH-fL",
        "TKh6Zj9FH5Zz",
        "OyRNKuD7h6Fs",
        "jOGRYPn-3bmp",
        "YygV4s372xYS"
      ],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}