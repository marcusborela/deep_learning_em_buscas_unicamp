{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aula 7 - DPR\n",
        "\n",
        "[Unicamp - IA368DD: Deep Learning aplicado a sistemas de busca.](https://www.cpg.feec.unicamp.br/cpg/lista/caderno_horario_show.php?id=1779)\n",
        "\n",
        "Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "[Repositório no github](https://github.com/marcusborela/deep_learning_em_buscas_unicamp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enunciado do Exercício"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fazer o finetuning de um buscador denso\n",
        "\n",
        "Usar como treino o dataset \"tiny\" do MS MARCO\n",
        "https://storage.googleapis.com/unicamp-dl/ia368dd_2023s1/msmarco/msmarco_triples.train.tiny.tsv\n",
        "\n",
        "Avaliar o modelo no TREC-COVID, e comparar os resultados com o BM25 e doc2query\n",
        "\n",
        "Comparar busca \"exaustiva\" (semelhança do vetor query com todos os vetores do corpus) com a busca aproximada (Approximate Nearest Neighbor - ANN)\n",
        "\n",
        "Para a busca aproximada, usar os algoritmos existentes na biblioteca sentence-transformers (ex: hnswlib) OU implemente um você mesmo (Bonus!)\n",
        "\n",
        "Dicas:\n",
        "\n",
        "    Usar a média dos vetores da última camada (conhecido como mean pooling) do transformer para representar queries e passagens; Alternativamente, usar apenas o vetor do [CLS] da última cada.\n",
        "    Tente inicialmente uma loss fácil de implementar, como a entropia-cruzada\n",
        "    Começar o treino a partir do microsoft/MiniLM-L12-H384-uncased\n",
        "    Avaliar o pipeline usando um modelo já bem treinado: sentence-transformers/all-mpnet-base-v2\n",
        "    Comparar resultados usando semelhança de cosseno e produto escalar como funções de similaridade\n",
        "    Para checar se seu codigo de avaliação está correto, comparar o seu desempenho com o do modelo já treinado no MS MARCO:   https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2; O nDCG@10 no TREC-COVID deve ser ~0.47\n",
        "    Usar a biblioteca do sentence-transformers para avaliar o modelo\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fase\n",
        "\n",
        "Fine tunning no modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmRLgbyi_Dvg"
      },
      "source": [
        "# Organizando o ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Upk7A-8Zdnd"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3twP0YJC4jmJ",
        "outputId": "39667ff3-9860-40bf-f95a-9aac6f71a49d"
      },
      "outputs": [],
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1InUqeoncLP0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/borela/miniconda3/envs/treinapython39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,  AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MO5ssyR9qeP4"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lUx84Olw88cZ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LTF06xq49F24"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "DIRETORIO_TRABALHO = '/home/borela/fontes/deep_learning_em_buscas_unicamp/local/dpr'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pasta já existia!\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(DIRETORIO_TRABALHO):\n",
        "    print('pasta já existia!')\n",
        "else:\n",
        "    os.makedirs(DIRETORIO_TRABALHO)\n",
        "    print('pasta criada!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DKAZ8CWCAM3-"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9XgIWvkkH-kn"
      },
      "outputs": [],
      "source": [
        "def mostra_memoria(lista_mem=['cpu']):\n",
        "  \"\"\"\n",
        "  Esta função exibe informações de memória da CPU e/ou GPU, conforme parâmetros fornecidos.\n",
        "\n",
        "  Parâmetros:\n",
        "  -----------\n",
        "  lista_mem : list, opcional\n",
        "      Lista com strings 'cpu' e/ou 'gpu'. \n",
        "      'cpu' - exibe informações de memória da CPU.\n",
        "      'gpu' - exibe informações de memória da GPU (se disponível).\n",
        "      O valor padrão é ['cpu'].\n",
        "\n",
        "  Saída:\n",
        "  -------\n",
        "  A função não retorna nada, apenas exibe as informações na tela.\n",
        "\n",
        "  Exemplo de uso:\n",
        "  ---------------\n",
        "  Para exibir informações de memória da CPU:\n",
        "      mostra_memoria(['cpu'])\n",
        "\n",
        "  Para exibir informações de memória da CPU e GPU:\n",
        "      mostra_memoria(['cpu', 'gpu'])\n",
        "  \n",
        "  Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "  \"\"\"  \n",
        "  if 'cpu' in lista_mem:\n",
        "    vm = virtual_memory()\n",
        "    ram={}\n",
        "    ram['total']=round(vm.total / 1e9,2)\n",
        "    ram['available']=round(virtual_memory().available / 1e9,2)\n",
        "    # ram['percent']=round(virtual_memory().percent / 1e9,2)\n",
        "    ram['used']=round(virtual_memory().used / 1e9,2)\n",
        "    ram['free']=round(virtual_memory().free / 1e9,2)\n",
        "    ram['active']=round(virtual_memory().active / 1e9,2)\n",
        "    ram['inactive']=round(virtual_memory().inactive / 1e9,2)\n",
        "    ram['buffers']=round(virtual_memory().buffers / 1e9,2)\n",
        "    ram['cached']=round(virtual_memory().cached/1e9 ,2)\n",
        "    print(f\"Your runtime RAM in gb: \\n total {ram['total']}\\n available {ram['available']}\\n used {ram['used']}\\n free {ram['free']}\\n cached {ram['cached']}\\n buffers {ram['buffers']}\")\n",
        "    print('/nGPU')\n",
        "    gpu_info = !nvidia-smi\n",
        "  if 'gpu' in lista_mem:\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dri9iiMAvCT",
        "outputId": "2ddd75fa-3123-4027-8d69-8bc94fc85615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 67.35\n",
            " available 57.57\n",
            " used 8.67\n",
            " free 12.58\n",
            " cached 45.6\n",
            " buffers 0.5\n",
            "/nGPU\n",
            "Tue Apr 18 18:18:22 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
            "| 58%   50C    P8    37W / 370W |     60MiB / 24576MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1260      G   /usr/lib/xorg/Xorg                 45MiB |\n",
            "|    0   N/A  N/A      1399      G   /usr/bin/gnome-shell               10MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "mostra_memoria(['cpu', 'gpu'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GYGL4MV_yhQ",
        "outputId": "5ad18083-48f1-4577-b0c5-863e1c45c1a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: /home/borela/fontes/deep_learning_em_buscas_unicamp/code/aula7_dpr\n"
          ]
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "print(\"Current directory:\", current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw3qjXs6X2ME"
      },
      "source": [
        "## Fixando as seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AG9RjMb8Qlot"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ySVSWRCXX2ME"
      },
      "outputs": [],
      "source": [
        "def inicializa_seed(num_semente:int=123):\n",
        "  \"\"\"\n",
        "  Inicializa as sementes para garantir a reprodutibilidade dos resultados do modelo.\n",
        "  Essa é uma prática recomendada, já que a geração de números aleatórios pode influenciar os resultados do modelo.\n",
        "  Além disso, a função também configura as sementes da GPU para garantir a reprodutibilidade quando se utiliza aceleração por GPU. \n",
        "  \n",
        "  Args:\n",
        "      num_semente (int): número da semente a ser utilizada para inicializar as sementes das bibliotecas.\n",
        "  \n",
        "  References:\n",
        "      http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "      https://github.com/CyberZHG/torch-multi-head-attention/blob/master/torch_multi_head_attention/multi_head_attention.py#L15\n",
        "  \"\"\"\n",
        "  # Define as sementes das bibliotecas random, numpy e pytorch\n",
        "  random.seed(num_semente)\n",
        "  np.random.seed(num_semente)\n",
        "  torch.manual_seed(num_semente)\n",
        "  \n",
        "  # Define as sementes da GPU\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "  #torch.cuda.manual_seed(num_semente)\n",
        "  #Cuda algorithms\n",
        "  #torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "j9dUkABwX2ME"
      },
      "outputs": [],
      "source": [
        "num_semente=123\n",
        "inicializa_seed(num_semente)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3W-iu3UX2MF"
      },
      "source": [
        "## Definindo Hiperparâmetros iniciais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_FxOjwQcX2MF"
      },
      "outputs": [],
      "source": [
        "def inicia_hparam()->dict:\n",
        "  # Inicialização dos parâmetros\n",
        "  hparam = {}\n",
        "  hparam[\"num_workers_dataloader\"] = 0\n",
        "  hparam[\"device\"] = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "  if torch.cuda.is_available(): print(torch. cuda. get_device_name(hparam[\"device\"]))    \n",
        "  return hparam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2HKHbrYX2MF",
        "outputId": "f90846d9-b669-4df5-a60a-4ab4d9ed986b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA GeForce RTX 3090\n"
          ]
        }
      ],
      "source": [
        "hparam=inicia_hparam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMz76cmAX2MF"
      },
      "source": [
        "## Preparando para debug e display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BJ6S4P5Hw4iG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKNAMVTnX2MG"
      },
      "source": [
        "https://zohaib.me/debugging-in-google-collab-notebook/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Tb1KfD9-X2MG"
      },
      "outputs": [],
      "source": [
        "# !pip install -Uqq ipdb\n",
        "import ipdb\n",
        "# %pdb off # desativa debug em exceção\n",
        "# %pdb on  # ativa debug em exceção\n",
        "# ipdb.set_trace(context=8)  para execução nesse ponto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wQ5pmlOHxHhk"
      },
      "outputs": [],
      "source": [
        "def config_display():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de display do Pandas.\n",
        "  \"\"\"\n",
        "\n",
        "  # Configurando formato saída Pandas\n",
        "  # define o número máximo de colunas que serão exibidas\n",
        "  pd.options.display.max_columns = None\n",
        "\n",
        "  # define a largura máxima de uma linha\n",
        "  pd.options.display.width = 1000\n",
        "\n",
        "  # define o número máximo de linhas que serão exibidas\n",
        "  pd.options.display.max_rows = 100\n",
        "\n",
        "  # define o número máximo de caracteres por coluna\n",
        "  pd.options.display.max_colwidth = 50\n",
        "\n",
        "  # se deve exibir o número de linhas e colunas de um DataFrame.\n",
        "  pd.options.display.show_dimensions = True\n",
        "\n",
        "  # número de dígitos após a vírgula decimal a serem exibidos para floats.\n",
        "  pd.options.display.precision = 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "b2tDy72ATNHs"
      },
      "outputs": [],
      "source": [
        "def config_debug():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de debug do PyTorch e dos pacotes\n",
        "  transformers e datasets.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define opções de impressão de tensores para o modo científico\n",
        "  torch.set_printoptions(sci_mode=True) \n",
        "  \"\"\"\n",
        "    Significa que valores muito grandes ou muito pequenos são mostrados em notação científica.\n",
        "    Por exemplo, em vez de imprimir o número 0.0000012345 como 0.0000012345, \n",
        "    ele seria impresso como 1.2345e-06. Isso é útil em situações em que os valores dos tensores \n",
        "    envolvidos nas operações são muito grandes ou pequenos, e a notação científica permite \n",
        "    uma melhor compreensão dos números envolvidos.  \n",
        "  \"\"\"\n",
        "\n",
        "  # Habilita detecção de anomalias no autograd do PyTorch\n",
        "  torch.autograd.set_detect_anomaly(True)\n",
        "  \"\"\"\n",
        "    Permite identificar operações que podem causar problemas de estabilidade numérica, \n",
        "    como gradientes explodindo ou desaparecendo. Quando essa opção é ativada, \n",
        "    o PyTorch verifica se há operações que geram valores NaN ou infinitos nos tensores \n",
        "    envolvidos no cálculo do gradiente. Se for detectado um valor anômalo, o PyTorch \n",
        "    interrompe a execução e gera uma exceção, permitindo que o erro seja corrigido \n",
        "    antes que se torne um problema maior.\n",
        "\n",
        "    É importante notar que a detecção de anomalias pode ter um impacto significativo \n",
        "    no desempenho, especialmente em modelos grandes e complexos. Por esse motivo,\n",
        "    ela deve ser usada com cautela e apenas para depuração.\n",
        "  \"\"\"\n",
        "\n",
        "  # Configura variável de ambiente para habilitar a execução síncrona (bloqueante) das chamadas da API do CUDA.\n",
        "  os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "  \"\"\"\n",
        "    o Python aguarda o término da execução de uma chamada da API do CUDA antes de executar a próxima chamada. \n",
        "    Isso é útil para depurar erros no código que envolve operações na GPU, pois permite que o erro seja capturado \n",
        "    no momento em que ocorre, e não depois de uma sequência de operações que pode tornar a origem do erro mais difícil de determinar.\n",
        "    No entanto, é importante lembrar que esse modo de execução é significativamente mais lento do que a execução assíncrona, \n",
        "    que é o comportamento padrão do CUDA. Por isso, é recomendado utilizar esse comando apenas em situações de depuração \n",
        "    e removê-lo após a solução do problema.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define o nível de verbosity do pacote transformers para info\n",
        "  ## transformers.utils.logging.set_verbosity_info() \n",
        "  \n",
        "  \n",
        "  \"\"\"\n",
        "    Define o nível de detalhamento das mensagens de log geradas pela biblioteca Hugging Face Transformers \n",
        "    para o nível info. Isso significa que a biblioteca irá imprimir mensagens de log informativas sobre\n",
        "    o andamento da execução, tais como tempo de execução, tamanho de batches, etc.\n",
        "\n",
        "    Essas informações podem ser úteis para entender o que está acontecendo durante a execução da tarefa \n",
        "    e auxiliar no processo de debug. É importante notar que, em alguns casos, a quantidade de informações\n",
        "    geradas pode ser muito grande, o que pode afetar o desempenho do sistema e dificultar a visualização\n",
        "    das informações relevantes. Por isso, é importante ajustar o nível de detalhamento de acordo com a \n",
        "    necessidade de cada tarefa.\n",
        "  \n",
        "    Caso queira reduzir a quantidade de mensagens, comentar a linha acima e \n",
        "      descomentar as duas linhas abaixo, para definir o nível de verbosity como error ou warning\n",
        "  \n",
        "    transformers.utils.logging.set_verbosity_error()\n",
        "    transformers.utils.logging.set_verbosity_warning()\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Define o modo verbose do xmode, que é utilizado no debug\n",
        "  ## %xmode Verbose \n",
        "\n",
        "  \"\"\"\n",
        "    Comando usado no Jupyter Notebook para controlar o modo de exibição das informações de exceções.\n",
        "    O modo verbose é um modo detalhado que exibe informações adicionais ao imprimir as exceções.\n",
        "    Ele inclui as informações de pilha de chamadas completa e valores de variáveis locais e globais \n",
        "    no momento da exceção. Isso pode ser útil para depurar e encontrar a causa de exceções em seu código.\n",
        "    Ao usar %xmode Verbose, as informações de exceção serão impressas com mais detalhes e informações adicionais serão incluídas.\n",
        "\n",
        "    Caso queira desabilitar o modo verbose e utilizar o modo plain, \n",
        "    comentar a linha acima e descomentar a linha abaixo:\n",
        "    %xmode Plain\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "    Dica:\n",
        "    1.  pdb (Python Debugger)\n",
        "      Quando ocorre uma exceção em uma parte do código, o programa para a execução e exibe uma mensagem de erro \n",
        "      com informações sobre a exceção, como a linha do código em que ocorreu o erro e o tipo da exceção.\n",
        "\n",
        "      Se você estiver depurando o código e quiser examinar o estado das variáveis ​​e executar outras operações \n",
        "      no momento em que a exceção ocorreu, pode usar o pdb (Python Debugger). Para isso, é preciso colocar o comando %debug \n",
        "      logo após ocorrer a exceção. Isso fará com que o programa pare na linha em que ocorreu a exceção e abra o pdb,\n",
        "      permitindo que você explore o estado das variáveis, examine a pilha de chamadas e execute outras operações para depurar o código.\n",
        "\n",
        "\n",
        "    2. ipdb\n",
        "      O ipdb é um depurador interativo para o Python que oferece recursos mais avançados do que o pdb,\n",
        "      incluindo a capacidade de navegar pelo código fonte enquanto depura.\n",
        "      \n",
        "      Você pode começar a depurar seu código inserindo o comando ipdb.set_trace() em qualquer lugar do \n",
        "      seu código onde deseja pausar a execução e começar a depurar. Quando a execução chegar nessa linha, \n",
        "      o depurador entrará em ação, permitindo que você examine o estado atual do seu programa e execute \n",
        "      comandos para investigar o comportamento.\n",
        "\n",
        "      Durante a depuração, você pode usar comandos:\n",
        "        next (para executar a próxima linha de código), \n",
        "        step (para entrar em uma função chamada na próxima linha de código) \n",
        "        continue (para continuar a execução normalmente até o próximo ponto de interrupção).\n",
        "\n",
        "      Ao contrário do pdb, o ipdb é um depurador interativo que permite navegar pelo código fonte em que\n",
        "      está trabalhando enquanto depura, permitindo que você inspecione variáveis, defina pontos de interrupção\n",
        "      adicionais e até mesmo execute expressões Python no contexto do seu programa.\n",
        "  \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Tb4aqtcExR84"
      },
      "outputs": [],
      "source": [
        "config_display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bGQAf_YX2MJ",
        "outputId": "13f0af4e-e2e2-44d7-9946-f46152af906d"
      },
      "outputs": [],
      "source": [
        "config_debug()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VEyI8MpX2MJ"
      },
      "source": [
        "## Rastro (neptune.ai)\n",
        "\n",
        "Gerado rastro da execução no Neptune (detalhes no artigo [Rastro-DM: Mineração de Dados com Rastro](https://revista.tcu.gov.br/ojs/index.php/RTCU/article/view/1664))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik2HW7K-X2MJ"
      },
      "source": [
        "### Importação de libraries para Rastro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass, copy, tempfile, re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['NEPTUNE_ALLOW_SELF_SIGNED_CERTIFICATE'] = 'TRUE'\n",
        "os.environ['NEPTUNE_PROJECT'] = 'marcusborela/IA386DD'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['NEPTUNE_API_TOKEN'] = getpass.getpass('Informe NEPTUNE_API_TOKEN')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "tag_contexto_rastro = 'Aula 7 - DPR'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "neptune_version = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95u6fg6QX2MK"
      },
      "source": [
        "### Código Rastro\n",
        "\n",
        "Busca implementar o rastro proposto em [Rastro-DM: Mineração de Dados com Rastro](https://revista.tcu.gov.br/ojs/index.php/RTCU/article/view/1664), autores Marcus Vinícius Borela de Castro e Remis Balaniuk, com o apoio da [solução Neptune](https://app.neptune.ai/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "03PO_YjJX2MK"
      },
      "outputs": [],
      "source": [
        "def converte_optimizer_state_dict(parm_optimizer)-> dict:\n",
        "  \"\"\"\n",
        "    Recebe um objeto \"parm_optimizer\" que é do tipo \"torch.optim.Optimizer\" e retorna um dicionário \n",
        "    com informações sobre o otimizador.\n",
        "\n",
        "    O dicionário de retorno é gerado a partir do estado do otimizador que é extraído da propriedade\n",
        "    \"state_dict()\" do objeto \"parm_optimizer\", seu primeiro grupo de parâmetros do otimizador.\n",
        "  \"\"\"\n",
        "  # return str(hparam['optimizer'])\n",
        "  return parm_optimizer.state_dict()['param_groups'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "if neptune_version == 0:\n",
        "  import neptune.new as neptune  \n",
        "  class NeptuneRastroRun():\n",
        "      se_geracao_rastro = True \n",
        "      neptune_project = \"\"\n",
        "      tag_contexto_rastro = \"\"\n",
        "      neptune_api_token = \"\"\n",
        "\n",
        "      def __init__(self, parm_params:dict,  parm_lista_tag:list = None):\n",
        "        # print(f\"NeptuneRastroRun.init: se_geracao_rastro {self.__class__.se_geracao_rastro} parm_params `{parm_params} \")\n",
        "        if self.__class__.se_geracao_rastro:      \n",
        "          self.run_neptune = neptune.init(project=self.__class__.neptune_project, api_token=self.__class__.neptune_api_token, capture_hardware_metrics=True)\n",
        "          self.run_neptune['sys/name'] = self.__class__.tag_contexto_rastro\n",
        "          vparams = copy.deepcopy(parm_params)\n",
        "          if \"optimizer\" in vparams:\n",
        "            vparams[\"optimizer\"] = converte_optimizer_state_dict(vparams[\"optimizer\"])\n",
        "          if 'criterion'  in vparams:\n",
        "            vparams[\"criterion\"] = str(vparams[\"criterion\"])\n",
        "          if 'scheduler'  in vparams:\n",
        "            vparams[\"scheduler\"] = str(type(vparams[\"scheduler\"]))\n",
        "          if 'device' in vparams:\n",
        "            vparams['device'] = str(vparams[\"device\"])\n",
        "          self.device = vparams[\"device\"]\n",
        "          for tag in parm_lista_tag:\n",
        "            self.run_neptune['sys/tags'].add(tag)\n",
        "          self.run_neptune['parameters'] = vparams\n",
        "          self.tmpDir = tempfile.mkdtemp()\n",
        "\n",
        "      @property\n",
        "      def run():\n",
        "        return self.run_neptune\n",
        "\n",
        "      @classmethod\n",
        "      def ativa_geracao_rastro(cls):\n",
        "        cls.se_geracao_rastro = True      \n",
        "\n",
        "      @classmethod\n",
        "      def def_contexto(cls):\n",
        "        cls.se_geracao_rastro = True      \n",
        "\n",
        "      @classmethod\n",
        "      def desativa_geracao_rastro(cls):\n",
        "        cls.se_geracao_rastro = False      \n",
        "\n",
        "      @classmethod\n",
        "      def retorna_status_geracao_rastro(cls):\n",
        "        return cls.se_geracao_rastro      \n",
        "\n",
        "      @classmethod\n",
        "      def retorna_tag_contexto_rastro(cls):\n",
        "        return cls.tag_contexto_rastro \n",
        "\n",
        "      @classmethod\n",
        "      def inicia_contexto(cls, neptune_project, tag_contexto_rastro, neptune_api_token):\n",
        "        assert '.' not in tag_contexto_rastro, \"NeptuneRastroRun.init(): tag_contexto_rastro não pode possuir ponto, pois será usado para gravar nome de arquivo\"      \n",
        "        cls.neptune_api_token = neptune_api_token\n",
        "        cls.tag_contexto_rastro = tag_contexto_rastro\n",
        "        cls.neptune_project = neptune_project\n",
        "\n",
        "      def salva_metrica(self, parm_metricas={}):\n",
        "        #print(f\"NeptuneRastroRun.salva_metrica: se_geracao_rastro {self.__class__.se_geracao_rastro} parm_metricas:{parm_metricas} \")\n",
        "        if self.__class__.se_geracao_rastro:\n",
        "          for metrica, valor in parm_metricas.items(): \n",
        "            self.run_neptune[metrica].log(valor)\n",
        "  \n",
        "      def gera_grafico_modelo(self, loader_train, model):\n",
        "        if self.__class__.se_geracao_rastro: \n",
        "          # efetuar um forward \n",
        "          \"\"\"\n",
        "          se dataloader devolver x e y:\n",
        "          \"\"\"\n",
        "          x_, y_ = next(iter(loader_train))\n",
        "          x_ = x_.to(self.device)\n",
        "          outputs = model(x_)\n",
        "          \"\"\"\n",
        "          # se dataloader devolver dict:\n",
        "          dados_ = next(iter(loader_train))\n",
        "          outputs = model(dados_['x'].to(self.device))\n",
        "          #outputs = model(x_['input_ids'].to(self.device), x_['attention_mask'].to(self.device))\n",
        "          \"\"\"\n",
        "          nome_arquivo = os.path.join(self.tmpDir, \"modelo \"+ self.__class__.tag_contexto_rastro + time.strftime(\"%Y-%b-%d %H:%M:%S\"))\n",
        "          make_dot(outputs, params=dict(model.named_parameters()), show_attrs=True, show_saved=True).render(nome_arquivo, format=\"png\")\n",
        "          self.run_neptune[\"parameters/model_graph\"].upload(nome_arquivo+'.png')\n",
        "          self.run_neptune['parameters/model'] = re.sub('<bound method Module.state_dict of ', '',str(model.state_dict))      \n",
        "\n",
        "\n",
        "\n",
        "      def stop(self):\n",
        "        if self.__class__.se_geracao_rastro:         \n",
        "          self.run_neptune.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "x2IIVG8EX2ML"
      },
      "outputs": [],
      "source": [
        "if neptune_version == 1:\n",
        "  import neptune\n",
        "  class NeptuneRastroRun():\n",
        "      \"\"\"\n",
        "        Classe para geração de rastro de experimento utilizando a ferramenta Neptune.\n",
        "\n",
        "        Busca implementar o rastro proposto em [Rastro-DM: Mineração de Dados com Rastro](https://revista.tcu.gov.br/ojs/index.php/RTCU/article/view/1664),\n",
        "        autores Marcus Vinícius Borela de Castro e Remis Balaniuk, com o apoio da [solução Neptune](https://app.neptune.ai/)\n",
        "\n",
        "        Attributes:\n",
        "        -----------\n",
        "        se_geracao_rastro : bool\n",
        "            Indica se deve ser gerado rastro de experimento. \n",
        "        neptune_project : str\n",
        "            Nome do projeto criado no Neptune. \n",
        "        tag_contexto_rastro : str\n",
        "            Nome da tag utilizada para identificar o experimento.\n",
        "        neptune_api_token : str\n",
        "            Token utilizado para autenticação na API do Neptune. \n",
        "        run_neptune : object\n",
        "            Objeto que representa o experimento no Neptune.\n",
        "        device : str\n",
        "            Dispositivo utilizado para o treinamento do modelo.\n",
        "        tmpDir : str\n",
        "          Diretório temporário utilizado para salvar gráfico do modelo.          \n",
        "      \"\"\"\n",
        "      se_geracao_rastro = True \n",
        "      neptune_project = \"\"\n",
        "      tag_contexto_rastro = \"\"\n",
        "      neptune_api_token = \"\"\n",
        "\n",
        "      def __init__(self, parm_params:dict,  parm_lista_tag:list = None):\n",
        "        \"\"\"\n",
        "          Método construtor da classe NeptuneRastroRun.\n",
        "          \n",
        "          Args:\n",
        "          - parm_params: dicionário contendo os parâmetros do modelo.\n",
        "          - parm_lista_tag: lista contendo tags adicionais para o experimento.\n",
        "        \"\"\"      \n",
        "        # print(f\"NeptuneRastroRun.init: se_geracao_rastro {self.__class__.se_geracao_rastro} parm_params `{parm_params} \")\n",
        "        if self.__class__.se_geracao_rastro:      \n",
        "          self.run_neptune = neptune.init_run(project=self.__class__.neptune_project, api_token=self.__class__.neptune_api_token, capture_hardware_metrics=True)\n",
        "          self.run_neptune['sys/name'] = self.__class__.tag_contexto_rastro\n",
        "          vparams = copy.deepcopy(parm_params)\n",
        "          if \"optimizer\" in vparams:\n",
        "            vparams[\"optimizer\"] = converte_optimizer_state_dict(vparams[\"optimizer\"])\n",
        "          if 'criterion'  in vparams:\n",
        "            vparams[\"criterion\"] = str(vparams[\"criterion\"])\n",
        "          if 'scheduler'  in vparams:\n",
        "            vparams[\"scheduler\"] = str(type(vparams[\"scheduler\"]))\n",
        "          if 'device' in vparams:\n",
        "            vparams['device'] = str(vparams[\"device\"])\n",
        "          self.device = vparams[\"device\"]\n",
        "          for tag in parm_lista_tag:\n",
        "            self.run_neptune['sys/tags'].add(tag)\n",
        "          self.run_neptune['parameters'] = vparams\n",
        "          # self.tmpDir = tempfile.mkdtemp()\n",
        "\n",
        "      @property\n",
        "      def run():\n",
        "        \"\"\"\n",
        "        Retorna a instância do objeto run_neptune.\n",
        "        \"\"\"      \n",
        "        return self.run_neptune\n",
        "\n",
        "      @classmethod\n",
        "      def ativa_geracao_rastro(cls):\n",
        "        \"\"\"\n",
        "        Ativa a geração de rastro.\n",
        "        \"\"\"      \n",
        "        cls.se_geracao_rastro = True      \n",
        "\n",
        "      @classmethod\n",
        "      def def_contexto(cls):\n",
        "        \"\"\"\n",
        "        Define o contexto para a geração de rastro.\n",
        "        \"\"\"      \n",
        "        cls.se_geracao_rastro = True      \n",
        "\n",
        "      @classmethod\n",
        "      def desativa_geracao_rastro(cls):\n",
        "        \"\"\"\n",
        "        Desativa a geração de rastro.\n",
        "        \"\"\"      \n",
        "        cls.se_geracao_rastro = False      \n",
        "\n",
        "      @classmethod\n",
        "      def retorna_status_geracao_rastro(cls):\n",
        "        \"\"\"\n",
        "          Retorna o status da geração de rastro.\n",
        "          \n",
        "          Returns:\n",
        "          - True se a geração de rastro está ativada, False caso contrário.\n",
        "        \"\"\"      \n",
        "        return cls.se_geracao_rastro      \n",
        "\n",
        "      @classmethod\n",
        "      def retorna_tag_contexto_rastro(cls):\n",
        "        \"\"\"\n",
        "          Retorna a tag do contexto de rastro.\n",
        "        \"\"\"      \n",
        "        return cls.tag_contexto_rastro \n",
        "\n",
        "      @classmethod\n",
        "      def inicia_contexto(cls, neptune_project, tag_contexto_rastro, neptune_api_token):\n",
        "        \"\"\"\n",
        "        Inicia o contexto de execução no Neptune.\n",
        "\n",
        "        Args:\n",
        "            neptune_project (str): Nome do projeto no Neptune.\n",
        "            tag_contexto_rastro (str): Tag que identifica o contexto de execução no Neptune.\n",
        "            neptune_api_token (str): Token de acesso à API do Neptune.\n",
        "\n",
        "        Raises:\n",
        "            AssertionError: Caso a tag_contexto_rastro possua um ponto (.), \n",
        "              o que pode gerar erros na gravação de arquivo.\n",
        "        \"\"\"      \n",
        "        assert '.' not in tag_contexto_rastro, \"NeptuneRastroRun.init(): tag_contexto_rastro não pode possuir ponto, pois será usado para gravar nome de arquivo\"      \n",
        "        cls.neptune_api_token = neptune_api_token\n",
        "        cls.tag_contexto_rastro = tag_contexto_rastro\n",
        "        cls.neptune_project = neptune_project\n",
        "\n",
        "      def salva_metrica(self, parm_metricas={}):\n",
        "        \"\"\"\n",
        "          Salva as métricas no Neptune Run caso a geração de rastro esteja ativa.\n",
        "\n",
        "          Parameters\n",
        "          ----------\n",
        "          parm_metricas: dict\n",
        "              Dicionário contendo as métricas a serem salvas. As chaves devem ser os nomes das métricas e os valores devem ser\n",
        "              os valores das métricas.\n",
        "        \"\"\"\n",
        "        #print(f\"NeptuneRastroRun.salva_metrica: se_geracao_rastro {self.__class__.se_geracao_rastro} parm_metricas:{parm_metricas} \")\n",
        "        if self.__class__.se_geracao_rastro:\n",
        "          for metrica, valor in parm_metricas.items(): \n",
        "            self.run_neptune[metrica].append(valor)\n",
        "  \n",
        "      def gera_grafico_modelo(self, loader_train, model):\n",
        "        \"\"\"\n",
        "          Gera um gráfico do modelo e o envia para o Neptune. \n",
        "          Para gerar o gráfico, um forward pass é realizado em um batch de exemplos \n",
        "          de treino e o resultado é renderizado como um gráfico de nós conectados. \n",
        "          O gráfico é salvo em um arquivo .png e enviado para o Neptune como um arquivo anexo.\n",
        "\n",
        "          Args:\n",
        "              loader_train (torch.utils.data.DataLoader): DataLoader do conjunto de treinamento.\n",
        "              model (torch.nn.Module): Modelo a ser visualizado.\n",
        "          \n",
        "          Pendente:\n",
        "            Evolui para usar from io import StringIO (buffer = io.StringIO()) ao invés de tempdir \n",
        "        \"\"\"    \n",
        "        return\n",
        "\n",
        "        \"\"\"\n",
        "        falta ajustar make_dot\n",
        "        if self.__class__.se_geracao_rastro: \n",
        "          # efetuar um forward \n",
        "          batch = next(iter(loader_train))\n",
        "          # falta generalizar linha abaixo. Criar função que recebe modelo e batch como parâmetro?\n",
        "          outputs = model(input_ids=batch['input_ids'].to(hparam['device']), attention_mask=batch['attention_mask'].to(hparam['device']), token_type_ids=batch['token_type_ids'].to(hparam['device']), labels=batch['labels'].to(hparam['device']))\n",
        "          nome_arquivo = os.path.join(self.tmpDir, \"modelo \"+ self.__class__.tag_contexto_rastro + time.strftime(\"%Y-%b-%d %H:%M:%S\"))\n",
        "          make_dot(outputs, params=dict(model.named_parameters()), show_attrs=True, show_saved=True).render(nome_arquivo, format=\"png\")\n",
        "          self.run_neptune[\"parameters/model_graph\"].upload(nome_arquivo+'.png')\n",
        "          self.run_neptune['parameters/model'] = re.sub('<bound method Module.state_dict of ', '',str(model.state_dict))      \n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "      def stop(self):\n",
        "        \"\"\"\n",
        "          Para a execução do objeto Neptune. Todos os experimentos do Neptune são sincronizados com o servidor, e nenhum outro \n",
        "          experimento poderá ser adicionado a este objeto após a chamada a este método.\n",
        "        \"\"\"\n",
        "        if self.__class__.se_geracao_rastro:         \n",
        "          self.run_neptune.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYAbHMteX2MM"
      },
      "source": [
        "### Definindo parâmetros para o rastro\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz6I6FITX2MM",
        "outputId": "f9a98945-28fa-4a9e-b50e-7253ad27184a"
      },
      "outputs": [],
      "source": [
        "NeptuneRastroRun.inicia_contexto(os.environ['NEPTUNE_PROJECT'], tag_contexto_rastro,  os.environ['NEPTUNE_API_TOKEN'])\n",
        "#NeptuneRastroRun.desativa_geracao_rastro()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uqF-LbXgrpFP"
      },
      "source": [
        "# Carregando modelo e tokenizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_NAME = 'microsoft/MiniLM-L12-H384-uncased'\n",
        "\n",
        "# NOME_CAMINHO_MODELO = \"/home/borela/fontes/deep_learning_em_buscas_unicamp/modelo/\" + MODEL_NAME\n",
        "# assert os.path.exists(NOME_CAMINHO_MODELO), f\"Path para {NOME_CAMINHO_MODELO} não existe!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se tiver que treinar os modelos, abre\n",
        "models = {'query': AutoModel.from_pretrained(MODEL_NAME).to(hparam['device']),\n",
        "'passage' : AutoModel.from_pretrained(MODEL_NAME).to(hparam['device'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "512 30522\n"
          ]
        }
      ],
      "source": [
        "print(models['query'].config.max_position_embeddings, models['passage'].config.vocab_size)\n",
        "# 512 e 30522\n",
        "#models['query'].config.__dict__\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Carga dos dados msmarco_triples.train.tiny.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pasta já existia!\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(f\"{DIRETORIO_TRABALHO}/msmarco_triples.train.tiny.tsv\"):\n",
        "    !wget https://storage.googleapis.com/unicamp-dl/ia368dd_2023s1/msmarco/msmarco_triples.train.tiny.tsv\n",
        "    !mv msmarco_triples.train.tiny.tsv {DIRETORIO_TRABALHO}\n",
        "    print(\"Pasta criada!\")\n",
        "else:\n",
        "    print(\"Pasta já existia!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"{DIRETORIO_TRABALHO}/msmarco_triples.train.tiny.tsv\", delimiter=\"\\t\", \n",
        "                 header=None, names=[\"query\", \"positive\", \"negative\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11000, 3)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "igtPldcHPwCS",
        "outputId": "594683c5-90e1-43d7-c00e-8d066b3fe161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            query                                           positive                                           negative\n",
            "0        is a little caffeine ok during pregnancy  We donât know a lot about the effects of caf...  It is generally safe for pregnant women to eat...\n",
            "1               what fruit is native to australia  Passiflora herbertiana. A rare passion fruit n...  The kola nut is the fruit of the kola tree, a ...\n",
            "2              how large is the canadian military  The Canadian Armed Forces. 1  The first large-...  The Canadian Physician Health Institute (CPHI)...\n",
            "3                            types of fruit trees  Cherry. Cherry trees are found throughout the ...  The kola nut is the fruit of the kola tree, a ...\n",
            "4  how many calories a day are lost breastfeeding  Not only is breastfeeding better for the baby,...  However, you still need some niacin each day; ...\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ3S90BBTrKJ"
      },
      "source": [
        "Verificando correção do arquivo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm7ss2BfTlOu",
        "outputId": "a7140122-cf21-46cd-cb04-decdcf3cb959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query       0\n",
            "positive    0\n",
            "negative    0\n",
            "Length: 3, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q ftfy\n",
        "import ftfy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = 'We donât know a lot about the effects'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We don't know a lot about the effects\n"
          ]
        }
      ],
      "source": [
        "print(ftfy.fix_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "query        34.2256364\n",
              "positive    353.7535455\n",
              "negative    340.4646364\n",
              "Length: 3, dtype: float64"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.applymap(len).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pois treinaremos doc2query apenas para geração de queries relevantes\n",
        "del df['negative']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Lg0b1wj0SEsY"
      },
      "outputs": [],
      "source": [
        "df['query'] = df['query'].apply(ftfy.fix_text)\n",
        "df['positive'] = df['positive'].apply(ftfy.fix_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "igtPldcHPwCS",
        "outputId": "594683c5-90e1-43d7-c00e-8d066b3fe161"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is a little caffeine ok during pregnancy</td>\n",
              "      <td>We don't know a lot about the effects of caffe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what fruit is native to australia</td>\n",
              "      <td>Passiflora herbertiana. A rare passion fruit n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how large is the canadian military</td>\n",
              "      <td>The Canadian Armed Forces. 1  The first large-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>types of fruit trees</td>\n",
              "      <td>Cherry. Cherry trees are found throughout the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how many calories a day are lost breastfeeding</td>\n",
              "      <td>Not only is breastfeeding better for the baby,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            query                                           positive\n",
              "0        is a little caffeine ok during pregnancy  We don't know a lot about the effects of caffe...\n",
              "1               what fruit is native to australia  Passiflora herbertiana. A rare passion fruit n...\n",
              "2              how large is the canadian military  The Canadian Armed Forces. 1  The first large-...\n",
              "3                            types of fruit trees  Cherry. Cherry trees are found throughout the ...\n",
              "4  how many calories a day are lost breastfeeding  Not only is breastfeeding better for the baby,...\n",
              "\n",
              "[5 rows x 2 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Divisão em treino e validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "passage_train, passage_valid, query_train, query_valid = train_test_split(df['positive'].tolist(), \n",
        "                                                      df['query'].tolist(),\n",
        "                                                      test_size=1000, \n",
        "                                                      random_state=num_semente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'> 1000 how many fitbit steps equal a mile\n"
          ]
        }
      ],
      "source": [
        "print(type(query_valid), len(query_valid), query_valid[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'> 10000 There are 40 weeks in a school year - and 12 weeks of holidays. Unless you live somewhere snowy and you have to take snow days. These can extend the length by another week or so. There are 40 weeks in a school year - and 12 weeks of holidays. Unless you live somewhere snowy and you have to take snow days.\n"
          ]
        }
      ],
      "source": [
        "print(type(passage_train), len(passage_train), passage_train[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Criando dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DprDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "      Classe para criar um dataset de texto e query.\n",
        "    \"\"\"  \n",
        "    def __init__(self, passages: list, queries:list, tokenizer):\n",
        "      \"\"\"\n",
        "      Inicializa um novo objeto DprDataset.\n",
        "\n",
        "      Args:\n",
        "          passages (np.ndarray): um array com as strings de passage.\n",
        "          passages (np.ndarray): um array com as strings de queries.\n",
        "          tokenizer: um objeto tokenizer do Hugging Face Transformers.\n",
        "      Raises:\n",
        "          AssertionError: se os parâmetros não estiverem no formato esperado.\n",
        "      \"\"\"\n",
        "      # Verifica se os parâmetros são do tipo esperado\n",
        "      # assert isinstance(passages, np.ndarray), f\"Parâmetro passages deve ser do tipo np.ndarray e não {type(passages)}\"\n",
        "      # assert isinstance(queries, np.ndarray), f\"Parâmetro queries deve ser do tipo np.ndarray e não {type(queries)}\"\n",
        "      for row in passages:\n",
        "          assert isinstance(row, str), f\"Each element in passages.row must be a string e não {type(row)}\"\n",
        "          break\n",
        "\n",
        "            # Salvar os dados dos tensores para adiantar o tempo de processamento\n",
        "      self.tokenized_passages = tokenizer(passages, return_length=True)\n",
        "      self.tokenized_queries = tokenizer(queries, return_length=True)\n",
        "      \n",
        "      print(\"tokenized_passages size stats:\\n{}\\n\".format(stats.describe(self.tokenized_passages['length'])))\n",
        "      print(\"tokenized_queries size stats:\\n{}\\n\".format(stats.describe(self.tokenized_queries['length']))) \n",
        "\n",
        "      self.shuffle()\n",
        "\n",
        "\n",
        "    def shuffle(self):\n",
        "        # Fonte: colega Eduardo Seiti\n",
        "        self.samples_order = list(range(len(self.tokenized_queries['input_ids'])))\n",
        "        np.random.shuffle(self.samples_order)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_queries['input_ids'])\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {'passage': {'input_ids': self.tokenized_passages['input_ids'][self.samples_order[index]],\n",
        "                            'attention_mask': self.tokenized_passages['attention_mask'][self.samples_order[index]]},\n",
        "                'query' : {'input_ids': self.tokenized_queries['input_ids'][self.samples_order[index]],\n",
        "                            'attention_mask': self.tokenized_queries['attention_mask'][self.samples_order[index]]}}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import  BatchEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DPRCollator(object):\n",
        "    # Fonte: colega Eduardo Seiti\n",
        "    def __init__(self, type='passage', tokenizer=None):\n",
        "        assert type in ('passage', 'query'), f\"type {type} deve estar em ('passage', 'query')\"\n",
        "        self.type = type\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # print(f\"batch {batch}\")\n",
        "        lista = [item[self.type] for item in batch]\n",
        "        # print(f\"lista {lista}\")\n",
        "        padded_batch = self.tokenizer.pad(lista, return_tensors='pt')\n",
        "        # print(f\"padded_batch {padded_batch}\")\n",
        "        return BatchEncoding(padded_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17AcNhe2C4tb"
      },
      "source": [
        "#### Testando o MyDataset e o Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "_tNkc8kmC8ie"
      },
      "outputs": [],
      "source": [
        "# Cria dados fictícios\n",
        "texts = ['This is the first text',\n",
        "                  'This is text 2.1',\n",
        "                  'This is text 3.1',\n",
        "                  'This is text 4.1',\n",
        "                  'This is text 5.1',\n",
        "                  'This is text 6.1',\n",
        "                  'This is text 7.1']\n",
        "queries = ['This is the first query',\n",
        "                  'This is query 2.1',\n",
        "                  'This is query 3.1',\n",
        "                  'This is query 4.1',\n",
        "                  'This is query 5.1',\n",
        "                  'This is query 6.1',\n",
        "                  'This is query 7.1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1996, 2034, 3793, 102], [101, 2023, 2003, 3793, 1016, 1012, 1015, 102], [101, 2023, 2003, 3793, 1017, 1012, 1015, 102], [101, 2023, 2003, 3793, 1018, 1012, 1015, 102], [101, 2023, 2003, 3793, 1019, 1012, 1015, 102], [101, 2023, 2003, 3793, 1020, 1012, 1015, 102], [101, 2023, 2003, 3793, 1021, 1012, 1015, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer(texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbaCMoKRDy20",
        "outputId": "1853f452-f5a4-4803-d33b-b0dd58c8ba65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenized_passages size stats:\n",
            "DescribeResult(nobs=7, minmax=(7, 8), mean=7.857142857142857, variance=0.1428571428571429, skewness=-2.041241452319312, kurtosis=2.1666666666666563)\n",
            "\n",
            "tokenized_queries size stats:\n",
            "DescribeResult(nobs=7, minmax=(7, 8), mean=7.857142857142857, variance=0.1428571428571429, skewness=-2.041241452319312, kurtosis=2.1666666666666563)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cria um objeto da classe MyDataset\n",
        "dummy_dataset = DprDataset(passages=texts, queries=queries, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFNuWyMYDz7v",
        "outputId": "f74ff3bd-84d6-42a8-a7de-88501b882de9"
      },
      "outputs": [],
      "source": [
        "# Testa o método __len__()\n",
        "assert len(dummy_dataset) == 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Testa o método __getitem__()\n",
        "sample = dummy_dataset[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['passage', 'query'])\n"
          ]
        }
      ],
      "source": [
        "print(sample.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 2023, 2003, 3793, 1016, 1012, 1015, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(sample['passage'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "assert set(sample.keys()) == {'passage', 'query'} # \n",
        "assert set(sample['passage']) == {'input_ids', 'attention_mask'} # \n",
        "assert set(sample['query']) == {'input_ids', 'attention_mask'} # \n",
        "assert isinstance(sample['passage']['input_ids'], list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9ng05CvFu1t",
        "outputId": "476a8515-b00e-4df7-b7f4-be4382ae8917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'passage': {'input_ids': [101, 2023, 2003, 3793, 1016, 1012, 1015, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}, 'query': {'input_ids': [101, 2023, 2003, 23032, 1016, 1012, 1015, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}}\n"
          ]
        }
      ],
      "source": [
        "print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "5INVpV1RGuau"
      },
      "outputs": [],
      "source": [
        "dummy_loader = DataLoader(dummy_dataset, batch_size=3, shuffle=False, num_workers=0, \n",
        "                                                        collate_fn=DPRCollator('passage', tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "first_batch = next(iter(dummy_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[ 101, 2023, 2003, 3793, 1016, 1012, 1015,  102],\n",
            "        [ 101, 2023, 2003, 3793, 1018, 1012, 1015,  102],\n",
            "        [ 101, 2023, 2003, 3793, 1019, 1012, 1015,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "print(first_batch)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Criando datasets e dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenized_passages size stats:\n",
            "DescribeResult(nobs=1000, minmax=(19, 270), mean=80.419, variance=1082.6901291291294, skewness=1.2249734252598994, kurtosis=1.8839424951259751)\n",
            "\n",
            "tokenized_queries size stats:\n",
            "DescribeResult(nobs=1000, minmax=(4, 32), mean=9.072, variance=7.095911911911913, skewness=1.5337855672942304, kurtosis=6.957955492738629)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# train_dataset = MyDataset(X_train, Y_train, tokenizer)\n",
        "valid_dataset = DprDataset(passages=passage_valid, queries= query_valid, tokenizer= tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenized_passages size stats:\n",
            "DescribeResult(nobs=10000, minmax=(13, 280), mean=80.6696, variance=1047.7126071007099, skewness=1.126008868700056, kurtosis=1.4884134181168802)\n",
            "\n",
            "tokenized_queries size stats:\n",
            "DescribeResult(nobs=10000, minmax=(4, 43), mean=9.1068, variance=8.229416701670168, skewness=2.2592354361208167, kurtosis=14.94412756929329)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset = DprDataset(passages=passage_train, queries=query_train, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000 1000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset),len(valid_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm6_PTH2i98e"
      },
      "source": [
        "# Teste do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-QD1mZkMM9b",
        "outputId": "8df3c78f-a2cc-44ff-815a-17d59ebbdfc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 67.35\n",
            " available 56.04\n",
            " used 10.19\n",
            " free 11.01\n",
            " cached 45.64\n",
            " buffers 0.5\n",
            "/nGPU\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Tue Apr 18 18:19:11 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
            "| 58%   48C    P8    31W / 370W |    991MiB / 24576MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1260      G   /usr/lib/xorg/Xorg                 45MiB |\n",
            "|    0   N/A  N/A      1399      G   /usr/bin/gnome-shell               10MiB |\n",
            "|    0   N/A  N/A     19626      C   ...treinapython39/bin/python      931MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "mostra_memoria(['cpu','gpu'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, None, None, 512)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models['passage'].config.pad_token_id, models['passage'].config.eos_token_id, models['passage'].config.sep_token_id, models['passage'].config.max_position_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McvufVnXGlBt",
        "outputId": "56d3cc04-9ed2-4f35-afe5-2932720d5d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_workers_dataloader': 0, 'device': device(type='cuda', index=0), 'batch_size': 2}\n"
          ]
        }
      ],
      "source": [
        "hparam['batch_size'] = 2\n",
        "print(hparam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgeqpYyoHV6-",
        "outputId": "256625f3-50dd-49a5-d644-83f1de5e029a"
      },
      "outputs": [],
      "source": [
        "sample_passage = next(iter(DataLoader(valid_dataset,batch_size=hparam['batch_size'],collate_fn=DPRCollator('passage', tokenizer))))\n",
        "sample_query = next(iter(DataLoader(valid_dataset,batch_size=hparam['batch_size'],collate_fn=DPRCollator('query', tokenizer))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101, 14925, 14399,  2594, 10032,  5158,  2012,  1037,  3446,  1997,\n",
            "          2539,  1012,  1021,  3572,  2566,  1015,  1010,  2199,  3653, 28207,\n",
            "          9243,  1999,  2167,  2637,  1998,  2003,  1037,  2877,  3426,  1997,\n",
            "         11062, 13356,  1999,  1996,  2034, 12241, 20367,  1012,  3618,  7073,\n",
            "          1997,  3891,  5876,  1998,  5301,  2974,  1006, 16012, 15869, 16387,\n",
            "          1998, 11087,  3385,  9888,  1007,  3499, 14925, 14399,  2594, 10032,\n",
            "          2000,  2022,  4453,  2077,  1996,  2458,  1997,  2166,  1011,  8701,\n",
            "          2824,  1012,   102],\n",
            "        [  101,  3361,  2490,  1011,  3361,  4219,  3024,  2000,  2191,  2070,\n",
            "          2622,  2825,  1025,  1996,  3192,  3024,  2490,  2005,  1996,  7551,\n",
            "          1012,  3361,  5150,  1010,  4804,  1010,  5150,  1010,  2490,  1012,\n",
            "          7692,  1011,  2800,  3120,  1997,  7177,  1025,  1037,  2047,  2030,\n",
            "          3914,  4425,  2008,  2064,  2022,  4567,  2588,  2043,  2734,  1012,\n",
            "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0]])}\n"
          ]
        }
      ],
      "source": [
        "print(sample_passage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 73]) 2\n"
          ]
        }
      ],
      "source": [
        "print(sample_passage['input_ids'].shape, len(sample_query['input_ids']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  2129,  4703,  2515, 14925, 14399,  2594, 10032,   102],\n",
            "        [  101,  9375,  3361,  2490,   102,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "print(sample_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 9]) torch.Size([2, 73])\n"
          ]
        }
      ],
      "source": [
        "print(sample_query['input_ids'].shape, sample_passage['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "0KzkMqPk8aU0"
      },
      "outputs": [],
      "source": [
        "saida_passage = models['passage'](**sample_passage.to(hparam['device']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "0KzkMqPk8aU0"
      },
      "outputs": [],
      "source": [
        "saida_query = models['query'](**sample_query.to(hparam['device']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ISrblKorF4",
        "outputId": "e3fbae92-10bd-4ded-c203-2f8629202503"
      },
      "outputs": [],
      "source": [
        "# obtendo embeddings do token cls, o primeiro, índice 0\n",
        "cls_embedding_saida_passage = saida_passage.last_hidden_state[:, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ISrblKorF4",
        "outputId": "e3fbae92-10bd-4ded-c203-2f8629202503"
      },
      "outputs": [],
      "source": [
        "# obtendo embeddings do token cls, o primeiro, índice 0\n",
        "cls_embedding_saida_query = saida_query.last_hidden_state[:, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "print(type(cls_embedding_saida_query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 384]) torch.Size([2, 384])\n"
          ]
        }
      ],
      "source": [
        "print(cls_embedding_saida_query.shape, cls_embedding_saida_passage.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "J0Ct-TaTIICk"
      },
      "outputs": [],
      "source": [
        "assert cls_embedding_saida_query.shape[1] == 384, \"Cls[1] deveria ser do tamanho do embedding size\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert cls_embedding_saida_query.shape[0] == 2, \"Cls[0] deveria ser do tamanho do batch size\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ60n9LEr5jp",
        "outputId": "c98bfef7-7d90-4c73-84ec-96ab71da4099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 30522\n"
          ]
        }
      ],
      "source": [
        "print(models['passage'].config.pad_token_id, models['passage'].config.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "del cls_embedding_saida_query, cls_embedding_saida_passage, saida_passage, saida_query\n",
        "del sample_passage, sample_query"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t_rYB_7aI2_x"
      },
      "source": [
        "# Loss e avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_loss(passages_outputs, topics_outputs):\n",
        "    # Fonte: colega Carísio\n",
        "    \n",
        "    # Extrai a última camada oculta associada ao token [CLS]\n",
        "    tcls_queries = topics_outputs.last_hidden_state[:, 0, :]\n",
        "    tcls_docs    = passages_outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    # Normaliza os tensores\n",
        "    #tcls_queries = tcls_queries / torch.norm(tcls_queries, dim=1, keepdim=True)\n",
        "    #tcls_docs = tcls_docs / torch.norm(tcls_docs, dim=1, keepdim=True)\n",
        "    \n",
        "    # Agora é necessário calcular a loss. Para isso, o primeiro passo é\n",
        "    # calcular a similaridade entre uma query e documento (sim(q, d))\n",
        "    similaridade = torch.matmul(tcls_queries, torch.transpose(tcls_docs, 0, 1))\n",
        "\n",
        "    # Calcula a exponencial da similaridade\n",
        "    exp_sim = torch.exp(similaridade)\n",
        "    \n",
        "    # Calcula a loss\n",
        "    # Valor para o denominador: inclui os exemplos positivos e negativos (in-batch)\n",
        "    soma_linhas = exp_sim.sum(dim=1) \n",
        "    diagonal = torch.diag(exp_sim)\n",
        "    log_loss = -1* torch.log(diagonal/soma_linhas)\n",
        "    \n",
        "    loss = torch.mean(log_loss)\n",
        "    return loss    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation_step(parm_models, \n",
        "             parm_dataloaders):\n",
        "    # Fonte: colega Eduardo Seiti (ajustada)\n",
        "    \n",
        "    eval_losses = []\n",
        "\n",
        "    for model in parm_models:\n",
        "       parm_models[model].eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(list(zip(parm_dataloaders['passage'], parm_dataloaders['query'])), mininterval=0.5, desc=\"Eval\", disable=False):\n",
        "            passages_outputs = parm_models['passage'](**batch[0].to(hparam['device']))\n",
        "            topics_outputs = parm_models['query'](**batch[1].to(hparam['device']))\n",
        "            eval_losses.append(compute_loss(passages_outputs, topics_outputs).cpu().numpy())\n",
        "\n",
        "    final_loss = np.mean(eval_losses)\n",
        "    print(\"Eval loss: {:0.3f}\".format(final_loss))\n",
        "\n",
        "    return final_loss\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJtrsqPnE_l"
      },
      "source": [
        "# Treinamento e Validação \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculando loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_loaders = {\n",
        "     'passage': DataLoader(valid_dataset, batch_size=hparam['batch_size'], shuffle=False, \n",
        "                           drop_last=True, num_workers=hparam['num_workers_dataloader'],\n",
        "                           collate_fn=DPRCollator('passage', tokenizer)),\n",
        "     'query': DataLoader(valid_dataset, batch_size=hparam['batch_size'], shuffle=False, \n",
        "                           drop_last=True, num_workers=hparam['num_workers_dataloader'],\n",
        "                           collate_fn=DPRCollator('query', tokenizer))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 500/500 [00:10<00:00, 48.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "validation_loss = validation_step(models, valid_loaders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(valid_loaders['passage']))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "12HRQXz_NHIA"
      },
      "source": [
        "## Funções auxiliares de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "uwMnuznWtiAd"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "UkNIPj_LuMJO"
      },
      "outputs": [],
      "source": [
        "def treina_modelo (parm_models, parm_loader_trains, parm_loader_valids, hparam:dict, parm_se_gera_rastro:bool=True,  parm_intervalo_print = 10):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  global DIRETORIO_TRABALHO, tag_contexto_rastro\n",
        "  if parm_se_gera_rastro:\n",
        "    rastro_neptune = NeptuneRastroRun(hparam, parm_lista_tag= tag_contexto_rastro )\n",
        "  try:\n",
        "    print(f'hparam: {hparam}')\n",
        "    path_modelo = f'{DIRETORIO_TRABALHO}_best_model_inicio_treino_{time.strftime(\"%Y-%b-%d %H:%M:%S\")}'\n",
        "    n_examples = 0\n",
        "    best_validation_loss= float('inf') # desejamos reduzir a distância entre pares (embeddings) próximos\n",
        "    best_epoca = 0\n",
        "    history = []\n",
        "    validation_loss = validation_step(parm_models, parm_loader_valids)       \n",
        "    metrica_rastro = {\"valid/loss\": validation_loss}  \n",
        "    print(f'Momento: {time.strftime(\"[%Y-%b-%d %H:%M:%S]\")} Métricas iniciais em validação: {metrica_rastro} Serão treinadas {hparam[\"max_examples\"]} amostras')\n",
        "    history.append(metrica_rastro)\n",
        "    if parm_se_gera_rastro:\n",
        "      rastro_neptune.salva_metrica(metrica_rastro)\n",
        "\n",
        "    time_inicio_treino = time.time()\n",
        "    ultima_epoca_treinada = 0\n",
        "    for model in parm_models:\n",
        "       parm_models[model].train()    \n",
        "\n",
        "    best_models_dict = {}\n",
        "    train_losses = []\n",
        "    for epoch in tqdm(range(hparam['num_epochs']), desc='Epochs'):    \n",
        "        \n",
        "\n",
        "        ultima_epoca_treinada += 1 \n",
        "\n",
        "        for batch in tqdm(list(zip(parm_loader_trains['passage'], parm_loader_trains['query'])), mininterval=0.5, desc=\"Train\", disable=False):\n",
        "\n",
        "\n",
        "            passages_outputs = parm_models['passage'](**batch[0].to(hparam['device']))\n",
        "            topics_outputs = parm_models['query'](**batch[1].to(hparam['device']))\n",
        "\n",
        "            loss = hparam['criterion'](passages_outputs, topics_outputs)\n",
        "            \n",
        "            loss.backward()\n",
        "\n",
        "            n_examples += len(batch[0]['input_ids']) # Increment of batch size\n",
        "\n",
        "            for model in parm_models:\n",
        "              hparam[f'optimizer_{model}'].step()\n",
        "              hparam[f'scheduler_{model}'].step()  \n",
        "              hparam[f'optimizer_{model}'].zero_grad()\n",
        "\n",
        "            train_losses.append(loss.detach().cpu().numpy()) \n",
        "       \n",
        "        if not isinstance( parm_loader_trains['passage'], list): # caso de treino com overfit \n",
        "            parm_loader_trains['passage'].dataset.shuffle()  # já funciona pra o 'query' também\n",
        "\n",
        "        if ultima_epoca_treinada % hparam['eval_every_epocas'] == 0:\n",
        "\n",
        "            train_loss = np.average(train_losses)\n",
        "\n",
        "            validation_loss = validation_step(parm_models, parm_loader_valids)                \n",
        "\n",
        "            train_losses = []\n",
        "\n",
        "            metrica_rastro = {\"train/loss\": train_loss, \n",
        "                              \"train/n_examples\": n_examples, \n",
        "                              \"train/learning_rate\": hparam[\"optimizer_passage\"].param_groups[0][\"lr\"],\n",
        "                              \"valid/loss\": validation_loss}  \n",
        "            history.append(metrica_rastro)\n",
        "            if parm_se_gera_rastro:\n",
        "              rastro_neptune.salva_metrica(metrica_rastro)\n",
        "\n",
        "            sufixo_msg = \"\"\n",
        "            \n",
        "            # Salvando o melhor modelo de acordo com a loss de validação\n",
        "            if validation_loss < best_validation_loss:\n",
        "                best_models_dict = {'passage': parm_models['passage'].state_dict(),\n",
        "                    'query': parm_models['query'].state_dict(),\n",
        "                }\n",
        "                best_validation_loss= validation_loss\n",
        "                best_epoca = epoch\n",
        "                sufixo_msg += f\" nova best epoca {validation_loss}\"\n",
        "\n",
        "                # salva quando encontrado best_epoca\n",
        "                # se não houve melhoria em 1 epoca anterior\n",
        "                \n",
        "                # if qtd_metrica_sem_melhor_metrica >= 1:                    \n",
        "                #  torch.save(parm_model, path_modelo)    \n",
        "                #  sufixo_msg += f\"; modelo salvo em {path_modelo}\"\n",
        "                #  print(sufixo_msg)\n",
        "\n",
        "                qtd_metrica_sem_melhor_metrica = 0\n",
        "              \n",
        "                # print('best model')\n",
        "            elif hparam['early_stop'] <= (ultima_epoca_treinada - best_epoca):\n",
        "                print(f\"Parando por critério de early_stop no step {ultima_epoca_treinada} sendo best_epoca {best_epoca} e ealy_stop {hparam['early_stop']}\")\n",
        "                break\n",
        "            else:\n",
        "                qtd_metrica_sem_melhor_metrica +=1\n",
        "\n",
        "            if parm_intervalo_print > 0:\n",
        "                if ultima_epoca_treinada%parm_intervalo_print == 0: \n",
        "                  print(f'Época: {ultima_epoca_treinada} Amostras:{n_examples:d} de um total de {int(hparam[\"max_examples\"])} ({100*n_examples/hparam[\"max_examples\"]:.3f}%)')\n",
        "                  print(f'Momento: {time.strftime(\"[%Y-%b-%d %H:%M:%S]\")} lr: {hparam[\"optimizer_passage\"].param_groups[0][\"lr\"]:.5e} Treino loss: {train_loss:.4f} Validação loss: {validation_loss:.4f} {sufixo_msg}')\n",
        "\n",
        "            for model in parm_models:\n",
        "              parm_models[model].train() \n",
        "\n",
        "            \n",
        "    # calculando tempo gasto e médio por step\n",
        "    tempo_treino = time.time() - time_inicio_treino   \n",
        "    print(f\"Tempo gasto total {tempo_treino:9.5f}, steps: {ultima_epoca_treinada}, tempo por step {tempo_treino/ultima_epoca_treinada:9.5f}\")\n",
        "    \n",
        "    print(f'Final: Step: {ultima_epoca_treinada} Amostras:{n_examples:d}  {100*n_examples/hparam[\"max_examples\"]:.3f}%  Momento: {time.strftime(\"[%Y-%b-%d %H:%M:%S]\")} lr:{hparam[\"optimizer_passage\"].param_groups[0][\"lr\"]:.5e} Train loss: {train_loss:.4f}  Validação loss: {validation_loss:.4f} ')\n",
        "\n",
        "    if 'passage' in best_models_dict:  # pode não existir se treino de overfit\n",
        "      for model in parm_models:\n",
        "          parm_models[model].load_state_dict(best_models_dict[model])\n",
        "          torch.save(parm_models[model], f\"{path_modelo}_{model}.pt\")    \n",
        "      print(f\"Modelo com melhor resultado em validação (step {best_epoca}) salvo após treino em {path_modelo}\")\n",
        "\n",
        "\n",
        "    validation_loss = validation_step(parm_models, parm_loader_valids)   \n",
        "\n",
        "    metrica_rastro = {\"valid/loss\": validation_loss}      \n",
        "    print(f\" Resultado com dados de teste para modelo treinado: {metrica_rastro}\")\n",
        "    if parm_se_gera_rastro:\n",
        "      rastro_neptune.run_neptune[\"context/tempo_treino\"] = tempo_treino\n",
        "      rastro_neptune.run_neptune[\"context/tempo_treino_por_step\"] = tempo_treino/ultima_epoca_treinada\n",
        "      rastro_neptune.run_neptune[\"valid/best_epoca\"] = best_epoca\n",
        "      rastro_neptune.salva_metrica(metrica_rastro)\n",
        "      #rastro_neptune.gera_grafico_modelo(parm_loader_train, parm_model)    \n",
        "\n",
        "\n",
        "  finally:\n",
        "    if parm_se_gera_rastro:\n",
        "      rastro_neptune.stop()\n",
        "\n",
        "\n",
        "  return {\"loss_validacao\":validation_loss, \"loss_treino\":train_loss, \"best_validation_loss\":best_validation_loss,  \"best_epoca\": best_epoca} #, \"best_model_dict\": best_model_dict}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IpynnWi-SoTi"
      },
      "source": [
        "Limpa o cache da memória da GPU\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AdamW #get_cosine_with_hard_restarts_schedule_with_warmup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import LambdaLR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def linear_warmup_cosine_annealing_lr(optimizer, num_warmup_steps, num_total_steps, min_lr, max_lr):\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda current_step: lr_lambda(current_step, num_warmup_steps, num_total_steps, min_lr, max_lr))\n",
        "    # print(f\"criado scheduler com num_warmup_steps {num_warmup_steps}, num_total_steps {num_total_steps}, min_lr {min_lr}, max_lr {max_lr}\")\n",
        "    return scheduler\n",
        "\n",
        "def lr_lambda(current_step, num_warmup_steps, num_total_steps, min_lr, max_lr):\n",
        "    if current_step < num_warmup_steps:\n",
        "        val = min(max_lr, float(current_step) / float(max(1, num_warmup_steps)))\n",
        "        # print(f\"Em lr_lambda current_step {current_step} < num_warmup_steps {num_warmup_steps} val {val}\")\n",
        "        return val\n",
        "    else:\n",
        "        progress = float(current_step - num_warmup_steps) / float(max(1, num_total_steps - num_warmup_steps))\n",
        "        val = max(min_lr, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "        # print(f\"Em lr_lambda current_step {current_step} >= num_warmup_steps {num_warmup_steps} val {val}\")\n",
        "        return val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "PZhfJhoC0Xmk"
      },
      "outputs": [],
      "source": [
        "def ajusta_parametro_grid(hparam, combinacao_parametro, parm_models, se_treina_poucos_dados:bool=False):\n",
        "  parametro_esperado_grid = (\"batch_size\", \n",
        "                             \"num_epochs\", \"learning_rate\")\n",
        "  if not parm_models or not isinstance(parm_models,dict):\n",
        "    raise Exception(\"Necessário informar model (tipo dict)!\")                            \n",
        "  if 'passage' not in parm_models or 'query' not in parm_models:\n",
        "    raise Exception(\"Necessário informar model!\")                            \n",
        "  for nome_parametro in parametro_esperado_grid:\n",
        "      if nome_parametro not in combinacao_parametro:\n",
        "          raise NotImplementedError(f'Gride de parâmetros está incompleto, não contem {nome_parametro}')\n",
        "      hparam[nome_parametro] = combinacao_parametro[nome_parametro]\n",
        "  for nome_parametro in combinacao_parametro:\n",
        "      if nome_parametro not in parametro_esperado_grid:\n",
        "          raise NotImplementedError(f'Gride de parâmetros está com parâmetro adicional não tratado: {nome_parametro}')\n",
        "      hparam[nome_parametro] = combinacao_parametro[nome_parametro]\n",
        "  hparam['num_workers_dataloader'] = 0 # MUDAR DEPOIS\n",
        "\n",
        "  # The drop_last=True parameter ignores the last batch \n",
        "  # (when the number of examples in your dataset is not divisible by your batch_size ) \n",
        "  hparam['drop_last'] = True\n",
        "  train_loaders = {\n",
        "     'passage': DataLoader(train_dataset, batch_size=hparam['batch_size'], shuffle=False, \n",
        "                           drop_last=hparam['drop_last'], num_workers=hparam['num_workers_dataloader'],\n",
        "                           collate_fn=DPRCollator('passage', tokenizer)),\n",
        "     'query': DataLoader(train_dataset, batch_size=hparam['batch_size'], shuffle=False, \n",
        "                           drop_last=hparam['drop_last'], num_workers=hparam['num_workers_dataloader'],\n",
        "                           collate_fn=DPRCollator('query', tokenizer))}\n",
        "                      \n",
        "  valid_loaders = {\n",
        "     'passage': DataLoader(valid_dataset, batch_size=hparam['batch_size'], shuffle=False, \n",
        "                           drop_last=hparam['drop_last'], num_workers=hparam['num_workers_dataloader'],\n",
        "                           collate_fn=DPRCollator('passage', tokenizer)),\n",
        "     'query': DataLoader(valid_dataset, batch_size=hparam['batch_size'], shuffle=False, \n",
        "                           drop_last=hparam['drop_last'], num_workers=hparam['num_workers_dataloader'],\n",
        "                           collate_fn=DPRCollator('query', tokenizer))}\n",
        "                      \n",
        "  hparam['train_size'] = len(train_dataset) \n",
        "  hparam['valid_size'] = len(valid_dataset) \n",
        "  if se_treina_poucos_dados:\n",
        "    train_loaders = {\n",
        "        'passage': [next(iter(train_loaders['passage']))],\n",
        "        'query': [next(iter(train_loaders['query']))] } # para overfit com poucos dados (1 batch)\n",
        "  hparam['steps_train_per_epoch'] = len(train_loaders['passage'])\n",
        "\n",
        "  hparam['max_examples'] = hparam['num_epochs'] * hparam['train_size']\n",
        "  hparam['eval_every_epocas'] = 1 \n",
        "  hparam['max_steps'] = hparam['num_epochs'] * hparam['steps_train_per_epoch']   # (hparam['train_size'] / hparam['batch_size'] )\n",
        "\n",
        "  hparam['early_stop'] = 10 * hparam['eval_every_epocas']\n",
        "  hparam['criterion'] = compute_loss\n",
        "  \n",
        "  inicializa_seed(123)\n",
        "  \n",
        "  hparam['num_warmup_steps'] = int(hparam['max_steps'] * 0.1) \n",
        "\n",
        "  hparam['num_params'] = count_parameters(parm_models['passage'])\n",
        "  print(f\"Number of model parameters: {hparam['num_params']}\")\n",
        "  # hparam['learning_rate'] =  3e-5 # 1e-3\n",
        "\n",
        "  for model in parm_models:\n",
        "    hparam[f'optimizer_{model}'] = AdamW(parm_models[model].parameters(), lr=hparam['learning_rate'])\n",
        "    #hparam[f'scheduler_{model}'] = get_cosine_with_hard_restarts_schedule_with_warmup(hparam[f'optimizer_{model}'], num_warmup_steps=hparam['num_warmup_steps'],num_training_steps=hparam['max_steps'],) \n",
        "    hparam[f'scheduler_{model}'] = linear_warmup_cosine_annealing_lr(optimizer=hparam[f'optimizer_{model}'],   num_warmup_steps = hparam['num_warmup_steps'], num_total_steps= hparam['max_steps'], min_lr=1e-7,  max_lr=0.001 )  # Criação do scheduler linear com warm-up e decaimento[\n",
        "  \n",
        "  return hparam, parm_models, train_loaders, valid_loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "-OKGe-cu9GkN"
      },
      "outputs": [],
      "source": [
        "def treina_grid(hparam, gridparam, parm_models, parm_se_gera_rastro:bool=True, se_treina_poucos_dados:bool=False): \n",
        "  if not parm_models or not isinstance(parm_models,dict):\n",
        "    raise Exception(\"Necessário informar model (tipo dict)!\")                            \n",
        "  if 'passage' not in parm_models or 'query' not in parm_models:\n",
        "    raise Exception(\"Necessário informar model!\")                               \n",
        "\n",
        "  keys, values = zip(*gridparam.items())\n",
        "  lista_combinacao_grid = [dict(zip(keys, v)) for v in itertools.product(*values)]  \n",
        "  total_combinacao = len(lista_combinacao_grid)\n",
        "  print(f\"Serão {total_combinacao} experimentações de parâmetros\")\n",
        "  qtd_experimento = 1\n",
        "  lista_resultado = []\n",
        "  # for cnt_combinacao, combinacao in enumerate(tqdm(lista_combinacao_grid, desc=f\"Experimento {qtd_experimento}/{total_combinacao}\")):\n",
        "  for cnt_combinacao, combinacao in enumerate(lista_combinacao_grid):\n",
        "    print(f\"\\n\\nNUM: {qtd_experimento}/{total_combinacao} : {combinacao} \")\n",
        "    hparam, parm_models, train_loaders, valid_loaders = ajusta_parametro_grid(hparam, combinacao, parm_models, se_treina_poucos_dados=se_treina_poucos_dados)\n",
        "    #ipdb.set_trace(context=4)\n",
        "    resultado = treina_modelo(parm_models, parm_loader_trains=train_loaders, parm_loader_valids=valid_loaders,\n",
        "                          hparam=hparam,\n",
        "                          parm_se_gera_rastro=parm_se_gera_rastro,  parm_intervalo_print=1)\n",
        "    \n",
        "    qtd_experimento += 1\n",
        "    print(cnt_combinacao, resultado)\n",
        "    lista_resultado.append((cnt_combinacao, resultado))\n",
        "  return lista_resultado\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x1RESg_Jb8vs"
      },
      "source": [
        "# Validando configuração de treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCxs2QdSY3da"
      },
      "source": [
        "### Testando em poucos dados (Overfit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se tiver que treinar os modelos, abre\n",
        "models = {'query': AutoModel.from_pretrained(MODEL_NAME).to(hparam['device']),\n",
        "'passage' : AutoModel.from_pretrained(MODEL_NAME).to(hparam['device'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "Pwep987wSLIx"
      },
      "outputs": [],
      "source": [
        "gridparam = { \n",
        "               'learning_rate': [ 1e-4],\n",
        "               'num_epochs':[10],\n",
        "               'batch_size':[8],\n",
        "             }                           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5tYXy4Y8Spu",
        "outputId": "5ff661ce-ed88-4844-a351-a79a66035b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Serão 1 experimentações\n",
            "\n",
            "\n",
            "NUM: 1/1 : {'learning_rate': 0.0001, 'num_epochs': 10, 'batch_size': 8} \n",
            "Number of model parameters: 33360000\n",
            "hparam: {'num_workers_dataloader': 0, 'device': device(type='cuda', index=0), 'batch_size': 8, 'num_epochs': 10, 'learning_rate': 0.0001, 'drop_last': True, 'train_size': 10000, 'valid_size': 1000, 'max_examples': 80, 'eval_every_epocas': 1, 'early_stop': 20, 'criterion': <function compute_loss at 0x7f5bd4e9d700>, 'num_warmup_steps': 8, 'num_params': 33360000, 'optimizer_query': AdamW (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0\n",
            "    weight_decay: 0.0\n",
            "), 'scheduler_query': <torch.optim.lr_scheduler.LambdaLR object at 0x7f5bd49ff790>, 'optimizer_passage': AdamW (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0\n",
            "    weight_decay: 0.0\n",
            "), 'scheduler_passage': <torch.optim.lr_scheduler.LambdaLR object at 0x7f5af22ff7c0>}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 38.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.056\n",
            "Momento: [2023-Apr-18 00:16:44] Métricas iniciais em validação: {'valid/loss': 2.0563312} Serão treinadas 80 amostras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 38.85it/s]\n",
            "Epochs:  10%|█         | 1/10 [00:03<00:34,  3.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.056\n",
            "Época: 1 Amostras:8 de um total de 80 (10.000%)\n",
            "Momento: [2023-Apr-18 00:16:48] lr: 1.25000e-05 Treino loss: 2.0446 Validação loss: 2.0563  nova best epoca 2.056331157684326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 39.54it/s]\n",
            "Epochs:  20%|██        | 2/10 [00:07<00:29,  3.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.055\n",
            "Época: 2 Amostras:16 de um total de 80 (20.000%)\n",
            "Momento: [2023-Apr-18 00:16:52] lr: 2.50000e-05 Treino loss: 2.0259 Validação loss: 2.0552  nova best epoca 2.0552475452423096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 37.93it/s]\n",
            "Epochs:  30%|███       | 3/10 [00:11<00:26,  3.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.053\n",
            "Época: 3 Amostras:24 de um total de 80 (30.000%)\n",
            "Momento: [2023-Apr-18 00:16:56] lr: 3.75000e-05 Treino loss: 2.0339 Validação loss: 2.0530  nova best epoca 2.052987813949585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 38.71it/s]\n",
            "Epochs:  40%|████      | 4/10 [00:14<00:22,  3.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.049\n",
            "Época: 4 Amostras:32 de um total de 80 (40.000%)\n",
            "Momento: [2023-Apr-18 00:16:59] lr: 5.00000e-05 Treino loss: 2.0092 Validação loss: 2.0491  nova best epoca 2.04911208152771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 38.90it/s]\n",
            "Epochs:  50%|█████     | 5/10 [00:18<00:18,  3.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.042\n",
            "Época: 5 Amostras:40 de um total de 80 (50.000%)\n",
            "Momento: [2023-Apr-18 00:17:03] lr: 6.25000e-05 Treino loss: 1.9530 Validação loss: 2.0422  nova best epoca 2.0422356128692627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 38.89it/s]\n",
            "Epochs:  60%|██████    | 6/10 [00:22<00:14,  3.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.030\n",
            "Época: 6 Amostras:48 de um total de 80 (60.000%)\n",
            "Momento: [2023-Apr-18 00:17:07] lr: 7.50000e-05 Treino loss: 1.8124 Validação loss: 2.0302  nova best epoca 2.030231475830078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 38.98it/s]\n",
            "Epochs:  70%|███████   | 7/10 [00:25<00:11,  3.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.012\n",
            "Época: 7 Amostras:56 de um total de 80 (70.000%)\n",
            "Momento: [2023-Apr-18 00:17:10] lr: 8.75000e-05 Treino loss: 1.6340 Validação loss: 2.0116  nova best epoca 2.011603355407715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 37.86it/s]\n",
            "Epochs:  80%|████████  | 8/10 [00:29<00:07,  3.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 1.985\n",
            "Época: 8 Amostras:64 de um total de 80 (80.000%)\n",
            "Momento: [2023-Apr-18 00:17:14] lr: 1.00000e-04 Treino loss: 1.4070 Validação loss: 1.9845  nova best epoca 1.9845304489135742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 38.74it/s]\n",
            "Epochs:  90%|█████████ | 9/10 [00:33<00:03,  3.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 1.994\n",
            "Época: 9 Amostras:72 de um total de 80 (90.000%)\n",
            "Momento: [2023-Apr-18 00:17:18] lr: 9.99524e-05 Treino loss: 1.0864 Validação loss: 1.9944 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 38.62it/s]\n",
            "Epochs: 100%|██████████| 10/10 [00:37<00:00,  3.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.092\n",
            "Época: 10 Amostras:80 de um total de 80 (100.000%)\n",
            "Momento: [2023-Apr-18 00:17:21] lr: 9.98097e-05 Treino loss: 0.7660 Validação loss: 2.0921 \n",
            "Tempo gasto total  37.00500, steps: 10, tempo por step   3.70050\n",
            "Final: Step: 10 Amostras:80  100.000%  Momento: [2023-Apr-18 00:17:21] lr:9.98097e-05 Train loss: 0.7660  Validação loss: 2.0921 \n",
            "Modelo com melhor resultado em validação (step 7) salvo após treino em /home/borela/fontes/deep_learning_em_buscas_unicamp/local/dpr_best_model_inicio_treino_2023-Apr-18 00:16:41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 125/125 [00:03<00:00, 38.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 2.092\n",
            " Resultado com dados de teste para modelo treinado: {'valid/loss': 2.0920947}\n",
            "0 {'loss_validacao': 2.0920947, 'loss_treino': 0.76597375, 'best_validation_loss': 1.9845304, 'best_epoca': 7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "resultado = treina_grid(hparam, gridparam, models, parm_se_gera_rastro = False, se_treina_poucos_dados=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCGzCsRe8Sf9",
        "outputId": "0a3a88a8-99b0-4ccb-a9a1-9cbeb73f42c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 67.35\n",
            " available 52.03\n",
            " used 14.17\n",
            " free 23.16\n",
            " cached 29.38\n",
            " buffers 0.64\n",
            "/nGPU\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Tue Apr 18 00:17:34 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
            "| 67%   59C    P2   127W / 370W |  17489MiB / 24576MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1241      G   /usr/lib/xorg/Xorg                 45MiB |\n",
            "|    0   N/A  N/A      1381      G   /usr/bin/gnome-shell               14MiB |\n",
            "|    0   N/A  N/A   2836714      C   ...treinapython39/bin/python    17425MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "mostra_memoria(['cpu','gpu'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Treinando em todos os dados (3 experimentos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se tiver que treinar os modelos, abre\n",
        "models = {'query': AutoModel.from_pretrained(MODEL_NAME).to(hparam['device']),\n",
        "'passage' : AutoModel.from_pretrained(MODEL_NAME).to(hparam['device'])}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### batch size 32 (zero_grad após chamada do modelo, antes da chamada de loss.backward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "bWyPky-Qd887"
      },
      "outputs": [],
      "source": [
        "gridparam = { \n",
        "               'learning_rate': [ 1e-4],\n",
        "               'num_epochs':[50],\n",
        "               'batch_size':[32],\n",
        "             }             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rayM8tB9d888",
        "outputId": "f510b233-cdf8-4ae3-f0e9-4b0649f9fa20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Serão 1 experimentações\n",
            "\n",
            "\n",
            "NUM: 1/1 : {'learning_rate': 0.0001, 'num_epochs': 50, 'batch_size': 32} \n",
            "Number of model parameters: 33360000\n",
            "hparam: {'num_workers_dataloader': 0, 'device': device(type='cuda', index=0), 'batch_size': 32, 'num_epochs': 50, 'learning_rate': 0.0001, 'drop_last': True, 'train_size': 10000, 'valid_size': 1000, 'max_examples': 1600, 'eval_every_epocas': 1, 'early_stop': 20, 'criterion': <function compute_loss at 0x7f5bd4e9d700>, 'num_warmup_steps': 160, 'num_params': 33360000, 'optimizer_query': AdamW (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0\n",
            "    weight_decay: 0.0\n",
            "), 'scheduler_query': <torch.optim.lr_scheduler.LambdaLR object at 0x7f5bd45888e0>, 'optimizer_passage': AdamW (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0\n",
            "    weight_decay: 0.0\n",
            "), 'scheduler_passage': <torch.optim.lr_scheduler.LambdaLR object at 0x7f5bd48716d0>}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 3.440\n",
            "Momento: [2023-Apr-18 00:18:12] Métricas iniciais em validação: {'valid/loss': 3.44012} Serão treinadas 1600 amostras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.25it/s]\n",
            "Epochs:   2%|▏         | 1/50 [02:29<2:02:14, 149.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.221\n",
            "Época: 1 Amostras:9984 de um total de 1600 (624.000%)\n",
            "Momento: [2023-Apr-18 00:20:42] lr: 9.72759e-05 Treino loss: 1.0875 Validação loss: 0.2209  nova best epoca 0.22086751461029053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.27it/s]\n",
            "Epochs:   4%|▍         | 2/50 [04:56<1:58:36, 148.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.120\n",
            "Época: 2 Amostras:19968 de um total de 1600 (1248.000%)\n",
            "Momento: [2023-Apr-18 00:23:09] lr: 7.64960e-05 Treino loss: 0.2211 Validação loss: 0.1196  nova best epoca 0.11955433338880539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.44it/s]\n",
            "Epochs:   6%|▌         | 3/50 [07:23<1:55:22, 147.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.120\n",
            "Época: 3 Amostras:29952 de um total de 1600 (1872.000%)\n",
            "Momento: [2023-Apr-18 00:25:35] lr: 4.39065e-05 Treino loss: 0.1059 Validação loss: 0.1202 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:23<00:00,  2.17it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.06it/s]\n",
            "Epochs:   8%|▊         | 4/50 [09:48<1:52:21, 146.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.080\n",
            "Época: 4 Amostras:39936 de um total de 1600 (2496.000%)\n",
            "Momento: [2023-Apr-18 00:28:00] lr: 1.40330e-05 Treino loss: 0.0424 Validação loss: 0.0804  nova best epoca 0.080406054854393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.60it/s]\n",
            "Epochs:  10%|█         | 5/50 [12:15<1:50:00, 146.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 5 Amostras:49920 de um total de 1600 (3120.000%)\n",
            "Momento: [2023-Apr-18 00:30:27] lr: 1.90265e-07 Treino loss: 0.0231 Validação loss: 0.0711  nova best epoca 0.07109829783439636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:23<00:00,  2.17it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.60it/s]\n",
            "Epochs:  12%|█▏        | 6/50 [14:40<1:47:13, 146.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 6 Amostras:59904 de um total de 1600 (3744.000%)\n",
            "Momento: [2023-Apr-18 00:32:53] lr: 0.00000e+00 Treino loss: 0.0230 Validação loss: 0.0711  nova best epoca 0.07109065353870392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.53it/s]\n",
            "Epochs:  14%|█▍        | 7/50 [17:06<1:44:45, 146.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 7 Amostras:69888 de um total de 1600 (4368.000%)\n",
            "Momento: [2023-Apr-18 00:35:19] lr: 0.00000e+00 Treino loss: 0.0215 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.30it/s]\n",
            "Epochs:  16%|█▌        | 8/50 [19:34<1:42:35, 146.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 8 Amostras:79872 de um total de 1600 (4992.000%)\n",
            "Momento: [2023-Apr-18 00:37:46] lr: 0.00000e+00 Treino loss: 0.0229 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.59it/s]\n",
            "Epochs:  18%|█▊        | 9/50 [22:01<1:40:14, 146.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 9 Amostras:89856 de um total de 1600 (5616.000%)\n",
            "Momento: [2023-Apr-18 00:40:13] lr: 0.00000e+00 Treino loss: 0.0166 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:23<00:00,  2.18it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.48it/s]\n",
            "Epochs:  20%|██        | 10/50 [24:26<1:37:30, 146.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 10 Amostras:99840 de um total de 1600 (6240.000%)\n",
            "Momento: [2023-Apr-18 00:42:38] lr: 0.00000e+00 Treino loss: 0.0210 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.42it/s]\n",
            "Epochs:  22%|██▏       | 11/50 [26:52<1:35:06, 146.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 11 Amostras:109824 de um total de 1600 (6864.000%)\n",
            "Momento: [2023-Apr-18 00:45:05] lr: 0.00000e+00 Treino loss: 0.0226 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.45it/s]\n",
            "Epochs:  24%|██▍       | 12/50 [29:19<1:32:39, 146.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 12 Amostras:119808 de um total de 1600 (7488.000%)\n",
            "Momento: [2023-Apr-18 00:47:31] lr: 0.00000e+00 Treino loss: 0.0195 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:23<00:00,  2.17it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.45it/s]\n",
            "Epochs:  26%|██▌       | 13/50 [31:44<1:30:05, 146.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 13 Amostras:129792 de um total de 1600 (8112.000%)\n",
            "Momento: [2023-Apr-18 00:49:57] lr: 0.00000e+00 Treino loss: 0.0225 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.37it/s]\n",
            "Epochs:  28%|██▊       | 14/50 [34:11<1:27:49, 146.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 14 Amostras:139776 de um total de 1600 (8736.000%)\n",
            "Momento: [2023-Apr-18 00:52:24] lr: 0.00000e+00 Treino loss: 0.0179 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.17it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.50it/s]\n",
            "Epochs:  30%|███       | 15/50 [36:37<1:25:18, 146.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 15 Amostras:149760 de um total de 1600 (9360.000%)\n",
            "Momento: [2023-Apr-18 00:54:50] lr: 0.00000e+00 Treino loss: 0.0202 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:23<00:00,  2.18it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.58it/s]\n",
            "Epochs:  32%|███▏      | 16/50 [39:02<1:22:41, 145.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 16 Amostras:159744 de um total de 1600 (9984.000%)\n",
            "Momento: [2023-Apr-18 00:57:15] lr: 0.00000e+00 Treino loss: 0.0191 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:23<00:00,  2.17it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.45it/s]\n",
            "Epochs:  34%|███▍      | 17/50 [41:28<1:20:13, 145.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 17 Amostras:169728 de um total de 1600 (10608.000%)\n",
            "Momento: [2023-Apr-18 00:59:41] lr: 0.00000e+00 Treino loss: 0.0230 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.12it/s]\n",
            "Epochs:  36%|███▌      | 18/50 [43:54<1:17:51, 145.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 18 Amostras:179712 de um total de 1600 (11232.000%)\n",
            "Momento: [2023-Apr-18 01:02:07] lr: 0.00000e+00 Treino loss: 0.0180 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.43it/s]\n",
            "Epochs:  38%|███▊      | 19/50 [46:21<1:15:29, 146.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 19 Amostras:189696 de um total de 1600 (11856.000%)\n",
            "Momento: [2023-Apr-18 01:04:33] lr: 0.00000e+00 Treino loss: 0.0212 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.55it/s]\n",
            "Epochs:  40%|████      | 20/50 [48:47<1:13:07, 146.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 20 Amostras:199680 de um total de 1600 (12480.000%)\n",
            "Momento: [2023-Apr-18 01:07:00] lr: 0.00000e+00 Treino loss: 0.0221 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.50it/s]\n",
            "Epochs:  42%|████▏     | 21/50 [51:14<1:10:41, 146.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 21 Amostras:209664 de um total de 1600 (13104.000%)\n",
            "Momento: [2023-Apr-18 01:09:26] lr: 0.00000e+00 Treino loss: 0.0168 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.23it/s]\n",
            "Epochs:  44%|████▍     | 22/50 [53:41<1:08:21, 146.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 22 Amostras:219648 de um total de 1600 (13728.000%)\n",
            "Momento: [2023-Apr-18 01:11:53] lr: 0.00000e+00 Treino loss: 0.0240 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.36it/s]\n",
            "Epochs:  46%|████▌     | 23/50 [56:07<1:05:54, 146.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 23 Amostras:229632 de um total de 1600 (14352.000%)\n",
            "Momento: [2023-Apr-18 01:14:20] lr: 0.00000e+00 Treino loss: 0.0201 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.27it/s]\n",
            "Epochs:  48%|████▊     | 24/50 [58:33<1:03:26, 146.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Época: 24 Amostras:239616 de um total de 1600 (14976.000%)\n",
            "Momento: [2023-Apr-18 01:16:46] lr: 0.00000e+00 Treino loss: 0.0204 Validação loss: 0.0711 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.30it/s]\n",
            "Epochs:  48%|████▊     | 24/50 [1:01:01<1:06:06, 152.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            "Parando por critério de early_stop no step 25 sendo best_epoca 5 e ealy_stop 20\n",
            "Tempo gasto total 3661.29248, steps: 25, tempo por step 146.45170\n",
            "Final: Step: 25 Amostras:249600  15600.000%  Momento: [2023-Apr-18 01:19:13] lr:0.00000e+00 Train loss: 0.0201  Validação loss: 0.0711 \n",
            "Modelo com melhor resultado em validação (step 5) salvo após treino em /home/borela/fontes/deep_learning_em_buscas_unicamp/local/dpr_best_model_inicio_treino_2023-Apr-18 00:18:10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.071\n",
            " Resultado com dados de teste para modelo treinado: {'valid/loss': 0.07109065}\n",
            "0 {'loss_validacao': 0.07109065, 'loss_treino': 0.020110017, 'best_validation_loss': 0.07109065, 'best_epoca': 5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  {'loss_validacao': 0.07109065,\n",
              "   'loss_treino': 0.020110017,\n",
              "   'best_validation_loss': 0.07109065,\n",
              "   'best_epoca': 5})]"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treina_grid(hparam, gridparam, models, parm_se_gera_rastro = False, se_treina_poucos_dados=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### batch size 32, lr menor, com rastro (zero_grad após chamada do modelo, antes da chamada de loss.backward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se tiver que treinar os modelos, abre\n",
        "models = {'query': AutoModel.from_pretrained(MODEL_NAME).to(hparam['device']),\n",
        "'passage' : AutoModel.from_pretrained(MODEL_NAME).to(hparam['device'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "bWyPky-Qd887"
      },
      "outputs": [],
      "source": [
        "gridparam = { \n",
        "               'learning_rate': [ 1e-5],\n",
        "               'num_epochs':[50],\n",
        "               'batch_size':[32],\n",
        "             }             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rayM8tB9d888",
        "outputId": "f510b233-cdf8-4ae3-f0e9-4b0649f9fa20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Serão 1 experimentações\n",
            "\n",
            "\n",
            "NUM: 1/1 : {'learning_rate': 1e-05, 'num_epochs': 50, 'batch_size': 32} \n",
            "Number of model parameters: 33360000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/borela/miniconda3/envs/treinapython39/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "https://app.neptune.ai/marcusborela/IA386DD/e/IAD-74\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2836714/1999415923.py:26: NeptuneDeprecationWarning: The object you're logging will be implicitly cast to a string. We'll end support of this behavior in `neptune-client==1.0.0`. To log the object as a string, use `str(object)` or `repr(object)` instead. For details, see https://docs.neptune.ai/setup/neptune-client_1-0_release_changes\n",
            "  self.run_neptune['parameters'] = vparams\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hparam: {'num_workers_dataloader': 0, 'device': device(type='cuda', index=0), 'batch_size': 32, 'num_epochs': 50, 'learning_rate': 1e-05, 'drop_last': True, 'train_size': 10000, 'valid_size': 1000, 'max_examples': 1600, 'eval_every_epocas': 1, 'early_stop': 30, 'criterion': <function compute_loss at 0x7f5bd4e9d700>, 'num_warmup_steps': 160, 'num_params': 33360000, 'optimizer_query': AdamW (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 1e-05\n",
            "    lr: 0.0\n",
            "    weight_decay: 0.0\n",
            "), 'scheduler_query': <torch.optim.lr_scheduler.LambdaLR object at 0x7f5bd4b21e50>, 'optimizer_passage': AdamW (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 1e-05\n",
            "    lr: 0.0\n",
            "    weight_decay: 0.0\n",
            "), 'scheduler_passage': <torch.optim.lr_scheduler.LambdaLR object at 0x7f5bd4b21e20>}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 22.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 3.440\n",
            "Momento: [2023-Apr-18 08:58:07] Métricas iniciais em validação: {'valid/loss': 3.44012} Serão treinadas 1600 amostras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.65it/s]\n",
            "Epochs:   2%|▏         | 1/50 [02:28<2:01:00, 148.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.335\n",
            "Época: 1 Amostras:9984 de um total de 1600 (624.000%)\n",
            "Momento: [2023-Apr-18 09:00:35] lr: 9.72759e-06 Treino loss: 1.8020 Validação loss: 0.3347  nova best epoca 0.33473724126815796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.16it/s]\n",
            "Epochs:   4%|▍         | 2/50 [04:54<1:57:53, 147.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.137\n",
            "Época: 2 Amostras:19968 de um total de 1600 (1248.000%)\n",
            "Momento: [2023-Apr-18 09:03:01] lr: 7.64960e-06 Treino loss: 0.3140 Validação loss: 0.1368  nova best epoca 0.1368064135313034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.14it/s]\n",
            "Epochs:   6%|▌         | 3/50 [07:22<1:55:25, 147.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.098\n",
            "Época: 3 Amostras:29952 de um total de 1600 (1872.000%)\n",
            "Momento: [2023-Apr-18 09:05:29] lr: 4.39065e-06 Treino loss: 0.1677 Validação loss: 0.0983  nova best epoca 0.09832019358873367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.10it/s]\n",
            "Epochs:   8%|▊         | 4/50 [09:49<1:52:58, 147.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 4 Amostras:39936 de um total de 1600 (2496.000%)\n",
            "Momento: [2023-Apr-18 09:07:56] lr: 1.40330e-06 Treino loss: 0.1248 Validação loss: 0.0903  nova best epoca 0.09032918512821198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.12it/s]\n",
            "Epochs:  10%|█         | 5/50 [12:17<1:50:40, 147.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 5 Amostras:49920 de um total de 1600 (3120.000%)\n",
            "Momento: [2023-Apr-18 09:10:24] lr: 1.90265e-08 Treino loss: 0.0962 Validação loss: 0.0901  nova best epoca 0.09012480825185776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.07it/s]\n",
            "Epochs:  12%|█▏        | 6/50 [14:44<1:48:02, 147.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 6 Amostras:59904 de um total de 1600 (3744.000%)\n",
            "Momento: [2023-Apr-18 09:12:51] lr: 0.00000e+00 Treino loss: 0.1008 Validação loss: 0.0901  nova best epoca 0.0901118814945221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.45it/s]\n",
            "Epochs:  14%|█▍        | 7/50 [17:12<1:45:45, 147.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 7 Amostras:69888 de um total de 1600 (4368.000%)\n",
            "Momento: [2023-Apr-18 09:15:19] lr: 0.00000e+00 Treino loss: 0.1023 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.29it/s]\n",
            "Epochs:  16%|█▌        | 8/50 [19:39<1:43:13, 147.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 8 Amostras:79872 de um total de 1600 (4992.000%)\n",
            "Momento: [2023-Apr-18 09:17:46] lr: 0.00000e+00 Treino loss: 0.1016 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.00it/s]\n",
            "Epochs:  18%|█▊        | 9/50 [22:07<1:40:48, 147.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 9 Amostras:89856 de um total de 1600 (5616.000%)\n",
            "Momento: [2023-Apr-18 09:20:14] lr: 0.00000e+00 Treino loss: 0.0963 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.41it/s]\n",
            "Epochs:  20%|██        | 10/50 [24:34<1:38:17, 147.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 10 Amostras:99840 de um total de 1600 (6240.000%)\n",
            "Momento: [2023-Apr-18 09:22:41] lr: 0.00000e+00 Treino loss: 0.0997 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.14it/s]\n",
            "Epochs:  22%|██▏       | 11/50 [27:02<1:36:00, 147.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 11 Amostras:109824 de um total de 1600 (6864.000%)\n",
            "Momento: [2023-Apr-18 09:25:09] lr: 0.00000e+00 Treino loss: 0.0968 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.35it/s]\n",
            "Epochs:  24%|██▍       | 12/50 [29:31<1:33:37, 147.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 12 Amostras:119808 de um total de 1600 (7488.000%)\n",
            "Momento: [2023-Apr-18 09:27:38] lr: 0.00000e+00 Treino loss: 0.0981 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.22it/s]\n",
            "Epochs:  26%|██▌       | 13/50 [31:59<1:31:13, 147.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 13 Amostras:129792 de um total de 1600 (8112.000%)\n",
            "Momento: [2023-Apr-18 09:30:06] lr: 0.00000e+00 Treino loss: 0.1052 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.34it/s]\n",
            "Epochs:  28%|██▊       | 14/50 [34:27<1:28:45, 147.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 14 Amostras:139776 de um total de 1600 (8736.000%)\n",
            "Momento: [2023-Apr-18 09:32:34] lr: 0.00000e+00 Treino loss: 0.1006 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.00it/s]\n",
            "Epochs:  30%|███       | 15/50 [36:53<1:26:05, 147.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 15 Amostras:149760 de um total de 1600 (9360.000%)\n",
            "Momento: [2023-Apr-18 09:35:00] lr: 0.00000e+00 Treino loss: 0.1000 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.08it/s]\n",
            "Epochs:  32%|███▏      | 16/50 [39:21<1:23:38, 147.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 16 Amostras:159744 de um total de 1600 (9984.000%)\n",
            "Momento: [2023-Apr-18 09:37:28] lr: 0.00000e+00 Treino loss: 0.1050 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.31it/s]\n",
            "Epochs:  34%|███▍      | 17/50 [41:49<1:21:12, 147.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 17 Amostras:169728 de um total de 1600 (10608.000%)\n",
            "Momento: [2023-Apr-18 09:39:56] lr: 0.00000e+00 Treino loss: 0.0998 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.48it/s]\n",
            "Epochs:  36%|███▌      | 18/50 [44:16<1:18:42, 147.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 18 Amostras:179712 de um total de 1600 (11232.000%)\n",
            "Momento: [2023-Apr-18 09:42:23] lr: 0.00000e+00 Treino loss: 0.1052 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 20.94it/s]\n",
            "Epochs:  38%|███▊      | 19/50 [46:43<1:16:08, 147.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 19 Amostras:189696 de um total de 1600 (11856.000%)\n",
            "Momento: [2023-Apr-18 09:44:50] lr: 0.00000e+00 Treino loss: 0.0931 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.46it/s]\n",
            "Epochs:  40%|████      | 20/50 [49:10<1:13:37, 147.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 20 Amostras:199680 de um total de 1600 (12480.000%)\n",
            "Momento: [2023-Apr-18 09:47:17] lr: 0.00000e+00 Treino loss: 0.1007 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.19it/s]\n",
            "Epochs:  42%|████▏     | 21/50 [51:38<1:11:13, 147.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 21 Amostras:209664 de um total de 1600 (13104.000%)\n",
            "Momento: [2023-Apr-18 09:49:45] lr: 0.00000e+00 Treino loss: 0.1000 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.41it/s]\n",
            "Epochs:  44%|████▍     | 22/50 [54:06<1:08:53, 147.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 22 Amostras:219648 de um total de 1600 (13728.000%)\n",
            "Momento: [2023-Apr-18 09:52:13] lr: 0.00000e+00 Treino loss: 0.1027 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.29it/s]\n",
            "Epochs:  46%|████▌     | 23/50 [56:33<1:06:23, 147.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 23 Amostras:229632 de um total de 1600 (14352.000%)\n",
            "Momento: [2023-Apr-18 09:54:40] lr: 0.00000e+00 Treino loss: 0.0980 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.33it/s]\n",
            "Epochs:  48%|████▊     | 24/50 [59:01<1:03:54, 147.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 24 Amostras:239616 de um total de 1600 (14976.000%)\n",
            "Momento: [2023-Apr-18 09:57:08] lr: 0.00000e+00 Treino loss: 0.1023 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.31it/s]\n",
            "Epochs:  50%|█████     | 25/50 [1:01:27<1:01:21, 147.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 25 Amostras:249600 de um total de 1600 (15600.000%)\n",
            "Momento: [2023-Apr-18 09:59:34] lr: 0.00000e+00 Treino loss: 0.1027 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.28it/s]\n",
            "Epochs:  52%|█████▏    | 26/50 [1:03:55<58:56, 147.35s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 26 Amostras:259584 de um total de 1600 (16224.000%)\n",
            "Momento: [2023-Apr-18 10:02:02] lr: 0.00000e+00 Treino loss: 0.0937 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.50it/s]\n",
            "Epochs:  54%|█████▍    | 27/50 [1:06:23<56:36, 147.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 27 Amostras:269568 de um total de 1600 (16848.000%)\n",
            "Momento: [2023-Apr-18 10:04:30] lr: 0.00000e+00 Treino loss: 0.0998 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.46it/s]\n",
            "Epochs:  56%|█████▌    | 28/50 [1:08:51<54:11, 147.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 28 Amostras:279552 de um total de 1600 (17472.000%)\n",
            "Momento: [2023-Apr-18 10:06:58] lr: 0.00000e+00 Treino loss: 0.0982 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 20.93it/s]\n",
            "Epochs:  58%|█████▊    | 29/50 [1:11:20<51:49, 148.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 29 Amostras:289536 de um total de 1600 (18096.000%)\n",
            "Momento: [2023-Apr-18 10:09:27] lr: 0.00000e+00 Treino loss: 0.1067 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.37it/s]\n",
            "Epochs:  60%|██████    | 30/50 [1:13:47<49:13, 147.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 30 Amostras:299520 de um total de 1600 (18720.000%)\n",
            "Momento: [2023-Apr-18 10:11:54] lr: 0.00000e+00 Treino loss: 0.1084 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 20.90it/s]\n",
            "Epochs:  62%|██████▏   | 31/50 [1:16:15<46:47, 147.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 31 Amostras:309504 de um total de 1600 (19344.000%)\n",
            "Momento: [2023-Apr-18 10:14:22] lr: 0.00000e+00 Treino loss: 0.0967 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.29it/s]\n",
            "Epochs:  64%|██████▍   | 32/50 [1:18:41<44:12, 147.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 32 Amostras:319488 de um total de 1600 (19968.000%)\n",
            "Momento: [2023-Apr-18 10:16:48] lr: 0.00000e+00 Treino loss: 0.1067 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.30it/s]\n",
            "Epochs:  66%|██████▌   | 33/50 [1:21:08<41:42, 147.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 33 Amostras:329472 de um total de 1600 (20592.000%)\n",
            "Momento: [2023-Apr-18 10:19:15] lr: 0.00000e+00 Treino loss: 0.0932 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.18it/s]\n",
            "Epochs:  68%|██████▊   | 34/50 [1:23:35<39:15, 147.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 34 Amostras:339456 de um total de 1600 (21216.000%)\n",
            "Momento: [2023-Apr-18 10:21:42] lr: 0.00000e+00 Treino loss: 0.1017 Validação loss: 0.0901 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.34it/s]\n",
            "Epochs:  68%|██████▊   | 34/50 [1:26:03<40:29, 151.87s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Parando por critério de early_stop no step 35 sendo best_epoca 5 e ealy_stop 30\n",
            "Tempo gasto total 5163.43968, steps: 35, tempo por step 147.52685\n",
            "Final: Step: 35 Amostras:349440  21840.000%  Momento: [2023-Apr-18 10:24:10] lr:0.00000e+00 Train loss: 0.1051  Validação loss: 0.0901 \n",
            "Modelo com melhor resultado em validação (step 5) salvo após treino em /home/borela/fontes/deep_learning_em_buscas_unicamp/local/dpr_best_model_inicio_treino_2023-Apr-18 08:58:05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            " Resultado com dados de teste para modelo treinado: {'valid/loss': 0.09011188}\n",
            "Shutting down background jobs, please wait a moment...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Waiting for the remaining 53 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 53 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/marcusborela/IA386DD/e/IAD-74\n",
            "0 {'loss_validacao': 0.09011188, 'loss_treino': 0.10510916, 'best_validation_loss': 0.09011188, 'best_epoca': 5}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  {'loss_validacao': 0.09011188,\n",
              "   'loss_treino': 0.10510916,\n",
              "   'best_validation_loss': 0.09011188,\n",
              "   'best_epoca': 5})]"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treina_grid(hparam, gridparam, models, parm_se_gera_rastro = True, se_treina_poucos_dados=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### batch size 32, outro otimizador, zero_grad após step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se tiver que treinar os modelos, abre\n",
        "models = {'query': AutoModel.from_pretrained(MODEL_NAME).to(hparam['device']),\n",
        "'passage' : AutoModel.from_pretrained(MODEL_NAME).to(hparam['device'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "bWyPky-Qd887"
      },
      "outputs": [],
      "source": [
        "gridparam = { \n",
        "               'learning_rate': [ 1e-5],\n",
        "               'num_epochs':[50],\n",
        "               'batch_size':[32],\n",
        "             }             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rayM8tB9d888",
        "outputId": "f510b233-cdf8-4ae3-f0e9-4b0649f9fa20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Serão 1 experimentações de parâmetros\n",
            "\n",
            "\n",
            "NUM: 1/1 : {'learning_rate': 1e-05, 'num_epochs': 50, 'batch_size': 32} \n",
            "Number of model parameters: 33360000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/borela/miniconda3/envs/treinapython39/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/tmp/ipykernel_19626/1999415923.py:12: NeptuneDeprecationWarning: `init` is deprecated, use `init_run` instead. We'll end support of it in `neptune-client==1.0.0`. For details, see https://docs.neptune.ai/setup/neptune-client_1-0_release_changes\n",
            "  self.run_neptune = neptune.init(project=self.__class__.neptune_project, api_token=self.__class__.neptune_api_token, capture_hardware_metrics=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "https://app.neptune.ai/marcusborela/IA386DD/e/IAD-81\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_19626/1999415923.py:26: NeptuneDeprecationWarning: The object you're logging will be implicitly cast to a string. We'll end support of this behavior in `neptune-client==1.0.0`. To log the object as a string, use `str(object)` or `repr(object)` instead. For details, see https://docs.neptune.ai/setup/neptune-client_1-0_release_changes\n",
            "  self.run_neptune['parameters'] = vparams\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hparam: {'num_workers_dataloader': 0, 'device': device(type='cuda', index=0), 'batch_size': 32, 'num_epochs': 50, 'learning_rate': 1e-05, 'drop_last': True, 'train_size': 10000, 'valid_size': 1000, 'steps_train_per_epoch': 312, 'max_examples': 500000, 'eval_every_epocas': 1, 'max_steps': 15600, 'early_stop': 20, 'criterion': <function compute_loss at 0x7f88ec367550>, 'num_warmup_steps': 1560, 'num_params': 33360000, 'optimizer_query': AdamW (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 1e-05\n",
            "    lr: 0.0\n",
            "    weight_decay: 0.0\n",
            "), 'scheduler_query': <torch.optim.lr_scheduler.LambdaLR object at 0x7f88ec385d60>, 'optimizer_passage': AdamW (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 1e-05\n",
            "    lr: 0.0\n",
            "    weight_decay: 0.0\n",
            "), 'scheduler_passage': <torch.optim.lr_scheduler.LambdaLR object at 0x7f88ec385d90>}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 3.440\n",
            "Momento: [2023-Apr-18 18:37:21] Métricas iniciais em validação: {'valid/loss': 3.4401646} Serão treinadas 500000 amostras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.76it/s]\n",
            "Epochs:   2%|▏         | 1/50 [02:31<2:03:22, 151.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 3.440\n",
            "Época: 1 Amostras:9984 de um total de 500000 (1.997%)\n",
            "Momento: [2023-Apr-18 18:39:52] lr: 1.00000e-08 Treino loss: 3.4458 Validação loss: 3.4396  nova best epoca 3.439648389816284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 20.13it/s]\n",
            "Epochs:   4%|▍         | 2/50 [05:00<2:00:07, 150.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 3.439\n",
            "Época: 2 Amostras:19968 de um total de 500000 (3.994%)\n",
            "Momento: [2023-Apr-18 18:42:21] lr: 1.00000e-08 Treino loss: 3.4450 Validação loss: 3.4391  nova best epoca 3.4391186237335205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.70it/s]\n",
            "Epochs:   6%|▌         | 3/50 [07:31<1:57:47, 150.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 3.439\n",
            "Época: 3 Amostras:29952 de um total de 500000 (5.990%)\n",
            "Momento: [2023-Apr-18 18:44:52] lr: 1.00000e-08 Treino loss: 3.4443 Validação loss: 3.4386  nova best epoca 3.438589572906494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.57it/s]\n",
            "Epochs:   8%|▊         | 4/50 [10:01<1:55:14, 150.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 3.438\n",
            "Época: 4 Amostras:39936 de um total de 500000 (7.987%)\n",
            "Momento: [2023-Apr-18 18:47:22] lr: 1.00000e-08 Treino loss: 3.4443 Validação loss: 3.4381  nova best epoca 3.4380502700805664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.51it/s]\n",
            "Epochs:  10%|█         | 5/50 [12:31<1:52:44, 150.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 3.438\n",
            "Época: 5 Amostras:49920 de um total de 500000 (9.984%)\n",
            "Momento: [2023-Apr-18 18:49:53] lr: 1.00000e-05 Treino loss: 3.4440 Validação loss: 3.4375  nova best epoca 3.437509298324585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.82it/s]\n",
            "Epochs:  12%|█▏        | 6/50 [15:01<1:50:06, 150.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.148\n",
            "Época: 6 Amostras:59904 de um total de 500000 (11.981%)\n",
            "Momento: [2023-Apr-18 18:52:22] lr: 9.98782e-06 Treino loss: 0.9448 Validação loss: 0.1484  nova best epoca 0.14838431775569916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.22it/s]\n",
            "Epochs:  14%|█▍        | 7/50 [17:32<1:47:50, 150.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.106\n",
            "Época: 7 Amostras:69888 de um total de 500000 (13.978%)\n",
            "Momento: [2023-Apr-18 18:54:54] lr: 9.95134e-06 Treino loss: 0.1710 Validação loss: 0.1064  nova best epoca 0.10642417520284653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.34it/s]\n",
            "Epochs:  16%|█▌        | 8/50 [20:02<1:45:06, 150.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.105\n",
            "Época: 8 Amostras:79872 de um total de 500000 (15.974%)\n",
            "Momento: [2023-Apr-18 18:57:23] lr: 9.89074e-06 Treino loss: 0.1004 Validação loss: 0.1049  nova best epoca 0.10487674176692963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.63it/s]\n",
            "Epochs:  18%|█▊        | 9/50 [22:33<1:42:51, 150.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 9 Amostras:89856 de um total de 500000 (17.971%)\n",
            "Momento: [2023-Apr-18 18:59:54] lr: 9.80631e-06 Treino loss: 0.0722 Validação loss: 0.0899  nova best epoca 0.08986566215753555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.75it/s]\n",
            "Epochs:  20%|██        | 10/50 [25:03<1:40:16, 150.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.093\n",
            "Época: 10 Amostras:99840 de um total de 500000 (19.968%)\n",
            "Momento: [2023-Apr-18 19:02:25] lr: 9.69846e-06 Treino loss: 0.0623 Validação loss: 0.0933 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.21it/s]\n",
            "Epochs:  22%|██▏       | 11/50 [27:33<1:37:38, 150.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.105\n",
            "Época: 11 Amostras:109824 de um total de 500000 (21.965%)\n",
            "Momento: [2023-Apr-18 19:04:54] lr: 9.56773e-06 Treino loss: 0.0480 Validação loss: 0.1052 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.71it/s]\n",
            "Epochs:  24%|██▍       | 12/50 [30:03<1:35:08, 150.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.089\n",
            "Época: 12 Amostras:119808 de um total de 500000 (23.962%)\n",
            "Momento: [2023-Apr-18 19:07:25] lr: 9.41474e-06 Treino loss: 0.0468 Validação loss: 0.0893  nova best epoca 0.08931393176317215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.70it/s]\n",
            "Epochs:  26%|██▌       | 13/50 [32:34<1:32:48, 150.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.108\n",
            "Época: 13 Amostras:129792 de um total de 500000 (25.958%)\n",
            "Momento: [2023-Apr-18 19:09:56] lr: 9.24024e-06 Treino loss: 0.0345 Validação loss: 0.1078 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.78it/s]\n",
            "Epochs:  28%|██▊       | 14/50 [35:04<1:30:10, 150.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.103\n",
            "Época: 14 Amostras:139776 de um total de 500000 (27.955%)\n",
            "Momento: [2023-Apr-18 19:12:26] lr: 9.04508e-06 Treino loss: 0.0362 Validação loss: 0.1029 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.66it/s]\n",
            "Epochs:  30%|███       | 15/50 [37:35<1:27:42, 150.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.104\n",
            "Época: 15 Amostras:149760 de um total de 500000 (29.952%)\n",
            "Momento: [2023-Apr-18 19:14:56] lr: 8.83022e-06 Treino loss: 0.0358 Validação loss: 0.1041 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.39it/s]\n",
            "Epochs:  32%|███▏      | 16/50 [40:05<1:25:07, 150.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.106\n",
            "Época: 16 Amostras:159744 de um total de 500000 (31.949%)\n",
            "Momento: [2023-Apr-18 19:17:26] lr: 8.59670e-06 Treino loss: 0.0259 Validação loss: 0.1055 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.72it/s]\n",
            "Epochs:  34%|███▍      | 17/50 [42:34<1:22:33, 150.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.088\n",
            "Época: 17 Amostras:169728 de um total de 500000 (33.946%)\n",
            "Momento: [2023-Apr-18 19:19:56] lr: 8.34565e-06 Treino loss: 0.0238 Validação loss: 0.0884  nova best epoca 0.0883638933300972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.74it/s]\n",
            "Epochs:  36%|███▌      | 18/50 [45:05<1:20:07, 150.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.101\n",
            "Época: 18 Amostras:179712 de um total de 500000 (35.942%)\n",
            "Momento: [2023-Apr-18 19:22:26] lr: 8.07831e-06 Treino loss: 0.0189 Validação loss: 0.1007 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.63it/s]\n",
            "Epochs:  38%|███▊      | 19/50 [47:35<1:17:37, 150.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.093\n",
            "Época: 19 Amostras:189696 de um total de 500000 (37.939%)\n",
            "Momento: [2023-Apr-18 19:24:57] lr: 7.79596e-06 Treino loss: 0.0208 Validação loss: 0.0930 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.45it/s]\n",
            "Epochs:  40%|████      | 20/50 [50:05<1:15:00, 150.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.107\n",
            "Época: 20 Amostras:199680 de um total de 500000 (39.936%)\n",
            "Momento: [2023-Apr-18 19:27:26] lr: 7.50000e-06 Treino loss: 0.0233 Validação loss: 0.1074 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.68it/s]\n",
            "Epochs:  42%|████▏     | 21/50 [52:35<1:12:33, 150.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.101\n",
            "Época: 21 Amostras:209664 de um total de 500000 (41.933%)\n",
            "Momento: [2023-Apr-18 19:29:56] lr: 7.19186e-06 Treino loss: 0.0219 Validação loss: 0.1009 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:30<00:00,  2.07it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.73it/s]\n",
            "Epochs:  44%|████▍     | 22/50 [55:07<1:10:22, 150.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.089\n",
            "Época: 22 Amostras:219648 de um total de 500000 (43.930%)\n",
            "Momento: [2023-Apr-18 19:32:29] lr: 6.87303e-06 Treino loss: 0.0162 Validação loss: 0.0893 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.57it/s]\n",
            "Epochs:  46%|████▌     | 23/50 [57:38<1:07:52, 150.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.096\n",
            "Época: 23 Amostras:229632 de um total de 500000 (45.926%)\n",
            "Momento: [2023-Apr-18 19:35:00] lr: 6.54508e-06 Treino loss: 0.0176 Validação loss: 0.0956 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.49it/s]\n",
            "Epochs:  48%|████▊     | 24/50 [1:00:09<1:05:17, 150.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.088\n",
            "Época: 24 Amostras:239616 de um total de 500000 (47.923%)\n",
            "Momento: [2023-Apr-18 19:37:30] lr: 6.20961e-06 Treino loss: 0.0168 Validação loss: 0.0879  nova best epoca 0.08788134902715683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.50it/s]\n",
            "Epochs:  50%|█████     | 25/50 [1:02:39<1:02:42, 150.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.090\n",
            "Época: 25 Amostras:249600 de um total de 500000 (49.920%)\n",
            "Momento: [2023-Apr-18 19:40:00] lr: 5.86824e-06 Treino loss: 0.0137 Validação loss: 0.0905 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.67it/s]\n",
            "Epochs:  52%|█████▏    | 26/50 [1:05:09<1:00:08, 150.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.092\n",
            "Época: 26 Amostras:259584 de um total de 500000 (51.917%)\n",
            "Momento: [2023-Apr-18 19:42:30] lr: 5.52264e-06 Treino loss: 0.0099 Validação loss: 0.0919 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.12it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.68it/s]\n",
            "Epochs:  54%|█████▍    | 27/50 [1:07:38<57:31, 150.05s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.095\n",
            "Época: 27 Amostras:269568 de um total de 500000 (53.914%)\n",
            "Momento: [2023-Apr-18 19:44:59] lr: 5.17450e-06 Treino loss: 0.0118 Validação loss: 0.0951 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.36it/s]\n",
            "Epochs:  56%|█████▌    | 28/50 [1:10:09<55:09, 150.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.096\n",
            "Época: 28 Amostras:279552 de um total de 500000 (55.910%)\n",
            "Momento: [2023-Apr-18 19:47:31] lr: 4.82550e-06 Treino loss: 0.0144 Validação loss: 0.0961 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.53it/s]\n",
            "Epochs:  58%|█████▊    | 29/50 [1:12:37<52:21, 149.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.097\n",
            "Época: 29 Amostras:289536 de um total de 500000 (57.907%)\n",
            "Momento: [2023-Apr-18 19:49:58] lr: 4.47736e-06 Treino loss: 0.0135 Validação loss: 0.0971 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.70it/s]\n",
            "Epochs:  60%|██████    | 30/50 [1:15:04<49:37, 148.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.094\n",
            "Época: 30 Amostras:299520 de um total de 500000 (59.904%)\n",
            "Momento: [2023-Apr-18 19:52:26] lr: 4.13176e-06 Treino loss: 0.0135 Validação loss: 0.0939 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.76it/s]\n",
            "Epochs:  62%|██████▏   | 31/50 [1:17:34<47:11, 149.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.088\n",
            "Época: 31 Amostras:309504 de um total de 500000 (61.901%)\n",
            "Momento: [2023-Apr-18 19:54:55] lr: 3.79039e-06 Treino loss: 0.0156 Validação loss: 0.0880 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.46it/s]\n",
            "Epochs:  64%|██████▍   | 32/50 [1:20:05<44:52, 149.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.094\n",
            "Época: 32 Amostras:319488 de um total de 500000 (63.898%)\n",
            "Momento: [2023-Apr-18 19:57:26] lr: 3.45492e-06 Treino loss: 0.0081 Validação loss: 0.0936 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.69it/s]\n",
            "Epochs:  66%|██████▌   | 33/50 [1:22:36<42:31, 150.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.088\n",
            "Época: 33 Amostras:329472 de um total de 500000 (65.894%)\n",
            "Momento: [2023-Apr-18 19:59:57] lr: 3.12697e-06 Treino loss: 0.0126 Validação loss: 0.0885 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.57it/s]\n",
            "Epochs:  68%|██████▊   | 34/50 [1:25:06<40:02, 150.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.094\n",
            "Época: 34 Amostras:339456 de um total de 500000 (67.891%)\n",
            "Momento: [2023-Apr-18 20:02:28] lr: 2.80814e-06 Treino loss: 0.0076 Validação loss: 0.0943 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:30<00:00,  2.08it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.61it/s]\n",
            "Epochs:  70%|███████   | 35/50 [1:27:38<37:41, 150.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.079\n",
            "Época: 35 Amostras:349440 de um total de 500000 (69.888%)\n",
            "Momento: [2023-Apr-18 20:05:00] lr: 2.50000e-06 Treino loss: 0.0103 Validação loss: 0.0794  nova best epoca 0.07940934598445892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.33it/s]\n",
            "Epochs:  72%|███████▏  | 36/50 [1:30:08<35:06, 150.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.084\n",
            "Época: 36 Amostras:359424 de um total de 500000 (71.885%)\n",
            "Momento: [2023-Apr-18 20:07:29] lr: 2.20404e-06 Treino loss: 0.0099 Validação loss: 0.0843 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.79it/s]\n",
            "Epochs:  74%|███████▍  | 37/50 [1:32:38<32:35, 150.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.089\n",
            "Época: 37 Amostras:369408 de um total de 500000 (73.882%)\n",
            "Momento: [2023-Apr-18 20:10:00] lr: 1.92169e-06 Treino loss: 0.0085 Validação loss: 0.0887 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.54it/s]\n",
            "Epochs:  76%|███████▌  | 38/50 [1:35:08<30:01, 150.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.089\n",
            "Época: 38 Amostras:379392 de um total de 500000 (75.878%)\n",
            "Momento: [2023-Apr-18 20:12:29] lr: 1.65435e-06 Treino loss: 0.0076 Validação loss: 0.0886 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.74it/s]\n",
            "Epochs:  78%|███████▊  | 39/50 [1:37:37<27:29, 149.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.085\n",
            "Época: 39 Amostras:389376 de um total de 500000 (77.875%)\n",
            "Momento: [2023-Apr-18 20:14:59] lr: 1.40330e-06 Treino loss: 0.0076 Validação loss: 0.0849 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.12it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.35it/s]\n",
            "Epochs:  80%|████████  | 40/50 [1:40:07<24:57, 149.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.085\n",
            "Época: 40 Amostras:399360 de um total de 500000 (79.872%)\n",
            "Momento: [2023-Apr-18 20:17:28] lr: 1.16978e-06 Treino loss: 0.0089 Validação loss: 0.0853 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.56it/s]\n",
            "Epochs:  82%|████████▏ | 41/50 [1:42:36<22:27, 149.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.083\n",
            "Época: 41 Amostras:409344 de um total de 500000 (81.869%)\n",
            "Momento: [2023-Apr-18 20:19:58] lr: 9.54915e-07 Treino loss: 0.0057 Validação loss: 0.0825 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.60it/s]\n",
            "Epochs:  84%|████████▍ | 42/50 [1:45:05<19:54, 149.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.084\n",
            "Época: 42 Amostras:419328 de um total de 500000 (83.866%)\n",
            "Momento: [2023-Apr-18 20:22:26] lr: 7.59760e-07 Treino loss: 0.0077 Validação loss: 0.0842 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.11it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.70it/s]\n",
            "Epochs:  86%|████████▌ | 43/50 [1:47:35<17:27, 149.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.084\n",
            "Época: 43 Amostras:429312 de um total de 500000 (85.862%)\n",
            "Momento: [2023-Apr-18 20:24:56] lr: 5.85262e-07 Treino loss: 0.0061 Validação loss: 0.0841 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:28<00:00,  2.10it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.48it/s]\n",
            "Epochs:  88%|████████▊ | 44/50 [1:50:05<14:58, 149.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.086\n",
            "Época: 44 Amostras:439296 de um total de 500000 (87.859%)\n",
            "Momento: [2023-Apr-18 20:27:27] lr: 4.32273e-07 Treino loss: 0.0060 Validação loss: 0.0855 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.40it/s]\n",
            "Epochs:  90%|█████████ | 45/50 [1:52:37<12:31, 150.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.086\n",
            "Época: 45 Amostras:449280 de um total de 500000 (89.856%)\n",
            "Momento: [2023-Apr-18 20:29:58] lr: 3.01537e-07 Treino loss: 0.0074 Validação loss: 0.0865 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.37it/s]\n",
            "Epochs:  92%|█████████▏| 46/50 [1:55:08<10:02, 150.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.087\n",
            "Época: 46 Amostras:459264 de um total de 500000 (91.853%)\n",
            "Momento: [2023-Apr-18 20:32:29] lr: 1.93692e-07 Treino loss: 0.0072 Validação loss: 0.0872 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:36<00:00,  1.99it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.57it/s]\n",
            "Epochs:  94%|█████████▍| 47/50 [1:57:47<07:38, 152.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.087\n",
            "Época: 47 Amostras:469248 de um total de 500000 (93.850%)\n",
            "Momento: [2023-Apr-18 20:35:08] lr: 1.09262e-07 Treino loss: 0.0081 Validação loss: 0.0868 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [05:39<00:00,  1.09s/it]\n",
            "Eval: 100%|██████████| 31/31 [00:07<00:00,  4.02it/s]\n",
            "Epochs:  96%|█████████▌| 48/50 [2:03:34<07:02, 211.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.087\n",
            "Época: 48 Amostras:479232 de um total de 500000 (95.846%)\n",
            "Momento: [2023-Apr-18 20:40:56] lr: 4.86597e-08 Treino loss: 0.0078 Validação loss: 0.0868 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [10:54<00:00,  2.10s/it]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.75it/s]\n",
            "Epochs:  98%|█████████▊| 49/50 [2:14:30<05:44, 344.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.087\n",
            "Época: 49 Amostras:489216 de um total de 500000 (97.843%)\n",
            "Momento: [2023-Apr-18 20:51:52] lr: 1.21797e-08 Treino loss: 0.0075 Validação loss: 0.0868 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n",
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.66it/s]\n",
            "Epochs: 100%|██████████| 50/50 [2:16:57<00:00, 164.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.087\n",
            "Época: 50 Amostras:499200 de um total de 500000 (99.840%)\n",
            "Momento: [2023-Apr-18 20:54:18] lr: 1.00000e-12 Treino loss: 0.0067 Validação loss: 0.0867 \n",
            "Tempo gasto total 8217.08914, steps: 50, tempo por step 164.34178\n",
            "Final: Step: 50 Amostras:499200  99.840%  Momento: [2023-Apr-18 20:54:18] lr:1.00000e-12 Train loss: 0.0067  Validação loss: 0.0867 \n",
            "Modelo com melhor resultado em validação (step 34) salvo após treino em /home/borela/fontes/deep_learning_em_buscas_unicamp/local/dpr_best_model_inicio_treino_2023-Apr-18 18:37:19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.087\n",
            " Resultado com dados de teste para modelo treinado: {'valid/loss': 0.08673091}\n",
            "Shutting down background jobs, please wait a moment...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Waiting for the remaining 53 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 53 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/marcusborela/IA386DD/e/IAD-81\n",
            "0 {'loss_validacao': 0.08673091, 'loss_treino': 0.0066537294, 'best_validation_loss': 0.079409346, 'best_epoca': 34}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  {'loss_validacao': 0.08673091,\n",
              "   'loss_treino': 0.0066537294,\n",
              "   'best_validation_loss': 0.079409346,\n",
              "   'best_epoca': 34})]"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treina_grid(hparam, gridparam, models, parm_se_gera_rastro = True, se_treina_poucos_dados=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH_MODELO_FINAL = \"/home/borela/fontes/deep_learning_em_buscas_unicamp/local/dpr/dpr_best_model_final\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model in models:\n",
        "    models[model].save_pretrained(f\"{PATH_MODELO_FINAL}_{model}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "512 30522\n"
          ]
        }
      ],
      "source": [
        "# Se tiver que treinar os modelos, abre\n",
        "models_final = {'query': AutoModel.from_pretrained(f\"{PATH_MODELO_FINAL}_query\").to(hparam['device']),\n",
        "'passage' : AutoModel.from_pretrained(f\"{PATH_MODELO_FINAL}_passage\").to(hparam['device'])}\n",
        "print(models_final['query'].config.max_position_embeddings, models_final['passage'].config.vocab_size)\n",
        "# 512 e 30522\n",
        "#models['query'].config.__dict__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_loaders = {\n",
        "     'passage': DataLoader(valid_dataset, batch_size=hparam['batch_size'], shuffle=False, \n",
        "                           drop_last=True, num_workers=hparam['num_workers_dataloader'],\n",
        "                           collate_fn=DPRCollator('passage', tokenizer)),\n",
        "     'query': DataLoader(valid_dataset, batch_size=hparam['batch_size'], shuffle=False, \n",
        "                           drop_last=True, num_workers=hparam['num_workers_dataloader'],\n",
        "                           collate_fn=DPRCollator('query', tokenizer))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 31/31 [00:01<00:00, 21.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss: 0.087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "validation_loss = validation_step(models_final, valid_loaders)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BmRLgbyi_Dvg",
        "0Upk7A-8Zdnd",
        "wew-gFbWeBTq"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "treinapython39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "e431eb1d856c426fade2a694f8536bd46c4e9c4bd47cb4afd3fb4d2c61122b03"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
